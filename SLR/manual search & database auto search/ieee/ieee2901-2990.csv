"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Try-Then-Eval: Equipping an LLM-based Agent with a Two-Phase Mechanism to Solve Computer Tasks","D. Cao; P. Nguyen; V. Le; L. Nguyen; V. Nguyen","Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Computer Science, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","1224","1229","Building an autonomous intelligent agent capable of carrying out web automation tasks from descriptions in natural language offers a wide range of applications, including software testing, virtual assistants, and task automation in general. However, recent studies addressing this problem often require manually constructing of prior human demonstrations. In this paper, we approach the problem by leveraging the idea of reinforcement learning (RL) with the two-phase mechanism to form an agent using LLMs for automating computer tasks without relying on human demonstrations. We evaluate our LLM-based agent using the MiniWob++ dataset of web-based application tasks, showing that our approach achieves 85% success rate without prior demonstrations. The results also demonstrate the agent's capability of self-improvement through training.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831260","","Training;Software testing;Automation;Virtual assistants;Supervised learning;Natural languages;Reinforcement learning;Planning;Intelligent agents;Cybernetics","","","","25","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Research on efficient inference of large language model based on routing policy","P. Shan; W. Xi; Y. Zhang; D. Liu","State Key Laboratory of High-end Heavy-Load Robots Midea Group Co., Ltd, FoShan, China; State Key Laboratory of High-end Heavy-Load Robots Midea Group Co., Ltd, FoShan, China; State Key Laboratory of High-end Heavy-Load Robots Midea Group Co., Ltd, FoShan, China; State Key Laboratory of High-end Heavy-Load Robots Midea Group Co., Ltd, FoShan, China","2025 IEEE 7th International Conference on Communications, Information System and Computer Engineering (CISCE)","10 Jul 2025","2025","","","1","7","To solve the problem of balancing high cost and high performance in large language model (LLMs) inference scenarios, an adaptive routing strategy (MA-Router) with multi-modal attention mechanism is proposed in this paper. By constructing a hierarchical data enhancement framework and a two-channel attention routing network, fine-grained perception of problem complexity and optimization of dynamic model selection are realized. Firstly, a data enhancement method based on syntax tree reconstruction and knowledge graph extension is designed to effectively alleviate the sparsity and domain bias of training data. Secondly, a semantic-grammatical dual-modal feature extraction module is proposed, which uses DeBERTa-v3 to encode semantic information and capture dependency syntactic structure with graph neural network (GNN). Furthermore, the cross-attention mechanism is introduced to integrate multi-modal features, and the model capability-problem complexity bipartite graph is constructed for relational reasoning. Finally, hierarchical reinforcement learning Agent dynamically adjusts the routing threshold to realize the environment adaptive decision optimization. In the three benchmark tests of MMLU, MT-Bench and GSM8K, compared with the optimal baseline model RouteLLM, MA-Router reduced the call rate of strong model (GPT-4) by 32.7% (CPT(80%) to 26.15%), and the inference cost was reduced by 2.8 times. At the same time, the response quality of 95.2% was maintained (APGR=0.682). Ablation experiments show that syntactic feature channels and reinforcement learning modules contribute 14.2% and 29.3% performance gains, respectively. This research provides an efficient and scalable solution for multi-model collaborative reasoning system, which shows significant application value in real-time scenarios such as customer service dialogue and code generation.","2833-2423","979-8-3315-0161-7","10.1109/CISCE65916.2025.11065479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065479","Large language model;Routing policy;Efficient reasoning;Data preprocessing;Attention mechanism;Agent collaborative model","Adaptation models;Attention mechanisms;Large language models;Data enhancement;Collaboration;Syntactics;Routing;Cognition;Data models;Optimization","","","","24","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"AI SoC Design Challenges in the Foundation Model Era","Z. Chen; D. Huang; M. Wang; B. Yang; J. L. Shin; C. Hu; B. Li; R. Prabhakar; G. Deng; Y. Sheng; S. Fu; L. Yuan; T. Zhao; Y. Du; C. Liu; J. Yang; V. Shah; V. Srinivasan; S. Jairath","SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA; SambaNova Systems, Palo Alto, CA",2023 IEEE Custom Integrated Circuits Conference (CICC),"11 May 2023","2023","","","1","8","Despite its unprecedented prevalence, a foundation model’s exponentially growing training cost, dataset sizes, and model capacity hinder the democratization of modern AI technology and require novel system design solutions. In this paper, we review state-of-the-art (SOTA) challenges and methodologies in scaling AI system-on-chip (SoC) design to harness the power of the foundation model. We organize our discussions four-fold. First, we discuss AI SoC architecture design to enable high-performance training for foundation models. Second, we discuss challenges in managing foundation model training with dataflow accelerators. We show that data flow accelerators, a class of promising architectures removing execution bottlenecks through overlapping computation and data fetching, pose new challenges for hardware resource mapping and allocation. Third, we discuss challenges for exploiting parallelism encompassing multiple dimensions, e.g., tensor, model, and data-level parallelism. Mapping models over tensor and model dimensions enables large model training at the cost of introducing distributed and orchestrated gradient synchronization. Last, we discuss electrical and energy design trade-offs for implementing massive computation and memory units capturing computation and data locality on a dataflow accelerator. The solution to all four aspects lies at the intersection of system-aware machine learning algorithms, dataflow-driven software systems, and scalable hardware design.","2152-3630","979-8-3503-9948-6","10.1109/CICC57935.2023.10121242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121242","","Training;Tensors;Costs;Computational modeling;Computer architecture;Parallel processing;Hardware","","1","","47","IEEE","11 May 2023","","","IEEE","IEEE Conferences"
"Artificial Intelligence in Action: Real-World Applications and Innovations","A. Banafa",NA,Artificial Intelligence in Action: Real-World Applications and Innovations,"","2025","","","i","xxx","This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly ""casual AI,"" and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.","","9788770046190","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948951.pdf&bkn=10948919&pdfType=chapter","","","","","","","","3 Apr 2025","","","River Publishers","River eBook Chapters"
"Integrating Sustainable Big AI: Quantum Anonymous Semantic Broadcast","S. Tariq; U. Khalid; B. E. Arfeto; T. Q. Duong; H. Shin","Kyung Hee University, Republic of Korea; Kyung Hee University, Republic of Korea; Kyung Hee University, Republic of Korea; Memorial University of Newfoundland, Canada; Kyung Hee University, Republic of Korea",IEEE Wireless Communications,"14 Jun 2024","2024","31","3","86","99","Semantic communication (SC) with native artificial intelligence (AI) is a context-centric framework that intelligently extracts task-specific semantics from source data and efficiently regenerates the intended meaning at the destination. Hence, this computing-intensive methodology enables goal-oriented communication by maintaining a high semantic quality of service with a low requirement for data transfer. Recently, the emergence of big-AI foundation models, such as the generative pre-trained transformer and diffusion models with zero-shot task generalization and native cross-modal learning capabilities, has brought a paradigm shift in designing AI-native frameworks for wireless networks. However, deploying big AI in wireless networks involves inherent challenges, such as large training parameters and computing requirements. To address these challenges, we use sustainability techniques, such as pruning and fine-tuning, to create sustainable (lightweight) models from big AI, which can reduce the resource consumption and environmental impact in computation-heavy SC systems while preserving or enhancing the task performance. Moreover, classical communication networks lack quantum-safe communication security and data privacy. In this article, we prototype a sustainable big AI-native quantum anonymous SC system. In this framework, we leverage big-AI models for semantic retrieval processing, that is, semantic extraction and recovery, and employ quantum anonymous communication protocols to broadcast semantics. We detail the underlying functionalities, sustainable practices, and potential challenges of integrating big AI into a quantum anonymous semantic broadcast system. We also formulate case studies demonstrating the sustainability and reliability of the envisioned framework. This work provides a sustainable and quantum-safe semantic communication framework by integrating big AI and quantum anonymous communication.","1558-0687","","10.1109/MWC.007.2300503","Korean government (MSIT)(grant numbers:NRF-2022R1A4A3033401,IITP-2024-RS-2023-00266615); Canada Excellence Research Chair (CERC)(grant numbers:CERC-2022-00109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558817","","Training;Adaptation models;Protocols;Computational modeling;Wireless networks;Semantics;Security;Context awareness;Broadcasting;Quantum communication;Artificial intelligence;Information retrieval","","7","","15","IEEE","14 Jun 2024","","","IEEE","IEEE Magazines"
"MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition","S. G. Fritsch; C. Oguz; V. F. Rey; L. Ray; M. Kiefer-Emmanouilidis; P. Lukowicz","Embedded Intelligence, DFKI, Kaiserslautern, Germany; Multilinguality and Language Technology, DFKI, Saarbrücken, Germany; Embedded Intelligence, DFKI, Kaiserslautern, Germany; Embedded Intelligence, DFKI, Kaiserslautern, Germany; Embedded Intelligence, DFKI, Kaiserslautern, Germany; Embedded Intelligence, DFKI, Kaiserslautern, Germany",2025 IEEE International Conference on Pervasive Computing and Communications (PerCom),"3 Jun 2025","2025","","","1","12","Human activity recognition (HAR) is a long-standing problem in artificial intelligence with applications in a broad range of areas, including healthcare, sports and fitness, security, and more. The performance of HAR in real-world settings is strongly dependent on the type and quality of the input signal that can be acquired. Given an unobstructed, high-quality camera view of a scene, computer vision systems, in particular in conjunction with foundation models, can today fairly reliably distinguish complex activities. On the other hand, recognition using modalities such as wearable sensors (which are often more broadly available, e.g., in mobile phones and smartwatches) is a more difficult problem, as the signals often contain less information and labeled training data is more difficult to acquire. To alleviate the need for labeled data, we introduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this work, which can be used with the proposed pre-training method MuJo (Multimodal Joint Feature Space Learning) to enhance HAR performance across various modalities. FiMAD was created using YouTube fitness videos and contains parallel video, language, pose, and simulated IMU sensor data. MuJo utilizes this dataset to learn a joint feature space for these modalities. We show that classifiers pre-trained on FiMAD can increase the performance on real HAR datasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on MM-Fit, we achieve a Macro F1-Score of up to 0.855 when fine-tuning on only 2% of the training data and 0.942 when utilizing the complete training set for classification tasks. We compare our approach with other self-supervised ones and show that, unlike them, ours consistently improves compared to the baseline network performance while also providing better data efficiency.","2474-249X","979-8-3315-3551-3","10.1109/PerCom64205.2025.00020","Ministry of Education; Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018705","multimodal representation learning;human activity recognition;multimodal fitness dataset","Training;Representation learning;Video on demand;Training data;Human activity recognition;Web sites;Security;Wearable sensors;Videos;Sports","","1","","52","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Coughprint: Distilled Cough Representations From Speech Foundation Model Embeddings","B. Laska; P. Xi; J. J. Valdés; B. Wallace; J. Green; R. Goubran; F. Knoefel","Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; National Research Council Canada, Ottawa, ON, Canada; National Research Council Canada, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada",IEEE Transactions on Instrumentation and Measurement,"11 Jun 2025","2025","74","","1","10","Supportive smart home systems with integrated sensors capable of measuring cough frequency and severity can support independent living and aging in place by helping monitor the state of acute and chronic health conditions. Previously, we showed that embeddings from speech foundation models are effective cough representations for a range of cough measurement applications. While powerful, the large compute and memory requirements of these models prevents them from being deployed in embedded smart sensors. In this work, we use knowledge distillation to train edge-compute focused student models, making them feasible for the measurement, identification, and classification of cough sounds directly in the smart home. This embedded processing avoids the privacy and security concerns associated with transmission and storage of sensitive audio recordings in the cloud. We show that the student networks preserve the universal cough representation capabilities of the teacher, even generalizing to unseen classes such as speech, allowing the same network to be used for multiple downstream applications without any task-specific fine-tuning. A student network based on a 14-layer variant of ResNet achieved the highest aggregate quality score across the downstream evaluation tasks, even outperforming the foundation model teacher on certain tasks despite having over  $200\mathbf {\times }$  fewer parameters. Linear classification on the embeddings from the proposed student network achieves strong performance on a diverse set of cough measurement tasks, scoring 98.3% on cough/noncough discrimination, 90.3% on human sound classification, 94.8% on cougher verification, 84.4% on cougher identification, and 87.8% on wet/dry cough classification.","1557-9662","","10.1109/TIM.2025.3568985","National Research Council Canada through the Aging in Place Challenge Program(grant numbers:AiP-006-1); Accessibility Standards Canada/the Government of Canada.; Bruyère Health Research Institute Chair in Research in Technology for Aging in Place; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024165","Aging in place;cough analysis;knowledge distillation;representation learning;smart home;speech foundation model","Foundation models;Monitoring;Representation learning;Speech recognition;Frequency measurement;Aging;Smart homes;Intelligent sensors;Training;Computational modeling","","","","50","Crown","6 Jun 2025","","","IEEE","IEEE Journals"
"Assessing Your Current State AI Ethics and Data Privacy","L. Pierson",Data-Mania,Data & AI Imperative: Designing Strategies for Exponential Growth,"","2024","","","215","234","<p>With respect to data projects and product development, one of the most often overlooked areas is that of artificial intelligence (AI) ethics and data privacy. Data‐first companies need to pay extra attention to current state provisions for data privacy and security. This requires the readers, the data strategist, to conduct a thorough assessment and identify gaps that need to be addressed immediately. The absence of roles like AI ethics officers or data stewards might indicate a lack of responsibility for ethical AI implementation. In reality, designing AI systems becomes vastly more complicated when we're working to address ethics and privacy issues that are inherent to building with foundation models. Model explainability is one of the hottest topics in the space. Developers are likely to argue that compliance is an unnecessary hindrance to progress.</p>","","9781394251971","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10982339.pdf&bkn=10964416&pdfType=chapter","","Law;Artificial intelligence;Data privacy;Ethics;Regulation;Companies;Reviews;Security;Interviews;Stakeholders","","","","","","2 May 2025","","","Wiley","Wiley AI eBook Chapters"
"ROK Defense M&S in the Age of Hyperscale AI: Concepts, Challenges, and Future Directions","Y. Lee; T. Park; Y. Kang; J. Kim; J. Kang","KAIST, South Korea; Center for Military Analysis and Planning, KIDA, South Korea; Center for Military Analysis and Planning, KIDA, South Korea; Center for Military Analysis and Planning, KIDA, South Korea; KAIST, South Korea",IEEE Internet of Things Magazine,"27 Feb 2025","2025","8","2","32","38","Integrating hyperscale AI into national defense M&S (Modeling and Simulation), under the expanding IoMDT (Internet of Military Defense Things) framework, is crucial for boosting strategic and operational readiness. We examine how IoMDT-driven hyperscale AI can provide high accuracy, speed, and the ability to simulate complex, interconnected battlefield scenarios in defense M&S. Countries like the United States and China are leading the adoption of these technologies, with varying levels of success. However, realizing the full potential of hyperscale AI requires overcoming challenges such as closed networks, sparse or “long-tail” data, complex decision-making processes, and a shortage of experts. Future directions highlight the need to adopt domestic foundation models, expand GPU/NPU investments, leverage large tech services, and employ open source solutions. These efforts will enhance national security, maintain a competitive edge, and spur broader technological and economic growth. With this blueprint, the Republic of Korea can strengthen its defense posture and stay ahead of emerging threats in modern warfare.","2576-3199","","10.1109/IOTM.001.2400157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10907847","","Economics;Heavily-tailed distribution;Foundation models;Decision making;Internet of Things;National security;Research and development;Open source software;Investment;Defense industry;Artificial intelligence;Modeling;Simulation","","","","12","IEEE","27 Feb 2025","","","IEEE","IEEE Magazines"
"Foundation Model-Based Federated Learning for Intrusion Detection in Drone-Aided Industrial IoT","S. Jiao; J. Wang; Z. Tong; Z. Wang; L. Tan; X. Zhang; K. I. Kostromitin","School of Cyber Science and Technology, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; School of Electronic Information Engineering, Beihang University, Beijing, China; Shandong Computer Science Center, Qilu University of Technology, Jinan, China; School of Cyber Science and Technology, Beihang University, Beijing, China; Department of Physics of Nanoscale Systems, South Ural State University, Chelyabinsk, Russian",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Drone networks are becoming increasingly significant in industrial Internet of Things (IIoT) applications. The limited resources of drones pose challenges in implementing robust security mechanisms that require substantial computation and power resources. Specifically, the inherent complexity of drone networks makes traditional intrusion detection systems (IDS) ineffective due to data imbalance and data scarcity. To address these challenges, this paper proposes a novel IDS framework that integrates conditional generative adversarial networks (CGANs) and utilizes the benefits from the systematic integration of foundation models within a federated learning (FL) paradigm. It leverages the CGANs to address the data issues ensures reliable performance and stable convergence against the foundation model. Moreover, our approach enhances data privacy relying on the differential privacy in FL and protects global model integrity through secure aggregation and updating. Simulation results show that the proposed framework achieve the accuracy rates of 91% and 99% on cyber and physical datasets, respectively. This framework achieves improvement ranging from 0.47% to 3.24% for cyber datasets and from 0.93% to 4.84% for physical datasets, which yields its superior performance in drone networks intrusion detection.","2327-4662","","10.1109/JIOT.2025.3597349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121664","Drone networks;industrial Internet of Things (IIoT);intrusion detection system (IDS);federated learning (FL);foundation model","Drones;Data models;Accuracy;Industrial Internet of Things;Training;Foundation models;Adaptation models;Intrusion detection;Computational modeling;Sampling methods","","","","","IEEE","11 Aug 2025","","","IEEE","IEEE Early Access Articles"
"RBAC-SC: Role-Based Access Control Using Smart Contract","J. P. Cruz; Y. Kaji; N. Yanai","Graduate School of Information Science and Technology, Osaka University, Suita, Japan; Information Strategy Office, Nagoya University, Nagoya, Japan; Graduate School of Information Science and Technology, Osaka University, Suita, Japan",IEEE Access,"19 Mar 2018","2018","6","","12240","12251","The role-based access control (RBAC) framework is a mechanism that describes the access control principle. As a common interaction, an organization provides a service to a user who owns a certain role that was issued by a different organization. Such trans-organizational RBAC is common in face-toface communication but not in a computer network, because it is difficult to establish both the security that prohibits the malicious impersonation of roles and the flexibility that allows small organizations to participate and users to fully control their own roles. In this paper, we present an RBAC using smart contract (RBAC-SC), a platform that makes use of Ethereum's smart contract technology to realize a trans organizational utilization of roles. Ethereum is an open blockchain platform that is designed to be secure, adaptable, and flexible. It pioneered smart contracts, which are decentralized applications that serve as “autonomous agents”running exactly as programmed and are deployed on a blockchain. The RBAC-SC uses smart contracts and blockchain technology as versatile infrastructures to represent the trust and endorsement relationship that are essential in the RBAC and to realize a challenge-response authentication protocol that verifies a user's ownership of roles. We describe the RBAC-SC framework, which is composed of two main parts, namely, the smart contract and the challenge-response protocol, and present a performance analysis. A prototype of the smart contract is created and deployed on Ethereum's Testnet blockchain, and the source code is publicly available.","2169-3536","","10.1109/ACCESS.2018.2812844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307397","Blockchain technology;role-based access control;smart contracts","Organizations;Contracts;Access control;Protocols;Standards organizations;Computer networks","","253","","30","OAPA","7 Mar 2018","","","IEEE","IEEE Journals"
"Automatic Assisstance System Based on Machine Learning for Effective Crowd Management","D. Saxena; S. Kumar; P. K. Tyagi; A. Singh; B. Pant; V. H. Reddy Dornadula","Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, United States; Computer Science Department, Lucknow Public College of Professional Studies; Chandigarh University, Mohali, India; Department of Computer_Science & Engineering, Kamala Nehru Institute of Technology, Sultanpur, Uttar Pradesh, India; Computer Science & Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; IT &ITES Department, Startups Mentoring Society, Tirupati, Andhra Pradesh, India",2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),"18 Jul 2022","2022","","","01","06","So here we are going to study about the machine learning and automatic assistance system in machine leering which help in the effective crowd management Machine learning (ML) is a form of artificial intelligence (AI) that enables software programmers to increase prediction accuracy without being specifically intended to do so. Machine learning techniques use previous data as input to anticipate new output values. Because data is so important, developing improved methods for intelligently managing the now-ubiquitous crowd-powered data-gathering systems is a critical next step toward totally autonomous agents. So here we will discuss about the machine learning and its automatic assistance system in crowd management. Learning for use in a variety of sectors is becoming more common as the availability of data expands over time. Computer vision and computer vision have improved a wide range of industries, including medical diagnoses, data display and procedures, science and research, and so on. Such approaches have already been used in the fields of Smartphone apps, computer equipment, online websites, and cyber security. So here we have reached a conclusion about the automatic assistance system based on machine learning for effective cored management.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823877","machine learning;automatic assistance;crowd management;Data Acquisition;Data processing;Algorithm;Data Management;Interpretation;statistics;probabilities;data wrangling;imputation;supervised learning;classification;regression;clustering","Industries;Computer science;Computer vision;Machine learning;Production;Software;Autonomous agents","","4","","20","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Ontology-Based Emotional Decision-Making in Self-Evolving Defensive Agents","R. R. Prasad; C. Thomas","Department of Information Technology, Government Engineering College Barton Hill, Thiruvananthapuram, Kerala, India; Directorate of Technical Education, Government of Kerala, Thiruvananthapuram, Kerala, India",IEEE Access,"18 Oct 2022","2022","10","","108749","108759","Responding instantaneously in an unprecedented situation is inevitable to mitigate zero day attacks in the cyber world. This situation has strong resemblance with the fight for survival in biological world. Both being complex systems, the biological world and the cyber world have structural similarities. Emotions are the key factor used by biological beings to take intuitive decisions, which are key to survival in the natural world. Inspired from the idea of emotional decision making in natural world and the structural similarity shown by biological and cyber worlds, this paper proposes an ontological mechanism to implement artificial emotion-based decision making for autonomous agents in cyber security scenario. Emotions are modelled as manifestation of the goals of agents. Stimuli and response are connected through emotions using the ontological structure. The mechanism is proven useful in eliciting appropriate response for the stimuli using ontological reasoning through SPARQL queries.","2169-3536","","10.1109/ACCESS.2022.3213659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915583","Artificial emotion;complex systems;self-evolving systems;emotional decisions;ontology","Decision making;Complex systems;Decision making;Computer crime;Cognition;Solid modeling;Biological system modeling;Artificial Intelligence;Emotion recognition;Ontologies","","","","58","CCBY","10 Oct 2022","","","IEEE","IEEE Journals"
"Credit Card Fraud Detection Using Advanced Transformer Model","C. Yu; Y. Xu; J. Cao; Y. Zhang; Y. Jin; M. Zhu","Northeastern University, Boston, MA, USA; Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Johns Hopkins University, Baltimore, MD, USA; University of Pittsburgh, Pittsburgh, PA, USA; University of Michigan, Ann Arbor, Ann Arbor, MI, USA; Miami University, Oxford, OH, USA","2024 IEEE International Conference on Metaverse Computing, Networking, and Applications (MetaCom)","6 Nov 2024","2024","","","343","350","With the proliferation of various online and mobile payment systems, credit card fraud has emerged as a significant threat to financial security. This study focuses on innovative applications of the latest Transformer models for more robust and precise fraud detection. To ensure the reliability of the data, we meticulously processed the data sources, balancing the dataset to address the issue of data sparsity significantly. We also selected highly correlated vectors to strengthen the training process. To guarantee the reliability and practicality of the new Transformer model, we conducted performance comparisons with several widely adopted models, including Support Vector Machine (SVM), Random Forest, Neural Network, Logistic Regression, XGBoost, and TabNet. We rigorously compared these models using metrics such as Precision, Recall, F1 Score, and ROC AUC. Through these detailed analyses and comparisons, we present to the readers a highly efficient and powerful anti-fraud mechanism with promising prospects. The results demonstrate that the Transformer model not only excels in traditional applications but also shows great potential in niche areas like fraud detection, offering a substantial advancement in the field.","","979-8-3315-1599-7","10.1109/MetaCom62920.2024.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740150","Credit card Fraud Detection;Transformer;pre-processing;Precision;Recall;F1-Score","Measurement;Support vector machines;Adaptation models;Accuracy;Neural networks;Transformers;Credit cards;Fraud;Security;Reliability","","20","","61","IEEE","6 Nov 2024","","","IEEE","IEEE Conferences"
"A Systematic Literature Review on AI-Based Recommendation Systems and Their Ethical Considerations","E. Masciari; A. Umair; M. H. Ullah","Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy",IEEE Access,"9 Sep 2024","2024","12","","121223","121241","With the rise of social media, individuals face challenges in decision-making due to the abundance of options available. Recommender Systems (RSs) leverage Artificial Intelligence (AI) to provide users with personalized suggestions aligned with their preferences and interests. This study presents a systematic review of AI-based Recommender Systems, focusing on recent advancements and primary studies published between 2019 and 2024. While several review papers have addressed various aspects of RSs, the rapid evolution of AI techniques necessitates an updated review to capture the latest trends and innovations. We systematically gathered data from five major databases: IEEE, Springer, Science Direct, ACM, and Wiley. Through the PRISMA methodology, we selected 85 relevant studies. Our analysis addresses several key research questions: the types of datasets and data sources used, major application fields, prevalent machine learning and AI techniques, overall research productivity, and the limitations and future trends in AI-based RSs. Our findings indicate that advanced AI techniques, particularly those incorporating deep learning with multiple hidden layers and transformer models like BERT, significantly enhance the accuracy and effectiveness of Recommender Systems. Furthermore, we observed a trend towards integrating contextual and real-time data to improve recommendation relevance. Additionally, we discuss ethical considerations such as privacy, data security, bias, and transparency, emphasizing the need for responsible AI development to ensure fair and equitable recommendations. These insights can guide future research and development efforts in the field.","2169-3536","","10.1109/ACCESS.2024.3451054","Piano Nazionale di Ripresa e Resilienza (PNRR) Project, Future Artificial Intelligence Research (FAIR), Resilient AI-SPOKE 3; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654261","Artificial intelligence;recommender systems;systematic literature review;ethical considering of RS","Recommender systems;Databases;Artificial intelligence;Data mining;Ethics;Systematics;Soft sensors;Systematic literature review","","15","","122","CCBY","28 Aug 2024","","","IEEE","IEEE Journals"
"CycleGAN-Based Data Augmentation with CNN and Vision Transformers (ViT) Models for Improved Maize Leaf Disease Classification","S. T. Yeasin Ramadan; T. Sakib; M. A. Rahat; S. Mosharrof","Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Department of Computer Science and Engineering, Military Institute of Science and Technology (MIST), Dhaka, Bangladesh",2023 IEEE 64th International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS),"17 Nov 2023","2023","","","1","6","Crop losses pose a serious danger to global food security, and this problem also affects maize crops. To successfully address this issue, precise disease detection techniques are required. However, a major hurdle to developing reliable models to address this issue is the dearth of datasets. In re-sponse, we present a novel approach that uses synthetic images created by CycleGAN to supplement constrained datasets. We thoroughly assessed deep learning models, such as ResNet50V2, DenseNet169, VGG16, VGG19, Xception, MobileNetV2, and emerging vision transformer models, such as ViT-B/16 and ViT-B/32, with a focus on the two critical classes of maize leaf diseases, blight and common rust. Notably, DenseNet169 performed better than other models with an accuracy of 98.48%, especially when trained on the CycleGAN -enhanced dataset. CycleGAN-augmented data outperformed the performance of the models trained solely on the original dataset, demonstrating the effectiveness of the augmentation approach in performance enhancement. By utilizing CycleGAN's synthetic images, this study expands the field of maize leaf disease diagnosis and establishes DenseNet169 as a viable model for precise disease identification. The findings of the study have the potential to significantly revolutionize agricultural operations using advanced maize disease detection techniques.","2771-6937","979-8-3503-7029-4","10.1109/ITMS59786.2023.10317666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317666","maize crops;disease detection techniques;syn-thetic images;augmentation;CycleGAN;deep learning models;vision transformers;accuracy","Deep learning;Crops;Food security;Transformers;Data augmentation;Data models;Reliability","","7","","15","IEEE","17 Nov 2023","","","IEEE","IEEE Conferences"
"CNN vs Transformer Variants: Malware Classification Using Binary Malware Images","M. M. Rahman; A. Ahmed; M. H. Khan; M. R. H. Mahin; F. B. Kibria; D. Z. Karim; M. Kaykobad","School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh; School of Data and Sciences, Brac University, Dhaka, Bangladesh","2023 IEEE International Conference on Communication, Networks and Satellite (COMNETSAT)","7 Feb 2024","2023","","","308","315","Malware classification is essential because their varieties can be characterized and labeled to provide information about their risks, how they enter our systems in the first place, and the precautions that need to be taken to prevent them. Numerous highly successful studies have been carried out on binary malware picture datasets utilizing models based on Convolutional Neural Networks in order to address this grave security-related problem. Common examples of such well-known models include ResNet-50, Inception-V3, VGG-16, DenseNet-201, etc. However, these models have very high parameters, giving them long run times. In order to address this issue and introduce novelty, we provide our own CNN-based approach that exhibits a noteworthy reduction in parameters, as low as 2.1 million while maintaining an excellent accuracy rate of 99.44% on the Malimg dataset. Furthermore, we include a range of Transformer models in our analysis due to the limited availability of literature on their application regarding binary malware image datasets. These highly developed models used for comparison on the binary malware image dataset called Malimg include Vision Transformer (ViT), Compact Convolutional Transformer (CCT), and External Attention Network (EANet). Finally, we use an explainable AI method called LIME to illustrate our suggested model’s sample selection and classification process to better understand the prediction process of our model.","","979-8-3503-4110-2","10.1109/COMNETSAT59769.2023.10420585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420585","Malware Image Classification;Deep Learning;Convolutional Neural Network (CNN);Transformer;Explainable AI (XAI)","Satellites;Explainable AI;Neural networks;Predictive models;Transformers;Malware;Convolutional neural networks","","5","","27","IEEE","7 Feb 2024","","","IEEE","IEEE Conferences"
"ML-FEED: Machine Learning Framework for Efficient Exploit Detection","T. Saha; T. Al Rahat; N. Aaraj; Y. Tian; N. K. Jha","Electrical and Computer Engineering, Princeton University, NJ, USA; Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Cryptography Research Center Technology Innovation Institute, Abu Dhabi, UAE; Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Electrical and Computer Engineering, Princeton University, NJ, USA","2022 IEEE 4th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)","15 Mar 2023","2022","","","140","149","Machine learning (ML)-based methods have recently become attractive for detecting security vulnerability exploits. Unfortunately, state-of-the-art ML models like long short-term memories (LSTMs) and transformers incur significant computation overheads. This overhead makes it infeasible to deploy them in real-time environments. We propose a novel ML-based exploit detection model, ML-FEED, that enables highly efficient inference without sacrificing performance. We develop a novel automated technique to extract vulnerability patterns from the Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE) databases. This feature enables ML-FEED to be aware of the latest cyber weaknesses. Second, it is not based on the traditional approach of classifying sequences of application programming interface (API) calls into exploit categories. Such traditional methods that process entire sequences incur huge computational overheads. Instead, ML-FEED operates at a finer granularity and predicts the exploits triggered by every API call of the program trace. Then, it uses a state table to update the states of these potential exploits and track the progress of potential exploit chains. ML-FEED also employs a feature engineering approach that uses natural language processing-based word embeddings, frequency vectors, and one-hot encoding to detect semantically-similar instruction calls. Then, it updates the states of the predicted exploit categories and triggers an alarm when a vulnerability fingerprint executes. Our experiments show that ML-FEED is 72.9× and 75, 828.9× faster than state-of-the-art lightweight LSTM and transformer models, respectively. We trained and tested ML-FEED on 79 real-world exploit categories. It predicts categories of exploit in real-time with 98.2% precision, 97.4% recall, and 97.8% F1 score. These results also outperform the LSTM and transformer baselines. In addition, we evaluated ML-FEED on the attack traces of CVE vulnerability exploits in three popular Java libraries and detected all three reported critical vulnerabilities in them.","","978-1-6654-7408-5","10.1109/TPS-ISA56441.2022.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063446","Machine Learning;Exploit detection","Privacy;Databases;Computational modeling;Natural languages;Machine learning;Transformers;Feature extraction","","3","","22","IEEE","15 Mar 2023","","","IEEE","IEEE Conferences"
"Deep Learning-Based Cyber Attack Detection in Power Grids with Increasing Renewable Energy Penetration","M. A. S. P. Dayarathne; M. S. M. Jayathilaka; R. M. V. A. Bandara; V. Logeeshan; S. Kumarawadu; C. Wanigasekara","Department of Electrical Engineering, University of Moratuwa Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa Moratuwa, Sri Lanka; Institute for the Protection of Maritime Infrastructures German Aerospace center Bremerhaven, Germany",2024 IEEE World AI IoT Congress (AIIoT),"10 Jul 2024","2024","","","521","526","As renewable energy sources are integrated into power grids worldwide, the vulnerability to cyber-attacks increases, necessitating robust detection mechanisms to ensure system integrity and stability. In this paper, we propose a novel approach for cyber-attack detection in power grids, specifically based on the conditions of the Sri Lankan power system. Using the concept of wide area network monitoring and utilizing Ceylon Electricity Board generation data, as well as a PSCAD model representing real-time solar farms, synthetic datasets resembling actual demand-supply curves are generated. By analyzing well-known cyber-attack methodologies such as fault data injection, replay attacks, man-in-the-middle, and spoofing, we create attack datasets. Subsequently, we train neural network models including Convolutional Neural Networks (CNNs), Transformer models, and Long Short-Term Memory (LSTM) networks. Through comprehensive comparative analysis of model effectiveness using various parameters, our objective is to swiftly identify cyber-attacks as they occur within the system. The proposed methodology aims to address two primary objectives of cyber-attacks on power grids: energy theft and destabilization. By preemptively detecting and mitigating such attacks, the integrity and stability of the power grid can be safeguarded effectively. Our research contributes to the advancement of cyber-security measures in power systems, particularly in regions experiencing increased penetration of renewable energy sources like Sri Lanka.","","979-8-3503-8780-3","10.1109/AIIoT61789.2024.10578979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578979","Deep learning;Cyber-attack detection;Renewable energy penetration;Convolutional Neural Networks (CNNs);Energy theft prevention;Cybersecurity","Wide area networks;Renewable energy sources;Neural networks;Power system stability;Transformers;Power grids;Stability analysis","","3","","12","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"Enhancing Mango Leaf Disease Classification: ViT, BiT, and CNN-Based Models Evaluated on CycleGAN-Augmented Data","S. T. Yeasin Ramadan; T. Sakib; M. Ahsan Rahat; S. Mosharrof; F. I. Rakin; R. Jahangir","Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Military Institute of Science and Technology (MIST), Dhaka, Bangladesh; Bangladesh University of Engineering and Technology (BUET), Dhaka, Bangladesh; Military Institute of Science and Technology (MIST), Dhaka, Bangladesh",2023 26th International Conference on Computer and Information Technology (ICCIT),"27 Feb 2024","2023","","","1","6","Mango farming, crucial to agriculture in Bangladesh, faces severe threats from leaf diseases, notably anthracnose and powdery mildew. For diseases to be effectively managed, it must be accurately identified. This work uses a novel approach called CycleGAN-generated data augmentation to classify these diseases. Exceptional results were achieved using various models, including ViT-B/16, ViT-B/32, BiT-M-R50x1, BiT-s-R50x1, VGG16, ResNet152, ResNet50, InceptionV3, and ResNet50V2, although only ViT-B/16, ViT-B/32, and BiT-M-R50x1 reached 100% accuracy. This represents a significant development in the detection of mango leaf diseases and demonstrates CycleGAN’s potential to improve model performance. The acclaimed image classification Vision Transformer models ViT-B/16 and ViT-B/32 performed exceptionally well at differentiating between healthy and damaged leaves. This performance was echoed by the adaptable BiT-M-R50x1 model, demonstrating the potency of our strategy. These findings hold great promise for Bangladesh’s agriculture, potentially revolutionizing mango leaf disease management, and addressing a significant concern for the nation’s mango industry. Future research may expand this methodology to encompass more mango leaf diseases, further enhancing its relevance. This study underscores the transformative potential of advanced deep learning techniques in safeguarding agricultural yields and ensuring food security in mango-producing regions of Bangladesh.","","979-8-3503-5901-5","10.1109/ICCIT60459.2023.10441374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441374","disease identification;CycleGAN;data augmentation;deep learning;image classification;vision transformer;mango leaf disease","Adaptation models;Transformers;Agriculture;Information technology;Diseases;Residual neural networks;Image classification","","3","","16","IEEE","27 Feb 2024","","","IEEE","IEEE Conferences"
"Efficient anomaly intrusion detection using Transformer based GAN network","J. Feng; C. Wang; H. Xue; L. Zhang","Department of Computer Technology, and Applications, Qinghai University, Xining, China; Department of Computer Technology, and Applications, Qinghai University, Xining, China; HUANGHE HYDROPOWER DEVELOPMENT CO., LTD, Xining, China; Department of Computer Technology, and Applications, Qinghai University, Xining, China",2024 IEEE 7th International Electrical and Energy Conference (CIEEC),"15 Jul 2024","2024","","","3876","3881","With the rapid development of power grid terminals technology and the continuous increase in threats of network attacks, network anomaly intrusion detection for power grid terminals has become more complicated and crucial. However, due to the large number of network protocol fields and diverse network behaviors, existing methods still face challenges. Therefore, this text proposed a network anomaly intrusion detection method based on TransGAN, which combines the ideas of generative adversarial networks and Transformer models, to learn the correlation between different types of network intrusion behaviors and capture the dependency relationship of the network data. Besides, XGBoost was utilized for feature extraction to reduce computational cost without compromising detection performance. The experimental results show that the proposed anomaly detection method achieved an accuracy of 84.64% on NSL-KDD, while reducing the computational cost of training and testing by 9% and 6% respectively. It makes a valuable contribution to the research and practice of network security in the field of power grid terminals.","","979-8-3503-5955-8","10.1109/CIEEC60922.2024.10583331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10583331","anomaly detection;GAN;Transformer;Xgboost","Training;Accuracy;Intrusion detection;Training data;Transformers;Generative adversarial networks;NSL-KDD","","2","","16","IEEE","15 Jul 2024","","","IEEE","IEEE Conferences"
"CropViT: A light-weight Transformer Model for Crop Disease Detection","G. Chemmalar Selvi; H. J. Charan; D. Kumar","School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, India; School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, India; School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, India",2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT),"2 Jul 2024","2024","","","1","6","Agricultural industry has grown significantly bring sustainable farming practices in improving the food quality, enhancing agricultural productivity and global food security. However, the crop yield and its quality are impacted when the timely identification and management of the crop diseases are not promptly solved. Thus, the crop disease detection becomes the critical aspect in the smart agriculture. Several researchers addressed this crop disease detection by developing optimized solutions through machine learning, deep learning and image processing techniques. However, these techniques face serious challenges when deployed in real-time crop disease identification problems like annotated training images, capturing long-range dependencies, adaption to real-time changes evolving over time and so on. This leads to performance degradation seeking for more powerful applications like some advanced deep learning techniques, in particular, the transformer models. In this paper, a novel crop disease detection model known as CropViT was proposed based on Vision Transformer. This CropViT was developed by fine-tuning the architecture of existing Vision Transformer and PlantVillage dataset was used in the experimental study. Nine crop species were selected and trained using CropViT whose performance was then compared with traditional Convolutional Neural Network model. The experimental study clearly showed the highest mean accuracy of 98.64% for CropViT when compared to 95.52% mean accuracy for traditional CNN. The experimental results also outperformed other existing state-of-the-art models. Finally, the work was concluded with the discussion of experimental results and its future scope of work.","","979-8-3503-7212-0","10.1109/AIIoT58432.2024.10574729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10574729","Convolutional Neural Network;Deep Learning;Model Fine-tuning;plant disease detection;Transformer architecture;Vision Transformer","Deep learning;Adaptation models;Accuracy;Crops;Food security;Transformers;Real-time systems","","1","","27","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"TRACK-GAME: Transformer-Assisted Malicious Financial Transaction Detection Framework for Meta Gaming Platform","L. Pathak; K. Shah; H. Shalin Panchal; N. Kumar Jadav; S. Tanwar; N. Yamsani","Department of Comp. Sci. & Engg, Nirma University, Ahmedabad, India; Department of Comp. Sci. & Engg, Nirma University, Ahmedabad, India; Department of Comp. Sci. & Engg, Nirma University, Ahmedabad, India; Department of Comp. Sci. & Engg, Nirma University, Ahmedabad, India; Department of Comp. Sci. & Engg, Nirma University, Ahmedabad, India; Department of CS & AI, SR University, Warangal, Telangana",2024 2nd World Conference on Communication & Computing (WCONF),"4 Oct 2024","2024","","","1","6","The emergence of artificial intelligence (AI) and machine learning, along with the onset of various technological advancements in the world, has been influential. These rapid advancements have allowed people to interact on different plat-forms. One such domain is the gaming sector. This development is associated with and transformed into multiplayer online gaming systems in the Metaverse virtual platform. Metaverse has proved to be a plausible tool for leveraging digital connectivity all over the world and making communication easier with other players across the globe. In the Metaverse gaming platform, players try to buy weapons to gain the advantage of the hidden features and to win against their opponents. During the transactions, the attackers take undue advantage of low-end security, and the player's sensitive information is captured and used for their own benefit. To address the aforementioned issue, this research article harnessed the power of the transformer model, i.e., the ALBERT model. The ALBERT model helped analyze large volumes of transactional data in Metaverse ecosystems using its memory utilization features and offering stability. The model succeeded in identifying fraudulent transactions with an accuracy of 98.45 % and a precision rate of 97.34 %. The results demonstrated the effectiveness of the proposed framework over the state-of-the-art model frameworks. Therefore, the integration of transformer models significantly enhances the Metaverse gaming platform.","","979-8-3503-9532-7","10.1109/WCONF61366.2024.10692026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10692026","Metaverse;gaming platform;transformers;AL-BERT;fake transaction;artificial intelligence;deep learning;cybersecurity","Training;Accuracy;Metaverse;Computational modeling;Weapons;Transformers;Stability analysis;Robustness;Security;Random forests","","1","","12","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
"Advancing intrusion detection with ML and deep learning: a comparative approach","M. Shahid; S. Y. Arafat; F. Tariq","Department of CSIT, Mirpur University of Science and Technology, Mirpur, Azad Jammu and Kashmir (AJK), Pakistan; Department of CSIT, Mirpur University of Science and Technology, Mirpur, Azad Jammu and Kashmir (AJK), Pakistan; Department of Training, Fauji Foundation, Head office, Rawalpindi, Pakistan","International Conference on Energy, Power, Environment, Control and Computing (ICEPECC 2025)","18 Apr 2025","2025","2025","","603","610","In network security, Intrusion Detection Systems (IDS) is increasingly important due to rise in cyber-attacks. To ensure accurate detection and prevention, IDS leverages Machine Learning (ML) and Deep Learning (DL) algorithms on benchmark datasets; CICIDS2017 and NSL-KDD. These datasets, with diverse attack types, are ideal for training and testing. Traditional IDS struggle to detect zero-day attacks due to lack of predefined signatures, leading to higher false positive rates and vulnerabilities. Our proposed methodology focuses on a DL-based NIDS. We pre-process and normalize data from CICIDS2017, NSL-KDD, and a custom home network dataset. Supervised ML models, including Random Forest, Decision Tree, and Gaussian Naive Bayes, were applied to CICIDS 2017, achieving high accuracy. For DL, BiLSTM and Transformer models were trained on NSL-KDD for 30–60 epochs, with accuracy rates of 87%–99%. We utilized dual approach of normalization technique using Log Transformation and enhanced the Log Transformation by adding weightage to the features and retrained the model LSTM-CNN on NSL-KDD. Additionally, an LSTM-CNN model was applied to the Home Network dataset, the accuracy result of H-N Version1 was 100%.","","978-1-83724-315-0","10.1049/icp.2025.1171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969694","","","","","","","","18 Apr 2025","","","IET","IET Conferences"
"Plant Disease Detection Using an Innovative Swin-Axial Transformer","A. Zhang; W. Liu","School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China; School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China",IEEE Access,"3 Jul 2025","2025","13","","111938","111952","Plant diseases are a significant threat to global agricultural production, and accurate and efficient disease detection is crucial for ensuring food security. With the rapid development of deep learning technology, Transformer architectures have demonstrated strong global feature extraction capabilities in image classification and detection tasks. However, traditional Transformer models still face high computational costs and large parameter volumes when handling multi-scale diseases and complex backgrounds. To address this challenge, this paper proposes the Swin-Axial Transformer model based on the Swin Transformer. By introducing the TokenEmbedder module, the number of tokens is reduced, and multi-scale deep convolution is used to efficiently extract image features, significantly lowering computational costs. Furthermore, the Axial Transformer module reduces computational complexity by restricting self-attention calculations to local regions along the axial direction. With the combination of the Axial Compression module and the Detail Enhancement module, the model can efficiently extract global semantic features and effectively supplement local detail information. Compared to traditional global self-attention mechanisms, the Axial Transformer successfully avoids computational bottlenecks through axial compression strategies. Experimental results show that the model achieves a precision of 79.52% on the PlantDoc dataset, 99.79% on the PlantVillage dataset, and 95.69% on a self-constructed fusion dataset. The model’s parameter size is 14.87 M with a computational load of 2.96 GMac, which represents a reduction of 46% and 32%, respectively, compared to the Swin Transformer-T model, significantly improving computational efficiency. The model presented in this paper provides an efficient and reliable solution for large-scale crop disease detection.","2169-3536","","10.1109/ACCESS.2025.3578486","Fundamental Scientific Research Project of Liaoning Provincial Department of Education(grant numbers:JYTMS20230189); Research Support Plan for Introducing High-Level Talents to Shenyang Ligong University(grant numbers:1010147001131); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029237","Plant disease detection;deep learning;global feature extraction;multi-scale features","Feature extraction;Transformers;Computational modeling;Plant diseases;Accuracy;Computational efficiency;Crops;Deep learning;Computational complexity;Support vector machines","","","","41","CCBY","10 Jun 2025","","","IEEE","IEEE Journals"
"Deceiving Deep Learning-based Fraud SMS Detection Models through Adversarial Attacks","A. Bajaj; D. K. Vishwakarma","Department of Information Technology, Biometric Research Laboratory, Delhi Technological University Bawana Road, Delhi, India; Department of Information Technology, Biometric Research Laboratory, Delhi Technological University Bawana Road, Delhi, India",2023 17th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),"21 Mar 2024","2023","","","327","332","Short Messaging Service (SMS) is one of the most extensively utilized mobile applications for communication around the world. Smishing is the technique of delivering harmful SMS to users in which intruders send malicious SMS to the victim. This content may contain links that direct the user to websites that contain harmful software and user interfaces. Researchers have acquired outstanding accuracy scores in proposing SMS spam detectors utilizing transformer-based deep learning algorithms. Despite their superior performance in Natural Language Processing-related tasks, deep learning models are vulnerable to adversarial attacks that result in misclassification. A few words or characters are altered to create adversarial text, fooling the machine into making inaccurate predictions. This research aims to analyze the security weaknesses of the smishing detection method by employing advanced attack techniques to generate adversarial text. In this study, we conducted a comparative analysis of various transformer models, including BERT, DistilBERT and RoBERTa. These models were trained on the SMS spam dataset, which is often used for detecting fraudulent SMS messages. Through our analysis, we examined and evaluated the behavior of these models to know which model is more vulnerable or which is more robust. The prospective outcomes have been assessed by the computation of Attack Success Rates (ASR) for each model. The findings indicate the feasibility of circumventing automated spam SMS detection systems, hence highlighting potential implications for existing regulatory interventions.","","979-8-3503-7091-1","10.1109/SITIS61268.2023.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472797","Textual Adversarial Attacks;Smishing Detection;Transformers;Natural Language Processing (NLP);Vulnerability","Deep learning;Analytical models;Vocabulary;Computational modeling;Phishing;User interfaces;Message services","","","","22","IEEE","21 Mar 2024","","","IEEE","IEEE Conferences"
"Deep Learning-Based Phishing Email Spam Detection with Region Attention Convolution and Adaptive Optimization","N. Jetty; M. G K; S. Pattanaik; S. R. Bittla","University of the Cumberlands, United States; Department of AIML, Nitte Meenakshi Institute of Technology, Bengaluru; Automatic Data Processing (ADP), NJ, USA; NA",2025 International Conference on Intelligent and Cloud Computing (ICoICC),"1 Jul 2025","2025","","","1","9","Phishing emails are a common kind of cyberattack that aim to trick victims into giving over personal information, financial data, and login credentials. Traditional spam filters have a hard time detecting phishing emails because they often look like they came from a trusted source. The need for more sophisticated detection procedures to distinguish between legitimate and malicious emails is growing in response to the sophistication of phishing assaults. With the help of an Adaptive Reproductive Harris Hawks Optimisation (ARHHO) fine-tuner, to provide EfficientNet, a phishing email spam detector based on residual attention mechanisms (RAM). By zeroing in on important parts of the email's content, metadata, and embedded links, the RAC module improves feature extraction, which in turn improves classification accuracy and decreases false positives. At its core, EfficientNet guarantees scalable and efficient deep learning processing thanks to its optimised depth and breadth scaling. Furthermore, ARHHO optimises the model's hyperparameters in real-time to enhance generalisability and resilience through better classification performance. Extensive tests on benchmark phishing datasets are conducted to evaluate the proposed approach. Our model beats traditional deep learning methods like CNNs, LSTMs, and transformers in every metric to measured: accuracy, precision, recall, and F1-score. The use of attention-driven feature extraction in conjunction with adaptive optimisation techniques allows us to significantly improve phishing detection skills while simultaneously reducing the sum of false positives. By developing a sophisticated, effective, and scalable method for detecting phishing emails, this study makes a contribution to cybersecurity. Improvements based on transformer models, detection techniques that work in real-time, and strategies to withstand adversarial attacks are all part of the future. Enterprise email security solutions can effectively implement the suggested structure to reduce the risks of phishing attacks.","","979-8-3315-1302-3","10.1109/ICoICC64033.2025.11052027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052027","Email Phishing;Cybersecurity Threats;Adaptive Reproductive Harris Hawks Optimization;Residual attention mechanism;Adversarial attack resilience strategies;Transformer-Based models","Deep learning;Adaptation models;Phishing;Unsolicited e-mail;Computational modeling;Transformers;Feature extraction;Real-time systems;Optimization;Resilience","","","","28","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Improving 3D Human Body Reconstruction Using Millimeter-Wave Radar-Based Kansformer","J. Peng; R. Huang; H. Hosobe","Graduate School of Computer and Information Sciences, Hosei University, Tokyo, Japan; Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan; Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan",2024 IEEE Smart World Congress (SWC),"24 Mar 2025","2024","","","976","982","As the unique advantages of millimeter wave (mmWave) radar technology in handling complex environments become increasingly apparent, research into constructing 3D human models using mmWave radar has received extensive attention. Capable of operating effectively in adverse conditions such as smoke, snow, and poor lighting, mmWave radar holds significant potential for applications in emergency response and security monitoring. This paper investigates the possibility of reconstructing accurate 3D skeletons or mesh models by analyzing noisy and sparse radar signals. Moreover, addressing the issues of large parameter size and long training periods inherent in traditional Transformer models, this study employs an optimized Kolmogorov-Arnold Network(KAN) [1] structure to enhance the Transformer model, which called Kansformer. This structural optimization significantly reduces the model’s parameter count and improves its learning efficiency and generalizability across different scenes. The results demonstrate that the optimized model exhibits higher robustness and accuracy in mmWave human body reconstruction tasks, especially in visually obstructed environments.","2993-396X","979-8-3315-2086-1","10.1109/SWC62898.2024.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10925019","Millimeter wave radar;Kolmogorov-Arnold Network;Transformer;Kansformer;optimized","Training;Solid modeling;Three-dimensional displays;Accuracy;Snow;Radar;Millimeter wave radar;Transformers;Skeleton;Millimeter wave communication","","","","20","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"Advancing AI-Driven Network Anomaly Detection: A Comparative Study Employing Big Data Analytics","B. Zhao; Z. Zeng; Z. Luo; Z. Z. J. Liu","School of Computer, National University of Defense Technology, Changsha, China; School of Information, Hunan University of Humanities, Science and Technology, Loudi, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China",2024 10th International Conference on Big Data and Information Analytics (BigDIA),"27 Dec 2024","2024","","","233","240","In the expanding realms of the Internet and IoT, the surge in network data both drives the digital economy and intensifies cybersecurity vulnerabilities. Network anomaly detection is essential for protecting against security threats. This paper conducted a comprehensive comparative study by applying big data analytics and sophisticated machine learning to enhance intelligent network anomaly detection. It confronts challenges such as data heterogeneity and model standardization, conducting extensive experiments across six datasets with a range of algorithms, from classical decision trees to cutting-edge CNN, LSTM, and Transformer models, the GWO algorithm was also employed for feature selection, and it was combined with the KNN algorithm to optimize classification performance. The evaluation focuses on metrics such as accuracy, recall rate, F1 score, and training time, revealing the performance of these algorithms with high-dimensional and imbalanced data. Notably, random forest shows exceptional detection performance on the CIC-MalMem-2022 dataset, while random forest and GBDT excel in accuracy and training speed on the RT-IoT2022 dataset. These insights are critical for creating more effective detection systems.","2771-6902","979-8-3503-5462-1","10.1109/BigDIA63733.2024.10808267","Natural Science Foundation of China(grant numbers:U22B2005,61972412); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808267","Network Anomaly Detection;Big Data Analysis;Machine Learning","Training;Performance evaluation;Accuracy;Machine learning algorithms;Big Data;Feature extraction;Data models;Classification algorithms;Random forests;Anomaly detection","","","","15","IEEE","27 Dec 2024","","","IEEE","IEEE Conferences"
"Protego: Detecting Adversarial Examples for Vision Transformers via Intrinsic Capabilities","J. Wu; K. Pan; Y. Chen; J. Deng; S. Pang; W. Xu","USSLAB, Zhejiang University; USSLAB, Zhejiang University; USSLAB, Zhejiang University; USSLAB, Zhejiang University; USSLAB, Zhejiang University; USSLAB, Zhejiang University","2024 IEEE International Conference on Metaverse Computing, Networking, and Applications (MetaCom)","6 Nov 2024","2024","","","105","112","Transformer models have excelled in natural language tasks, prompting the vision community to explore their implementation in computer vision problems. However, these models are still influenced by adversarial examples. In this paper, we investigate the attack capabilities of six common adversarial attacks on three pre-trained ViT models to reveal the vulnerability of ViT models. To understand and analyse the bias in neural network decisions when the input is adversarial, we use two visualisation techniques that are attention rollout and grad attention rollout. To prevent ViT models from adversarial attack, we propose Protego, a detection framework that leverages the transformer intrinsic capabilities to detection adversarial examples of ViT models. Nonetheless, this is challenging due to a diversity of attack strategies that may be adopted by adversaries. Inspired by the attention mechanism, we know that the token of model’s prediction contains all the information from the input sample. Additionally, the attention region for adversarial examples differs from that of normal examples. Given these points, we can train a detector that achieves superior performance than existing detection methods to identify adversarial examples. Our experiments have demonstrated the high effectiveness of our detection method. For these six adversarial attack methods, our detector’s AUC scores all exceed 0.95. Protego may advance investigations in metaverse security.","","979-8-3315-1599-7","10.1109/MetaCom62920.2024.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740148","ViT;Adversarial Attack;Detector;Attention","Computer vision;Visualization;Metaverse;Computational modeling;Neural networks;Natural languages;Detectors;Predictive models;Transformers;Security","","","","34","IEEE","6 Nov 2024","","","IEEE","IEEE Conferences"
"A Comprehensive Survey on Phytopathogen Surveillance with Modern Artificial Intelligence Practices","K. G; S. R","Department of Computer Applications, Kalasalingam Academy of Research and Education, Virudhunagar, Tamilnadu; Department of Information Technology, Kalasalingam Academy of Research and Education, Virudhunagar, Tamilnadu",2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS),"10 Jan 2025","2024","","","1491","1496","The most important aspect of modern agriculture is the detection of plant diseases with the goal of improving crop quality and output. This survey paper investigates modern approaches of deep learning algorithms, Explainable AI and Federated Learning to plant disease diagnosis. The background and broadening of plant disease detection are briefly reviewed at the outset of the study, with a focus on the importance of precise and effective identification techniques. The multivariate normal DL neural network (MNDLNN) classifier and Customized CNN are the most robust feature extraction and classification techniques among the examined technologies. Using Higher-Order Whitened Singular Value Decomposition (HOWSVD), complex data is processed in a way that highlights distinct patterns and features for easy data classification and also increases accuracy. The E-GreenNet generates disease classification features based on a MobileNetV3. The ResNet9 and Improved Vision Transformer models perform better when processing complicated visual data. Spectral Generative Adversarial Neural Network (DSGAN2) and Lite Multikernel Depthwise Convolutions architecture are suitable for real-time applications because they provide promising results with less computational overhead. These findings' implications point to a possible move toward disease detection systems that are easier to use and more effective, which would improve crop management and food security. The development of more affordable solutions for small scale farmers, the integration of Embedded systems for real-time monitoring, and the improvement of these models for increased precision are some future directions. This survey highlights the transformative potential of combining deep learning with other techniques like Federated Learning in advancing agricultural practices.","","979-8-3315-1809-7","10.1109/ICICNIS64247.2024.10823299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823299","Deep learning;Federated learning;Explainable AI;Real-time detection","Surveys;Deep learning;Plant diseases;Visualization;Federated learning;Surveillance;Neural networks;Crops;Transformers;Real-time systems","","","","25","IEEE","10 Jan 2025","","","IEEE","IEEE Conferences"
"Malicious Design in AIVR, Falsehood and Cybersecurity-oriented Immersive Defenses","N. -M. Aliman; L. Kester","Department of Information and Computing Sciences, Utrecht University, Utrecht, Netherlands; Intelligent Autonomous Systems, TNO Netherlands, The Hague, Netherlands",2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),"15 Jan 2021","2020","","","130","137","Advancements in the AI field unfold tremendous opportunities for society. Simultaneously, it becomes increasingly important to address emerging ramifications. Thereby, the focus is often set on ethical and safe design forestalling unintentional failures. However, cybersecurity-oriented approaches to AI safety additionally consider instantiations of intentional malice - including unethical malevolent AI design. Recently, an analogous emphasis on malicious actors has been expressed regarding security and safety for virtual reality (VR). In this vein, while the intersection of AI and VR (AIVR) offers a wide array of beneficial cross-fertilization possibilities, it is responsible to anticipate future malicious AIVR design from the onset on given the potential socio-psycho-technological impacts. For a simplified illustration, this paper analyzes the conceivable use case of Generative AI (here deepfake techniques) utilized for disinformation in immersive journalism. In our view, defenses against such future AIVR safety risks related to falsehood in immersive settings should be transdisciplinarily conceived from an immersive co-creation stance. As a first step, we motivate a cybersecurity-oriented procedure to generate defenses via immersive design fictions. Overall, there may be no panacea but updatable transdisciplinary tools including AIVR itself could be used to incrementally defend against malicious actors in AIVR.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319051","AI Safety;VR;AI;Immersive Journalism;Disinformation;HCI;Design Fiction;Psychology;Cybersecurity","Artificial intelligence;Information integrity;Videos;Safety;Media;Journalism;Computer crime","","15","","95","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"AI Literacy for All: Adjustable Interdisciplinary Socio-technical Curriculum","S. Y. Tadimalla; M. L. Maher","University of North Carolina at Charlotte, Charlotte, U.S.A.; University of North Carolina at Charlotte, Charlotte, U.S.A.",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","9","This research-to-practice paper presents a curriculum, “AI Literacy for All,” to promote an interdisciplinary under-standing of AI, its socio-technical implications, and its practical applications for all levels of education. With the rapid evolution of artificial intelligence (AI), there is a need for AI literacy that goes beyond the traditional AI education curriculum. AI literacy has been conceptualized in various ways, including public literacy, competency building for designers, conceptual understanding of AI concepts, and domain-specific upskilling. Most of these conceptualizations were established before the public release of Generative AI (Gen-AI) tools such as ChatGPT. AI education has focused on the principles and applications of AI through a technical lens that emphasizes the mastery of AI principles, the mathematical foundations underlying these technologies, and the programming and mathematical skills necessary to implement AI solutions. The non-technical component of AI literacy has often been limited to social and ethical implications, privacy and security issues, or the experience of interacting with AI. In AI Literacy for all, we emphasize a balanced curriculum that includes technical as well as non-technical learning outcomes to enable a conceptual understanding and critical evaluation of AI technologies in an interdisciplinary socio-technical context. The paper presents four pillars of AI literacy: understanding the scope and technical dimensions of AI, learning how to interact with Gen-AI in an informed and responsible way, the socio-technical issues of ethical and responsible AI, and the social and future implications of AI. While it is important to include all learning outcomes for AI education in a Computer Science major, the learning outcomes can be adjusted for other learning contexts, including, non-CS majors, high school summer camps, the adult workforce, and the public. This paper advocates for a shift in AI literacy education to offer a more interdisciplinary socio-technical approach as a pathway to broaden participation in AI. This approach not only broadens students' perspectives but also prepares them to think critically about integrating AI into their future professional and personal lives.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10893159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893159","AI literacy;AI education;Active learning;Responsible AI;Democratizing AI","Ethics;Privacy;Navigation;Generative AI;Education;Chatbots;Security;Artificial intelligence;Programming profession;Lenses","","7","","38","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Prompt-to-OS (P2OS): Revolutionizing Operating Systems and Human-Computer Interaction with Integrated AI Generative Models","G. Tolomei; C. Campagnano; F. Silvestri; G. Trappolini","Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer Engineering, Sapienza University of Rome, Italy; Department of Computer Engineering, Sapienza University of Rome, Italy",2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI),"19 Feb 2024","2023","","","128","134","In this ambitious paper, we present a groundbreaking paradigm for human-computer interaction that revolutionizes the traditional notion of an operating system. Within this innovative framework, user requests issued to the machine are handled by an interconnected ecosystem of generative AI models that seamlessly integrate with or even replace traditional software applications. At the core of this paradigm shift are large generative models, such as language and diffusion models, which serve as the central interface between users and computers. This pioneering approach leverages the abilities of advanced language models, empowering users to engage in natural language conversations with their computing devices. By capitalizing on the power of language models, users can articulate their intentions, tasks, and inquiries directly to the system, eliminating the need for explicit commands or complex navigation. The language model comprehends and interprets the user's prompts, generating and displaying contextual and meaningful responses that facilitate seamless and intuitive interactions. This paradigm shift not only streamlines user interactions but also opens up new possibilities for personalized experiences. Generative models can adapt to individual preferences, learning from user input and continuously improving their understanding and response generation. Furthermore, it enables enhanced accessibility, as users can interact with the system using speech or text, accommodating diverse communication preferences. However, this visionary concept also raises significant challenges, including privacy, security, trustability, and the ethical use of generative models. Robust safeguards must be in place to protect user data and prevent potential misuse or manipulation of the language model. While the full realization of this paradigm is still far from being achieved, this paper serves as a starting point for envisioning the transformative potential of a human-computer interaction paradigm centered around artificial intelligence. We discuss the envisioned benefits, challenges, and implications, paving the way for future research and development in this exciting and promising direction.","","979-8-3503-2383-2","10.1109/CogMI58952.2023.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10431539","AI generative models for operating systems;AI generative models for human-computer interaction;AI generative models as universal applications","Human computer interaction;Ethics;Navigation;Biological system modeling;Computational modeling;Operating systems;Data models","","6","","33","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"Message-Driven Generative Music Steganography Using MIDI-GAN","Z. Su; G. Zhang; Z. Shi; D. Hu; W. Zhang","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Cyber Science and Technology, University of Science and Technology of China, Hefei, China",IEEE Transactions on Dependable and Secure Computing,"12 Nov 2024","2024","21","6","5196","5207","Generative steganography has become a popular research topic in the field of generative AI, including generative image and synthetic speech steganography. However, music files have different statistical properties and knowledge representation compared to image and speech files, and the reversible transform between secret message and music is also challenging. Therefore, the existing generative steganographic methods that are effective for image/speech may not be directly effective for music. In this article, we propose a generative music steganography method, named MIDI-GAN, to generate a secret message as an artificial stego MIDI file using generative adversarial networks (GANs). The created stego MIDI file is small in size, has sweet melodies, and is undetectable to deep learning-based steganalyzers. Unlike the previous generative image/speech steganography, the stego MIDI can also be presented as a sequence of chord numbers, making it difficult for anyone to detect and see grounds for suspicion. Moreover, these chord numbers can be transmitted as any other digital or physical medium to evade detection. Specifically, MIDI-GAN comprises a generator, a discriminator, and an extractor. The generator synthesizes a stego MIDI file from the secret message, while the discriminator ensures that the stego MIDI file approaches the authentic rather than the synthetic MIDI file as much as possible in statistical distribution. The extractor recovers the secret message from the stego MIDI file or chord sequence. Experimental results demonstrate that MIDI-GAN has high concealment and security, as the stego MIDI generated by our method is closely similar to the authentic MIDI files and maintains excellent anti-detection ability against deep learning-based steganalysis.","1941-0018","","10.1109/TDSC.2024.3372139","Anhui Provincial Key Research and Development Program(grant numbers:202104d07020001); Natural Science Foundation of Anhui Province(grant numbers:2208085MF166); Fundamental Research Funds for the Central Universities(grant numbers:PA2023IISL0097,PA2023GDSK0049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10457038","Music steganography;generative adversarial networks;MIDI;chord numbers;statistical distribution","Steganography;Generators;Generative adversarial networks;Videos;Speech recognition;Multiple signal classification;Adversarial machine learning","","3","","53","IEEE","1 Mar 2024","","","IEEE","IEEE Journals"
"A Generative Approach to Mitigate Bias in Face Matching using Learned Latent Structure","J. Alasadi; A. AlHilli; P. K. Atrey; V. K. Singh","Rutgers University, USA; Al-Fural Al-Awsat Technical University, Iraq; State University of New York, Albany, USA; Rutgers University, State University of New Jersey, USA",2022 IEEE Eighth International Conference on Multimedia Big Data (BigMM),"29 Dec 2022","2022","","","150","157","This work tackles the problem of bias in face matching algorithms. Face matching refers to the task of matching a low-resolution face image of a person with a high-resolution face image of the same person and has applications in security and personalization. Algorithmic bias is the difference in performance of an algorithm based on demographic descriptors of various users. Such bias can significantly reify and amplify societal biases and make certain advancements in technology benefit one section of the society while hurting the other. This work proposes a generative AI framework that can counter multiple kinds bias (e.g., gender bias and age bias) at the same time. The framework consists of two major components: a variational auto-encoder (VAE) that converts the images into their more generic underlying representation, and second, a neural network architecture that uses the above representations to undertake multi-label classification. A generative approach is useful in ensuring that the system learns to deal with the underlying (latent) structure of the data for better generalizability and bias reduction. The approach is tested over a public image dataset and found to be effective at reducing bias while maintaining high accuracy.","","978-1-6654-5963-1","10.1109/BigMM55396.2022.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999088","Fairness;Bias in Machine Learning;Face Matching;Face Detection;Neural Network","Ethics;Multimedia systems;Neural networks;Training data;Probability distribution;Classification algorithms;Security","","2","","25","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"GenCheck: A LoRA-Adapted Multimodal Large Language Model for Check Analysis","F. Zhao; J. Chen; B. Huang; C. Zhang; G. Warner; R. Chen; S. Tang; Y. Ma; Z. Nan","The University of Alabama at Birmingham, Birmingham, USA; Beijing-Dublin International College, Beijing University of Technology, Beijing, China; Beijing Hua Yu Xin Zhang Technologies Co., Ltd, Beijing, China; The University of Alabama at Birmingham, Birmingham, USA; The University of Alabama at Birmingham, Birmingham, USA; College of Information Science and Technology, Shihezi University, Shihezi, China; Computer Science and Technology College, University of Chinese Academy of Sciences, Beijing, China; Beijing-Dublin International College, Beijing University of Technology, Beijing, China; Beijing-Dublin International College, Beijing University of Technology, Beijing, China",2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR),"15 Oct 2024","2024","","","88","94","Rising incidences of paper check fraud, particularly with checks illicitly sold on platforms such as Telegram, pose significant challenges in financial security. Despite investigators' capability to gain access to these platforms, manually pinpointing checks in images and extracting necessary details to alert banks are inefficient and unscalable. Traditional optical character recognition-based (OCR) systems for extracting textual details from checks specifically struggle with handwritten content and are constrained by their dependency on predefined check layouts, limiting their effectiveness across varied and evolving check designs. To address these challenges, we introduce GenCheck, a generative AI-based framework that automates both the check detection and accurate extraction of check information, ensuring robust performance across various check layouts or styles. GenCheck operates through a two-stage pipeline: the preliminary stage encompasses multiple sub-tasks including check image classification, single check segmentation, image rectification, and check element detection, while the main stage focuses on the key task of check information extraction. Central to our pipeline is the strategic enhancement of a state-of-the-art (SOTA) multimodal large language model (LLaVA-NeXT) using Low-Rank Adaptation (LoRA). This fine-tuning leverages the model's pre-trained knowledge, applying a targeted, parameter-efficient approach that significantly enhances its ability to accurately extract key details such as dates, amounts, and payee information from paper check images. Our framework achieves exceptional accuracy rates in extracting date information with 92.07 % for year, 85.16% for month, and 82.72% for day. It also obtains an accuracy of 80.61 % in extracting monetary amounts and a normalized edit distance of 0.2583 for payee information, demonstrating substantial improvements over pure OCR-based methods. As the first framework of its kind, GenCheck estab-lishes a methodological base that supports continuous innovation and enhancement, allowing for independent updates of each component model. This also sets a new standard in automated check analysis, reducing the need for labor-intensive, rule-based processes and significantly advancing fraud prevention initiatives.","2770-4319","979-8-3503-5142-2","10.1109/MIPR62202.2024.00021","NSF(grant numbers:CNS-2154589,2154507); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707807","Multimodal Large Language Model;Handwritten Check;Deep Learning;Low-Rank Adaptation;Check Fraud","Adaptation models;Technological innovation;Accuracy;Large language models;Optical character recognition;Layout;Fraud;Data mining;Security;Standards","","1","","16","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"Enabling Trustable Financing: A Verifiable Privacy-Preserving Cross-Chain Protocol","L. Lou; W. He; X. Tang; Y. Yang; T. Zhang; Y. Cheng; C. Xu","Key Laboratory of Ethnic Language Intelligent Analysis and Security Governance of MOE, Minzu University of China, China; Key Laboratory of Ethnic Language Intelligent Analysis and Security Governance of MOE, Minzu University of China, China; Key Laboratory of Ethnic Language Intelligent Analysis and Security Governance of MOE, Minzu University of China, China; School of Software, University of South, China; School of Software Engineering, Beijing Jiaotong University, China; School of Cyberspace, Hangzhou Dianzi University, China; State Key Laboratory of Media Convergence Production Technology and Systems, China",2024 IEEE/CIC International Conference on Communications in China (ICCC Workshops),"4 Oct 2024","2024","","","214","219","Generative AI-enabled wireless communications enhance efficiency and offer new tools for supply chain finance (SCF) innovation. SCF optimizes capital efficiency and reduces risk, but information asymmetry hinders risk assessment. Blockchain technology addresses these challenges by solving information asymmetry and regulatory issues. However, issues of privacy protection, reliability, and traceability remain. To address this, we design a verifiable privacy protection cross-chain protocol based on threshold homomorphic encryption. This protocol ensures confidential sharing and verifiable access to enterprise information through homomorphic encryption and distributed private key technology, enhancing data security and controllability in SCF. Our simulation experiments demonstrate the protocol's feasibility and effectiveness in cross-chain SCF scenarios, supporting the application of blockchain technology in supply chain finance.","2474-9141","979-8-3503-7767-5","10.1109/ICCCWorkshops62562.2024.10693771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10693771","Threshold Homomorphic Encryption;Supply Chain Finance;Blockchain Technology","Wireless communication;Privacy;Technological innovation;Protocols;Supply chains;Finance;Blockchains;Reliability;Homomorphic encryption;Protection","","1","","25","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
"Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems","D. Lilienthal; P. Mello; M. Eirinaki; S. Tiomkin","Department of Computer Engineering, San Jose State University, San Jose, CA, USA; Department of Computer Engineering, San Jose State University, San Jose, CA, USA; Department of Computer Engineering, San Jose State University, San Jose, CA, USA; Department of Computer Engineering, San Jose State University, San Jose, CA, USA",IEEE Access,"2 May 2024","2024","12","","58275","58287","While recommender systems have become an integral component of the Web experience, their heavy reliance on user data raises privacy and security concerns. Substituting user data with synthetic data can address these concerns, but accurately replicating these real-world datasets has been a notoriously challenging problem. Recent advancements in generative AI have demonstrated the impressive capabilities of diffusion models in generating realistic data across various domains. In this work we introduce a Score-based Diffusion Recommendation Module (SDRM), which captures the intricate patterns of real-world datasets required for training highly accurate recommender systems. SDRM allows for the generation of synthetic data that can replace existing datasets to preserve user privacy, or augment existing datasets to address excessive data sparsity. Our method outperforms competing baselines such as generative adversarial networks, variational autoencoders, and recently proposed diffusion models in synthesizing various datasets to replace or augment the original data by an average improvement of 4.30% in Recall@ $k$  and 4.65% in NDCG@ $k$ .","2169-3536","","10.1109/ACCESS.2024.3388299","SJSU College of Engineering Davidson Student Scholar; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497577","Data privacy;diffusion models;machine learning;recommender systems;synthetic data","Training;Recommender systems;Data models;Synthetic data;Data privacy;Noise reduction;Gaussian distribution;Diffusion processes;Machine learning","","1","","73","CCBYNCND","12 Apr 2024","","","IEEE","IEEE Journals"
"Navigating the Obscured: A Novel Deepfake Detection Framework Tackling Trending Occlusions in Social Media","B. Biswas; A. D. Raha; C. Paul; S. K. Dam; A. Adhikary; R. Debnath; A. K. Bairagi; M. Gain","AI Innovation Lab, Khulna, Bangladesh; AI Innovation Lab, Khulna, Bangladesh; AI Innovation Lab, Khulna, Bangladesh; Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh; Dept. of ICE, Noakhali Science and Technology University, Noakhali, Bangladesh; Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh; Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh; AI Innovation Lab, Khulna, Bangladesh",2024 27th International Conference on Computer and Information Technology (ICCIT),"10 Jun 2025","2024","","","2986","2991","Images and videos have become a ubiquitous part of modern life, used extensively for entertainment and security purposes. In recent years, Generative AI (Gen-AI) has gained immense popularity due to its advanced capabilities in generating highly realistic images. However, the use of Gen-AI in creating deepfakes—manipulated videos or images designed to mimic real individuals has also increased. Deepfakes have become a growing concern, particularly for the authenticity of visual content shared online. Detecting these fabricated visuals remains a critical challenge. While several methods exist for detecting deepfakes, new trends in image manipulation on social media have introduced significant complications. One of the recent trends involves occlusions, such as large text overlays or windows inserted into images, commonly seen on various platforms. These occlusions pose a serious challenge to current detection techniques, as they often interfere with the model’s ability to recognize facial features accurately. In this research, we address these newly emerging occlusion patterns and propose a novel deepfake detection model capable of effectively identifying fake images even in such obstructions. We propose a deep learning model that can recognize both clean and occluded deepfakes. Our approach integrates knowledge of both clean and occluded images, allowing the model to detect deepfakes under a variety of conditions, including occlusions created by text, stickers, or other overlays. We conducted an extensive study of trending occlusion patterns, focusing specifically on images featuring text within a window overlay. We analyzed how various factors such as occlusion size, shape, and position influenced model accuracy. Our model, tested on both traditional clean images and those with occlusions, demonstrated robust performance. In particular, DenseNet121 outperformed ResNet50 and VGGNet16 in handling these challenging occluded images with an accuracy of more than 99%.","2474-9656","979-8-3315-1909-4","10.1109/ICCIT64611.2024.11021926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11021926","deepfake;occlusion;obscured face;social media","Deep learning;Training;Deepfakes;Adaptation models;Visualization;Accuracy;Social networking (online);Shape;Market research;Residual neural networks","","","","20","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack","H. -H. Nguyen-Le; V. -T. Tran; D. -T. Nguyen; N. -A. Le-Khac","University College Dublin, Ireland; Trinity College Dublin, Ireland; University of Science, Vietnam; University College Dublin, Ireland",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","The advancements in generative AI have enabled the improvement of audio synthesis models, including text-to-speech and voice conversion. This raises concerns about its potential misuse in social manipulation and political interference, as synthetic speech has become indistinguishable from natural human speech. Several speech-generation programs are utilized for malicious purposes, especially impersonating individuals through phone calls. Therefore, detecting fake audio is crucial to maintain social security and safeguard the integrity of information. Recent research has proposed a D-CAPTCHA system based on the challenge-response protocol to differentiate fake phone calls from real ones. In this work, we study the resilience of this system and introduce a more robust version, D-CAPTCHA++, to defend against fake calls. Specifically, we first expose the vulnerability of the D-CAPTCHA system under the transferable imperceptible adversarial attack. Secondly, we mitigate such vulnerability by improving the robustness of the system by using adversarial training in D-CAPTCHA deepfake detectors and task classifiers.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10650401","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650401","black-box attacks;transferability;imperceptible adversarial examples;deepfake;deep learning","Training;Deepfakes;Protocols;Generative AI;Neural networks;Interference;Robustness","","","","33","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Multi-Media Authentication Through Application of Generative Adversarial Networks and Blockchain Technology","S. Nandwani; D. A. Ostrowski","School Of Professional Studies, Northwestern University, USA; School Of Professional Studies, Northwestern University, USA",2025 19th International Conference on Semantic Computing (ICSC),"19 Jun 2025","2025","","","279","285","The surge in deepfake technology poses significant threats to the integrity of digital media. This paper combines generative AI with Blockchain - based authentication for a novel approach to deepfake detection and media verification. By pairing a Generative Adversarial Model (GAN) for synthetic data verification with Blockchain's immutability a secure and robust framework for authentication is determined. The first step of this process is to characterize the method used to forge unauthentic media and leverage it with a discriminative model for advanced pattern detections. The second step would involve creating unique digital fingerprints for media on the blockchain developing characterizations of authentic as well as unauthentic media. Preliminary results show that this dual-layered system effectively enhances digital content's reliability and security.","2472-9671","979-8-3315-2426-5","10.1109/ICSC64641.2025.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036146","gans;deepfake;blockchain","Deepfakes;Adaptation models;Costs;Generative AI;Federated learning;Scalability;Authentication;Media;Real-time systems;Blockchains","","","","12","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Robust Zero Trust Systems Based on Collaborative ai to Secure the 6G-Enabled VANETs","H. Sedjelmaci; M. Ayaida","EricssonRD, France; Université Polytechnique Hauts-de-France, France",IEEE Wireless Communications,"28 Mar 2025","2025","32","2","164","170","The research in cyber security for vehicular ad-hoc networks (VANETs) has received great attention from the scientific community. However, the intrusion detection and prevention for Sixth Generation (6G)-enabled VANETs has not attracted much attention up to this point. In this research article, we propose new robust zero trust agents based on collaborative artificial intelligence (AI) algorithms to protect the 6G-enabled VANETs from attacks targeting simultaneously the VANETs and 6G infrastructure. Collaborative AI is based on generative AI and transfer learning (TL) algorithms. Two kinds of zero trust agents are proposed - local zero trust systems (LZTS) and global zero trust systems (GZTS) - that monitor the network and infrastructure with the goal of detecting malicious behaviors promptly.","1558-0687","","10.1109/MWC.003.2300571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10944630","","6G mobile communication;Measurement;Generative AI;Prevention and mitigation;Transfer learning;Collaboration;Lead;Zero Trust;Smart grids;Monitoring","","","","15","IEEE","28 Mar 2025","","","IEEE","IEEE Magazines"
"Optical Quality Control System Improvement for an SME. A Case Study for Test-Before-Invest Partnerhips","L. -A. Bakos; Z. Forgó; E. Egyed-Faluvégi","Mechanical Engineering Dept., Sapientia Hungarian University of Translyvania, Cluj Napoca, Romania; Mechanical Engineering Dept., Sapientia Hungarian University of Translyvania, Cluj Napoca, Romania; Mechanical Engineering Dept., Sapientia Hungarian University of Translyvania, Cluj Napoca, Romania",2024 IEEE 6th International Symposium on Logistics and Industrial Informatics (LINDI),"7 Jan 2025","2024","","","000189","000194","The manuscript presents the results of a case study, a test-before-invest experiment, to set up an AI-based optical control system in a manufacturing company in order to improve the throughput and to improve the rate of false negative signals provided by the quality control system. The manufactured parts, small fasteners (rivets) could be critical elements in many industries, the quality requirements are set by special standards. The literature study proved us, that the accuracy of the existing machine-vision algorithms, at least at experimental level is about 98%. Our state of art review led to the conclusion that measurement-error improvement can be achieved by changing the detection technology and downsizing the false negative signals. During the research a secure environment was created in which generative AI solutions were tested, mitigating many security risks, without disturbing the real shopfloor environment and without using the resources of the manufacturing company. On the studied sample on a higher investigation speed, we had no false positive signals, and the number of false negative signals were decreased from 7% to 2%. The research intends to show how collaboration between SMEs and research groups can solve real technological problems using the latest achievements in science and technology. The proposed solution overcomes some of the weaknesses of the existing technology by a single digitalization project.","2156-8804","979-8-3315-1620-8","10.1109/LINDI63813.2024.10820414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10820414","image-based inspection;defect detection;AI based quality inspection;test-before-invest partnerships","Generative AI;Collaboration;Companies;Quality control;System improvement;Throughput;Manufacturing;Security;Reliability;Optical control","","","","32","IEEE","7 Jan 2025","","","IEEE","IEEE Conferences"
"HIFI-Stego: A High-Fidelity Embedding Audio Steganography Based on Audio Features Decoupling","S. Zhang; B. Tian; Y. Gao; X. Liu; W. Yang","School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China","IEEE Transactions on Audio, Speech and Language Processing","29 May 2025","2025","33","","2032","2044","The higher audio quality of steganography is directly correlated with the increased resistance to steganalysis tools. The advancement of generative AI technologies, particularly those that decouple style features from content, has shown promising developments by facilitating the creation of superior media content. This paper introduces the concept of audio decoupling and presents HIFI-Stego, an embedding audio steganography technique that aims to improve security while maintaining elevated stego audio quality. HIFI-Stego comprises a generator based on the encoder-decoder architecture and a secret message extractor. The encoder of the generator decouples the original audio, yielding the content vector, while the vocoder WORLD is employed to extract the style vector to preserve high-quality audio related features such as timbre and tone. Subsequently, the decoder embeds the secret vector into the decoupled content vector and then couples it with the style vector to generate high-fidelity stego audio. As embedding is not done in traditional time domain or frequency domain, existing analysis tools targeted at traditional steganographies fail to effectively detect the presence of the hidden message. The secret message extractor reuses the generator encoder and augments it with a single-layer convolutional neural network, resulting in a simplified structure suitable for lightweight deployment. Experimental results demonstrate that HIFI-Stego outperforms traditional generative and embedding steganographies in terms of audio quality, steganographic capacity, anti-analysis ability, and concealment.","2998-4173","","10.1109/TASLPRO.2025.3570942","National Key Research and Development Program of China(grant numbers:2022YFB3104601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007018","Embedding audio steganography;audio decoupling;encoder-decoder;steganographic capacity;stego audio quality","Steganography;Vectors;Time-domain analysis;Generators;Feature extraction;Training;Resistance;Generative adversarial networks;Convolutional neural networks;Security","","","","52","IEEE","19 May 2025","","","IEEE","IEEE Journals"
"Building the AI Sandbox: Safe, Responsible Spaces for Innovation","N. Russell",NA,Scaling Responsible AI: From Enthusiasm to Execution,"","2025","","","37","53","Summary <p>The artificial intelligence (AI) sandbox provides a safe space for experimentation and innovation without putting operational systems at risk. Innovation is at the heart of AI exploration, and identifying low‐risk use cases enables organizations to push boundaries while maintaining a safety net. As businesses dive deeper into the realm of AI, it becomes increasingly crucial to align technological advancements with ethical principles and societal values. Every success story in the AI world stems from a humble beginning—a point of inception where an idea or prototype takes shape within the confines of an AI sandbox. Generative AI applications can boost productivity by automating repetitive tasks and providing data‐driven insights to employees. Policies and governance structures are critical for overseeing AI implementation responsibly. This includes guidelines for data privacy, security, ethical practices, risk assessments, and compliance monitoring.</p>","","9781394289660","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10955759.pdf&bkn=10955558&pdfType=chapter","","Artificial intelligence;Technological innovation;Organizations;Standards organizations;Buildings;Ethics;Training;Protocols;Monitoring;Data privacy","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-Based Copilot","A. Crossman; A. R. Plummer; C. Sekharudu; D. Warrier; M. Yekrangian",JPMorgan Chase; JPMorgan Chase; JPMorgan Chase; JPMorgan Chase; JPMorgan Chase,2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","1160","1167","We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat models in minutes, relative to the weeks or months a manual process takes. The focus on tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. We establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050643","Cybersecurity;Threat Modeling;Generative Artificial Intelligence","Threat modeling;Generative AI;Prevention and mitigation;System performance;Systems architecture;Information security;Standardization;Manuals;Matrix decomposition;Computer security","","","","22","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"AI Regulation for Ecuador","J. Meza; M. F. L. Saltos; E. U. V. Campoverde; M. C. N. Cejas; V. C. A. Castro","Faculty of Computer Sciences, Universidad Técnica de Manabi, Portoviejo, Ecuador; Faculty of Humanistic and Social Sciences, Universidad Técnica de Manabi, Portoviejo, Ecuador; Facultad Latinoamericana de Ciencias Sociales, Quito, Ecuador; Faculty of Humanistic and Social Sciences, Universidad Técnica de Manabi, Portoviejo, Ecuador; Facultad Latinoamericana de Ciencias Sociales, Quito, Ecuador",2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG),"21 Jul 2025","2025","","","311","316","Generative AI has emerged exponentially. However, countries should prepare the administrative conditions to face the challenges and risks of AI. This research explores the regulatory design and governance processes of Artificial Intelligence (AI) at the European and American levels to compare them with the practices implemented in Ecuador from 2021-2024 by analyzing the role of institutions in this process and the results generated. It used Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) to pick up scientific documents. Data were chosen from three databases: IEEE Digital Library, Scopus, and Science Direct; furthermore, the theoretical Lens of Normative Institutionalism was applied to analyze the social relations of actors for the practice executed in Ecuador, front to international practices. Outcomes found that the standard practices between different countries around the world are based on (i) fairness, (ii) reliability, safety, and control, (iii) privacy and security, (iv) inclusiveness, (v) transparency, (vi) accountability and (vii) in pursuit of human benefits and happiness. In Ecuador, the road map has started to agree with international trends. However, future efforts will require mapping current institutional capacities and existing legal structures to determine what can be used.","2573-1998","979-8-3315-9809-9","10.1109/ICEDEG65568.2025.11081572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081572","IA;governance;framework;risk;government","Privacy;Roads;Reliability theory;Market research;Regulation;Libraries;Safety;Security;Standards;Systematic literature review","","","","10","IEEE","21 Jul 2025","","","IEEE","IEEE Conferences"
"A Conceptual Framework for Guiding the Workforce on Using Responsible AI","A. Chin; L. R. Varshney; G. Singh; J. Riel; R. M. Avadhanam; V. Sachdev","Discovery Partners Institute, University of Illinois System, Chicago, USA; Dept of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, USA; Siebel School of Computing and Data Science, University of Illinois Urbana-Champaign, Urbana, USA; College of Education, University of Illinois Chicago, Chicago, USA; Discovery Partners Institute, University of Illinois System, Chicago, USA; Gies College of Business, University of Illinois Urbana-Champaign, Urbana, USA","2025 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)","4 Aug 2025","2025","","","1","5","Artificial intelligence (AI) is rapidly permeating various industries, yet significant gaps remain in workforce readiness, training, and adoption practices. These gaps create heightened risks around bias, security, and ethical implications. While AI safety frameworks exist, many focus primarily on technical measures and omit the broader human-centric needs and challenges employees face when integrating AI into daily workflows. This paper addresses these concerns by proposing a conceptual framework that emphasizes stakeholder needs analysis, interdisciplinary education and experiential learning programs, certification, and policy guidance to foster responsible AI (RAI) practices. The framework moves beyond mere technical compliance to include robust guardrails, ethical awareness, and practical engagement strategies designed to mitigate the risks of misinformation, hate, privacy breaches, and inadvertent harm. By outlining how organizations can embed this comprehensive approach to AI safety into their operations, the framework aims to equip employees with the knowledge and skills necessary to navigate AI's rapidly evolving capabilities responsibly. We present both the framework itself and preliminary results from its application in the context of Generative AI, illustrating how workforce development can be systematically aligned with RAI principles for safer, more effective AI adoption.","2996-3648","979-8-3315-3228-4","10.1109/ETHICS65148.2025.11098243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098243","responsible AI;AI risk;AI safety;workforce development;certification;AI policy","Industries;Ethics;Navigation;Organizations;Privacy breach;Safety;Stakeholders;Security;Artificial intelligence;Certification","","","","18","IEEE","4 Aug 2025","","","IEEE","IEEE Conferences"
"Latent Diffusion Shield - Mitigating Malicious Use of Diffusion Models Through Latent Space Adversarial Perturbations","H. Phan; B. Huang; A. Jaiswal; E. Sabir; P. Singhal; B. Yuan",Rutgers University; Amazon; Amazon; Amazon; Amazon; Rutgers University,2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW),"29 Apr 2025","2025","","","1350","1358","Diffusion models have revolutionized the landscape of generative AI, particularly in the application of text-to-image generation. However, their powerful capability of generating high-fidelity images raises significant security concerns on the malicious use of the state-of-the-art (SOTA) text-to-image diffusion models, notably the risks of misusing personal photos and copyright infringement through the replication of human faces and art styles. Existing pro-tection methods against such threats often suffer from lack of generalization, poor performance, and high computational demands, rendering them unsuitable for real-time or resource-constrained environments. Addressing these chal-lenges, we introduce the Latent Diffusion Shield (LDS), a novel protection approach designed to operate within the latent space of diffusion models, thereby offering robust de-fense against unauthorized diffusion-based image synthesis. We validate LDS's performance through extensive experiments across multiple personalized diffusion models and datasets, establishing new benchmarks in image protection against the malicious use of diffusion models. Notably, the generative version of LDS provides SOTA protection, while being 150 x faster and using 2.6 x less memory.","2690-621X","979-8-3315-3662-6","10.1109/WACVW65960.2025.00158","National Science Foundation(grant numbers:CMMI-2152908); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972526","","Image synthesis;Perturbation methods;Memory management;Text to image;Diffusion models;Rendering (computer graphics);Robustness;Real-time systems;Security;Protection","","","","28","IEEE","29 Apr 2025","","","IEEE","IEEE Conferences"
"Proactive Audio Authentication Using Speaker Identity Watermarking","Q. Li; X. Lin","School of Computer Science, University of Guelph, Guelph, Canada; School of Computer Science, University of Guelph, Guelph, Canada","2024 21st Annual International Conference on Privacy, Security and Trust (PST)","16 Dec 2024","2024","","","1","10","Generative AI, particularly through “deep fake” technology, stands at the crossroads of innovation and ethical dilemma. On one hand, it brings unprecedented advancements, transforming how we interact with digital content. On the other hand, it significantly compromises privacy and security, casting a shadow over the reliability of speaker recognition systems and fueling misuse in telecommunication fraud and manipulation of public opinion. This stark contrast not only raises legitimate concerns over the safety of sharing personal audio and video but also questions the very authenticity of digital media. To address the challenges of traceability in deepfake content and guarantee the integrity of audio, we propose a new solution specifically designed to counteract voice conversion and synthetic speech attacks. Leveraging cutting-edge deep learning technology, three extension strategies and ensemble learning of synthesis layer, this approach not only overcomes the inherent limitations of existing forensic methods but also resolves the issues associated with high-capacity watermarks. It achieves exceptionally high accuracy and imperceptibility across multiple speech datasets, various synthetic forgery methods, and numerous speech processing algorithms.","2643-4202","979-8-3503-6709-6","10.1109/PST62714.2024.10788060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788060","Audio Authentication;Deepfake;Deep learning;Speech;Watermark","Resistance;Privacy;Technological innovation;Accuracy;Forensics;Cloning;Watermarking;Distortion;Speaker recognition;Speech synthesis","","","","28","IEEE","16 Dec 2024","","","IEEE","IEEE Conferences"
"TALIU: A Novel Decoder and Augmentation Strategy for Boosting Tampered Document Image Detection","A. D. Nguyen; H. -Y. Kim; H. N. Nguyen","Department of Information Systems, VNU University of Engineering and Technology, Hanoi, Vietnam; School of Games, Hongik University, Seoul, South Korea; Department of Information Systems, VNU University of Engineering and Technology, Hanoi, Vietnam",IEEE Access,"28 Apr 2025","2025","13","","70340","70351","In modern information exchange, document images are vital, often embedding sensitive data. The emergence of advanced image editing tools and generative AI models has elevated the risks associated with document forgery and tampering, representing considerable security concerns. Although many studies have been developed recently, they focus on images saved with compression factors. For lossless compression formats like PNG images, current methods based on segmentation exhibit poor performance. Thus, this study tackles the specific challenges of identifying tampered text within lossless compression factor images. We introduce a lightweight and efficient model for document image tampering detection, named TALIU, which is based on segmentation networks. Our model employs an encoder-decoder architecture with a novel streamlined iterative upsampling decoder specifically designed for the context of document tampering. Moreover, we present an innovative data augmentation strategy, tampered region augmentation, intended to enhance sample diversity during the training phase. Extensive experiments utilizing the DocTamper dataset, the largest of its kind, show that our TALIU model surpasses current state-of-the-art methods in both detection accuracy and computational efficiency for detecting tampered text in lossless compression images.","2169-3536","","10.1109/ACCESS.2025.3560360","Culture, Sports and Tourism Research and Development Program through Korea Creative Content Agency Grant funded by the Ministry of Culture, Sports and Tourism, in 2024 (Project Name: Global Talent Training Program for Copyright Management Technology in Game Contents) (Contribution Rate: 100%)(grant numbers:RS-2024-00396709); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10964281","Tampered region augmentation;light iterative upsampling decoder;image manipulation detection;tampered document image detection;copyright protection","Training;Image coding;Forgery;Decoding;Predictive models;Data augmentation;Visualization;Iterative methods;Image segmentation;Boosting","","","","60","CCBY","14 Apr 2025","","","IEEE","IEEE Journals"
"On the Transferability of Adversarial Attacks from Convolutional Neural Networks to Variants of ChatGPT4","N. Bunzel","Fraunhofer SIT / ATHENE / TU Darmstadt, Darmstadt, Germany",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),"14 Jul 2025","2025","","","250","255","This research evaluates the ability of adversarial attacks, primarily designed for CNN-based classifiers, to target the multimodal image captioning tasks executed by large vision language models, such as ChatGPT4. The study included different versions of ChatGPT4, several attacks, with a particular emphasis on the Projected Gradient Descent (PGD) attack, considering various parameters, surrogate models, and datasets. Initial but limited experiments support the hypothesis that PGD attacks are partly transferable to ChatGPT4. Subsequently, results demonstrated that PGD attacks could be adaptively transferred to disrupt the normal functioning of ChatGPT. On the other hand, other adversarial attack strategies showed a limited ability to compromise ChatGPT. These findings provide insights into the security vulnerabilities of emerging neural network architectures used for generative AI. Moreover, they underscore the possibility of cost-effectively crafting adversarial examples against novel architectures, necessitating the development of robust defense mechanisms for large vision language models in practical applications.","2325-6664","979-8-3315-1205-7","10.1109/DSN-W65791.2025.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071551","Adversarial Attack;Transfer Attacks;Black Box Attacks;Multimodal Models;CNN;ChatGPT4","Hands;Adaptation models;Generative AI;Conferences;Neural networks;Chatbots;Convolutional neural networks;Security","","","","40","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Spoofing-Jamming Attack Strategy Using Optimal Power Distributions in Wireless Smart Grid Networks","K. Gai; M. Qiu; Z. Ming; H. Zhao; L. Qiu","Department of Computer Science, Pace University, New York, NY, USA; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Software School, Henan University, Kaifeng, China; Nanjing Foreign Language School, Nanjing, China",IEEE Transactions on Smart Grid,"21 Aug 2017","2017","8","5","2431","2439","As an emerging fast-growing technology, smart grid networks (SGNs) have been dramatically accepted by the current power supply industry for achieving high performance power governance system. The wireless SGN (WSGNs) have enabled numerous flexible power management solutions without the restrictions of the wired infrastructure. The cognitive radio network (CRN) is one of the widely deployed wireless networking approaches. The communication security is a major concern while CRN is used in WSGNs. Currently, jamming and spoofing are two common attack approaches that are active in the deployment of WSGNs when using CRNs. This paper proposes an attack strategy, maximum attacking strategy using spoofing and jamming (MASS-SJ), which utilizes an optimal power distribution to maximize the adversarial effects. Spoofing and jamming attacks are launched in a dynamic manner in order to interfere with the maximum number of signal channels. Our proposed approach has been evaluated by our experiments and the results have shown the positive performance of using MAS-SJ.","1949-3061","","10.1109/TSG.2017.2664043","National Natural Science Foundation of China(grant numbers:61672358); NSF(grant numbers:CNS-1457506,CNS-1359557); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840056","Attack strategy;wireless smart grid network;jamming;spoofing;optimal power distribution","Jamming;Wireless communication;Smart grids;Communication system security;Phasor measurement units;Power distribution;Computer science","","156","","27","IEEE","2 Feb 2017","","","IEEE","IEEE Journals"
"Investigation of Protection Strategy for Microgrid System Using Lithium-Ion Battery During Islanding","H. F. Habib; M. M. Esfahani; O. A. Mohammed","Energy Systems Research Laboratory, Department of Electrical and Computer Engineering, Florida International University, Miami, FL, USA; Energy Systems Research Laboratory, Department of Electrical and Computer Engineering, Florida International University, Miami, FL, USA; Energy Systems Research Laboratory, Department of Electrical and Computer Engineering, Florida International University, Miami, FL, USA",IEEE Transactions on Industry Applications,"1 Jul 2019","2019","55","4","3411","3420","Microgrid protection schemes require a fast, reliable, and a robust communication system, to adjust relay settings for the appropriate current levels according to the microgrid's operation mode. However, risks of communication link failures and cyber security threats are major challenges for the implementation of protection scheme. This paper presents a co-simulation platform for microgrid based on multiagent system (MAS) when the communication is available in the system. IEC 61850 is used to emulate the proposed protection scheme. The data distribution service (DDS) middleware is used to link between the hardware and software environments. During islanded mode, the system is capable of riding-through communication failures by the aid of a lithium-ion battery. When the communication is attacked, the battery plays an important role and contribute to the fault current for helping the circuit breaker to trip during islanded mode. The design of the control algorithm for the battery's ac/dc converter is developed with single mode operation to eliminate the reliance on communicated control command signals to shift the controller between different modes.","1939-9367","","10.1109/TIA.2019.2904566","US Department of Energy; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665925","Control;data distribution service (DDS);distributed energy resources;IEC 61850;lithium-ion battery;microgrid;multi-agent system;protection","Microgrids;Circuit breakers;Batteries;Generators;Relays;Fault currents;Quality of service","","25","","27","IEEE","12 Mar 2019","","","IEEE","IEEE Journals"
"Providing a transparent dynamic organization technique for efficient aggregation of multiple JADE agent platforms","H. Abbas; S. Shaheen; M. Amin","Department of Electrical Engineering, Assiut University, Assiut, Egypt; Department of Computer Engineering, Cairo University, Giza, Egypt; Department of Electrical Engineering, Assiut University, Assiut, Egypt",2018 International Conference on Innovative Trends in Computer Engineering (ITCE),"15 Mar 2018","2018","","","100","108","JADE (Java Agent DEvelopment framework) is a popular agent development platform that is widely used to develop diverse agent-based real-life applications based on flat system architecture. It is considered as an agent-centered platform where agents are given the main focus and are implemented with a behavior-based architecture. This paper provides a transparent dynamic organization technique for efficiently aggregating multiple JADE platforms. The provided dynamic organization is described as transparent because it doesn't constrain the assumed autonomy and reactivity of JADE agents. It transparently and efficiently supports them in coordinating their interactions and locating each other based on the services they provide. The applicability of the provided technique is demonstrated by developing a large-scale consumer-provider application. A performance evaluation has been conducted which shows that compared to present techniques provided by JADE such as the federation of directory facilitators of multiple JADE platforms, the proposed technique gives about 47% performance improvement and is recommended to be used for dynamically, transparently, and efficiently aggregating multiple JADE platforms for developing large-scale MAS. Further research is recommended on the wide applicability, security, and proactive adaptation of the proposed technique.","","978-1-5386-0879-1","10.1109/ITCE.2018.8316607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316607","agent-centered agent platforms;JADE platform;dynamic organization;coordination and location;agent platforms aggregation;large-scale applications","Organizations;Tools;Containers;Power system dynamics;Java;Performance evaluation;Middleware","","2","","23","IEEE","15 Mar 2018","","","IEEE","IEEE Conferences"
"Improvement of Protection Scheme for Microgrids using Lithium- Ion Battery during Islanding","H. F. Habib; M. M. Esfahani; O. Mohammed","Department of Electrical and Computer Engineering, Florida International University, Miami, FL; Department of Electrical and Computer Engineering, Florida International University, Miami, FL; Department of Electrical and Computer Engineering, Florida International University, Miami, FL",2018 IEEE Industry Applications Society Annual Meeting (IAS),"29 Nov 2018","2018","","","1","8","Microgrid protection schemes require a fast, reliable and robust communication system, to adjust relay settings for the appropriate current levels according to the microgrid's operation mode. However, risks of communication link failures and cyber security threats are major challenges for the implementation of protection scheme. This paper presents a co-simulation platform for microgrid based on multiagent system (MAS) when the communication is available in the system. IEC 61850 is used to emulate the proposed protection scheme. The DDS middleware is used to link between the hardware and software environments. During islanded mode, the system is capable of riding-through communication failures by the aid of a lithium ion battery. A battery - as the main contributor to fault currents in the microgrid's islanded mode when the communication link fails to detect the shift to the islanded mode. The design of an autonomous control algorithm for the battery's AC/DC converter capable of operating when the microgrid is in both grid-connected and islanded mode. Utilizing a single mode of operation for the converter will eliminate the reliance on communicated control command signals to shift the controller between different modes.","2576-702X","978-1-5386-4536-9","10.1109/IAS.2018.8544559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8544559","control;DDS;distributed energy resources;IEC 61850;lithium ion battery;microgrid;multi agent system;protection","Microgrids;Circuit breakers;IEC Standards;Batteries;Relays;Generators;Quality of service","","1","","25","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Autonomous On-Device Protocols: Empowering Wireless with Self-Driven Capabilities","H. B. Pasandi; T. Nadeem","Department of Electrical Engineering and Computer Sciences, UC Berkeley; Department of Computer Science, Virginia Commonwealth University",2024 IEEE Wireless Communications and Networking Conference (WCNC),"3 Jul 2024","2024","","","1","6","This paper presents a study on applying on-device machine learning (ML) algorithms to enhance MAC layer protocols in wireless communications. It focuses on the MU-MIMO Grouping algorithm and explores the benefits of executing ML models directly on devices such as computers, smartphones, and IoT devices. This approach promises improved speed, privacy, security, and adaptability in dynamic networks. The paper evaluates the effectiveness of this strategy in Wi-Fi and Mas-sive MIMO scenarios, demonstrating significant system capacity enhancement, latency reduction, and improved user experience. Additionally, it examines the interaction between on-device ML and changing network environments, underscoring the method's adaptability and robustness. This research represents a significant advancement in MAC layer protocols using on-device ML and may inspire future innovations in wireless networks.","1558-2612","979-8-3503-0358-2","10.1109/WCNC57260.2024.10571037","U.S. National Science Foundation(grant numbers:OAC-2212424); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10571037","Medium Access Control;MU-MIMO;Machine Learning;Reinforcement Learning","Technological innovation;Protocols;Machine learning algorithms;Wireless networks;Heuristic algorithms;Media Access Protocol;User experience","","","","36","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"Co-pilots for Arrowhead-based Cyber-Physical System of Systems Engineering","C. Hegedűs; P. Varga","Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary",NOMS 2024-2024 IEEE Network Operations and Management Symposium,"2 Jul 2024","2024","","","1","6","One benefit of Large Language Model (LLM) based applications (e.g. chat assistants or co-pilots) is that they can bring humans closer to the loop in various IT and OT solutions. Co-pilots can achieve many things at once, i.e. provide a context-aware natural language interface to knowledge bases, reach various systems (via APIs), or even help solving multi-step problems with their planning and reasoning abilities. However, making production-grade chat assistants is a topical challenge, as fast-evolving LLMs expose new types of application design and security issues that need tackling. These especially rise to power when we try to apply these solutions to industrial automation use cases, as they need additional explainability and reliability engineered into the architecture. This paper describes the envisioned use cases and the findings of proof of concept copilots for the Cyber-Physical System of Systems (CPSoS) engineering domain. The paper suggests three types of copilots to support the stages throughout the CPSoS engineering lifecycle – and shows Proof-of-Concept scenarios for the Eclipse Arrowhead engineering process.","2374-9709","979-8-3503-2793-9","10.1109/NOMS59830.2024.10575845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575845","","Natural languages;Knowledge based systems;Cyber-physical systems;Systems engineering and theory;Reliability engineering;Cognition;Planning","","5","","27","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"ChatGPT Meets Iris Biometrics","P. Farmanifard; A. Ross","Michigan State University, USA; Michigan State University, USA",2024 IEEE International Joint Conference on Biometrics (IJCB),"11 Nov 2024","2024","","","1","10","This study utilizes the advanced capabilities of the GPT-4 multimodal Large Language Model (LLM) to explore its potential in iris recognition — a field less common and more specialized than face recognition. By focusing on this niche yet crucial area, we investigate how well AI tools like ChatGPT can understand and analyze iris images. Through a series of meticulously designed experiments employing a zero-shot learning approach, the capabilities of ChatGPT-4 was assessed across various challenging conditions including diverse datasets, presentation attacks, occlusions such as glasses, and other real-world variations. The findings convey ChatGPT-4’s remarkable adaptability and precision, revealing its proficiency in identifying distinctive iris features, while also detecting subtle effects like makeup on iris recognition. A comparative analysis with Gemini Advanced – Google’s AI model – highlighted ChatGPT-4’s better performance and user experience in complex iris analysis tasks. This research not only validates the use of LLMs for specialized biometric applications but also emphasizes the importance of nuanced query framing and interaction design in extracting significant insights from biometric data. Our findings suggest a promising path for future research and the development of more adaptable, efficient, robust and interactive biometric security solutions.","2474-9699","979-8-3503-6413-2","10.1109/IJCB62174.2024.10744525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744525","","Large language models;Face recognition;Zero shot learning;Focusing;Glass;Chatbots;Feature extraction;User experience;Security;Iris recognition","","2","","37","IEEE","11 Nov 2024","","","IEEE","IEEE Conferences"
"Towards LLM-Powered Ambient Sensor Based Multi-Person Human Activity Recognition","X. Chen; J. Cumin; F. Ramparany; D. Vaufreydaz","Orange Innovation, Grenoble, France; CNRS,Grenoble INP,LIG, Univ. Grenoble Alpes, Grenoble, France; Orange Innovation, Grenoble, France; CNRS,Grenoble INP,LIG, Univ. Grenoble Alpes, Grenoble, France",2024 IEEE 30th International Conference on Parallel and Distributed Systems (ICPADS),"28 Nov 2024","2024","","","609","616","Human Activity Recognition (HAR) is one of the central problems in fields such as healthcare, elderly care, and security at home. However, traditional ambient-sensor-based HAR approaches face challenges including data scarcity, difficulties in model generalization, and the complexity of recognizing activities in multi-person scenarios. This paper proposes a large-language-model-based framework called LAHAR which addresses HAR in multi-person scenarios. By endowing LLMs with inter-sensor relevance estimation and sensor-subject relevance estimation abilities, LAHAR can assign sensor events to the corresponding subjects. By providing action-level descriptions of sensor events and subsequently performing activity-level reasoning based on these descriptions, LAHAR is ultimately able to process data spanning several tens of hours with second-level resolution and results in an activity timeline for each subject. We validated LAHAR on the ARAS dataset. The results demonstrate that LAHAR achieves comparable accuracy to the state-of-the-art method at higher resolutions and maintains robustness in multiperson scenarios.","2690-5965","979-8-3315-1596-6","10.1109/ICPADS63350.2024.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763542","Human Activity Recognition;Large Language Model;Smart Home;IoT","Face recognition;Estimation;Medical services;Cognition;Robustness;Data models;Complexity theory;Human activity recognition;Security;Older adults","","2","","22","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"FDI attack detection and LLM-assisted resource allocation for 6G edge intelligence-empowered distribution power grid","Z. Sunxuan; Z. Hongshuo; Z. Wen; Z. Ruqi; Y. Zijia; Z. Zhenyu","State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University), Beijing 102206, China",China Communications,"6 Aug 2025","2025","22","7","58","73","The intelligent operation management of distribution services is crucial for the stability of power systems. Integrating the large language model (LLM) with 6G edge intelligence provides customized management solutions. However, the adverse effects of false data injection (FDI) attacks on the performance of LLMs cannot be overlooked. Therefore, we propose an FDI attack detection and LLM-assisted resource allocation algorithm for 6G edge intelligence-empowered distribution power grids. First, we formulate a resource allocation optimization problem. The objective is to minimize the weighted sum of the global loss function and total LLM fine-tuning delay under constraints of long-term privacy entropy and energy consumption. Then, we decouple it based on virtual queues. We utilize an LLM-assisted deep Q network (DQN) to learn the resource allocation strategy and design an FDI attack detection mechanism to ensure that fine-tuning remains on the correct path. Simulations demonstrate that the proposed algorithm has excellent performance in convergence, delay, and security.","1673-5447","","10.23919/JCC.fa.2024-0652.202507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119169","distribution power grids;false data injection (FDI) attack;large language model (LLM);resource allocation;6G edge intelligence","Resource management;6G mobile communication;Power grids;Optimization;Privacy;Entropy;Power system stability;Accuracy;Energy consumption;Delays","","","","","","6 Aug 2025","","","IEEE","IEEE Magazines"
"Malware Behavior Detection System with RAG-Enhanced eBPF and Advanced Language Model","S. Yu; Z. Li; J. Chen; X. Deng; C. Hou","State Grid Fujian Electric Power Research Institute, Fuzhou, Fujian, China; State Grid Fujian Electric Power Research Institute, Fuzhou, Fujian, China; State Grid Fujian Electric Power Research Institute, Fuzhou, Fujian, China; State Grid Fujian Fuzhou Electric Power Supply Company, Fuzhou, Fujian, China; School of Computer and Big Data, Minjiang University, Fuzhou, Fujian, China",2024 5th International Conference on Smart Grid and Energy Engineering (SGEE),"12 Feb 2025","2024","","","500","506","The article focuses on the malware threat within network security, especially the challenge of behavior detection on Linux systems. Traditional methods have limitations since static analysis is affected by various factors and dynamic analysis can be bypassed. To overcome these challenges, we propose an integrated approach using eBPF and language models. Its primary contributions are implementing malware behavior monitoring with eBPF for high-precision data collection, introducing a few-shot prompt-based log parsing and data structuring method to optimize inference, achieving integrated detection of malicious behavior using eBPF and LLMs to streamline log processing, and proposing an anomaly detection scheme with RAG-enhanced knowledge integration to improve the recognition of unknown behaviors and reduce training costs. Experiments involved identifying mining malware samples and behavior data from Virus Total and MalwareBazaar and executing them in a simulated Linux environment to analyze behavior. The results show that the accuracy reached 98.56%, and the introduction of RAG increased the recognition accuracy for unknown behavior logs by 15%.","","979-8-3315-3068-6","10.1109/SGEE64306.2024.10865871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10865871","Malicious mining malware;extended Berkeley Packet Filter;large language model;malware detection","Training;Accuracy;Costs;Linux;Static analysis;Network security;Data collection;Smart grids;Viruses (medical);Monitoring","","","","25","IEEE","12 Feb 2025","","","IEEE","IEEE Conferences"
"Can AI Fix Buggy Code? Exploring the Use of Large Language Models in Automated Program Repair","L. Zhang; A. Singhal; Q. Zou; X. Sun; P. Liu; H. -Y. Lin","Northern Arizona University, Flagstaff, AZ, USA; National Institute of Standards and Technology, Gaithersburg, MD, USA; University of Texas, Southwestern Medical Center, Dallas, TX, USA; Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA; The Pennsylvania State University, State College, PA, USA; Huawei France, France",Computer,"26 Jun 2025","2025","58","7","122","128","This article reviews the current human–large language models collaboration approach to bug fixing and points out the research directions toward (the development of) autonomous program repair artificial intelligence agents.","1558-0814","","10.1109/MC.2025.3527407","National Science Foundation(grant numbers:CNS-2019340,NSF ECCS-2140175,DGE2105801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052844","","","","","","37","IEEE","26 Jun 2025","","","IEEE","IEEE Magazines"
"Software Service Engineering in the Era of Large Language Models","X. Xia; Z. Jin; M. Aiello; D. Zhang; G. Liang; X. Hu",Huawei Technologies; Peking University; University of Stuttgart; Microsoft; Huawei Cloud; Zhejiang University,2024 IEEE International Conference on Software Services Engineering (SSE),"18 Sep 2024","2024","","","xxiii","xxiii","Large Language Models (LLMs) such as GPT-4, trained on massive amounts of natural language and source code data, have exhibited remarkable proficiency in automating many aspects of software development and maintenance. As a result, these models have been extensively applied to various Software Service Engineering (SSE) tasks, including software requirement analysis, software coding, software testing, and Artificial Intelligence for IT Operations (AIOps). Despite their widespread adoption, numerous challenges persist in fully utilizing LLMs for SSE, such as the need for integrating domain-specific knowledge to generate project-level code or patches effectively. Furthermore, there remains a lack of clarity on how traditional SSE practices can adapt to support the full lifecycle of LLMs, from the initial training and fine-tuning with domain-specific data to the ongoing inference, application, and maintenance (i.e., LLMOps). Effective LLMOps require new methodologies and tools to manage the unique demands of LLMs, including data handling, model updates, performance monitoring, and scalability. These challenges underscore the need for innovative approaches to manage the integration of LLM capabilities within established SSE frameworks.","","979-8-3503-6851-2","10.1109/SSE62657.2024.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664350","","","","1","","0","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"Software Testing in the Generative AI Era: A Practitioner’s Playbook","D. C. Schmidt","School of Computing, Data Sciences & Physics, William & Mary, Williamsburg, VA, USA",Computer,"26 Jun 2025","2025","58","7","147","152","This article presents a practitioner-focused playbook on how generative artificial intelligence is transforming software testing by automating tasks like test generation, simulation, and anomaly detection, while also introducing new challenges like hallucinations, bias, and nondeterminism.","1558-0814","","10.1109/MC.2025.3562940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052614","","","","","","10","IEEE","26 Jun 2025","","","IEEE","IEEE Magazines"
"Governing Agentic AI: Security, Identity, and Oversight in the Age of Autonomous Intelligent Systems","N. Kshetri","Bryan School of Business and Economics, University of North Carolina, Greensboro, NC, USA",Computer,"30 Jul 2025","2025","58","8","123","129","This article examines the governance and security challenges of deploying agentic artificial intelligence systems in organizations. It highlights the need for strategies to ensure compliance and mitigate risks.","1558-0814","","10.1109/MC.2025.3572173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11104161","","","","","","30","IEEE","30 Jul 2025","","","IEEE","IEEE Magazines"
"Pair Programming With Generative AI","D. Spinellis","Department of Management Science and Technology, Athens University of Economics and Business, Athens, Greece",IEEE Software,"5 Apr 2024","2024","41","3","16","18","Generative AI based on large-language models is significantly impacting software development through IDE assistants, cloud-based APIs, and interactive chatbots for coding assistance. It excels in generating and translating code and data, navigating APIs, and creating boilerplate content, thereby enhancing productivity. However, it is prone to generating inaccurate information (“hallucinations”), erroneous code, and potentially introducing security vulnerabilities. To counter these risks, employing automated analysis tools, conducting rigorous testing, and maintaining a deep understanding of computer science concepts are essential. While generative AI can substantially aid development tasks it is not a replacement for human expertise, especially in understanding complex software, its requirements, and architecture.","1937-4194","","10.1109/MS.2024.3363848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493185","","Generative adversarial networks;Artificial intelligence;Codes;Security;Navigation;Encoding;Large language models;Analytical models;Fake news;Information integrity;Human factors;Chatbots","","5","","4","IEEE","5 Apr 2024","","","IEEE","IEEE Magazines"
"Redefining Human Resource Practices With AI Agents and Agentic AI: Automated Compliance and Enhanced Productivity","N. Kshetri","University of North Carolina at Greensboro, Greensboro, NC, USA",Computer,"23 May 2025","2025","58","6","119","124","This article analyzes how agentic artificial intelligence is revolutionizing human resource management through automated workflows, enhanced decision making, and improved employee experiences while addressing implementation challenges like security risks, regulatory compliance, and workforce adoption.","1558-0814","","10.1109/MC.2025.3559245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014291","","","","1","","30","IEEE","23 May 2025","","","IEEE","IEEE Magazines"
"Generative AI Is Changing How and What We Learn","S. Eldh",NA,IEEE Software,"22 Feb 2024","2024","41","2","4","5","This issue is tackling the Future of Software Engineering Education and Training in the Age of AI. Generative AI tools will change how we learn. A new, more precise language is needed to communicate better with AI tools. Learn prompt engineering!— Sigrid Eldh, EIC IEEE Software.","1937-4194","","10.1109/MS.2023.3346069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10443799","","","","","","0","IEEE","22 Feb 2024","","","IEEE","IEEE Magazines"
"Citizen Development, Low-Code/No-Code Platforms, and the Evolution of Generative AI in Software Development","J. T. Sodano; J. F. DeFranco","EPAM Systems, Newtown, PA, USA; The Pennsylvania State University, University Park, PA, USA",Computer,"18 Apr 2025","2025","58","5","101","104","The demand for faster software solutions exceeds the supply of skilled software developers. More businesses will adopt citizen development frameworks and generative AI tools; however, this solution adds some challenges for project governance and security.","1558-0814","","10.1109/MC.2025.3547073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10970190","","","","","","16","IEEE","18 Apr 2025","","","IEEE","IEEE Magazines"
"Parallel Seeds: From Foundation Models to Foundation Intelligence for Agricultural Sustainability","L. Fu; S. Ling; D. Wu; M. Kang; F. -Y. Wang; H. Sun","Faculty of Electronic and Information Engineering, Shool of Automation Science and Engineering, Xi'an Jiaotong University, Xi'an, China; Faculty of Electronic and Information Engineering, Shool of Automation Science and Engineering, Xi'an Jiaotong University, Xi'an, China; College of Information Engineering, Northwest A&F University, Xianyang, China; State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China; Faculty of Electronic and Information Engineering, Shool of Automation Science and Engineering, Xi'an Jiaotong University, Xi'an, China",IEEE/CAA Journal of Automatica Sinica,"3 Mar 2025","2025","12","3","481","484","The development of agriculture faces significant challenges due to population growth, climate change, land depletion, and environmental pollution, threatening global food security [1]. This necessitates the development of sustainable agriculture, where a fundamental step is crop breeding to improve agronomic or economic traits, e.g., increasing yields of crops while decreasing resource usage and minimizing pollution to the environment [2].","2329-9274","","10.1109/JAS.2024.124914","National Natural Science Foundation of China(grant numbers:62303372,GYKP034); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10909140","","","","","","18","","3 Mar 2025","","","IEEE","IEEE Journals"
"Mentor's Musings on Concerns, Challenges & Opportunities for Generative AI at the Edge in IoT","N. K. Narang","Technology Philanthropist, Ethicist, Innovation Standardization & Sustainability Evangelist",IEEE Internet of Things Magazine,"2 May 2024","2024","7","3","6","11","Generative AI (GenAI) is developing faster than ever - and it stands to have a profound impact on how we live and work. Today's cutting-edge generative AI is capable of astounding things-and also has serious flaws. It is a double edge sword. Like any other disruptive digital technology it has the capability to solve many complex problems while also capability to accidentally create the thing that we have been trying to prevent the whole time. Like other forms of AI, generative AI can influence a number of ethical issues and risks surrounding exponentially growing Carbon Footprint data privacy, security, policies and workforces; and generating misinformation, plagiarism, copyright infringements and harmful content…","2576-3199","","10.1109/MIOT.2024.10517510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10517510","","Generative AI;Internet of Things;Artificial intelligence;Security;Ethics;Data models;Biological system modeling;Cloud computing;Disruptive technologies;Market opportunities;Social implications of technology","","1","","0","IEEE","2 May 2024","","","IEEE","IEEE Magazines"
"Degenerative AI?","S. M. Bellovin","Columbia University, New York, NY, USA",IEEE Security & Privacy,"17 May 2024","2024","22","3","88","88","It is not secret that generative AI, especially in the form of large language models (LLMs), is extremely popular today. One might go so far as to say that it’s eaten the world. It may be a bubble, or it may last—though the death of cryptocurrencies has long been predicted, as I write this Bitcoin has just reached an all-time high value against the American dollar—but for now and at least the next few years, generative AI will be with us. As people who care about security and privacy, we need to understand the implications of it: is it good or bad for our field, and if the latter, what should we do about it? Ignoring it is not an option.","1558-4046","","10.1109/MSEC.2024.3385549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533723","","","","","","1","IEEE","17 May 2024","","","IEEE","IEEE Magazines"
"Prudence and Generative Artificial Intelligence","G. F. Hurlburt","University System of Maryland at Southern Maryland, California, MD, USA",IT Professional,"15 Apr 2025","2025","27","2","4","8","As we rush headlong into generative artificial intelligence (AI), which agentic AI is rapidly overtaking, we must pay attention to history’s lessons. This article examines what history has to offer regarding the scope, data integrity, security, and talent development of generative AI.","1941-045X","","10.1109/MITP.2025.3552883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10965549","","","","","","18","IEEE","15 Apr 2025","","","IEEE","IEEE Magazines"
"ICSE 2018 Sponsors and Supporters","",,2018 IEEE/ACM 13th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS),"30 Dec 2018","2018","","","19","19","The following topics are dealt with: adaptive systems; learning (artificial intelligence); security of data; optimisation; formal specification; software fault tolerance; multi-agent systems; formal verification; self-adjusting systems; Markov processes.","2157-2305","978-1-4503-5715-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8595372","","","","","","","","30 Dec 2018","","","IEEE","IEEE Conferences"
"Message from the PC Chairs, IEEE AITest 2024","M. Bhuyan; H. Chen","Department of Computing Science, Umeå University, Sweden; Department of Information Science, University of North Texas, USA",2024 IEEE International Conference on Artificial Intelligence Testing (AITest),"25 Sep 2024","2024","","","xi","xi","On behalf of the organizers, we are pleased to welcome you all to the 6th IEEE International Conference on Artificial Intelligence Testing (IEEE AITest), taking place in Shanghai, China, from July 15th to 18th, 2024. This conference presents a unique opportunity for experts from around the world to gather in the vibrant city of Shanghai. IEEE AITest is co-located within the IEEE CISOSE 2024 Congress, enabling participants to interact with researchers and practitioners from various disciplines, fostering the exchange of breakthrough ideas and potentially leading to major collaborative projects. The 32 submissions for IEEE AITest 2024 cover a wide range of topics, including AI testing, quality assurance of AI applications, and the ethical implications of AI. 9 submissions were desk-rejected by the PC chairs based on quality and relevance. All the other submissions were carefully reviewed by at least two of the 48 technical program committee members. A total of 10 papers were accepted as regular papers, 3 as short papers, and 2 as fast abstracts to be presented at the conference. The topics include testing large-language models, deep learning models, simulation-based AI testing, metamorphic testing for machine learning models, using machine learning methods for software application testing, testing autonomous driving systems, AI security verification, text classification, natural language processing, and testing Q&A systems.","2835-3560","979-8-3503-6505-4","10.1109/AITest62860.2024.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685200","","","","","","0","IEEE","25 Sep 2024","","","IEEE","IEEE Conferences"
"Rewriting the Unix Stream Editor in Rust [Adventures in Code]","D. Spinellis",NA,IEEE Software,"6 Aug 2025","2025","42","5","21","25","A legacy Unix stream editor implemented in C was reengineered in Rust to explore systems porting, Rust’s safety and abstraction features, and generative AI’s role in code conversion, testing, and refactoring. Benefits and challenges of each are systematically examined.","1937-4194","","10.1109/MS.2025.3579008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119110","","Software engineering;Codes;C languages;Central Processing Unit","","","","3","IEEE","6 Aug 2025","","","IEEE","IEEE Magazines"
"Super-conducting Tsetlin Machines and Neuromorphic Computing","D. Vasudevan; C. Kirst",NA; NA,2024 International Symposium on the Tsetlin Machine (ISTM),"24 Mar 2025","2024","","","1","1","Current trends in foundational models of AI have unleashed new challenges in system design to handle new generative AI applications. These systems when scaled will lead to highly memory intensive and communication congesting challenges which current Von-Neumann architectures cannot handle efficiently, leading to highly energy consuming systems. Alternative paradigms in computing, logic, architectures and devices are needed to tackle this energy crisis. Superconducting logic based systems are one of the promising venues to develop new directions to lower the energy consumption by several orders of magnitude. In this presentation, we will take a look at recent new and promising computing paradigms developed using superconducting electronics (SCE) and their advantages towards energy efficiency and scalability. After introducing super-conducting technologies, we will present our new computing model called Super- Tsetlin, a Superconducting Tsetlin Machine designed using superconducting RSFQ technology and demonstrate some applications. We will then discuss the superconducting Temporal Design for a set of hard compute problems and their benefits. Finally, we will introduce innovative meromorphic computing frameworks for high-performance and energy efficient computations, including neuromorphic oscillator networks and their implementations and applications in superconducting technology. We will conclude with a future vision towards building energy efficient systems for foundational models for AI and neuromorphic computing paradigms.","","979-8-3315-0498-4","10.1109/ISTM62799.2024.10931720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10931720","","","","","","","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"AI’s 10 to Watch, 2022","J. Dix; Z. Zhang","Clausthal University of Technology, Clausthal, Germany; Binghamton University, State University of New York, Binghamton, NY, USA",IEEE Intelligent Systems,"28 Apr 2023","2023","38","2","3","14","IEEE Intelligent Systems is promoting young and aspiring artificial intelligence (AI) scientists and recognizing the rising stars as “AI‘s 10 Watch.” This biennial 2022 edition is slightly different from the previous editions: We solicited submissions from individuals who had obtained their Ph.D. up to 10 years prior (as opposed to 5 years in all of the previous editions). This led to more applications of the highest quality. The selection committee finally had to select 10 outstanding contributors from a pool of 30+ highly competitive and strong nominations, which made the selection decisions rather difficult. After a careful and detailed selection process through many rounds of discussions via e-mails and live meetings, the committee voted unanimously on a short list of 10 top candidates who have all demonstrated outstanding achievements in different areas of AI. The selection was based solely on scientific quality, reputation, impact, and expert endorsements accumulated since their Ph.D. It is our honor and privilege to announce the following 2022 class of “AI’s 10 to Watch.”• Bo Li. She is working on trustworthy machine learning (ML) at the intersection of ML, security and privacy, and game theory. She was able to integrate domain knowledge and logical reasoning abilities into data-driven statistical ML models to improve learning robustness with guarantees, and she has designed scalable privacy-preserving data-publishing frameworks for high-dimensional data. Her work has provided rigorous guarantees for the trustworthiness of learning systems and been deployed in industrial applications. She is an assistant professor with the University of Illinois at Urbana-Champaign.• Tongliang Liu. He is working in the fields of trustworthy ML. His work in theories and algorithms of ML with noisy labels has led to significant contributions and influence in the fields of ML, computer vision, natural language processing (NLP), and data mining, as large-scale datasets in those fields are prone to suffering severe label errors. He is a senior lecturer at the School of Computer Science, University of Sydney, and a visiting associate professor at the Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence.• Liqiang Nie. He is the dean of and a professor with the School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen). He works on multimedia content analysis and search, with a particular emphasis on data-driven multimodal learning and knowledge-guided multimodal reasoning. He pioneered the explicit modeling of consistent, complementary, and partial alignment relationships among modalities.• Soujanya Poria. He is an assistant professor at Singapore University of Technology and Design (SUTD). His seminal research on fusing information from textual, audio, and visual modalities for diverse behavioral and affective tasks significantly improved systems reliant on multimodal data, paving the way to various novel research avenues. His latest works are on information extraction, vision–language reasoning, and understanding human conversations in terms of common sense-based, context-grounded causal explanations.• Deqing Sun. He is a staff research scientist at Google. He has made significant contributions to computer vision, in particular in motion estimation. His work on optical flow (“Classic+NL” and “PWC-Net”) has been very influential and has been powering commercial applications such as Super SloMo in NVIDIA’s RTX platform, Face Unblur, and Fusion Zoom on Google’s Pixel phone.• Yizhou Sun. She is a pioneer in heterogeneous information network (HIN) mining, with a recent focus on deep graph learning, neural symbolic reasoning, and providing neural solutions to multiagent dynamical systems. Her work has a wide spectrum of applications, ranging from e-commerce, health care, and material science to hardware design. She is currently an associate professor at the University of California, Los Angeles (UCLA).• Jiliang Tang. He is a University Foundation Professor at Michigan State University. He works on graph ML and trustworthy AI and their applications in education and biology. His contributions to these fields include highly cited algorithms, well-received systems, and popular books.• Zhangyang “Atlas” Wang. He works on efficient and reliable ML. Recently, his core research theme is to leverage, understand, and expand the role of sparsity, from classical optimization to modern neural networks (NNs), whose impacts span the efficient training/inference of large-foundation models, robustness and trustworthiness, generative AI, graph learning, and more.• Hongzhi Yin. He has worked on trustworthy data intelligence to turn data into privacy-preserving, robust, explainable, and fair intelligent services in various industries and scenarios. He is also a leading expert researching and developing next-generation intelligent systems and algorithms for lightweight on-device predictive analytics as well as recommendation and decentralized ML on massive and heterogeneous data. He is an associate professor and ARC Future Fellow at the University of Queensland.• Liang Zheng. He is a senior lecturer at the Australian National University and works on data-centric computer vision, where he seeks to improve the quality of training and validation data, predict test data difficulty without labels, and more. These efforts provide a complementary perspective to model-centric developments. He has also made significant contributions to object re-identification and the broader smart city initiative through the introduction of widely used benchmarks and baseline methods.","1941-1294","","10.1109/MIS.2023.3252919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10111517","","Intelligent systems;Artificial intelligence;Companies;Computer applications","","","","0","IEEE","28 Apr 2023","","","IEEE","IEEE Magazines"
"Intelligent and Autonomous Systems in Government","P. Dasgupta; D. Marriott; L. Li; P. Narayanan","Naval Research Laboratory, Washington, DC, USA; Defence Science and Technology Group, Adelaide, SA, Australia; Defence Research and Development Canada, Nepean, ON, Canada; DEVCOM Army Research Laboratory, Adelphi, MD, USA",IEEE Intelligent Systems,"12 Aug 2025","2025","40","4","5","7","Artificial intelligence (AI)-driven autonomous and intelligent systems are increasingly shaping human life, with government-led AI projects playing a crucial role in both enhancing societal well-being and influencing AI policy. Implementing AI at national or regional scales presents some unique challenges including ensuring widespread access across diverse populations, guaranteeing fairness and accountability, and effectively communicating the impact of these technologies to the public. Our special issue presents six articles highlighting real-world experiences from ongoing and recently concluded government projects. The articles describe research that leverage autonomy and intelligence for various initiatives including safeguarding citizens and infrastructure from drone-based aerial threats, inspecting civilian infrastructure, cyber-security, conversational AI and responsible use of AI. We envisage that these articles will guide researchers with insights and best practices for ethically and effectively deploying AI in diverse government projects worldwide.","1941-1294","","10.1109/MIS.2025.3586086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123570","","","","","","","IEEE","12 Aug 2025","","","IEEE","IEEE Magazines"
"The Rise of Accelerator-Based Data Centers: Opportunities and Challenges","C. Kachris; C. Z. Patrikakis","Department of Electrical and Electronics Engineering, University of West Attica, Egaleo, Greece; Department of Electrical and Electronics Engineering, University of West Attica, Athens, Greece",IT Professional,"7 Jan 2025","2024","26","6","4","9","Emerging applications such as generative artificial intelligence (AI) and deep neural networks are extremely computationally intensive, making traditional CPU-based infrastructure insufficient for handling complexity and scale. Accelerators like GPUs and field-programmable gate arrays have become essential to efficiently process the vast datasets and complex models that these applications require. Hyperscale data centers deploy thousands of accelerators to meet workload demand; however, as more enterprises recognize the strategic importance of owning and customizing their generative AI models, many are shifting toward deploying accelerator-based data centers on their premises. This shift presents unique opportunities, including improved data security, latency reduction, and the flexibility to customize models in-house. However, it also introduces significant challenges, including high initial capital expenditure, the need for specialized infrastructure and cooling solutions, and the complexity of managing these advanced resources. IT professionals need to analyze several factors (technological, economic, and operational) carefully before deploying accelerators in their premises.","1941-045X","","10.1109/MITP.2024.3506792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832449","","","","1","","14","IEEE","7 Jan 2025","","","IEEE","IEEE Magazines"
"News","E. Strickland; M. Hampson; C. Q. Choi; M. Anderson; M. S. Smith; E. Ackerman",NA; NA; NA; NA; NA; NA,IEEE Spectrum,"6 Sep 2024","2024","61","9","5","12","It's horrifyingly easy to insert anyone into deepfake pornography, thanks to today's generative AI tools. A 2023 report by Home Security Heroes (a company that reviews identity-theft protection services) found that it took just one clear image of a face and less than 25 minutes to create a 60-second deepfake pornographic video—for free.","1939-9340","","10.1109/MSPEC.2024.10669142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669142","","","","","","0","IEEE","6 Sep 2024","","","IEEE","IEEE Magazines"
"Addressing Exponential Scale Problems at Infosys","V. Setty",Infosys,"2023 IEEE 30th International Conference on High Performance Computing, Data, and Analytics (HiPC)","5 Apr 2024","2023","","","xxv","xxv","In this talk I am going to share the use cases for high performance computing for the many clients oflnfosys in the domains of Logistics, Finance, Pharma, Manufacturing andthe like. What are some of the problems of exponential size that we have encountered? And what are the technology solutions that Infosys has adopted to address these use cases? What is the role of Quantum Computing for example in this space? What is the potential of this technology for solving large problems of exponential scale in optimization, simulation, drug discovery, Cyber security and ML? These are some of the questions we will get to explore in this talk. Secondly, we will see the opportunities and challenges in using LLMs in the SDLC process. And lastly, we will discuss the challenges in using enterprise data for experimenting with new cutting edge OS/third party solutions. What worked for us, and what did not? Maybe your research and ideas can address some of the gaps we are facing. Come join this talk to explore opportunities on how best we can collaborate.","2640-0316","979-8-3503-8322-5","10.1109/HiPC58850.2023.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487087","","","","","","0","IEEE","5 Apr 2024","","","IEEE","IEEE Conferences"
"Ipek Ozkaya on Generative AI for Software Architecture","P. Raghavan","Maersk, Bangalore, Karnataka, India",IEEE Software,"4 Oct 2024","2024","41","6","141","144","In Episode 626 of “Software Engineering Radio,” Ipek Ozkaya, principal researcher and technical director of the Engineering Intelligent Software Systems Group at the Software Engineering Institute, Carnegie Mellon, discusses generative AI for software architecture with SE Radio host Priyanka Raghavan. The episode delves into fundamental definitions of software architecture and explores use cases in which generative AI can enhance architecture activities. The conversation spans from straightforward to challenging scenarios and highlights examples of relevant tooling. The episode concludes with insights on verifying the correctness of output for software architecture prompts and future trends in this domain. We provide summary excerpts next; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.—Robert Blumen and Karthik Vaidhyanathan","1937-4194","","10.1109/MS.2024.3441888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705676","","Software architecture;Generative AI;Computer architecture;Software systems;Market research;Interviews","","","","0","IEEE","4 Oct 2024","","","IEEE","IEEE Magazines"
"Table of contents","",,2017 Brazilian Conference on Intelligent Systems (BRACIS),"8 Jan 2018","2017","","","v","xii","The following topics are dealt with: machine learning; data mining; planning; scheduling; multi-agent systems; agent-based systems; deep learning; neural networks; evolutionary computation; metaheuristics; pattern recognition; cluster analysis; natural language processing; search; optimization; knowledge representation; and reasoning.","","978-1-5386-2407-4","10.1109/BRACIS.2017.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247012","","","","","","","IEEE","8 Jan 2018","","","IEEE","IEEE Conferences"
"Matthew Adams on AI Threat Modeling and STRIDE GPT","P. Raghavan","Maersk, Bangalore, Karnataka, India",IEEE Software,"7 Apr 2025","2025","42","3","157","160","In episode 648 of Software Engineering Radio, Matthew Adams, Head of Security Enablement at Citi, joins SE Radio host Priyanka Raghavan to explore the use of large language models in threat modeling, with a special focus on Matthew’s work, STRIDE GPT. The episode kicks off with an overview of threat modeling, its applications, and the stages of the development life cycle where it fits in. The episode further explores STRIDE methodology and STRIDE GPT in detail with practical examples and finally concludes with tips and tricks for optimizing tool outputs and advice on other open source projects that utilize generative AI to enhance cybersecurity. We provide summary excerpts next; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.—Robert Blumen and Karthik Vaidhyanathan.","1937-4194","","10.1109/MS.2025.3540515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10953344","","Threat modeling;Generative AI;Large language models;Interviews;Computer security;Software engineering","","","","0","IEEE","7 Apr 2025","","","IEEE","IEEE Magazines"
"Table of contents","",,2017 International Conference on Intelligent Computing and Control Systems (ICICCS),"11 Jan 2018","2017","","","1","15","The following topics are dealt with: data security; image processing; cryptography; cloud computing; mobile computing; ontologies; learning; support vector machines; evolutionary computation; software engineering; multi-agent systems; wireless sensor networks; traffic engineering computing; and decision trees.","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250779","","","","","","","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"Table of contents","",,2017 3rd IEEE International Conference on Cybernetics (CYBCONF),"20 Jul 2017","2017","","","1","6","The following topics are dealt with: face identification; SDN; robot vision; video classification; multi-agent systems; information security management system; electric vehicle charging stations; LTI MIMO discrete-time systems; personal health indicators; UAV swarm target tracking; hybrid cyber-physical systems; online feature selection; interactive multimedia system; 3D virtual objects selection; neural networks; microfluidics chip production; face biometrics; palmprint multimodal biometrics; mobile visualization platform; agriculture; pointillistic art; human gender classification; protein structure prediction; PPI network; spectral-spatial hyperspectral image destriping; object tracking; crowd preference mining; ELM-based privacy preserving protocol; smart tourism destinations; dynamic firmware updates; virtual reality; bioinformatics; drug repositioning; image enhancement; and phishing Web sites.","","978-1-5386-2201-8","10.1109/CYBConf.2017.7985742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985742","","","","","","","IEEE","20 Jul 2017","","","IEEE","IEEE Conferences"
"Table of contents","",,2017 IEEE Second Ecuador Technical Chapters Meeting (ETCM),"8 Jan 2018","2017","","","1","4","The following topics are dealt with: neural networks; machine learning; Internet; multi-agent systems; data security; image processing; video signal processing; and robotics.","","978-1-5386-3894-1","10.1109/ETCM.2017.8247539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247539","","","","","","","IEEE","8 Jan 2018","","","IEEE","IEEE Conferences"
