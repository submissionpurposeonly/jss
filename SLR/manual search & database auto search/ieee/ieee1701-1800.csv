"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"TabLinkLLM: An LLM-Based Approach for Entity Linking in Tabular Data","I. Jayawardene; R. Avogadro; A. Soylu; D. Roman","SINTEF AS, Oslo, Norway; SINTEF AS, Oslo, Norway; Kristiania University College, Oslo, Norway; SINTEF AS, Oslo, Norway",2024 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),"5 May 2025","2024","","","206","214","Entity linking (EL) involves identifying references to entities in source data, which can be structured or unstructured, and associating them with their respective records in a structured knowledge base. This technique is beneficial when applied to tabular data, facilitating tasks such as data integration, business intelligence, and the construction of knowledge graphs. Current EL algorithms for tabular data often face challenges such as ambiguity, heterogeneity, and limited context. In this paper, we propose TabLinkLLM - a generic approach for tabular data entity linking using Large Language Models (LLMs), specifically optimized through prompt engineering, retrieval-augmented generation, and fine-tuning. Our experimental comparisons with leading EL models reveal that while our approach does not outperform specialized EL models in terms of performance, the broad knowledge base of LLMs proves advantageous in addressing scenarios that these specialized models cannot handle.","","979-8-3315-0494-6","10.1109/WI-IAT62293.2024.00035","National Research Foundation of Korea(grant numbers:RS-2023-00268071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973362","Entity linking;Tabular data;Large language models;Knowledge graphs","Training;Computational modeling;Large language models;Retrieval augmented generation;Knowledge based systems;Switches;Knowledge graphs;Prompt engineering;Intelligent agents;Faces","","1","","52","IEEE","5 May 2025","","","IEEE","IEEE Conferences"
"Knowledge Augmented Significant Language Model-Based Chatbot for Explainable Diabetes Mellitus Prediction","M. Elfayoumi; M. AbouElazm; O. Mohamed; T. Abuhmed; S. El-Sappagh","Faculty of Computer Science and Engineering Galala University, Egypt; Faculty of Computer Science and Engineering Galala University, Egypt; Faculty of Computer Science, Goldsmith, UOL, United Kingdom; College of Computing and Informatics, Sungkyunkwan University, South Korea; Faculty of Computer Science and Engineering Galala University, Egypt",2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM),"4 Feb 2025","2025","","","1","8","This study proposes an innovative diabetes prediction chatbot that utilizes large language models (LLMs) to determine the likelihood of diabetes based on specific patient inputs. Unlike conventional machine learning models and in addition to providing precise, individualized, robust prediction of diabetes augmented by the percentage of its confidence, this chatbot provides detailed text-based explanations for its individual predictions and enhances user's understanding by retrieving and presenting similar cases using case-based reasoning techniques. Utilizing key health indicators such as hypertension status, heart disease presence, smoking history, BMI, HbA1c level, and blood glucose levels, the chatbot not only predicts the presence of diabetes but also educates users about the underlying reasons for each prediction. The system's explanation module promotes transparency and trust in the predictive process. The proposed architecture integrates the retrieval augmented generation (RAG) technique with prompt engineering across multiple LLMs, including Llama 3.1, GPT- 3.5, and Gemma2. This approach augments the chatbot's responses with contextually relevant data from similar past cases, thereby enhancing both relevance and accuracy. Furthermore, RAG minimizes LLM hallucinations while enhancing them with up-to-date, precise, personalized medical information. The objective of this chatbot is to offer healthcare professionals and patients a dependable, educational instrument for early detection of diabetes supported by transparent AI principles. This will have a positive effect on preventative healthcare measures.","","979-8-3315-0781-7","10.1109/IMCOM64595.2025.10857525","National Research Foundation of Korea(grant numbers:2021R1A2C1011198); MSIT; IITP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857525","Large Language Models;Diabetes Prediction;Retrieval Augmented Generation;Chatbot;Explainable AI;Clinical Decision Support Systems","Technological innovation;Accuracy;Large language models;Computational modeling;Retrieval augmented generation;Medical services;Predictive models;Chatbots;Diabetes;Medical diagnostic imaging","","","","30","IEEE","4 Feb 2025","","","IEEE","IEEE Conferences"
"Edge-Preserving Consensus via Non-Recursive Filters: A Parallel System Design","L. Rong; Y. Kan; X. Xie; G. -P. Jiang; S. Xu","School of Automation and Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Automation and Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Automation and Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China",IEEE Transactions on Circuits and Systems II: Express Briefs,"21 Dec 2022","2023","70","1","181","185","This brief studies the edge-preserving consensus problem in discrete-time multi-agent systems. An edge-based parallel system design method is proposed for designing the channel filters, which consist of the nominal elements and the masking elements. Firstly, the design criterions for the edge-preserving protocols are provided by discussing the edge sensitivity matrix of the stuided multi-agent system. It is shown that the design of the masking element is based on the single parameter of the nominal element and the  $\mathcal {H}_{\infty }$  norm of a collapsed system. Then, an algorithm for designing the heterogenous channel filters is provided, which is based on adopting a cascade realization of several subsystems.","1558-3791","","10.1109/TCSII.2022.3204942","Natural Science Foundation of Nanjing University of Posts and Telecommunications(grant numbers:NY220018,NY221083); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881550","Multi-agent system;edge-preserving consensus;channel filter;edge sensitivity matrix","Eigenvalues and eigenfunctions;Telecommunications;Sensitivity;Privacy;Multi-agent systems;Consensus protocol;Transfer functions","","3","","21","IEEE","8 Sep 2022","","","IEEE","IEEE Journals"
"Foundation Models for Transportation Intelligence: ITS Convergence in TransVerse","C. Zhao; X. Dai; Y. Lv; Y. Tian; Y. Ren; F. -Y. Wang","University of Chinese Academy of Sciences, Beijing, China; CASIA, Beijing, China; CASIA, Beijing, China; Waytous Incorporation, Beijing, China; North Automatic Control Technology Institute, Taiyuan, China; Macau University of Science and Technology, Macao, China",IEEE Intelligent Systems,"14 Feb 2023","2022","37","6","77","82","Smart cities are our aspiration for a better life where transportation intelligence is indispensable. Recent technological advances in intelligent transportation systems have opened up new possibilities for smart mobility in smart cities. Here we present TengYun, a transportation foundation model designed and developed with parallel learning and federated intelligence for our transportation metaverse called TransVerse. TengYun enables decentralized/distributed autonomous organizations with decentralized/ distributed operations, as well as various federated technologies, from federated security, federated control, federated management, federated services, to federated ecology for transportation intelligence in smart cities. An example for a federation of transportation transformers is discussed for illustrating the operating procedure of TengYun.","1941-1294","","10.1109/MIS.2022.3221342","National Natural Science Foundation of China(grant numbers:U1811463); Science and Technology Development Fund; Macau SAR(grant numbers:0050/2020/A1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10044573","","Smart cities;Metaverse;Biological system modeling;Transportation;Organizations;Intelligent transportation systems;Ecology","","26","","20","IEEE","14 Feb 2023","","","IEEE","IEEE Magazines"
"Balancing Security and Efficiency in GAI-Driven Semantic Communication: Challenges, Solutions, and Future Paths","Q. Zhang; J. Shi; W. Zeng; X. Xu; Z. Guan; S. Li; Z. Qin","School of Cyber Science and Technology, Beihang University, China; School of Cyber Science and Technology, Beihang University, China; School of Cyber Science and Technology, Beihang University, China; School of Cyber Science and Technology, Beihang University, China; School of Cyber Science and Technology, Beihang University, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, China; Department of Electronic Engineering, Tsinghua University, China",IEEE Network,"","2025","PP","99","1","1","The convergence of artificial intelligence (AI) and wireless communications has driven the emergence of semantic communication (SC), a paradigm that prioritizes context-aware semantic exchange over traditional bit-level transmission. Although enhancing efficiency and task-specific reliability, this advancing capability is accompanied by significant security challenges that remain underexplored. In this paper, we provide an overview of security challenges in SC systems, with a particular focus on the confidentiality, integrity, and availability of the wireless transmission and generative AI (GAI) models. To defend against risks of model confidentiality compromise and semantic feature leakage, we propose a solution integrating trusted execution environments (TEEs) for secure model inference and adversarial cryptography for the protection of semantics over realistic wireless channels. Test results show it achieves close-to-black-box attack resistance in model stealing effectiveness, and the BLEU scores of eavesdropping attackers are effectively reduced to below 0.1 across various SNR levels. Finally, we discuss potential open issues and solutions for enhancing the SC security, paving the way for future research in this critical area. The proposed framework demonstrates promising results in enhancing both model and data confidentiality, contributing to the development of secure SC systems for 6G networks.","1558-156X","","10.1109/MNET.2025.3578783","National Natural Science Foundation of China(grant numbers:62172025,62472019,T2425023); Open Research Project of the State Key Laboratory of Media Convergence and Communication(grant numbers:SKLMCC2023KF001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030612","Data security;generative artificial intelligence;network security;semantic communications","Semantics;Security;Wireless communication;Data models;Training;Communication system security;Accuracy;Feature extraction;Wireless sensor networks;Eavesdropping","","","","","IEEE","11 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification","M. Akyash; H. M. Kamali","Dept. of Electrical and Comp. Eng. (ECE), University of Central Florida, Orlando, US; Dept. of Electrical and Comp. Eng. (ECE), University of Central Florida, Orlando, US",2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"25 Sep 2024","2024","","","391","396","The rise of instruction-tuned Large Language Models (LLMs) marks a significant advancement in artificial intelligence (AI) (tailored to respond to specific prompts). Despite their popularity, applying such models to debug security vulnerabilities in hardware designs, i.e., register transfer language (RTL) modules, particularly at system-on-chip (SoC) level, presents considerable challenges. One of the main issues lies in the need for precisely designed instructions for pinpointing and mitigating the vulnerabilities, which requires substantial time and expertise from human experts. In response to this challenge, this paper proposes Self-HWDebug, an innovative framework that leverages LLMs to automatically create required debugging instructions. In Self-HWDebug, a set of already identified bugs from the most critical hardware common weakness enumeration (CWE) listings, along with mitigation resolutions, is provided to the framework, followed by prompting the LLMs to generate targeted instructions for such mitigation. The LLM-generated instructions are subsequently used as references to address vulnerabilities within the same CWE category but in totally different designs, effectively demonstrating the framework's ability to extend solutions across related security issues. Self-HWDebug significantly reduces human intervention by using the model's own output to guide debugging. Through comprehensive testing, Self-HWDebug proves not only to reduce experts' effort/time but also to even improve the Quality of the debugging process.","2159-3477","979-8-3503-5411-9","10.1109/ISVLSI61997.2024.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10682659","LLM;Hardware Security;Validation;CWE","Prevention and mitigation;Large language models;Hardware security;Computational modeling;Computer bugs;Debugging;Very large scale integration","","5","","25","IEEE","25 Sep 2024","","","IEEE","IEEE Conferences"
"Validation of LLM-Generated Object Co-Occurrence Information for Understanding Three-Dimensional Scenes","K. Gunji; K. Ohno; S. Kurita; K. Sakurada; R. Bezerra; S. Kojima; Y. Okada; M. Konyo; S. Tadokoro","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; National Institute of Informatics, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan",IEEE Access,"17 Dec 2024","2024","12","","186573","186585","This study delves into verifying the applicability of object co-occurrence information generated by a large-scale language model (LLM) to enhance a robot’s spatial ability to understand objects in the real world. Co-occurrence information is crucial in enabling robots to perceive and navigate their surroundings. LLM can generate object co-occurrence information based on the learned representations acquired from the learning process. However, the challenge lies in determining whether the co-occurrence gleaned from linguistic data can effectively translate to real-world object relationships, a concept yet to be thoroughly examined. After providing category information about a specific situation, this paper compares and evaluates the co-occurrence degree (co-occurrence coefficient) output by gpt-4-turbo-2024-04-09 (GPT-4) against the object pair data from the ScanNet v2 dataset. The results revealed that GPT-4 achieved a high recall of 0.78 across various situation categories annotated by ScanNet v2, although its precision was relatively low at an average of 0.29. The root mean square error of the co-occurrence coefficient was 0.31. While GPT-4 tends to output slightly higher co-occurrence coefficients, it effectively captures the overall co-occurrence patterns observed in the ScanNet v2 dataset. GPT-4 produced co-occurrence information for more objects than those available in ScanNet v2 while covering co-occurrences among objects within ScanNet v2. These results demonstrate that integrating co-occurrence data from different sources could enhance the ability to recognize real-world objects and potentially strengthen robot intelligence.","2169-3536","","10.1109/ACCESS.2024.3514473","Innovation and Technology Commission of the Hong Kong Special Administrative Region (HKSAR) Government under the InnoHK initiative; Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP1268578); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786984","Semantic scene understanding;large language models;co-occurrence validation;prompt engineering","Robots;Three-dimensional displays;Chatbots;Standards;Knowledge graphs;Semantics;Navigation;Market research;Data models;Data mining","","1","","28","CCBY","9 Dec 2024","","","IEEE","IEEE Journals"
"Automating Persona Generation: Leveraging ChatGPT-4 in Educational Digital Services","T. Wongabut; U. Ninrutsirikun; C. Arpnikanondt","School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand","2025 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT & NCON)","15 Apr 2025","2025","","","549","554","This research provides a preliminary study on automating user persona generation via ChatGPT-4 with a case study on educational digital services. Data were collected from 40 undergraduate students at one of Thailand’s science and technology higher education institutes through questionnaires and semi-structured interviews, with participants grouped via K-means clustering based on similar responses. The study relied on ChatGPT-4 to generate personas based on empathy maps, jobs-to-be-done analysis, and Hofstede’s cultural dimensions. The validity of the generated personas was assessed using SHapley Additive exPlanations to identify key influencing features, revealing that integrating cultural contexts enhances persona specificity and relevance. The findings demonstrate that personas generated through this approach accurately reflect unique traits of target clusters, while significantly reducing the time and resources required. This study highlights a practical method for using ChatGPT-4 to generate personas, focusing on Thai science and tech undergraduates. It shows how tailored data collection improves ChatGPT’s understanding of specific user groups. Future research could expand sample sizes and explore broader contexts to enable generalization of the approach to become a framework that works across multiple target users and application contexts. Additionally, exploring methods like hierarchical K-means may improve clustering accuracy. Incorporating expert evaluations using the Persona Perception Scale could further ensure the real-world applicability.","2768-4644","979-8-3315-4327-3","10.1109/ECTIDAMTNCON64748.2025.10962020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962020","ChatGPT;Human-Computer Interaction;Large Language Models;Prompt Engineering;User Persona","Accuracy;Large language models;Education;Psychology;Focusing;Data collection;Cultural differences;Reliability;Prompt engineering;Interviews","","","","29","IEEE","15 Apr 2025","","","IEEE","IEEE Conferences"
"Using ChatGPT to Generate Gendered Language","S. Soundararajan; M. N. Jeyaraj; S. J. Delany","School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland",2023 31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS),"20 Mar 2024","2023","","","1","8","Gendered language is the use of words that denote an individual's gender. This can be explicit where the gender is evident in the actual word used, e.g. mother, she, man, but it can also be implicit where social roles or behaviours can signal an individual's gender - for example, expectations that women display communal traits (e.g., affectionate, caring, gentle) and men display agentic traits (e.g., assertive, competitive, decisive). The use of gendered language in NLP systems can perpetuate gender stereotypes and bias. This paper proposes an approach to generating gendered language datasets using ChatGPT which will provide data for data-driven approaches for gender stereotype detection and gender bias mitigation. The approach focuses on generating implicit gendered language that captures and reflects stereotypical characteristics or traits of a particular gender. This is done by engineering prompts to ChatGPT that use gender-coded words from gender-coded lexicons. The evaluation of the datasets generated shows good instances of English-language gendered sentences that can be identified as those that are consistent with gender stereotypes and those that are contradictory. The generated data also shows strong gender bias.","","979-8-3503-6021-9","10.1109/AICS60730.2023.10470830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10470830","natural language processing;machine learning;large language models;ChatGPT;gendered language;prompt engineering;zero-shot prompting","Natural languages;Chatbots;Cognitive science;Artificial intelligence","","","","68","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Multi-Stage Retriever Model for Document Classification Using Fine Tuned Embedding Model","N. Amarnath; S. Tallam; P. Rasamsetty; D. Kumar","Infrrd.ai, Bengaluru, India; Infrrd.ai, Bengaluru, India; Infrrd.ai, San Jose, USA; Infrrd.ai, Bengaluru, India",2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC),"5 Mar 2025","2025","","","00209","00218","Accurate and efficient classification of business documents is essential for organizations to streamline operations and enhance data management. Traditional document classification methods, relying on manual feature extraction and annotation, often struggle with the diversity and complexity of business documents such as invoices, contracts, and financial reports. In this paper, we propose a novel approach that utilizes custom vector embeddings and predefined document classes to address these challenges. Our method leverages the semantic richness of vector embeddings to capture the inherent meanings and relationships within documents, enabling precise classification even in complex and nuanced contexts. By fine-tuning embedding models for retrieval tasks using a proprietary in-house dataset, we ensure the model's robustness and scalability across various document types. We demonstrate through extensive experiments that our approach achieves superior performance compared to traditional methods, offering a scalable, accurate, and interpretable solution for business document classification.","","979-8-3315-0769-5","10.1109/CCWC62904.2025.10903719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903719","Document Classification;Large language models;Knowledge based systems;Prompt engineering;Vector Embeddings","Training;Accuracy;Annotations;Scalability;Knowledge based systems;Semantics;Organizations;Vectors;Robustness;Tuning","","","","17","IEEE","5 Mar 2025","","","IEEE","IEEE Conferences"
"SecRAG: A Graph-Enhanced RAG Framework with Dynamic Prompt for Cybersecurity Applications","Y. Qiao; L. Li; F. Cheng; J. Zhang; J. Gao; H. Zhu","Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China",2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"23 Jun 2025","2025","","","2053","2058","In this paper, we introduce SecRAG, a novel Retrieval-Augmented Generation (RAG) system specifically designed for cybersecurity applications. SecRAG tackles fundamental challenges in context precision and domain-specific terminology through a dual-pronged approach: 1) a data augmentation method optimized for cybersecurity contexts, particularly addressing the RAG system's numerical information sensitivity limitations; and 2) an enhanced dual-level retrieval architecture that integrates graph-based knowledge representation and adaptive text indexing, incorporating a dynamic prompt weighting mechanism based on dual similarity metrics (δ1, δ2) for query relationship and output coherence assessment, to enable comprehensive information discovery. Experimental evaluation on the SecEval benchmark demonstrates that SecRAG achieves stantial improvements over conventional RAG implementations, with a 30% increase in vulnerability node recall rates and reduction in temporal confusion rate to 1.1%. The system has shown particular strengths in specialized areas, achieving overall accuracy rate of 72.02% on the SecEval benchmarks. Our framework effectively addresses the unique challenges of cybersecurity-focused RAG systems, particularly in handling precise numeric attributes and maintaining contextual coherence in multi-turn dialogues.","2768-1904","979-8-3315-1305-4","10.1109/CSCWD64889.2025.11033478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033478","Retrieval-Augmented Generation;Large Language Models;Cybersecurity;Knowledge Graphs;Prompt Engineering","Sensitivity;Terminology;Federated learning;Large language models;Retrieval augmented generation;Coherence;Knowledge graphs;Benchmark testing;Prompt engineering;Indexing","","","","26","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting","T. -O. Li; W. Zong; Y. Wang; H. Tian; Y. Wang; S. -C. Cheung; J. Kramer","The Hong Kong University of Science and Technology, Hong Kong, China; Northeastern University, Shenyang, China; Northeastern University, Shenyang, China; University of Luxembourg, Luxembourg, Luxembourg; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; Imperial College London, London, United Kingdom",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","14","26","Automated detection of software failures is an important but challenging software engineering task. It involves finding in a vast search space the failure-inducing test cases that contain an input triggering the software fault and an oracle asserting the incorrect execution. We are motivated to study how far this outstanding challenge can be solved by recent advances in large language models (LLMs) such as ChatGPT. However, our study reveals that ChatGPT has a relatively low success rate (28.8%) in finding correct failure-inducing test cases for buggy programs. A possible conjecture is that finding failure-inducing test cases requires analyzing the subtle differences (nuances) between the tokens of a program's correct version and those for its buggy version. When these two versions have similar sets of tokens and attentions, ChatGPT is weak in distinguishing their differences. We find that ChatGPT can successfully generate failure-inducing test cases when it is guided to focus on the nuances. Our solution is inspired by an interesting observation that ChatGPT could infer the intended functionality of buggy code if it is similar to the correct version. Driven by the inspiration, we develop a novel technique, called Differential Prompting, to effectively find failure-inducing test cases with the help of the compilable code synthesized by the inferred intention. Prompts are constructed based on the nuances between the given version and the synthesized code. We evaluate Differential Prompting on Quixbugs (a popular benchmark of buggy programs) and recent programs published at Codeforces (a popular programming contest portal, which is also an official benchmark of ChatGPT). We compare Differential Prompting with two baselines constructed using conventional ChatGPT prompting and Pynguin (the state-of-the-art unit test generation tool for Python programs). Our evaluation results show that for programs of Quixbugs, Differential Prompting can achieve a success rate of 75.0% in finding failure-inducing test cases, outperforming the best baseline by 2.6X. For programs of Codeforces, Differential Prompting's success rate is 66.7%, outperforming the best baseline by 4.0X.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00089","National Science Foundation of China(grant numbers:61932021,62141210); Fundamental Research Funds for the Central Universities(grant numbers:N2217005); State Key Lab. for Novel Software Technology; Nanjing University(grant numbers:KFKT2021B01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298538","failure-inducing test cases;large language models;program intention inference;program generation","Codes;Benchmark testing;Programming;Chatbots;Software;Test pattern generators;Task analysis","","35","","56","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"T-FREX: A Transformer-based Feature Extraction Method from Mobile App Reviews","Q. Motger; A. Miaschi; F. Dell'Orletta; X. Franch; J. Marco","Universitat Politecnica de Catalunya, Barcelona; ItaliaNLP Lab, Institute for Computational Linguistics “A. Zampolli” (CNR-ILC), Pisa; ItaliaNLP Lab, Institute for Computational Linguistics “A. Zampolli” (CNR-ILC), Pisa; Universitat Politecnica de Catalunya, Barcelona; Universitat Politecnica de Catalunya, Barcelona","2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","16 Jul 2024","2024","","","227","238","Mobile app reviews are a large-scale data source for software-related knowledge generation activities, including software maintenance, evolution and feedback analysis. Effective extraction of features (i.e., functionalities or characteristics) from these reviews is key to support analysis on the acceptance of these features, identification of relevant new feature requests and prioritization of feature development, among others. Traditional methods focus on syntactic pattern-based approaches, typically context-agnostic, evaluated on a closed set of apps, difficult to replicate and limited to a reduced set and domain of apps. Mean-while, the pervasiveness of Large Language Models (LLMs) based on the Transformer architecture in software engineering tasks lays the groundwork for empirical evaluation of the performance of these models to support feature extraction. In this study, we present T-FREX, a Transformer-based, fully automatic approach for mobile app review feature extraction. First, we collect a set of ground truth features from users in a real crowdsourced software recommendation platform and transfer them automatically into a dataset of app reviews. Then, we use this newly created dataset to fine-tune multiple LLMs on a named entity recognition task under different data configurations. We assess the performance of T- FREX with respect to this ground truth, and we complement our analysis by comparing T- FREX with a baseline method from the field. Finally, we assess the quality of new features predicted by T- FREX through an external human evaluation. Results show that T- FREX outperforms on average the traditional syntactic-based method, especially when discovering new features from a domain for which the model has been fine-tuned.","2640-7574","979-8-3503-3066-3","10.1109/SANER60148.2024.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589848","feature extraction;mobile apps;reviews;token classification;named entity recognition;large language models","Software maintenance;Reviews;Soft sensors;Named entity recognition;Syntactics;Feature extraction;Transformers","","7","","51","IEEE","16 Jul 2024","","","IEEE","IEEE Conferences"
"Assessing the Impact of GPT-4 Turbo in Generating Defeaters for Assurance Cases","K. K. Shahandashti; M. Sivakumar; M. M. Mohajer; A. B. Belle; S. Wang; T. C. Lethbridge","York University, Toronto, Canada; York University, Toronto, Canada; York University, Toronto, Canada; York University, Toronto, Canada; York University, Toronto, Canada; University of Ottawa, Ottawa, Canada",2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym:,"30 Jul 2024","2024","","","52","56","Assurance cases (ACs) are structured arguments that allow verifying the correct implementation of the created systems' non-functional requirements (e.g., safety, security). This allows for preventing system failure. The latter may result in catastrophic outcomes (e.g., loss of lives). ACs support the certification of systems in compliance with industrial standards, e.g., DO-178C and ISO 26262. Identifying defeaters-arguments that challenge these ACs - is crucial for enhancing ACs' robustness and confidence. To automatically support that task, we propose a novel approach that explores the potential of GPT-4 Turbo, an advanced Large Language Model (LLM) developed by OpenAI, in identifying defeaters within ACs formalized using the Eliminative Argumentation (EA) notation. Our preliminary evaluation assesses the model's ability to comprehend and generate arguments in this context and the results show that GPT-4 turbo is very proficient in EA notation and can generate different types of defeaters.","","979-8-4007-0536-6","10.1145/3650105.3652291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599567","Large Language Models;assurance cases;assurance defeaters;system certification;FM for Requirement Engineering","Terminology;Prevention and mitigation;Mission critical systems;Robustness;Safety;Security;Requirements engineering","","3","","38","","30 Jul 2024","","","IEEE","IEEE Conferences"
"A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems","W. Zhang; X. Kong; C. Dewitt; T. Braunl; J. B. Hong","The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia",2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW),"3 Dec 2024","2024","","","361","368","The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot’s understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings demonstrate a substantial overall improvement of approximately 30.8% in both attack detection and system performance with the implementation of robust defence mechanisms, highlighting their critical role in enhancing security and reliability in mission-oriented tasks.","2994-810X","979-8-3503-6704-1","10.1109/ISSREW63542.2024.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771340","LLM;Mobile Robot;Embodied AI;Security;Prompt Engineering","Navigation;System performance;Prevention and mitigation;Large language models;Conferences;Software reliability;Security;Mobile robots;Robots;Context modeling","","2","","29","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"Translation of Low-Resource COBOL to Logically Correct and Readable Java leveraging High-Resource Java Refinement","S. Gandhi; M. Patwardhan; J. Khatri; L. Vig; R. K. Medicherla",TCS Research; TCS Research; TCS Research; TCS Research; TCS Research,2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"30 Oct 2024","2024","","","46","53","Automated translation of legacy code to modern programming languages is the need of the hour for modernizing enterprise systems. This work specifically addresses automated COBOL to Java translation. Traditional rule-based tools for this perform statement-wise translation, overlooking possible modularization and refactoring of the source COBOL code to translate to human-readable target Java code. Our investigation reveals that state-of-the-art Large Language Models (LLMs) in the domain of code encounter difficulties with regard to logical correctness and readability when directly translating low-resource COBOL code to Java. To address these challenges, we propose an LLM-based workflow, leveraging temperature sampling and refinement-based strategies, to not only ensure logical correctness of the translation but also maximize the readability of the target Java code. We exploit the fact that, due to their extensive exposure to human-written Java codes during pre-training, the LLMs are more equipped with profound comprehension and capability for refining translated Java codes than COBOL to Java translation. With a dataset sourced from CodeNet, we perform sequential refinement of the translated high-resource Java code with execution-guided logic feedback followed by LLM-based readability feedback. We demonstrate that this yields better performance in terms of logical correctness (81.99% execution accuracy) and readability (0.610 score), than LLM based translation with test cases and readability guidance (60.25% and 0.539) or refinement of the translation task itself (77.95% and 0.572).CCS CONCEPTS• Computing methodologies → Machine translation; Neural networks; • Software and its engineering → Software evolution; Maintaining software.","","979-8-4007-0579-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734649","Code Translation;Low Resource Programming Languages;Large Language Models;Code Readability;Self-Refinement","Java;Codes;Accuracy;Large language models;Refining;Neural networks;Programming;Software;Logic;Machine translation","","2","","42","","30 Oct 2024","","","IEEE","IEEE Conferences"
"How Do So ware Developers Use ChatGPT? An Exploratory Study on GitHub Pull Requests","M. Chouchen; N. Bessghaier; M. Begoug; A. Ouni; E. A. AlOmar; M. Wiem Mkaouer","ETS Montreal, University of Quebec; ETS Montreal, University of Quebec; ETS Montreal, University of Quebec; ETS Montreal, University of Quebec; Stevens Institute of Technology; University of Michigan-Flint",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","212","216","Nowadays, Large Language Models (LLMs) play a pivotal role in software engineering. Developers can use LLMs to address software development-related tasks such as documentation, code refactoring, debugging, and testing. ChatGPT, released by OpenAI, has become the most prominent LLM. In particular, ChatGPT is a cutting-edge tool for providing recommendations and solutions for developers in their pull requests (PRs). However, little is known about the characteristics of PRs that incorporate ChatGPT compared to those without it and what developers usually use it for. To this end, we quantitatively analyzed 243 PRs that listed at least one ChatGPT prompt against a representative sample of 384 PRs without any ChatGPT prompts. Our findings show that developers use ChatGPT in larger, time-consuming pull requests that are five times slower to be closed than PRs that do not use ChatGPT. Furthermore, we perform a qualitative analysis to build a taxonomy of the topics developers primarily address in their prompts. Our analysis results in a taxonomy comprising 8 topics and 32 sub-topics. Our findings highlight that ChatGPT is often used in review-intensive pull requests. Moreover, our taxonomy enriches our understanding of the developer’s current applications of ChatGPT.CCS CONCEPTS• Software and its engineering → Collaboration in software development.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555786","Large Language Models;ChatGPT;Manual analysis;Mining Software Repositories;Pull Requests","Taxonomy;Documentation;Debugging;Chatbots;Software;Data mining;Task analysis","","1","","43","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Intelligent Cybersecurity Defense Strategies Based on Large Language Model Agents","D. Ye; Z. Wang; Y. Song; J. Liang","School of Cyber Science and Engineering, Xi'an Jiaotong University, Xi’an, China; School of Computer Science, China West Normal University, Nanchong, China; School of Software Engineering, Xi'an Jiaotong University, Xi’an, China; School of Computer and Information Engineering, Shanghai Second Polytechnic University, China","2025 2nd International Conference on Algorithms, Software Engineering and Network Security (ASENS)","27 May 2025","2025","","","225","228","As the complexity of cyberattacks continues to increase, traditional static defense strategies have shown significant limitations. This study proposes an intelligent cybersecurity defense framework based on large language model Agents, and conducts a comparative analysis of the effectiveness of various leading models in the cybersecurity defense domain. By developing an attack behavior model, designing an Agent decision-making mechanism, and constructing a defense strategy execution and evaluation system, we assess the defense performance of models such as GPT-4.5, Claude 3.7, LLaMA 3.3, and Gemini 2.0 under different attack scenarios. The experimental results demonstrate that defense strategies based on LLM Agents outperform traditional methods in terms of attack detection rate, response time, and false alarm rate. Furthermore, each model exhibits unique advantages in specific security contexts. This research provides new insights for the development of more adaptive and efficient cybersecurity defense systems.","","979-8-3315-2029-8","10.1109/ASENS64990.2025.11011130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011130","Large Language Models;Cybersecurity;Intelligent Defense;Agent Systems;Attack Detection","Analytical models;Large language models;Software algorithms;Decision making;Network security;Complexity theory;Time factors;Computer crime;Software engineering;Context modeling","","1","","13","IEEE","27 May 2025","","","IEEE","IEEE Conferences"
"Multi-Agent Interactive Game Simulation for Enhancing Child Safety","C. Valliyammai; K. Jennie; K. Rameshbabu; D. P. Prshanth","Department of Computer Science and Engineering College of Engineering, Guindy, Anna University, Chennai, India; Department of Computer Science and Engineering College of Engineering, Guindy, Anna University, Chennai, India; Department of Computer Science and Engineering College of Engineering, Guindy, Anna University, Chennai, India; Department of Computer Science and Engineering College of Engineering, Guindy, Anna University, Chennai, India",2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),"28 Nov 2024","2024","","","1355","1359","The proposed multi-agent interactive game simulation combines immersive storytelling with state-of-the-art language models as well as artificial intelligence (AI) characters that will help children to discover the enigmas behind derelict buildings reveal all its mysteries. The simulated personalities provide personalized advice which equips these little explorers with knowledge and security within an exciting virtual environment. Therefore, simulated dialogues between a kid and different characters found inside a dilapidated structure are created using the most advanced language types namely fine-tuned versions of Large Language Model (LLM). In their own unique ways each of the avatars in the game would give accurate direction or encouragement to the child. The design of AI system is put on a server that allows a seamless interaction between the child and virtual characters in real time. Their use of modern technologies empowers children select wisely while remaining secure in urban places. This proposed multi-agent interactive game simulation enhances child safety in derelict buildings by mimicking gameplay.","","979-8-3503-6841-3","10.1109/ICSSAS64001.2024.10760823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760823","Game;Non-Player Characters;Multi-agents;Large Language Models;Artificial Intelligence","Training;Adaptation models;Accuracy;Buildings;Games;Real-time systems;Safety;Artificial intelligence;Engines;Load modeling","","","","15","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Students' Perception of ChatGPT in Software Engineering: Lessons Learned from Five Courses","L. Baresi; A. De Lucia; A. Di Marco; M. Di Penta; D. Di Ruscio; L. Mariani; D. Micucci; F. Palomba; M. T. Rossi; F. Zampetti","Politecnico di Milano, Milano, Italy; University of Salerno, Fisciano, Italy; University of l'Aquila, L'Aquila, Italy; University of Sannio, Benevento, Italy; University of l'Aquila, L'Aquila, Italy; University of Milano - Bicocca, Milano, Italy; University of Milano - Bicocca, Milano, Italy; University of Salerno, Fisciano, Italy; University of Milano - Bicocca, Milano, Italy; University of Sannio, Benevento, Italy",2025 IEEE/ACM 37th International Conference on Software Engineering Education and Training (CSEE&T),"12 Jun 2025","2025","","","158","169","A few years after their release, Large Language Models (LLMs)-based tools are becoming an essential component of software education, as calculators are used in math courses. When learning software engineering (SE), the challenge is the extent to which LLMs are suitable and easy to use for different software development tasks. In this paper, we report the findings and lessons learned from using LLM-based tools-ChatGPT in particular-in five SE courses from four universities. After instructing students on the LLM potentials in SE and about prompting strategies, we ask participants to complete a survey and be involved in semi-structured interviews. The collected results report (i) indications about the usefulness of the LLM for different tasks, (ii) challenges to prompt the LLM, i.e., interact with it, (iii) challenges to adapt the generated artifacts to their own needs, and (iv) wishes about some valuable features students would like to see in LLM-based tools. Although results vary among different courses, also because of students' seniority and course goals, the perceived usefulness is greater for lowlevel phases (e.g., coding or debugging/fault localization) than for analysis and design phases. Interaction and code adaptation challenges vary among tasks and are mostly related to the need for task-specific prompts, as well as better specification of the development context.","2832-7578","979-8-3315-3709-8","10.1109/CSEET66350.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024336","Large Language Models for Software Engineering;Empirical Study;Software Engineering Education","Surveys;Location awareness;Codes;Large language models;Education;Software;Problem-solving;System analysis and design;Software engineering;Software development management","","","","34","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Privacy-Preserving Federated Learning Framework for Disease Progression Prediction via Temporal-Aware Large Language Modeling","F. Yue; R. Qiu; J. Li; G. Li","Department of Computer Science, China University of Petroleum-Beijing at Karamay, Karamay, China; Department of Computer Science, China University of Petroleum-Beijing at Karamay, Karamay, China; Department of Computer Science, China University of Petroleum-Beijing at Karamay, Karamay, China; Department of Computer Science, China University of Petroleum-Beijing at Karamay, Karamay, China",2025 International Conference on Sensor-Cloud and Edge Computing System (SCECS),"10 Jul 2025","2025","","","414","417","This study presents a novel federated learning approach for disease prediction by integrating the Chronos temporal large language model. The system addresses two critical challenges in public health management: data privacy protection and complex spatiotemporal modeling. Through a hierarchical federated architecture, the model enables collaborative learning across medical institutions without sharing raw data, ensuring compliance with privacy regulations such as GDPR. The Chronos model’s innovative temporal discretization and dual-stream attention mechanism effectively capture disease transmission patterns across different regions and time scales. Experimental results demonstrate that our system achieves a 21.4% improvement in prediction accuracy compared to traditional methods, while maintaining robust privacy protection with a reconstruction accuracy below 12.4% under various attack scenarios. The model’s practical value is validated through successful deployment in vaccine distribution optimization, achieving a 12.6% increase in coverage rate and reducing high-risk community response time by 3.2±0.8 days. This research provides a reliable technical foundation for public health decision-making while ensuring data security and privacy protection.","","979-8-3315-2068-7","10.1109/SCECS65243.2025.11065627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065627","Federated Learning;Disease Prediction;Large Language Models;Privacy Protection;Public Health","Data privacy;Privacy;Accuracy;Federated learning;Large language models;Predictive models;Data models;Protection;Public healthcare;Diseases","","","","18","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"Research on Commercial Cryptography Large Language Model Based on Retrieval Augmented Generation and Low-Rank Adaptation Technology","H. Wen; Y. Cao; W. Zhang; S. Wang; X. Dai; H. Fu","CNCERT Shaanxi Branch, Xi’an, China; CNCERT Shaanxi Branch, Xi’an, China; CNCERT Shaanxi Branch, Xi’an, China; CNCERT Shaanxi Branch, Xi’an, China; CNCERT Shaanxi Branch, Xi’an, China; CNCERT Shaanxi Branch, Xi’an, China","2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)","13 Mar 2025","2024","","","1074","1079","As large language model technology improves by leaps and bounds, artificial intelligence has been initially applied in the field of the law and medical education. However, commercial passwords have not been widely used, resulting in the failure of information security of citizens and enterprises. This paper proposes a large language model of commercial cryptography based on search retrieval augmented generation and low-rank adaptation technology, aiming to improve the application of commercial passwords. The results show that the model is more effective than GPT4 in answering questions in the field of commercial cryptography.","","979-8-3315-4169-9","10.1109/RICAI64321.2024.10911095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911095","component;Large Language Models;Fine-tuning;Retrieval Augmented Generation","Large language models;Retrieval augmented generation;Knowledge based systems;Education;Training data;Information security;Passwords;Cryptography;Robots;Intelligent control","","","","15","IEEE","13 Mar 2025","","","IEEE","IEEE Conferences"
"CORAAL QA: A Dataset and Framework for Open Domain Spontaneous Speech Question Answering from Long Audio Files","N. B. Shankar; A. Johnson; C. Chance; H. Veeramani; A. Alwan","Department of Electrical and Computer Engineering, University of California, Los Angeles; Department of Electrical and Computer Engineering, University of California, Los Angeles; Department of Computer Science, University of California, Los Angeles; Department of Electrical and Computer Engineering, University of California, Los Angeles; Department of Electrical and Computer Engineering, University of California, Los Angeles","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","13371","13375","This paper presents a novel dataset (CORAAL QA) and framework for audio question-answering from long audio recordings containing spontaneous speech. The dataset introduced here provides sets of questions that can be factually answered from short spans of a long audio files (typically 30min to 1hr) from the Corpus of Regional African American Language. Using this dataset, we divide the audio recordings into 60 second segments, automatically transcribe each segment, and use PLDA scoring of BERT-based semantic embeddings to rank the relevance of ASR transcript segments in answering the target question. In order to improve this framework through data augmentation, we use large language models including ChatGPT and Llama 2 to automatically generate further training examples and show how prompt engineering can be optimized for this process. By creatively leveraging knowledge from large-language models, we achieve state-of-the-art question-answering performance in this information retrieval task.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447109","Spoken Question Answering;Large Language Models;Automatic Speech Recognition;Spoken Language Understanding","Training;Adaptation models;Training data;Speech recognition;Data augmentation;Information retrieval;Audio recording","","","","29","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"Towards Responsible Generative AI: A Reference Architecture for Designing Foundation Model Based Agents","Q. Lu; L. Zhu; X. Xu; Z. Xing; S. Harrer; J. Whittle","Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia",2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C),"21 Aug 2024","2024","","","119","126","Foundation models, such as large language models (LLMs), have been widely recognised as transformative AI technologies due to their capabilities to understand and generate content, including plans with reasoning capabilities. Foundation model based agents derive their autonomy from the capabilities of foundation models, which enable them to autonomously break down a given goal into a set of manageable tasks and orchestrate task execution to meet the goal. Despite the huge efforts put into building foundation model based agents, the architecture design of the agents has not yet been systematically explored. Also, while there are significant benefits of using agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability. Therefore, this paper presents a pattern-oriented reference architecture that serves as guidance when designing foundation model based agents. We evaluate the completeness and utility of the proposed reference architecture by mapping it to the architecture of two real-world agents.","2768-4288","979-8-3503-6625-9","10.1109/ICSA-C63560.2024.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628258","Foundation model;large language model;LLM;agent;architecture;pattern;responsible AI;AI safety","Software architecture;Generative AI;Large language models;Computer architecture;Software quality;Cognition;Safety","","5","","69","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Joint Optimization of Prompt Security and System Performance in Edge-Cloud LLM Systems","H. Huang; T. Meng; W. Jia","Institute of Artificial Intelligence and Future Networks, Beijing Normal University, Zhuhai, China; Department of Computer Science, BNU-HKBU United International College, Zhuhai, China; Institute of Artificial Intelligence and Future Networks, Beijing Normal University, Zhuhai, China",IEEE INFOCOM 2025 - IEEE Conference on Computer Communications,"1 Jul 2025","2025","","","1","10","Large language models (LLMs) have significantly facilitated human life, and prompt engineering has improved the efficiency of these models. However, recent years have witnessed a rise in prompt engineering-empowered attacks, leading to issues such as privacy leaks, increased latency, and system resource wastage. Though safety fine-tuning based methods with Reinforcement Learning from Human Feedback (RLHF) are proposed to align the LLMs, existing security mechanisms fail to cope with fickle prompt attacks, highlighting the necessity of performing security detection on prompts. In this paper, we jointly consider prompt security, service latency, and system resource optimization in Edge-Cloud LLM (EC-LLM) systems under various prompt attacks. To enhance prompt security, a vector-database-enabled lightweight attack detector is proposed. We formalize the problem of joint prompt detection, latency, and resource optimization into a multi-stage dynamic Bayesian game model. The equilibrium strategy is determined by predicting the number of malicious tasks and updating beliefs at each stage through Bayesian updates. The proposed scheme is evaluated on a real implemented EC-LLM system, and the results demonstrate that our approach offers enhanced security, reduces the service latency for benign users, and decreases system resource consumption compared to state-of-the-art algorithms.","2641-9874","979-8-3315-4305-1","10.1109/INFOCOM55648.2025.11044720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044720","Prompt attack;edge-cloud;LLM;resource optimization;Bayesian game","Image edge detection;System performance;Games;Detectors;Dynamic scheduling;Bayes methods;Safety;Security;Resource management;Optimization","","","","34","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Generative Artificial Intelligence: Transforming the Future","K. R","Department of Computational Intelligence, SRM Institute of Science and Technology, Kattankulathur, India",2024 International Conference on Emerging Technologies and Innovation for Sustainability (EmergIN),"21 Apr 2025","2024","","","448","453","We are at the dawn of a new area of AI: Generative Artificial Intelligence (AI), which holds the potential to automate and generate in ways never before possible and can be applied across countless disciplines from natural language processing (NLP) to image synthesis, interactive simulations, and more. Generative models like Generative Adversarial Networks and transformers, as well as cutting edge AI tools such as GitHub Copilot, DALL-E, Gemini, and Bing Copilot have made content generation a different game. From realizing intelligent code generation, realistic image synthesis, or personalized search, these tools are transforming industries to software development and digital art, to search engines. In this paper we present a comprehensive survey of generative AI technologies and the methodologies behind these technologies, including attention mechanisms, variational autoencoders, diffusion models, and transformer-based models such as GPT and BERT. The paper also discusses the implementation of generative AI across Augmented Reality and Virtual Reality, highlighting how the use of AI to generate content is revolutionizing the interactive experiences in gaming, education, and training. In the study we also perform performance evaluations of generative AI models on benchmark datasets using BLEU, ROUGE scores etc. We discuss some of the challenges facing generative AI on ethical, computational, and too-often opaque lines and predict that generative AI can transform industries by creating autonomous creativity and personalized learning.","","979-8-3503-9126-8","10.1109/EmergIN63207.2024.10961802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10961802","Large Language Models;Artificial Intelligence;Generative Artificial Intelligence;GPT-4 and Beyond","Industries;Training;Solid modeling;Technological innovation;Generative AI;Image synthesis;Transforms;Transformers;Natural language processing;Software development management","","","","18","IEEE","21 Apr 2025","","","IEEE","IEEE Conferences"
"Cyber-physical production systems for SMEs-A generic multi agent based architecture and case study","H. Najjari; M. Seitz; E. Trunzer; B. Vogel-Heuser","KNOSPA GmbH & Co. KG, Munich, Germany; Automation and Information Systems Technical University of Munich, Garching, Germany; Automation and Information Systems Technical University of Munich, Garching, Germany; Automation and Information Systems Technical University of Munich, Garching, Germany",2021 4th IEEE International Conference on Industrial Cyber-Physical Systems (ICPS),"5 Jul 2021","2021","","","625","630","One of the major challenges that SMEs (small and medium enterprises) face when it comes to the implementation of Industry 4.0 is the high technological complexity and consequently the high investment and operation cost to be expected as well as the need for highly qualified specialists to operate and maintain such complex systems. This paper presents a generic CPPS (cyber-physical production system) architecture that copes with SMEs specific challenges and simplifies the implementation of the Industry 4.0 paradigm in real world applications. The proposed CPPS architecture has been validated in an industrial pilot application. The COSMIXER-CPPS is able to control devices with different interfaces and protocols as well as to communicate with external databases and web-services. The unified communication middleware within the CPPS enables furthermore the reconfiguration and scaling of the system with minimal disruption. This research is a contribution to reduce inhibitions towards the implementation of Industry 4.0 in SMEs, further research has to be carried out to investigate and enhance the dependability, security, real-time capability and performance of SME-friendly CPPS.","","978-1-7281-6207-2","10.1109/ICPS49255.2021.9468232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9468232","cyber-physical production systems;CPPS;Industry 4.0;multi-agent systems;MAS;small and medium enterprises;SMEs","Production systems;Protocols;Databases;Ecosystems;Real-time systems;Complexity theory;Security","","5","","19","IEEE","5 Jul 2021","","","IEEE","IEEE Conferences"
"Elevating Crop Protection: Vision Transformer Models for Brassica Black Rot Detection","V. Kukreja; V. Sharma; R. Sharma","Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India; Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India","2024 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)","20 Mar 2024","2024","","","1","5","The agricultural sector is currently faced with the urgent problem of reducing the incidence of crop diseases to maintain food security and environmentally responsible farming practices. Among these, the Brassica black rot disease poses a considerable risk to crops in the Brassicaceae family, which includes several different cabbage and broccoli varieties. This study aims to revolutionize the diagnosis and classification of Brassica black rot disease at varied severity levels by tapping into the capabilities of cutting-edge deep learning (DL) techniques, more specifically ViT models. This study is based on a rigorously curated dataset that contains 5,000 high-resolution photos of Brassica leaves. These images have been categorized into six different severity levels, ranging from ""Class 0"" to ""Class 5"", and the researchers have annotated each of these images. The accuracy and reliability of the annotations were ensured under the oversight of seasoned plant pathologists. To aid in the evaluation and development of the model, a training set, a validation set, and a test set were meticulously collected from the dataset. As our research developed, the ViT-based model, a sophisticated DL architecture, became the key focus of our attention. Excellent accuracy was achieved in classifying the varying degrees of disease severity by meticulous training and tuning the model using the dataset containing cases of Brassica black rot. By incorporating Cohen's Upsilon (), a new performance indicator, we gained a more nuanced understanding of the model's propensity to correctly classify diseases. That was possible because of the additional context provided regarding the model's propensity to correctly classify diseases. Our research showed that the ViT-based model achieved a fantastic level of classification accuracy, with an average rate of 96.17%. In addition, the significant Cohen's Upsilon value of 0.94 demonstrated that the model was able to distinguish between different degrees of severity of Brassica black rot with a high level of concordance.","","979-8-3503-0641-5","10.1109/IITCEE59897.2024.10467942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467942","Brassica Black Rot;Disease Detection;Vision Transformer;Deep Learning;Machine Learning;Precision Agriculture;Crop Protection;Agriculture Technology","Training;Biological system modeling;Instruments;Crops;Food security;Predictive models;Transformers","","2","","17","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Identifying missing relationships of CAPEC attack patterns by transformer models and graph structure","R. Miyata; H. Washizaki; K. Sumoto; N. Yoshioka; Y. Fukazawa; T. Okubo","Waseda University, Japan; Waseda University, Japan; Waseda University, Japan; Waseda University, Japan; Waseda University, Japan; Institute of Information Security, Japan",2023 IEEE/ACM 1st International Workshop on Software Vulnerability (SVM),"27 Jul 2023","2023","","","14","17","As threats to software vulnerabilities diversify, countermeasures against various threat patterns become more critical. The Common Attack Pattern Enumeration and Classification (CAPEC) is a catalog of security attack patterns that helps understand what attacks can be launched against these vulnerabilities. CAPEC defines relationships between attack patterns, but these are manually associated so that some may be missed. This paper proposes a method to identify missed relationships using the transformer model and existing relational graph structures. Specifically, pre-trained models are fine-tuned using BERT and Longformer based on the names and descriptions of the two attack patterns and their relationships. Then missed relationships are identified by the classification task, and graph structure rules are defined for the identified relations to determine whether they are graph-structurally correct. Finally, whether the relations are semantically correct is verified. Our evaluation found that 41 likely relationships were missed.","","979-8-3503-0190-8","10.1109/SVM59160.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10190618","CAPEC;relation prediction;Transformer;BERT;Longformer","Support vector machines;Conferences;Bit error rate;Predictive models;Transformers;Software;Security","","1","","17","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Leveraging ChatGPT to Enhance Computational Thinking Learning Experiences","A. Ouaazki; K. Bergram; A. Holzer","Information Management Institute, University of Neuchâtel, Neuchâtel, Switzerland; Information Management Institute, University of Neuchâtel, Neuchâtel, Switzerland; Information Management Institute, University of Neuchâtel, Neuchâtel, Switzerland","2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)","26 Jan 2024","2023","","","1","7","Given the pervasive reliance on technology in modern society, teaching Computational Thinking (CT) abilities is becoming increasingly relevant. These abilities, such as modeling and coding, have become crucial for a larger audience of students, not only those who wish to become software engineers or computer scientists. Recent advances in Large Language Models (LLMs), such as ChatGPT, provide powerful assistance to complete computational tasks, by simplifying code generation and debugging, and potentially enhancing interactive learning. However, it is not clear if these advances make CT tasks more accessible and inclusive for all students, or if they further contribute to a digital skills divide, favoring the top students. To address this gap, we have created and evaluated a novel learning scenario for transversal CT skills that leveraged LLMs as assistants. We conducted an exploratory field study during the spring semester of 2022, to assess the effectiveness and user experience of LLM-augmented learning. Our results indicate that the usage of ChatGPT as a learning assistant improves learning outcomes. Furthermore, contrary to our predictions, the usage of ChatGPT by students does not depend on prior CT capabilities and as such does not seem to exacerbate prior inequalities.","","978-1-6654-5331-8","10.1109/TALE56641.2023.10398358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398358","Large Language Models;Interactive Learning Environments;Collaborative Learning;Human-Computer Interaction","Computational modeling;Education;Chatbots;User experience;Software;Task analysis;Springs","","1","","31","IEEE","26 Jan 2024","","","IEEE","IEEE Conferences"
"CodeFuse-13B: A Pretrained Multi-Lingual Code Large Language Model","P. Di; J. Li; H. Yu; W. Jiang; W. Cai; Y. Cao; C. Chen; D. Chen; H. Chen; L. Chen; G. Fan; J. Gong; Z. Gong; W. Hu; T. Guo; Z. Lei; T. Li; Z. Li; M. Liang; C. Liao; B. Liu; J. Liu; Z. Liu; S. Lu; M. Shen; G. Wang; H. Wang; Z. Wang; Z. Xu; J. Yang; Q. Ye; G. Zhang; Y. Zhang; Z. Zhao; X. Zheng; H. Zhou; L. Zhu; X. Zhu","Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China; Ant Group, China",2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"18 Jun 2024","2024","","","418","429","Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering. However, the effectivness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied. This paper introduces CODEFuSE-13B, an open-sourced pre-trained code LLM 2. It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages. CODEFUSE achieves its effectiveness by utilizing a high-quality pre-training dataset that is carefully filtered by program analyzers and optimized during the training process. Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HUMANEvAL-x, and the specially designed CODEFUSEEvAL for Chinese prompts. To assess the effectiveness of CODEFUSE, we actively collected valuable human feed-back from the AntGroup's software development process where CODEFUSE has been successfully deployed. The results demonstrate that CODEFUSE-13B achieves a HUMANEvAL pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes. In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CODEFUSE performs better than other models when confronted with Chinese prompts.","2832-7659","979-8-4007-0501-4","10.1145/3639477.3639719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554734","code large language models;multi-lingual;Chinese prompts","Training;Industries;Computer languages;Codes;Benchmark testing;Task analysis;Software engineering","","","","55","","18 Jun 2024","","","IEEE","IEEE Conferences"
"(POSTER) Visual Transformer Models on UAV-Captured Images for Person Detection","I. . -. G. Zahia; D. Popescu; L. Ichim","Faculty of Automatic Control and Computer Science, National University of Science and Technology POLITEHNICA Bucharest, Bucharest, Romania; Faculty of Automatic Control and Computer Science, National University of Science and Technology POLITEHNICA Bucharest, Bucharest, Romania; Faculty of Automatic Control and Computer Science, National University of Science and Technology POLITEHNICA Bucharest, Bucharest, Romania",2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT),"12 Aug 2024","2024","","","759","761","One of the most important applications of UAVs is person detection for security or rescue tasks. The goal of the proposed paper is to develop, experiment, and compare the performance of two new neural networks based on the transformer architecture, Detection Transformer and Vision Transformer. Two datasets were used, an own one for testing and COCO for learning. The results are promising to take into account the difficulties of person detection at a distance.","2325-2944","979-8-3503-6944-1","10.1109/DCOSS-IoT61029.2024.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10621554","unmanned aerial vehicle;person detection;image processing;neural networks;performance metrics","Measurement;Computer vision;Visualization;Neural networks;Computer architecture;Object detection;Transformers","","","","9","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Evaluating LLM-driven User-Intent Formalization for Verification-Aware Languages","S. K. Lahirie","Microsoft Research, Redmond, USA",2024 Formal Methods in Computer-Aided Design (FMCAD),"13 Mar 2025","2024","","","142","147","Verification-aware programming languages such as Dafny and F* provide means to formally specify and prove properties of a program. Although the problem of checking an implementation against a specification can be defined mechanically, there is no algorithmic way of ensuring the correctness of the user-intent formalization for programs — that a specification adheres to the user's intent behind the program. This is because intent or requirement is expressed informally in natural language and the specification is a formal artefact. However, the advent of large language models (LLMs) has made tremendous strides bridging the gap between informal intent and formal program implementations in the last couple of years, driven in large parts due to benchmarks and automated metrics to evaluate different techniques. Recent work has developed a framework for evaluating and benchmarking the user-intent formalization problem for main-stream programming languages [12]. However, as we argue in this paper, such an approach does not readily extend to verification-aware languages that support rich specifications (using quantifiers and ghost variables) that cannot be evaluated through dynamic execution. Previous work also required generating program mutants using LLMs to create the benchmark. We advocate an alternate, perhaps simpler approach of symbolically testing specifications to provide an intuitive metric for evaluating the quality of specifications that can be easily instantiated with most verification-aware languages. We demonstrate that our automated metric agrees closely on a human-labeled dataset of Dafny specifications for the popular MBPP code-generation benchmark, yet demonstrates cases where the human labeling is not perfect. We also outline formal verification challenges that need to be addressed to apply the technique more widely. We believe our work provides a stepping stone to enable the establishment of a benchmark and research agenda for the problem of user-intent formalization for programs.","2708-7824","978-3-85448-065-5","10.34727/2024/isbn.978-3-85448-065-5_19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918369","formal verification;specifications;large language models","Measurement;Computer languages;Design automation;Costs;Large language models;Natural languages;Benchmark testing;Labeling;Formal verification","","","","30","","13 Mar 2025","","","IEEE","IEEE Conferences"
"Achieving High-Level Software Component Summarization via Hierarchical Chain-of-Thought Prompting and Static Code Analysis","S. A. Rukmono; L. Ochoa; M. R. V. Chaudron","Mathematics and Computer Science Eindhoven University of Technology, Eindhoven, The Netherlands; Mathematics and Computer Science Eindhoven University of Technology, Eindhoven, The Netherlands; Mathematics and Computer Science Eindhoven University of Technology, Eindhoven, The Netherlands",2023 IEEE International Conference on Data and Software Engineering (ICoDSE),"27 Oct 2023","2023","","","7","12","Comprehension of software systems is key to their successful maintenance and evolution. This comprehension comes at different levels of abstraction: At the low level, one must focus on comprehending functions; while at the high level, one must abstract and comprehend the system's requirements. Diverse Automated Source Code Summarization (ASCS) techniques have been proposed to comprehend systems at the lower level. However, techniques for abstracting higher-level explanations fall short. Research on related fields, such as software architecture recovery, has tried to address system comprehension at the higher level by attempting to detect abstractions of design decisions from source code. Nevertheless, this is an on-going effort and many steps in the process are still unsolved. In this paper, we lever-age the emergent abilities of Large Language Models (LLMs) together with the achievements in the ASCS and static code analysis fields to design an approach that produces component-level summaries of software systems. Particularly, we address the unreliability of LLMs in performing reasoning by applying a chain-of-thought prompting strategy, which allows us to emulate inductive reasoning. We follow a bottom-up approach, where we start by comprehending lower-level software abstractions (e.g., functions), and then we compose these findings-in a cascading style-to comprehend higher-level ones (e.g., classes, components). We demonstrate the feasibility of our approach by applying it to the open-source Java project JHotDraw version 5.1. We believe our approach offers a stepping stone in developing robust automated software summarization approaches that can be applied generally across domains and types of software system.","2640-0227","979-8-3503-8138-2","10.1109/ICoDSE59534.2023.10292037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292037","comprehension of software systems;automated source code summarization;static analysis;large language models;chain-of-thought prompting","Analytical models;Java;Codes;Software architecture;Source coding;Maintenance engineering;Software systems","","4","","19","IEEE","27 Oct 2023","","","IEEE","IEEE Conferences"
"Large Language Model based Framework for Secure Operation of Power Systems","L. Tan; Y. Xiang; B. Tang; H. Li; Z. Du; Y. Lu; H. Ma; Z. Xi; J. Yang; S. Wang; L. Li","College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; Economic and Technological Research Institute of Henan, State Grid Henan Electric Power Company, Zhengzhou, China; College of Electrical Engineering, Sichuan University, Chengdu, China",2024 3rd International Conference on Power Systems and Electrical Technology (PSET),"30 Dec 2024","2024","","","695","699","This paper proposes an intelligent scheduling system for power systems, leveraging Large Language Modelling (LLM) to overcome challenges posed by complex system specifications expressed in natural language. By invoking the LLM and making use of its reasoning and natural language generation functions, our method enables automated comprehension and processing of power scheduling rules. Through customization of the LLM, paper directly model difficult-to-quantify safety regulations as constraints, facilitating the determination of system safety and providing empirically-based scheduling recommendations. Experimental validation on IEEE 14-bus and IEEE 30-bus systems confirms the effectiveness of our approach in enhancing scheduling efficiency and reliability.","","979-8-3503-5320-4","10.1109/PSET62496.2024.10808693","Sichuan University; National Natural Science Foundation of China; Sichuan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808693","power system;LLMs;Language security provisions;system security;dispatch","Codes;Large language models;Natural languages;Natural language generation;Regulation;Power systems;Safety;Power system reliability;Power system security;Reliability","","1","","6","IEEE","30 Dec 2024","","","IEEE","IEEE Conferences"
"Predicting the Root Cause of Flaky Tests Based on Test Smells","J. Wang; W. Zhang; W. Wang; R. Zhao; Y. Shang","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Engineering, Beijing Institute of Petrochemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China",2025 IEEE/ACM 22nd International Conference on Software and Systems Reuse (ICSR),"10 Jun 2025","2025","","","84","94","Flaky tests refer to test cases that exhibit inconsistent behaviors across multiple executions, potentially passing or failing unpredictably. They are frequently associated with suboptimal design practices that testers may utilize when crafting test cases, which undermine the quality of software testing. So, identifying the root causes of flaky tests is crucial for fixing them. Currently, inspired by the success of the Large Language Models (LLMs), researchers leverage the pre-trained language model to embed flaky test code as vectors and predict its root cause category based on vector similarity measures. However, such code embeddings generated by LLM mainly focus on capturing general semantic features but lack sufficient comprehension of the behavioral patterns involved in test scenarios, resulting in poor root cause identification. Test smells, which reflect poor coding practices or habits when writing test cases, provide complementary information in the root cause identification of test flakiness. Therefore, this paper proposes a root cause identification method for flaky tests based on test smells. Test smells are used to abstract and express behavioral patterns of test codes, and general semantic features extracted by vector embeddings to enhance the feature representation of flaky tests. Furthermore, to capture the complex nonlinear relationships between test smell features and code embeddings, a Feedforward Neural Network is constructed to categorize the root cause of test flakiness. To validate the effectiveness of our method, we performed evaluations on a dataset consisting of 451 Java flaky test cases. The experimental results indicate that our method achieves an F1-score of 80%, which is 7% higher than that of the baseline model that does not incorporate test smells.","","979-8-3315-2617-7","10.1109/ICSR66718.2025.00015","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024524","flaky tests root causes;test smells;software testing;LLMs;CodeBERT","Software testing;Codes;Semantics;Writing;Predictive models;Feature extraction;Vectors;Eigenvalues and eigenfunctions;Software;Feedforward neural networks","","","","24","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"LLM and RAG-Based Question Answering Assistant for Enterprise Knowledge Management","G. Şahin; K. Varol; B. K. Pak","R&D Centre, Adesso Türkiye, İstanbul, Türkiye; R&D Centre, Adesso Türkiye, İstanbul, Türkiye; R&D Centre, Adesso Türkiye, İstanbul, Türkiye",2024 9th International Conference on Computer Science and Engineering (UBMK),"11 Dec 2024","2024","","","1","6","Large language models (LLM) have become integral to many natural language processing applications, particularly in the area of automatic question answering. In this study, a question answering system was developed to enable Adesso Turkiye employees to access internal company information quickly and accurately. A Retrieval Augmented Generation (RAG)-based question answering framework was constructed by utilizing multiple large language models and embedding techniques, along with content curated by experts in human resources and information security. The performance of the system was evaluated using ROUGE, BLEU, and accuracy metrics, and the results indicated high levels of success. Future work will focus on enhancing performance through the use of different language models, enriching the system with datasets from various domains, and integrating the developed system into MS Teams to ensure accessibility for employees.","2521-1641","979-8-3503-6588-7","10.1109/UBMK63289.2024.10773564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773564","generative artificial intelligence;natural language processing;large language models;question answering;retrieval augmented generation (RAG);GPT","Measurement;Computer science;Accuracy;Large language models;Information security;Companies;Question answering (information retrieval);Vectors;Knowledge management;Usability","","1","","21","IEEE","11 Dec 2024","","","IEEE","IEEE Conferences"
"DiffQRCoder: Diffusion-Based Aesthetic QR Code Generation with Scanning Robustness Guided Iterative Refinement","J. -W. Liao; W. Wang; T. -S. Wang; L. -X. Peng; J. -H. Weng; C. -F. Chou; J. -C. Chen","Research Center for Information Technology Innovation, Academia Sinica; Research Center for Information Technology Innovation, Academia Sinica; Research Center for Information Technology Innovation, Academia Sinica; Research Center for Information Technology Innovation, Academia Sinica; Research Center for Information Technology Innovation, Academia Sinica; National Taiwan University; Research Center for Information Technology Innovation, Academia Sinica",2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),"8 Apr 2025","2025","","","5916","5925","With the success of Diffusion Models for image generation, the technologies also have revolutionized the aesthetic Quick Response (QR) code generation. Despite significant improvements in visual attractiveness for the beautified codes, their scannabilities are usually sacrificed and thus hinder their practical uses in real-world scenarios. To address this issue, we propose a novel training-free Diffusion-based QR Code generator (DiffQRCoder) to effectively craft both scannable and visually pleasing QR codes. The proposed approach introduces Scanning-Robust Perceptual Guidance (SRPG), a new diffusion guidance for Diffusion Models to guarantee the generated aesthetic codes to obey the ground-truth QR codes while maintaining their attractiveness during the denoising process. Additionally, we present another post-processing technique, Scanning Robust Manifold Projected Gradient Descent (SR-MPGD), to further enhance their scanning robustness through iterative latent space optimization. With extensive experiments, the results demonstrate that our approach not only outperforms other compared methods in Scanning Success Rate (SSR) with better or comparable CLIP aesthetic score (CLIP-aes.) but also significantly improves the SSR of the ControlNet-only approach from 60% to 99%. The subjective evaluation indicates that our approach achieves promising visual attractiveness to users as well. Finally, even with different scanning angles and the most rigorous error tolerance settings, our approach robustly achieves over 95% SSR, demonstrating its capability for real-world applications. Our project page is available at https://jwliao1209.github.io/DiffQRCoder.","2642-9381","979-8-3315-1083-1","10.1109/WACV61041.2025.00577","National Science and Technology Council, Taiwan(grant numbers:NSTC-112-2634-F-002-006,NSTC-112-2222-E-001-001-MY2,NSTC-113-2634-F-001-002-MBK,NSTC-113-2221-E-002-201); Academia Sinica(grant numbers:AS-CDA-110-M09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943781","aesthetic qr code;generative ai art;diffusion models;controlnet;scanning robustness;manifold optimization","Manifolds;Visualization;Codes;Pipelines;QR codes;Diffusion models;Robustness;Generators;Iterative methods;Optimization","","","","48","IEEE","8 Apr 2025","","","IEEE","IEEE Conferences"
"Large Language Model Powered In-House Question Answering Assistant","G. Şahin; K. Varol; B. K. Pak","R&D Centre Adesso Türkiye, İstanbul, Türkiye; R&D Centre Adesso Türkiye, İstanbul, Türkiye; R&D Centre Adesso Türkiye, İstanbul, Türkiye",2024 Innovations in Intelligent Systems and Applications Conference (ASYU),"28 Nov 2024","2024","","","1","6","Large language models are widely used in many natural language processing applications today. Automatic question answering is one of the areas where language models are frequently used. In this study, a question answering system was developed that allows Adesso Türkiye employees to access internal company information quickly and accurately. A Retrieval Augmented Generation (RAG)-based question answering structure was created by giving content prepared by experts in the field of human resources and information security as input to the large language model. As a result of the experiments, high accuracy results were obtained on datasets. In future studies, it is aimed to increase performance by using different language models and to make the developed system available to employees by integrating it into MS Teams.","2770-7946","979-8-3503-7943-3","10.1109/ASYU62119.2024.10757102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757102","large language models;generative artificial intelligence;gpt;rag;question answering;natural language processing","Technological innovation;Accuracy;Large language models;Information security;Companies;User interfaces;Question answering (information retrieval);Vectors;Libraries;Intelligent systems","","","","22","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"A Feature Engineering Approach for Detecting Phishing Emails","A. Dumitras; C. M. Mocan; C. Oprisa","Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania",2024 IEEE 20th International Conference on Intelligent Computer Communication and Processing (ICCP),"17 Dec 2024","2024","","","1","8","Phishing detection is a well-studied problem, yet no universal solution, applicable in all scenarios have been found. The current research tries to leverage recent breakthroughs in the Machine Learning field, by extracting advanced features from suspicious emails. The classical features, extracted algorithmically from the email headers and body are augmented with expert features extracted by Large Language Models that are fed the email text. All these features are used in multiple Machine Learning classifiers, obtaining Accuracies and AUC scores above 90%.","2766-8495","979-8-3315-3997-9","10.1109/ICCP63557.2024.10793001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10793001","phishing;email;feature engineering;large language models;machine learning;security","Machine learning algorithms;Phishing;Large language models;Computational modeling;Pipelines;Machine learning;Feature extraction;Electronic mail;Classification algorithms;Servers","","","","34","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Can ChatGPT Pass Modern Control Theory Exam?","I. Ogo; M. Koga","Department of Intelligent and Control Systems, Kyushu Institute of Technology, Fukuoka, Japan; Department of Intelligent and Control Systems, Kyushu Institute of Technology, Fukuoka, Japan","2024 24th International Conference on Control, Automation and Systems (ICCAS)","9 Dec 2024","2024","","","1287","1292","Large language models (LLMs), such as GPT models, have been rapidly studied in recent years and are expected to be applied to academic fields such as mathematics and engineering. In this study, we examined how accurately ChatGPT (GPT-4o) can answer modern control theory questions at the undergraduate-level. A set of 98 questions on modern control theory was used to evaluate GPT-4o’s problem-solving ability on modern control theory. The results revealed that the GPT-4o showed a 49.0% correct response rate to the undergraduate-level modern control theory exercises, and that the correct response rate tended to be lower for problems involving calculations, especially those that require step-by-step thinking and complex computation. This may be attributed to the Transformer architecture of the GPT model, which generates answers based on probabilistic predictions. In this study, we proposed a method to improve response accuracy by developing a customized GPT which leverages prompt engineering methods to address these issues. In order to evaluate the proposed method, a question set consisting of 45 graduate school entrance exam questions on modern control theory was developed. The results of the evaluation showed that the correct response rate was improved by 26.6 points, yielding a 64.4% correct response rate.","2642-3901","978-89-93215-38-0","10.23919/ICCAS63016.2024.10773183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773183","ChatGPT;Modern Control Theory;Generative AI;GPTs;GPT-4o","Accuracy;Computer architecture;Predictive models;Transformers;Chatbots;Probabilistic logic;Mathematical models;Control theory;Prompt engineering;Problem-solving","","","","23","","9 Dec 2024","","","IEEE","IEEE Conferences"
"Harnessing ChatGPT for Model Transformation in Software Architecture: From UML State Diagrams to Rebeca Models for Formal Verification","Z. Moezkarimi; K. Eriksson; A. A. Johansson; A. Bucaioni; M. Sirjani","School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden",2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C),"30 May 2025","2025","","","387","396","Software architecture relies heavily on modeling techniques to describe, analyze, and verify system designs. The Unified Modeling Language (UML) is widely recognized as both a de facto and de jure standard for modeling various types of systems. While UML has formalized semantics that enhance consistency and precision, it is not inherently designed for model checking. Rebeca, an actor-based modeling language, is designed to enable formal verification of concurrent reactive systems. Previous efforts to bridge UML and Rebeca through model transformations have required combining multiple UML diagrams and a deep understanding of Rebeca, limiting practical applicability. In this paper, we explore the potential of leveraging large language models, specifically GPT-4, to automate the transformation of UML state diagrams into Rebeca models. Using a few-shot learning approach, we investigated the feasibility of this translation process. Initial results revealed that UML state diagrams alone were insufficient for generating accurate Rebeca models. To address this limitation, we augmented the diagrams with metadata, enabling GPT-4 to produce models that required only minor corrections to be executable in Rebeca's model-checking tool, Afra. Our findings demonstrate that LLMs hold promise in facilitating model transformations for software architecture, particularly for translating UML state diagrams into Rebeca models for formal verification. While not yet fully automated, this approach significantly reduces the effort required for transformation, paving the way for further research into the integration of LLMs into model-driven engineering practices.","2768-4288","979-8-3315-3336-6","10.1109/ICSA-C65153.2025.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014908","Model transformation;Large language model (LLM);Formal methods;Rebeca modeling language;Unified Modeling Language (UML) state diagram","Translation;Software architecture;Large language models;Unified modeling language;Semantics;Model checking;Model driven engineering;System analysis and design;Standards;Formal verification","","","","27","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Attention-Enhanced Hybrid AI Model for IoT Security","A. Gaurav; V. Arya; B. B. Gupta; K. Tai Chui","Ron in Institute, Montclair, NJ, USA; Hong Kong Metropolitan University, Hong Kong SAR, China; Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; University of Economics and Human Science, Warsaw, Poland",2025 International Wireless Communications and Mobile Computing (IWCMC),"2 Jul 2025","2025","","","1360","1365","Recently, the use of smart IoT devices is increased. This increases the incidence of cyber attacks in IoT devices. In this context, this paper introduces an Attention-Enhanced Hybrid Model for the detection of attack in IoT. The proposed model integrates Success History Intelligent Optimizer (SHIO) for optimal feature selection and a CNN-LSTM-ASPP-based deep learning framework for attack classification. The proposed model used CNN to extract spatial features and LSTM to capture temporal dependencies. In addition of that, Atrous Spatial Pyramid Pooling (ASPP) for multi-scale feature refinement. Experimental evaluations achieve 88.3% accuracy and more then.90 of AUC curve for all the attack classes. The proposed model also outperforming GRU, LSTM, RNN, and Transformer models.","2376-6506","979-8-3315-0887-6","10.1109/IWCMC65282.2025.11059511","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059511","IoT Security;Temporal and Spatial Features;Hybrid Deep Learning;Atrous Spatial Pyramid Pooling (ASPP);Success History Intelligent Optimizer (SHIO)","Deep learning;Accuracy;Computational modeling;Feature extraction;Transformers;Internet of Things;Security;History;Artificial intelligence;Long short term memory","","","","16","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"LAMD: Context-Driven Android Malware Detection and Classification with LLMs","X. Qian; X. Zheng; Y. He; S. Yang; L. Cavallaro",University College London; University College London; University College London; University of Hong Kong; University College London,2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","126","136","The rapid growth of mobile applications has escalated Android mal ware threats. Although there are numerous detection methods, they often struggle with evolving attacks, dataset biases, and limited explainability. Large Language Models (LLMs) offer a promising alternative with their zero-shot inference and reasoning capabilities. However, applying LLMs to Android malware detection presents two key chal-lenges: (1) the extensive support code in Android applications, often spanning thousands of classes, exceeds LLMs' context limits and obscures malicious behavior within benign functionality; (2) the structural complexity and interdepen-dencies of Android applications surpass LLMs' sequence-based reasoning, fragmenting code analysis and hindering malicious intent inference. To address these challenges, we propose LAMD, a practical context-driven framework to enable LLM-based Android malware detection. LAMD integrates key context extraction to isolate security-critical code regions and construct program structures, then applies tier-wise code reasoning to analyze application behavior progressively, from low-level instructions to high-level semantics, providing final prediction and explanation. A well-designed factual consistency verification mechanism is equipped to mitigate LLM hallucinations from the first tier. Evaluation in real-world settings demonstrates LAMD's effectiveness over conventional detectors, establishing a feasible basis for LLM -driven mal ware analysis in dynamic threat landscapes.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050830","","Privacy;Codes;Operating systems;Large language models;Semantics;Detectors;Malware;Cognition;Mobile applications;Security","","1","","61","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Artificial Intelligence Based Fraud Detection, Data Security and Privacy for Telecommunication Systems","K. Prabhu Rajasekar; D. Vezhaventhan","School of Law, Specialization: Cyber Crime and Cyber Law, Saveetha University (SIMATS DEEMED UNIVERSITY), Chennai, India; Department of Humanities and Social Sciences, SIMATS, Saveetha School of Law, Chennai",2024 4th International Conference on Sustainable Expert Systems (ICSES),"3 Dec 2024","2024","","","402","406","Globally, fraud is increasing and has the potential to cost firms billions of dollars and inflict serious financial harm. Scholars hailing from several domains of application have put forth distinct methodologies. Examining these concepts can help us see the problems more clearly. Examining several approaches to fraud detection and prevention in the communications industry is the aim of this article. This paper gives a summary of the various categories of telecom fraud, problems that arise throughout the detection process, and some recommendations for how to solve them. The efficacy of the existing methodologies is documented at, succeeded by suggestions and suggestions for selecting the performance measurements that best suit the needs. There has been a notable shift in the use of advanced AI-driven solutions for fraud management in the telecom industry. The development of Generative AI is a significant breakthrough, giving CSPs powerful instruments to fight fraud. As a result of the transition from conventional to AI-based methodologies, fraud management is becoming more proactive and predictive, enabling CSPs to stay one step ahead of criminals.","","979-8-3315-4036-4","10.1109/ICSES63445.2024.10763168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763168","Banking;Communication Service Providers;Consumers;Electronics;Industry;Real time Security","Technological innovation;Consumer behavior;Banking;Media;Real-time systems;Robustness;Fraud;Telecommunications;Sensors;Internet of Things","","","","21","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"Developing Hybrid Privacy Channels in Cloud Architecture using Several Agents","A. Sharma; M. Joshi; S. J. Mamatkulov; S. Thakur; S. O. Husain; S. Goyal","Department of Mechanical Engineering, GLA University, Mathura, India; School of Computing Graphic Era Hill, University Bhimtal Campus, Uttarakhand, India; Docent of the Department of Marketing, Samarkand Institute of Economics and Service Uzbekistan, Samarkand; Department of Computer Application, Chandigarh Engineering College Chandigarh Group of Colleges, Mohali, Punjab, India; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University of Al Diwaniyah, Al Diwaniyah, Iraq; Department of Electrical Engineering, Graphic Era Deemed to be University, Dehradun, India","2024 International Conference on Communication, Computing and Energy Efficient Technologies (I3CEET)","13 May 2025","2024","","","1268","1273","An information security plan often assesses the risk, the likelihood that it would materialize as a result of an unusual incident, and the related ramifications for cloud enterprises. Different computer safety and risk mitigation techniques are implemented by different cloud organizations and disciplines. When comparing the risk management techniques that cloud firms now use, it becomes clear that they have shortcomings since they only take into account traditional criteria and ignore an agent-based approach that takes into account every aspect of the risk involved. The failure to include well-known risk mitigation frameworks, appropriate comparisons, and agent procedures is what spurred this investigation. This paper presents the Agent-Based Security of Knowledge Model for Blended Cloud Computing, a complete methodology that combines cloud-specific methodologies for analyzing and comparing well-known systems now in use, to solve challenges in cloud computing risk. New elements are also included from the assessed techniques. The goal of introducing intelligent agents and software agents is to provide a decision-making framework that will direct organizational actions against danger agents by using data from security agents. These agents are in charge of gathering trustworthy data and organizing it for frameworks. The research focuses on risk assessment methods that compute results by examining resources, possible threats, weaknesses, and related actions. ISO/IEC 27005:2011 is the best technique inside the Agent-Based security professionals Framework (ABISF) after a comprehensive comparison with popular Individual Security Assessment of Risk (ISRA) methodologies. The suggested framework is developed using a fuzzy inference method based on fuzzy set theory, and its effectiveness is verified using fuzzy logic rules in MATLAB®. The inconclusive results confirm that the proposed technique has potential to protect privacy of information in cloud settings.","","979-8-3315-4158-3","10.1109/I3CEET61722.2024.10994007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994007","Agent-Based Information Security Framework;Hybrid Cloud Computing;Risk Management Techniques;Software Agents;Fuzzy Logic;ISO/IEC 27005:2011;Threats;Vulnerabilities;Multi-Agent Systems;Privacy Protection","Fuzzy logic;Cloud computing;Privacy;ISO Standards;Information security;Computer architecture;Security;Intelligent agents;IEC Standards;Risk mitigation","","","","30","IEEE","13 May 2025","","","IEEE","IEEE Conferences"
"Agent-based IoT Coordination for Smart Cities Considering Security and Privacy","I. García-Magariño; G. Gray; R. Muttukrishnan; W. Asif","Dept. of Software Engineering and Artificial Intelligence, Complutense University of Madrid, Madrid, Spain; Dept. of Informatics, Technological University of Dublin, Dublin, Ireland; Dept. of Electrical and Electronic Engineering, City University of London, London, United Kingdom; Dept. of Electrical and Electronic Engineering, City University of London, London, United Kingdom","2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","23 Dec 2019","2019","","","221","226","The interest in Internet of Things (IoT) is increasing steeply, and the use of their smart objects and their composite services may become widespread in the next few years increasing the number of smart cities. This technology can benefit from scalable solutions that integrate composite services of multiple-purpose smart objects for the upcoming large-scale use of integrated services in IoT. This work proposes an agent-based approach for supporting large-scale use of IoT for providing complex integrated services. Its novelty relies in the use of distributed blackboards for implicit communications, decentralizing the storage and management of the blackboard information in the smart objects, which are accessed by nearby requests. This avoids (a) the common bottlenecks of implicit communications based on centralized blackboards and (b) the overload of bandwidth due to explicit peer-to-peer communications. This solution raises challenges in privacy and security, and some potential solutions are discussed in this paper. Simulations based on a region in Dublin city shows the potential utility of this approach illustrated in the domain of coordination of electric vehicles in selecting paths and charging stations.","","978-1-7281-2949-5","10.1109/IOTSMS48152.2019.8939194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939194","Internet of Things;multi-agent systems;distributed blackboard;agent-based simulation;electric vehicle;smart city","Internet of Things;Security;Smart cities;Privacy;Computational modeling","","4","","22","IEEE","23 Dec 2019","","","IEEE","IEEE Conferences"
"Enhancing LLM-Based Coding Tools through Native Integration of IDE-Derived Static Context","Y. Li; Y. Peng; Y. Huo; M. R. Lyu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China",2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"30 Oct 2024","2024","","","70","74","Large Language Models (LLMs) have achieved remarkable success in code completion, as evidenced by their essential roles in developing code assistant services such as Copilot. Being trained on in-file contexts, current LLMs are quite effective in completing code for single source files. However, it is challenging for them to conduct repository-level code completion for large software projects that require cross-file information. Existing research on LLM-based repository-level code completion identifies and integrates crossfile contexts, but it suffers from low accuracy and limited context length of LLMs. In this paper, we argue that Integrated Development Environments (IDEs) can provide direct, accurate and realtime cross-file information for repository-level code completion. We propose IDECoder, a practical framework that leverages IDE native static contexts for cross-context construction and diagnosis results for self-refinement. IDECoder utilizes the rich cross-context information available in IDEs to enhance the capabilities of LLMs of repository-level code completion. We conducted preliminary experiments to validate the performance of IDECoder and observed that this synergy represents a promising trend for future exploration.CCS CONCEPTS• Software and its engineering → Automatic programming.","","979-8-4007-0579-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734625","Large language model;code generation","Codes;Accuracy;Automatic programming;Large language models;Conferences;Market research;Software;Encoding;Context modeling","","","","28","","30 Oct 2024","","","IEEE","IEEE Conferences"
"Data Breach Prevention in AI Systems: Employing Event-Driven Architecture to Combat Prompt Injection Attacks in Chatbots","M. J. C. Samonte; J. E. R. Aparize; E. J. S. Gonzales; J. L. Morilla","School of Information Technology Mapua University, Makati, Philippines; School of Information Technology Mapua University, Makati, Philippines; School of Information Technology Mapua University, Makati, Philippines; School of Information Technology Mapua University, Makati, Philippines","2024 IEEE 12th International Conference on Information, Communication and Networks (ICICN)","2 Dec 2024","2024","","","626","632","While incorporating Large Language Models (LLMs) into applications has transformed user experiences, it has also brought about serious security flaws, most notably quick injection attacks. These attacks risk user privacy and data integrity by manipulating system behavior with AI model defects. This study thoroughly reviews the literature on quick injection attacks in chatbots to examine vulnerabilities in AI system integration. It suggests different strategies and synthesizes them into an event-driven architecture (EDA) that is specifically designed to thwart rapid injection assaults by synthesizing the findings of previous research. The suggested EDA offers a scientific breakthrough in comprehending and resolving security challenges in AI system integration by enabling proactive threat identification and mitigation. The results highlight how crucial strong architectural security and systems integration is to defend AI systems from changing threats. The importance of these actions in strengthening cybersecurity standards and safeguarding digital environments is also covered in the report. This study adds to the current conversation around AI system security by offering ideas and viewpoints for more investigation and advancement.","","979-8-3503-5580-2","10.1109/ICICN62625.2024.10761619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10761619","large language models;prompt injection;artificial intelligence;event-driven architecture","Prevention and mitigation;Large language models;Architecture;Systems architecture;System integration;Data breach;Chatbots;Data models;Security;Artificial intelligence","","","","18","IEEE","2 Dec 2024","","","IEEE","IEEE Conferences"
"Developing a Cloud Information Monitoring and Recommendation Multi-agent System based on Artificial Intelligence Technology for Smart Energy-saving","S. -Y. Yang","Department of Computer Information and Network Engineering, Lunghwa University of Science and Technology","2021 IEEE 3rd Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)","13 Aug 2021","2021","","","161","164","Smart energy-saving is one of the important topics of applied science. Artificial intelligence (AI) is also worth paying attention to for intelligent systems. This study aimed to develop a cloud multi-agent system that integrates multiple intelligent technologies for quickly, accurately, and effectively obtaining useful cloud energy-saving information on time for applying science. The proposed system was successfully built by ontology, Web services, and big data analytic technologies based on many practical developments in the Dr. What-Info system. To build the system, we surveyed the related techniques for constructing a Web service platform and explored how to broadly combine cloud interactions among all sub-agents. The preliminary system shows that the proposed system architecture and operation have met the system design requirements.","","978-1-7281-9304-5","10.1109/ECBIOS51820.2021.9510217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510217","artificial intelligence;smart energy saving;information monitoring and recommendation multi-agent systems","Web services;Conferences;Systems architecture;Medical services;Ontologies;Sustainable development;Intelligent systems","","2","","14","IEEE","13 Aug 2021","","","IEEE","IEEE Conferences"
"A Mobile-Edge Computing Bio-Surveillance Framework for Multiple Biological Attacks Detection","M. Al-Zinati; T. Almasri; M. Alsmirat; Y. Jararweh","School of Computer and Information Technology, Jordan University of Science and Technology, Irbid, Jordan; School of Computer and Information Technology, Jordan University of Science and Technology, Irbid, Jordan; School of Computer and Information Technology, Jordan University of Science and Technology, Irbid, Jordan; School of Computer and Information Technology, Jordan University of Science and Technology, Irbid, Jordan","2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","23 Dec 2019","2019","","","104","109","Hostile biological attacks are becoming increasingly dangerous and life-threatening. Nevertheless, most of these attacks are not detected in a timely manner. Current biosurveillance systems depend on the data gathered from different medical sources such as hospitals and specialized laboratories. Recently, bio-surveillance systems start to utilize recent advances in sensors and IoT technologies to improve their real-time detection of health security threats. Despite the great improvements shown by these systems, there is no evidence on their effectiveness in case of multiple concurrent attacks. Triggering multiple concurrent attacks further complicates the problem as gathered monitoring information tend to obfuscate each other. To address this issue, we propose a multi-agent framework for multiple biological threat detection. The proposed framework utilizes recent advances in wearable sensors to monitor human vital signs. Moreover, intelligent agents are defined in the context of mobile-edge computing platforms to group monitoring information into focused clusters. These clusters are then used to effectively detect multiple concurrent health security threats. The evaluation of the proposed frame-work shows its effectiveness in detecting concurrent biological attacks.","","978-1-7281-2949-5","10.1109/IOTSMS48152.2019.8939175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939175","Mobile Edge Computing;Cloud Computing;Biosurveillance Systems;Edge Cloud Data Management;Multi-Agent Systems","Cloud computing;Multi-access edge computing;Biology;Threat assessment;Sensor systems;Real-time systems;Security;Monitoring;Wearable sensors;Multi-agent systems","","1","","25","IEEE","23 Dec 2019","","","IEEE","IEEE Conferences"
"Partial Agreement Task Assignment Algorithm for Secure Plan Consensus in Multi-Agent System","H. -Y. Kim; H. -L. Choi","Department of Aerospace Engineering, KAIST, Daejeon, Korea; Department of Aerospace Engineering, KAIST, Daejeon, Korea","2018 18th International Conference on Control, Automation and Systems (ICCAS)","13 Dec 2018","2018","","","856","861","This paper presents a secure market based task assignment algorithm for decentralized multi-agent system. In a decentralized algorithm, individual agents calculate their solution with imperfect information of environments. To achieve agreement in the system, the plan consensus solves local task assignment problems and reach a conflict-free solution through the plan exchange. The Consensus Based Bundle Algorithm(CBBA), which is well-known consensus based plan auction method, guarantees feasible and conflict-free solution. However, in the plan consensus protocol, each agent determines tasks only through bidding for each task like maximum bid consensus. It is vulnerable to malicious data to attack a consensus process or solution result. Therefore, providing security to the decentralized agent system is a major issue. The main contribution of this paper is an algorithm, termed partial-agreement consensus-based bundle algorithm, that proposed for two types of attacks, exaggerated score attack and changing score attack. Partial agreement of the agent with some of the mission plans resists attacks that are intended to degrade the overall plan. The security solution is a more robust task allocation algorithm with a partial agreement on the plans and task bidding data.","","978-89-93215-16-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8571687","Cyber-attack;Multi-agent systems;Plan consensus algorithms;Secure task allocation","Task analysis;Multi-agent systems;Planning;Security;Resource management;Optimization","","","","20","","13 Dec 2018","","","IEEE","IEEE Conferences"
"Multi-Agent System for Closed Loop Model-Based Control of Dissolved Oxygen Concentration","J. Pośpiech","Department of Automatic Control and Robotics, Silesian University of Technology, Gliwice, Poland",2021 25th International Conference on Methods and Models in Automation and Robotics (MMAR),"21 Sep 2021","2021","","","145","149","This paper presents a proposition of Multi-Agent System design dedicated to control dissolved oxygen concentration inside reactor with activated sludge. Designed Multi-Agent System is able to switch between multiple available control algorithms to reach the best possible control quality. Design goal was to create encapsulated agents where modification of one agent's code would not cause the necessity to change any other agent in system. Created Multi-Agent system was tested in laboratory setup with a well-mixed bioreactor. Experimental comparison with conventional on-off controller showed improvement in control precision.","","978-1-7281-7380-1","10.1109/MMAR49549.2021.9528445","SUT(grant numbers:BKM-2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528445","Adaptive control;model-based control;Multi-Agent Systems;practical-validation;process control","Adaptation models;Oxygen;Codes;Automation;Biological system modeling;Switches;Control systems","","","","15","IEEE","21 Sep 2021","","","IEEE","IEEE Conferences"
"How Effective are LLMs for Data Science Coding? A Controlled Experiment","N. Nascimento; E. Guimaraes; S. S. Chintakunta; S. A. Boominathan","EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA; EASER, Eng. Division, Pennsylvania State University, Great Valley, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","211","222","The adoption of Large Language Models (LLMs) for code generation in data science offers substantial potential for enhancing tasks such as data manipulation, statistical analysis, and visualization. However, the effectiveness of these models in the data science domain remains underexplored. This paper presents a controlled experiment that empirically assesses the performance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4 Turbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs (Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges sourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM) approach, we evaluated each model’s effectiveness across task types (Analytical, Algorithm, Visualization) and varying difficulty levels. Our statistical testing confirms that all models achieved success rates significantly above $50 \%$, demonstrating performance beyond chance. ChatGPT and Claude significantly exceeded the $60 \%$ threshold, but no model reached $70 \%$, indicating limitations in achieving higher accuracy. ChatGPT maintained consistent performance across difficulty levels, whereas Claude’s success varied with task complexity. Hypothesis testing indicates that task type does not significantly impact success rate overall. For analytical tasks, efficiency analysis shows no significant differences in execution times, though ChatGPT tended to be slower and less predictable despite high success rates. For visualization tasks, while similarity quality among LLMs is comparable, ChatGPT consistently delivered the most accurate outputs. This study provides a structured, empirical evaluation of LLMs in data science, delivering insights that support informed model selection tailored to specific task demands. Our findings establish a framework for future AI assessments, emphasizing the value of rigorous evaluation beyond basic accuracy measures.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025766","data science;large language model;coding generation;empirical study;hypothesis testing","Visualization;Accuracy;Statistical analysis;Large language models;Data visualization;Data science;Chatbots;Encoding;Data models;Testing","","","","22","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Optimizing Secure AI Lifecycle Model Management With Innovative Generative AI Strategies","A. Omran Almagrabi; R. A. Khan","Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science and IT, Software Engineering Research Group, University of Malakand, Chakdara, Pakistan",IEEE Access,"24 Jan 2025","2025","13","","12889","12920","Generative AI (GAI) is one of the significant components that can efficiently improve and augment the AI cycle model’s robustness when it comes to different threats, weaknesses, and abnormalities detection. When applied in this field, GAI is very useful in emulating the various forms of security violations in actual adversarial settings. These scenarios are important when different aspects of an AI system are tested on how robust they are and thus permit the developers to amend any vulnerability that may be induced before the time it could be utilized in practice. Data and model manipulation, data theft, and adversarial attacks as well as model inference threats which we do a systematic analysis to disrupt the integrity, confidentiality as well as availability of AI models. Considering the current weaknesses and threats related to GAI we provide a systematic approach to how safety concerns that are currently relevant can be integrated with every stage of Artificial Intelligence (AI) lifecycle management: from continuous monitoring to the application of cybersecurity trends and practices, etc. In our approach, the emphasis is placed on the multi-level security management strategy that incorporates the improvement of coding practices, validation and testing, and the implementation of advanced intrusion detection systems. Before proceeding to further analysis and discussion of the given topic, it is also critical to mention the aspect of regulation and ethical concern as the major drivers of GAI usage. Additionally, organizations can involve GAI in the lifecycle to address security needs, during the development, acquisition, deployment, updating, maintenance, and decommissioning of the AI system, making them reliable, safe, and secure all through their lifecycle. Toward these ends, the goal of this work is to present a set of canonical recommendations for the many scientists, engineers, managers, technologists, and policymakers who will play a key role in constructing a sound and secure AI future.","2169-3536","","10.1109/ACCESS.2024.3491373","Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Deanship of Scientific Research (DSR) at King Abdulaziz University(grant numbers:GPIP: 1278-611-2024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10742321","Generative artificial intelligence;AI lifecycle model;security threats and practices;systematic mapping study","Artificial intelligence;Data models;Security;Training;Organizations;Law;Generative AI;Ethics;Synthetic data;Generative adversarial networks","","4","","70","CCBYNCND","4 Nov 2024","","","IEEE","IEEE Journals"
"On the Effectiveness of LLMs for Manual Test Verifications","M. Peixoto; D. Baía; N. Nascimento; P. Alencar; B. Fonseca; M. Ribeiro","Computing Institute, Federal University of Alagoas, Maceió, Alagoas, Brasil; Computing Institute, Federal University of Alagoas, Maceió, Alagoas, Brasil; Engineering Division, Penn State University, Malvern, Pennsylvania, USA; Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; Computing Institute, Federal University of Alagoas, Maceió, Alagoas, Brasil; Computing Institute, Federal University of Alagoas, Maceió, Alagoas, Brasil",2025 IEEE/ACM International Workshop on Deep Learning for Testing and Testing for Deep Learning (DeepTest),"11 Jun 2025","2025","","","45","52","Background: Manual testing is vital for detecting issues missed by automated tests, but specifying accurate verifications is challenging. Aims: This study aims to explore the use of Large Language Models (LLMs) to produce verifications for manual tests. Method: We conducted two independent and complementary exploratory studies. The first study involved using 2 closed-source and 6 open-source LLMs to generate verifications for manual test steps and evaluate their similarity to original verifications. The second study involved recruiting software testing professionals to assess their perception and agreement with the generated verifications compared to the original ones. Results: The open-source models Mistral-7B and Phi-3-mini-4k demonstrated effectiveness and consistency comparable to closed-source models like Gemini-1.5-flash and GPT-3.5-turbo in generating manual test verifications. However, the agreement level among professional testers was slightly above 40%, indicating both promise and room for improvement. While some LLM-generated verifications were considered better than the originals, there were also concerns about AI hallucinations, where verifications significantly deviated from expectations. Conclusion: We contributed by evaluating the effectiveness of 8 LLMs through similarity and human acceptance studies, identifying top-performing models like Mistral-7B and GPT-3.5-turbo. Although the models show potential, the relatively modest 40% agreement level highlights the need for further refinement. Enhancing the accuracy, relevance, and clarity of the generated verifications is crucial to ensure greater reliability in real-world testing scenarios.","","979-8-3315-0190-7","10.1109/DeepTest66595.2025.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11026915","manual testing;LLM;test verifications;AI-generated testing;model performance evaluation","Deep learning;Software testing;Performance evaluation;Accuracy;Large language models;Conferences;Manuals;Reliability;Testing","","1","","10","IEEE","11 Jun 2025","","","IEEE","IEEE Conferences"
"What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?","S. Gao; X. -C. Wen; C. Gao; W. Wang; H. Zhang; M. R. Lyu","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; School of Big Data and Software Engineering, Chongqing University, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","761","773","Pre-trained models of source code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning (ICL). ICL employs task instructions and a few examples as demonstrations, and then inputs the demonstrations to the language models for making predictions. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of ICL heavily relies on the quality of demonstrations, e.g., the selected examples. It is important to systematically investigate how to construct a good demonstration for code-related tasks. In this paper, we empirically explore the impact of three key factors on the performance of ICL in code intelligence tasks: the selection, order, and number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including code summarization, bug fixing, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of ICL in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We also show that a carefully-designed demonstration based on our findings can lead to substantial improvements over widely-used demonstration construction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%, 175.96%, and 50.81% on code summarization, bug fixing, and program synthesis, respectively.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00109","National Natural Science Foundation of China(grant numbers:62002084); Natural Science Foundation of Guangdong Province(grant numbers:2023A1515011959); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298329","","Codes;Source coding;Computer bugs;Predictive models;Natural language processing;Task analysis;Software engineering","","55","","68","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"LLM Generative AI and Students’ Exam Code Evaluation: Qualitative and Quantitative Analysis","E. Smolić; M. Pavelić; B. Boras; I. Mekterović; T. Jagušt","Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb; Šibenik University of Applied Sciences; Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb; Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb; Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb",2024 47th MIPRO ICT and Electronics Convention (MIPRO),"28 Jun 2024","2024","","","1261","1266","Since the introduction of generative artificial intelligence (GAI) technology in the context of large language models (LLMs), it has been widely used for information extraction and/or extrapolation from different sources. In computer science education, a potential application of such technology is for automatic code review, i. e. shifting the burden of debugging non-compilable code, detecting overlooked optimization concerns such as poor memory management in code that otherwise passes automated tests, and other advanced tasks from a human grader to LLMs. However, LLMs are currently not capable of evaluating code or mathematical expressions with 100% reliability, i. e. beyond token pattern recognition and subsequent probabilistic answer generation. With that in mind, in this paper, we explore the risk of incorrect LLM code evaluation, both descriptive and numerical, as well as begin research on its mitigation and propose further work directions.","2623-8764","979-8-3503-8250-1","10.1109/MIPRO60963.2024.10569820","Erasmus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569820","LLM;code evaluation;supported grading","Codes;Reviews;Generative AI;Statistical analysis;Memory management;Probabilistic logic;Pattern recognition","","3","","19","IEEE","28 Jun 2024","","","IEEE","IEEE Conferences"
"Understanding and Mitigating the Soft Error of Contrastive Language-Image Pre-training Models","Y. Shi; B. Wang; S. Luo; Q. Xue; X. Zhang; S. Ma","National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China",2024 IEEE International Test Conference in Asia (ITC-Asia),"10 Sep 2024","2024","","","1","6","In recent years, MultiModal Large Language Models (MM-LLMs), based on the Contrastive Language-Image Pretraining models (CLIP), have achieved the best results in many fields. CLIP breaks through the gaps between language models and image models, realizes zero-shot image classification, and achieves excellent performance in tasks such as text-to-image generation, image style transformation, and long video generation. However, there are few studies on the fault tolerance of CLIP with soft errors, which hinders the application of multimodal large models in the field of security. Based on the analysis of the fault tolerance of common multimodal large models, we proposes a soft error mitigation framework. According to the experiments in this paper, the framework can effectively detect soft errors and mitigate the errors.","2768-069X","979-8-3315-4033-3","10.1109/ITC-Asia62534.2024.10661330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10661330","ABFT;fault-tolerance;MM-LLMs;soft errors","Fault tolerance;Analytical models;Prevention and mitigation;Fault tolerant systems;Text to image;Hardware;Software","","1","","10","IEEE","10 Sep 2024","","","IEEE","IEEE Conferences"
"A Chat Bot for Enrollment of Xi 'an Jiaotong-Liverpool University Based on RAG*","L. Xu; J. Liu","College of Intelligent Engineering Xi 'an Jiaotong-Liverpool University, Suzhou, China; College of Intelligent Engineering Xi 'an Jiaotong-Liverpool University, Suzhou, China",2024 8th International Workshop on Control Engineering and Advanced Algorithms (IWCEAA),"9 Jan 2025","2024","","","125","129","Recent advancements in large language models (LLMs) have established pre-training on extensive textual cor-pora as a foundational methodology. However, in specialised applications such as admissions systems, the focus shifts from general knowledge-based reasoning to ensuring accuracy and relevance in domain-specific responses. This study presents the development of an automated admissions system for Xi'an Jiaotong-Liverpool University, leveraging GLM-4 in conjunction with Retrieval-Augmented Generation (RAG) to handle targeted queries. The implementation of RAG mitigates the occurrence of hallucinations often seen in LLM outputs, thereby enhancing the reliability and alignment of generated responses with real-world data, which is critical for prospective students and their parents. This paper details the construction of the RAG corpus and cue word methodology, and provides an empirical comparison of the efficacy of various major language models with and without RAG integration. The results demonstrate the potential of RAG to significantly improveresponse accuracy in domain-specific tasks, and suggest directions for future research in optimising LLMs for admissions processes.","","979-8-3315-2888-1","10.1109/IWCEAA63616.2024.10823979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823979","Chatbots;Large Language Model (LLM);Retriever_Augmented Generation (RAG);Prompt Engineering","Accuracy;Pollution;Large language models;Retrieval augmented generation;Web and internet services;Search engines;Question answering (information retrieval);Maintenance;Web search;Context modeling","","","","12","IEEE","9 Jan 2025","","","IEEE","IEEE Conferences"
"Movable Antenna Aided Physical Layer Security with No Eavesdropper CSI","Z. Cheng; C. Ouyang; X. Zhang","6G Research Centre, China Telecom Beijing Research Institute, Beijing, China; University College Dublin, Dublin, Ireland; Department of Electrical and Computer Engineering, University of Alberta, Canada","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","A novel movable antenna (MA)-aided secure transmission framework is proposed to enhance the secrecy transmission rate without relying on the eavesdropper’s channel state information. Within this framework, a joint beamforming and jamming scheme is proposed, where the power of the confidential signal is minimized by optimizing the positions of the MAs, and the residual power is used to jam the eavesdropper. An efficient gradient-based method is employed to solve this non-convex problem. Numerical results are provided to demonstrate the superiority of the MA-based framework over systems using traditional fixed-position antennas in secure transmission.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10887653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887653","Antenna position;movable antenna;physical layer security;secrecy rate","Array signal processing;Simulation;Transmitting antennas;Signal processing algorithms;Physical layer security;Acoustics;Jamming;Speech processing;Channel state information","","","","22","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Risk-Based Mitigation of Load Curtailment Cyber Attack Using Intelligent Agents in a Shipboard Power System","T. R. B. Kushal; K. Lai; M. S. Illindala","Electrical and Computer Engineering Department, Ohio State University, Columbus, OH, USA; Electrical and Computer Engineering Department, Ohio State University, Columbus, OH, USA; Electrical and Computer Engineering Department, Ohio State University, Columbus, OH, USA",IEEE Transactions on Smart Grid,"21 Aug 2019","2019","10","5","4741","4750","Modern shipboard power systems (SPSs) with advanced cyber infrastructure need urgent attention because they have higher risk of cyber attacks. In particular, false data injection (FDI) attacks can interfere with state estimation by tampering with measurement devices, or they may also directly target the central control system. This paper proposes a twofold strategy to mitigate the effects of such an unconventional FDI attack, using battery to actively reduce load curtailment. To detect signs of malicious data, a multiagent system (MAS) that checks commands from the central energy management system is employed. A novel bilevel optimization problem is formulated to model the interaction between the battery and the compromised SPS. A heuristic defense parameter is developed to improve the detection of corrupted commands. The merits of the proposed scheme are evaluated using a risk analysis model. The results of the case studies prove that a combination of autonomous battery with MAS-based heuristic method is effective in mitigating the effects of the cyber attack.","1949-3061","","10.1109/TSG.2018.2867809","Office of Naval Research(grant numbers:N00014-16-1-2753); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449841","Cyber security;energy storage;intelligent agents;microgrids;multi-agent systems;optimization;risk analysis;shipboard power system","Cyberattack;Power systems;Batteries;Generators;Energy management;Load modeling","","53","","38","IEEE","29 Aug 2018","","","IEEE","IEEE Journals"
"When Geoscience Meets Foundation Models: Toward a general geoscience artificial intelligence system","H. Zhang; J. -J. Xu; H. -W. Cui; L. Li; Y. Yang; C. -S. Tang; N. Boers","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Earth Sciences and Engineering, Nanjing University, Nanjing, China; Huawei Technologies Co., Ltd., Shanghai, China; School of Earth Sciences and Engineering, Nanjing University, Nanjing, China; School of Civil and Environmental Engineering, Nanyang Technological University, Singapore, Singapore; School of Earth Sciences and Engineering, Nanjing University, Nanjing, China; School of Engineering and Design, Technical University of Munich, Munich, Germany",IEEE Geoscience and Remote Sensing Magazine,"","2024","PP","99","2","41","Artificial intelligence (AI) has significantly advanced Earth sciences, yet its full potential in to comprehensively modeling Earth’s complex dynamics remains unrealized. Geoscience foundation models (GFMs) emerge as a paradigm-shifting solution, integrating extensive cross-disciplinary data to enhance the simulation and understanding of Earth system dynamics. These data-centric AI models extract insights from petabytes of structured and unstructured data, effectively addressing the complexities of Earth systems that traditional models struggle to capture. The unique strengths of GFMs include flexible task specification, diverse input-output capabilities, and multimodal knowledge representation, enabling analyses that surpass those of individual data sources or traditional AI methods. This review not only highlights the key advantages of GFMs, but also presents essential techniques for their construction, with a focus on transformers, pre-training, and adaptation strategies. Subsequently, we examine recent advancements in GFMs, including large language models, vision models, vision-language models, and foundation-model-based agents, particularly emphasizing the potential applications in remote sensing. Additionally, the review concludes with a comprehensive analysis of the challenges and future trends in GFMs, addressing five critical aspects: data integration, model complexity, uncertainty quantification, interdisciplinary collaboration, and concerns related to privacy, trust, and security. This review offers a comprehensive overview of emerging geoscientific research paradigms, emphasizing the untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of GFMs. The paper highlights a dynamic field rich with possibilities, poised to unlock new insights into Earth’s complexities and further advance geoscience exploration.","2168-6831","","10.1109/MGRS.2024.3496478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10770814","","Geoscience;Artificial intelligence;Frequency modulation;Earth;Reviews;Data models;Adaptation models;Surveys;Analytical models;Computational modeling","","5","","","IEEE","28 Nov 2024","","","IEEE","IEEE Early Access Articles"
"Efficient Prompting for LLM-Based Generative Internet of Things","B. Xiao; B. Kantarci; J. Kang; D. Niyato; M. Guizani","School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Machine Learning Department, Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE",IEEE Internet of Things Journal,"20 Dec 2024","2025","12","1","778","791","Large language models (LLMs) have demonstrated remarkable capacities on various tasks, and integrating the capacities of LLMs into the Internet of Things (IoT) applications has drawn much research attention recently. Due to security concerns, many institutions avoid accessing state-of-the-art commercial LLM services, requiring the deployment and utilization of open-source LLMs in a local network setting. However, open-source LLMs usually have more limitations regarding their performance, such as their arithmetic calculation and reasoning capacities, and practical systems of applying LLMs to IoT have yet to be well-explored. Therefore, we propose an LLM-based Generative IoT (GIoT) system deployed in the local network setting in this study. To alleviate the limitations of LLMs and provide service with competitive performance, we apply prompt engineering methods to enhance the capacities of the open-source LLMs, design a Prompt Management Module and a Postprocessing Module to manage the tailored prompts for different tasks and process the results generated by the LLMs. To demonstrate the effectiveness of the proposed system, we discuss a challenging table question answering (Table-QA) task as a case study of the proposed system, as tabular data is usually more challenging than plaintext because of their complex structures, heterogeneous data types and sometimes huge sizes. We conduct comprehensive experiments on the two popular Table-QA data sets, and the results show that our proposal can achieve competitive performance compared with state-of-the-art LLMs, demonstrating that the proposed LLM-based GIoT system can provide competitive performance with tailored prompting methods and is easily extensible to new tasks without training.","2327-4662","","10.1109/JIOT.2024.3470210","Natural Sciences and Engineering Research Council of Canada (NSERC); CREATE TRAVERSAL Program and NSERC DISCOVERY Program; National Research Foundation, Singapore; Infocomm Media Development Authority under its Future Communications Research & Development Programme, AI Singapore Programme(grant numbers:FCP-NTU-RG-2022-010,FCP-ASTAR-TG-2022-003); Singapore Ministry of Education (MOE) Tier 1(grant numbers:RG87/22); NTU Centre for Computational Technologies in Finance (NTU-CCTF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705427","Generative Internet of Things (GIoT);large language model (LLM);prompt engineering;table question answering (Table-QA)","Internet of Things;Cognition;Python;Artificial intelligence;Structured Query Language;Training;Servers;Question answering (information retrieval);Security;Performance evaluation","","11","","59","IEEE","4 Oct 2024","","","IEEE","IEEE Journals"
"A Survey on Semantic Communication Networks: Architecture, Security, and Privacy","S. Guo; Y. Wang; N. Zhang; Z. Su; T. H. Luan; Z. Tian; X. Shen","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Department of Electrical and Computer Engineering, University of Windsor, Windsor, Canada; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Computer Science, University of Technology Sydney, Sydney, Australia; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",IEEE Communications Surveys & Tutorials,"","2024","PP","99","1","1","With the rapid advancement and deployment of intelligent agents and artificial general intelligence (AGI), a fundamental challenge for future networks is enabling efficient communications among agents. Unlike traditional human-centric, data-driven communication networks, the primary goal of agent-based communication is to facilitate coordination among agents. Therefore, task comprehension and collaboration become the key objectives of communications, rather than data synchronization. Semantic communication (SemCom) aims to align information and knowledge among agents to expedite task comprehension. While significant research has been conducted on SemCom for two-agent systems, the development of semantic communication networks (SemComNet) for multi-agent systems remains largely unexplored. In this paper, we provide a comprehensive and up-to-date survey of SemComNet, focusing on their fundamentals, security, and privacy aspects. We introduce a novel three-layer architecture for multi-agent interaction, comprising the control layer, semantic transmission layer, and cognitive sensing layer. We explore working modes and enabling technologies, and present a taxonomy of security and privacy threats, along with state-of-the-art defense mechanisms. Finally, we outline future research directions, paving the way toward intelligent, robust, and energy-efficient SemComNet. This survey represents the first comprehensive analysis of SemComNet, offering detailed insights into its core principles as well as associated security and privacy challenges.","1553-877X","","10.1109/COMST.2024.3516819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10798108","Semantic communication;artificial intelligence;security;privacy;trust","Security;Surveys;Privacy;Artificial intelligence;Knowledge based systems;Collaboration;Training;Sensors;Wireless communication;Computer hacking","","6","","","IEEE","13 Dec 2024","","","IEEE","IEEE Early Access Articles"
"Smart Prep: AI Based Interactive Interview Preparation System","R. M. Marvaniya; A. S. Acharya; D. M. Detroja; V. K. Dabhi; H. B. Prajapati","BTech (IT) Student, Dept. of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India; BTech (IT) Student, Dept. of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India; BTech (IT) Student, Dept. of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India; Dept. of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India; Dept. of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India",2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0,"14 Jul 2025","2025","","","1","6","This paper introduces Smart Prep, an interactive platform where users can choose to interact with an agents or professional team to practice interviewing. During each session, Smart Prep staff, AI agents, ask domain-specific questions, to which users respond by writing or speaking their answers. The agents then analyze these responses and provide users with constructive feedback and suggestions to improve their interviewing skills. Powered by OpenAI ChatGPT and with speech and text capabilities, Smart Prep provides a virtual and helpful environment for users to practice, improving their interview performance Built with Svelte for front-end and Flask for back-end, Smart Prep demonstrates significant potential as a valuable training tool in professional and educational settings.","","979-8-3315-3536-0","10.1109/OTCON65728.2025.11070972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11070972","Smart Prep;Multi-Agent Systems;Prompt Engineering;Interview Simulation;Speech-to-Text;OpenAI API;AI-driven Feedback;Svelte Frontend;Flask Backend;Educational Technology;Skill Development;Realistic Practice Environment;Interactive Learning;Domain-Specific Agents","Training;Technological innovation;Writing;Real-time systems;Prompt engineering;Interviews;Artificial intelligence;Multi-agent systems;Speech to text;Recruitment","","","","10","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Brief State of the Art on Human-AI in Software Engineering: Impact, Ethical Challenges, and Academic Evolution","Y. V. Morales M.; B. D. Valenzuela R.; R. S. Salgado; G. G. Serna; N. A. C. Sánchez","TecNM/Cenidet, Cuernavaca, México; TecNM/Cenidet, Cuernavaca, México; TecNM/Cenidet, Cuernavaca, México; TecNM/Cenidet, Cuernavaca, México; TecNM/Cenidet, Cuernavaca, México",2024 13th International Conference On Software Process Improvement (CIMPS),"4 Aug 2025","2024","","","117","124","This article presents a brief state of the art on the integration of artificial intelligence (AI) in software engineering, focusing on its impact, emerging ethical challenges, and the academic evolution required to address these changes. Through a systematic literature review based on the PRISMA methodology and the analysis of case studies, it explores how AI, particularly large language models (LLMs), is transforming key processes such as code generation, program verification, and integration with DevOps practices, thereby improving software productivity and quality. However, these advances entail significant ethical challenges, such as the introduction of biases, lack of transparency in automated decisions, and excessive reliance on automation, raising concerns about privacy and security. This study highlights the importance of reformulating curricula, developing models for academic institutions that integrate an ethical approach to AI teaching, and fostering collaboration with the industry. This work offers a comprehensive vision that combines the technical, ethical, and educational aspects necessary for the responsible implementation of AI. Finally, directions for future research centered on developing more transparent AI technologies and creating robust ethical frameworks to ensure effective synergy between humans and AI in software engineering are identified.","","979-8-3315-1086-2","10.1109/CIMPS65195.2024.11095939","National Technological Institute of Mexico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095939","Artificial Intelligence (AI);Software Engineering;Large Language Models (LLM);DevOps;Human-AI","Productivity;Ethics;Privacy;DevOps;Large language models;Collaboration;Software;Security;Artificial intelligence;Software engineering","","","","49","IEEE","4 Aug 2025","","","IEEE","IEEE Conferences"
"Probing with Precision: Probing Question Generation for Architectural Information Elicitation","G. Rejithkumar; P. R. Anish; J. Shukla; S. Ghaisas","TCS Research, Pune, India; TCS Research, Pune, India; TCS Research, Pune, India; TCS Research, Pune, India","2024 IEEE/ACM Workshop on Multi-disciplinary, Open, and RElevant Requirements Engineering (MO2RE)","11 Sep 2024","2024","","","8","14","Software Requirements Specifications (SRS) often lack the necessary level of specificity required by software architects to make well-informed architectural decisions. This deficiency compels software architects to probe business analysts to collect more details pertinent to architectural requirements from the clients. In our previous work, we introduced Probing Question-flows (PQ-flows) that can assist business analysts to probe stakeholders and gather architecturally significant information for the creation of a more comprehensive SRS. Key limitations of our previous work were the manually created templatized PQ-flows and the mapping of PQ-flows to the software requirements based on standard Vector Space Model. In this study, we propose a Retrieval Augmented Generation (RAG) prompting framework to address these limitations. We conducted experiments using ChatGPT and Mistral-7B models. We present our findings utilizing human and automated evaluation metrics on a subset of the publicly available PUblic REquirements (PURE) dataset.CCS CONCEPTS• Software and its engineering → Requirements analysis; • Computing methodologies → Natural language generation; • Information systems → Information retrieval query processing; Question answering.","","979-8-4007-0569-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669649","Requirements Engineering;Probing Questions;Large Language Models;Prompting;Retrieval Augmented Generation;ChatGPT;Mistral","Barium;Chatbots;Software;Vectors;Time measurement;Stakeholders;Probes","","","","21","","11 Sep 2024","","","IEEE","IEEE Conferences"
"SecureGenKeys: Building Secure and Personalized Keypads with Generative AI","V. M","Department of Artificial Intelligence and Machine Learning, Rajalakshmi Engineering College, Chennai, India",2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS),"23 Oct 2024","2024","1","","1416","1421","Ensuring the security of systems is paramount in safeguarding confidential information from unauthorized access, particularly in today's interconnected digital landscape. Visual eavesdropping techniques, such as “Shoulder Surfing,” pose significant threats to security, including unauthorized access, data breaches, and identity theft, whereby sensitive information is illicitly obtained during user input. This paper introduces a novel method designed to fortify password security, simultaneously enhancing the user experience and facilitating secure transactions. The proposed methodology introduces a personalized interactive password selection process that not only increases user engagement but also bolsters security measures. User-entered prompts undergo processing to transform into personalized tokens and form a secure password. These tokens are utilized to generate foundational images in which the tokens are strategically allocated ensuring both clarity and randomness. The system employs machine learning algorithm, particularly focusing on deep learning approaches for image analysis and pattern recognition techniques to verify user-entered passwords against stored data. Successful authentication triggers secure transactions, providing a seamless and protected user experience.","2575-7288","979-8-3503-8436-9","10.1109/ICACCS60874.2024.10716821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716821","Shoulder Surfing (SS);Generative Artificial Intelligence (AI);Secure Keypad;Dynamic Token Generation Module (DTGM);Large Language Model (LLM);Token Repository Module (TRM);Foundational Image Generation Module (FIGM);Image Segmentation;Secure Keypad Generation Module (SKGM);Token Sequence Validation and Authentication Module (TSVA);Machine Learning","Visualization;Generative AI;Refining;Authentication;Passwords;Transforms;User interfaces;User experience;Security;Resource management","","","","15","IEEE","23 Oct 2024","","","IEEE","IEEE Conferences"
"Comparative Studies: Leveraging Large Language Model In Theoritical and Practical Assessment Sample Question-Answer Bank on Programming Related Subjects","C. W. Luen William; T. M. Lim","Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology, Kuala Lumpur, Malaysia; Centre for Business Incubation and Entrepreneurial Ventures, Tunku Abdul Rahman University of Management and Technology, Kuala Lumpur, Malaysia","2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)","2 Aug 2024","2024","","","331","335","Practical Code Assessment has been important in assessing students' level of understanding, coding, and assessing/evaluating. One of the challenges faced by lecturers is the difficulty in producing questions and answers creatively. To address this issue, an experimental proof-of-concept (POC) prototype was developed using Natural Language Processing (NLP) and Prompt Engineering techniques in the Large Language Model (LLM) to generate practical and high-quality questions and answers. Two Large Language Models, namely LLaMa2-7b and Mixtral-7b were compared to provide a scalable POC solution. Through evaluation and benchmarking, the prototype was tested based on Human-level Performance (HLP) standards. This prototype enhanced the work efficiency of the lecturers as it shortened the time to create questions and answers for assessments, which eventually enhanced learning outcomes and the educational, learning, and teaching experience.","","979-8-3503-6072-1","10.1109/ICEIB61477.2024.10602701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602701","large language model (LLM);natural language processing (NLP);prompt engineering;practical code assessment","Training;Codes;Large language models;Prototypes;Natural language processing;Encoding;Prompt engineering","","1","","11","IEEE","2 Aug 2024","","","IEEE","IEEE Conferences"
"Mystery Game Script Compose Based on a Large Language Model","J. Li; Z. Chen; W. Lin; L. Zou; X. Xie; Y. Hu; D. Li","Tanwei College, Tsinghua University, Beijing, China; FITC, Tsinghua University, Beijing, China; FITC, Tsinghua University, Beijing, China; Sofware Engineering, Beijing University of Technology, Beijing, China; Materials Science & Engineering, Tsinghua University, Beijing, China; iCenter, Tsinghua University, Beijing, China; School of Life Sciences, Tsinghua University, Beijing, China",2024 IEEE World AI IoT Congress (AIIoT),"10 Jul 2024","2024","","","451","455","In this paper, we present a method based on large language models for murder mystery game scriptwriting, which not only helps ordinary user’s one-click generation of ideas into a complete work, but also helps professional scriptwriters to improve the efficiency of creation. The main idea of this paper is to develop prompt engineering to communicate with the large language model, so that the model can accurately generate the required content according to the user’s thread, and improve the quality of the output scripts. Through the effective combination of AI and human thinkings, the paper explores the potential application prospects of AI in murder mystery game script generation and expression with a new perspective and means.","","979-8-3503-8780-3","10.1109/AIIoT61789.2024.10579034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579034","Large Language Model;Murder Mystery Creation;Prompt Engineering","Large language models;Games;Prompt engineering","","","","17","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"A Privacy-Preserving and Trustworthy Inference Framework for LLM-IoT Integration via Hierarchical Federated Collaborative Computing","C. Han; T. Yang; Z. Cui; X. Sun","School of Cyber Science and Engineering, Southeast University, Nanjing, China; Peng Cheng Laboratory, Shenzhen, China; Criminal Investigation Police University of China, Shenyang, China; School of Navigation, Dalian Maritime University, Dalian, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","This paper addresses the challenges of privacy protection, device constraints, resource heterogeneity, and trusted inference in the integration of large language models (LLMs) with Internet of Things (IoT) devices, proposing a Hierarchical Federated Collaborative Computing (HFCC) framework. Unlike traditional federated learning, HFCC employs horizontal splitting + chunking to reduce LLMs computation overhead. The framework dynamically splits LLMs into: 1) global shared layers optimized by edge servers, and 2) device-local layers trained on private data, ensuring raw data remains on-device. During inference, chunking of shared layers and dynamic task allocation adjust computational loads based on real-time device states, mitigating high-load security risks. Furthermore, leveraging the hierarchical federated learning architecture, the system employs an anonymized parameter aggregation mechanism during training to achieve multi-level privacy protection. Simultaneously, a cross-device consensus verification mechanism performs trusted validation of distributed intermediate results, effectively identifying malicious node behavior. Experiments show 58% faster inference in resource-constrained environments, significantly reduced data exposure risks, and 94% malicious node detection accuracy versus traditional federated learning. This lays a solid foundation for building an intelligent, efficient, and secure IoT ecosystem.","2327-4662","","10.1109/JIOT.2025.3583764","National Defense Foundation Strengthening Plan under Grant(grant numbers:2020-JCJQ-ZD-020-05); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053989","LLMs Deployment;IoT Security;Federated Learning;Privacy Preservation;Trustworthy Inference","Computational modeling;Federated learning;Collaboration;Training;Servers;Internet of Things;Data models;Edge computing;Data privacy;Biological system modeling","","","","","IEEE","27 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Detection Method for Offensive Speech Based on Prompting and Parameter Fine-Tuning","D. Cheng; Y. Fu; X. Fan; T. Zhou; J. Liu","College of Computer Science and Technology, Xinjiang Normal University, Urumqi, Xinjiang, China; College of Computer Science and Technology, Xinjiang Normal University, Urumqi, Xinjiang, China; College of Computer Science and Technology, Xinjiang Normal University, Urumqi, Xinjiang, China; College of Control Engineering, Xinjiang Institute of Engineering, Urumqi, Xinjiang, China; College of Computer Science and Technology, Xinjiang Normal University, Urumqi, Xinjiang, China","2025 4th International Conference on Artificial Intelligence, Internet and Digital Economy (ICAID)","17 Jun 2025","2025","","","345","349","With the rapid development of social media, the convenience of online communication has led to the frequent occurrence of offensive speech, posing a threat to the online social environment. Ensuring the safety, health, and friendliness of online platforms has made the automatic detection of offensive speech an urgent necessity. Despite the superior performance of large language models in natural language processing tasks due to their extensive parameter sets, their effectiveness in detecting offensive speech is limited by the complexity and diversity of language and the models' tendency to avoid sensitive content. The inherent biases and imbalances in existing datasets further constrain model performance. To address these issues, this paper proposes an offensive speech detection method that combines prompt engineering and parameter fine-tuning (ChatGLM-PPFT), aiming to improve the shortcomings of the large language model ChatGLM in such tasks. By designing strategies such as role-playing, few-shot prompting, and historical response referencing, ChatGLM-PPFT not only mitigates the problem of non-standard responses to offensive content but also enhances detection performance for Chinese offensive speech through lightweight fine-tuning using the LoRA method. On the TOXICN and SWSR datasets, ChatGLM-PPFT achieves state-of-the-art detection results.","","979-8-3315-1066-4","10.1109/ICAID65275.2025.11034535","Xinjiang Normal University; Xinjiang Normal University; Xinjiang Normal University; Ministry of Education; Xinjiang Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034535","component;Offensive Speech Detection;Partial Parameter Fine-Tuning;Prompt Engineering;ChatGLM-PPFT","Voice activity detection;Social networking (online);Biological system modeling;Large language models;LoRa;Speech enhancement;Natural language processing;Safety;Internet;Prompt engineering","","","","17","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Prompting LLM for Embodied Tasks with Expert Instruction and Dimension Separation","G. Zhao; T. Xu; S. Zhao","School of Computer and Technology, University of Science and Technology of China, Hefei, China; School of Computer and Technology, University of Science and Technology of China, Hefei, China; School of Computer and Technology, University of Science and Technology of China, Hefei, China",2024 International Conference on Intelligent Robotics and Automatic Control (IRAC),"12 Feb 2025","2024","","","422","426","With the development of large language models, it has become possible to use multimodal models to build embodied agents. Currently, most approaches for handling embodied intelligence tasks with multimodal large models rely on prompt engineering or fine-tuning the models. However, to construct a general embodied intelligence model, the model needs to transfer world knowledge to corresponding embodied intelligence scenarios and spatial contexts. Language models that have not been optimized for embodied intelligence scenarios lack a good understanding of 3D scenes and the robot's action space. We attempted to address this issue in two ways, separated prompting approach where the model decomposes 3D spatial problems into 2D spatial problems and a trained expert model to guide the general model in spatial perception and action execution. Ultimately, the general model achieved improvements in embodied intelligence tasks. Experimental results demonstrated the effectiveness of our method.","","979-8-3503-8980-7","10.1109/IRAC63143.2024.10871329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871329","Large Language Model;Embodied AI;Prompt Engineering","Solid modeling;Three-dimensional displays;Large language models;Buildings;Predictive models;Aerospace electronics;Prompt engineering;Robots;Context modeling","","","","11","IEEE","12 Feb 2025","","","IEEE","IEEE Conferences"
"MCM-Llama: A Fine-Tuned Large Language Model for Real-Time Threat Detection through Security Event Correlation","M. L. Diakhame; C. Diallo; M. Mejri","Department of Computer Science, Gaston Berger University, Saint Louis, Senegal; Department of Computer Science, Gaston Berger University, Saint Louis, Senegal; Department of Computer Science & Software Engineering, Laval University, Quebec, Canada","2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","8 Oct 2024","2024","","","1","6","The correlation of security alerts is crucial for effective threat detection and mitigation in modern cybersecurity landscapes. With the exponential growth in the volume of generated alerts, there arises an imperative to continually develop new, efficient methods for alert correlation. The use of Large Language Models (LLMs) presents new avenues for enhancing real-time threat detection in the field of cybersecurity. In this paper, we introduce MCM-Llama, a fine-tuned language model aimed at improving security event correlation for real-time threat detection. Building upon our prior research, we augment the current framework by integrating MCM-Llama and introducing a novel architecture to practically implement our proposition. In doing so, we replace the correlation module previously based on Named Entity Recognition (NER) and semantic similarity with a fine-tuned Large Language Model (LLM). This transition allows us to capitalize on the advanced capabilities of LLM in comprehending and correlating security events dynamically. Through this enhancement, we aim to significantly improve the accuracy and efficiency of our threat detection system while leveraging the full potential of LLM technology in cybersecurity. Our experimental results validate the efficacy of the proposed approach by significantly improving the correlation rate, thereby reinforcing the pivotal role of Large Language Models (LLMs) in advancing security event correlation and threat detection methodologies.","","979-8-3503-9591-4","10.1109/ICECET61485.2024.10698464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698464","Large Language Model;Alert correlation;In-trusion Detection System;Cyber attack;Attack scenario reconstruction","Correlation;Accuracy;Large language models;Prevention and mitigation;Semantics;Decision making;Named entity recognition;Threat assessment;Real-time systems;Computer crime","","","","32","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Jupiter: Fast and Resource-Efficient Collaborative Inference of Generative LLMs on Edge Devices","S. Ye; B. Ouyang; L. Zeng; T. Qian; X. Chu; J. Tang; X. Chen","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; The Chinese University of Hong Kong, Hong Kong SAR, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Data Science and Analytics Thrust, HKUST (Guangzhou), Guangzhou, China; Midea Group, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",IEEE INFOCOM 2025 - IEEE Conference on Computer Communications,"1 Jul 2025","2025","","","1","10","Generative large language models (LLMs) have garnered significant attention due to their exceptional capabilities in various AI tasks. Traditionally deployed in cloud datacenters, LLMs are now increasingly moving towards more accessible edge platforms to protect sensitive user data and ensure privacy preservation. The limited computational resources of individual edge devices, however, can result in excessively prolonged in-ference latency and overwhelmed memory usage. While existing research has explored collaborative edge computing to break the resource wall of individual devices, these solutions yet suffer from massive communication overhead and under-utilization of edge resources. Furthermore, they focus exclusively on optimizing the prefill phase, neglecting the crucial autoregressive decoding phase for generative LLMs. To address that, we propose Jupiter, a fast, scalable, and resource-efficient collaborative edge AI system for generative LLM inference. Jupiter introduces a flexible pipelined architecture as a principle and differentiates its system design according to the differentiated characteristics of the prefill and decoding phases. For prefill phase, Jupiter submits a novel intra-sequence pipeline parallelism and develops a meticulous parallelism planning strategy to maximize resource efficiency; For decoding, Jupiter devises an effective outline-based pipeline parallel decoding mechanism combined with speculative decoding, which further magnifies inference acceleration. Extensive evaluation based on realistic implementation demon-strates that Jupiter remarkably outperforms state-of-the-art approaches under various edge environment setups, achieving up to 26.1 × end-to-end latency reduction while rendering on-par generation quality.","2641-9874","979-8-3315-4305-1","10.1109/INFOCOM55648.2025.11044734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044734","","Jupiter;Large language models;Pipelines;Collaboration;Computer architecture;Parallel processing;Rendering (computer graphics);Decoding;Planning;System analysis and design","","","","44","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Efficient Federated Intrusion Detection in 5G Ecosystem Using Optimized BERT-Based Model","F. Adjewa; M. Esseghir; L. Merghem-Boulahia","LIST3N, University of Technology of Troyes; LIST3N, University of Technology of Troyes; LIST3N, University of Technology of Troyes","2024 20th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)","4 Dec 2024","2024","","","62","67","The fifth-generation (5G) offers advanced services, supporting applications such as intelligent transportation, con-nected healthcare, and smart cities within the Internet of Things (IoT). However, these advancements introduce significant security challenges, with increasingly sophisticated cyber-attacks. This paper proposes a robust intrusion detection system (IDS) using federated learning and large language models (LLMs). The core of our IDS is based on BERT, a transformer model adapted to identify malicious network flows. We modified this transformer to optimize performance on edge devices with limited resources. Experiments were conducted in both centralized and federated learning contexts. In the centralized setup, the model achieved an inference accuracy of 97.79 %. In a federated learning context, the model was trained across multiple devices using both IID (Independent and Identically Distributed) and non-IID data, based on various scenarios, ensuring data privacy and compliance with regulations. We also leveraged linear quantization to com-press the model for deployment on edge devices. This reduction resulted in a slight decrease of 0.02 % in accuracy for a model size reduction of 28.74 %. The results underscore the viability of LLMs for deployment in IoT ecosystems, highlighting their ability to operate on devices with constrained computational and storage resources.","2160-4894","979-8-3503-8744-5","10.1109/WiMob61911.2024.10770340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10770340","5G;Internet of Things;Intrusion detection system;Federated Learning;Large Language Models;Data privacy;Cybersecurity","Performance evaluation;Adaptation models;5G mobile communication;Federated learning;Computational modeling;Large language models;Ecosystems;Intrusion detection;Transformers;Data models","","7","","27","IEEE","4 Dec 2024","","","IEEE","IEEE Conferences"
"Unlocking Large Language Model Power in Industry: Privacy-Preserving Collaborative Creation of Knowledge Graph","L. Xia; J. Fan; A. Parlikad; X. Huang; P. Zheng","Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Institute for Manufacturing, University of Cambridge, Cambridge, U.K.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong",IEEE Transactions on Big Data,"10 Jul 2025","2025","11","4","2046","2060","Semantic expertise remains a reliable foundation for industrial decision-making, while Large Language Models (LLMs) can augment the often limited empirical knowledge by generating domain-specific insights, though the quality of this generative knowledge is uncertain. Integrating LLMs with the collective wisdom of multiple stakeholders could enhance the quality and scale of knowledge, yet this integration might inadvertently raise privacy concerns for stakeholders. In response to this challenge, Federated Learning (FL) is harnessed to improve the knowledge base quality by cryptically leveraging other stakeholders’ knowledge, where knowledge base is represented in Knowledge Graph (KG) form. Initially, a multi-field hyperbolic (MFH) graph embedding method vectorizes entities, furnishing mathematical representations in lieu of solely semantic meanings. The FL framework subsequently encrypted identifies and fuses common entities, whereby the updated entities’ embedding can refine other private entities’ embedding locally, thus enhancing the overall KG quality. Finally, the KG complement method refines and clarifies triplets to improve the overall quality of the KG. An experiment assesses the proposed approach across different industrial KGs, confirming its effectiveness as a viable solution for collaborative KG creation, all while maintaining data security.","2332-7790","","10.1109/TBDATA.2024.3522814","Research Funding Scheme for Supporting Intra-Faculty Interdisciplinary Projects(grant numbers:1-WZ4N); Hong Kong Polytechnic University; COMAC International Collaborative Research Project(grant numbers:COMAC-SFGS-2023-3148); PolyU-Rhein Köster Joint Laboratory on Smart Manufacturing(grant numbers:H-ZG6L); Smart Traffic Fund(grant numbers:PSRI/35/2202/PR); State Key Laboratory of Intelligent Manufacturing Equipment and Technology of Huazhong University of Science and Technology(grant numbers:IMETKF2024010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816465","Federated learning;graph embedding;industrial 4.0;knowledge graph;large language models","Collaboration;Stakeholders;Data models;Knowledge engineering;Knowledge graphs;Federated learning;Big Data;Uncertainty;Tail;Mathematical models","","2","","40","IEEE","26 Dec 2024","","","IEEE","IEEE Journals"
"Data Provenance for Multi-Agent Models","D. B. Davis; J. Featherston; M. Fukuda; H. U. Asuncion","School of Science, University of Washington Bothell, Bothell, Washington, United States; School of Science, University of Washington Bothell, Bothell, Washington, United States; School of Science, University of Washington Bothell, Bothell, Washington, United States; School of Science, University of Washington Bothell, Bothell, Washington, United States",2017 IEEE 13th International Conference on e-Science (e-Science),"16 Nov 2017","2017","","","39","48","Multi-agent simulations are useful for exploring collective patterns of individual behavior in social, biological, economic, network, and physical systems. However, there is no provenance support for multi-agent models (MAMs) in a distributed setting. To this end, we introduce ProvMASS, a novel approach to capture provenance of MAMs in a distributed memory by combining inter-process identification, lightweight coordination of in-memory provenance storage, and adaptive provenance capture. ProvMASS is built on top of the Multi-Agent Spatial Simulation (MASS) library, a framework that combines multi-agent systems with large-scale fine-grained agent-based models, or MAMs. Unlike other environments supporting MAMs, MASS parallelizes simulations with distributed memory, where agents and spatial data are shared application resources. We evaluate our approach with provenance queries to support three use cases and performance measures. Initial results indicate that our approach can support various provenance queries for MAMs at reasonable performance overhead.","","978-1-5386-2686-3","10.1109/eScience.2017.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109121","data provenance;agent-based systems;distributed parallel computing","Computational modeling;Biological system modeling;Mathematical model;Adaptation models;Multi-agent systems;Data models","","2","","37","IEEE","16 Nov 2017","","","IEEE","IEEE Conferences"
"Ai Machine Learning: Transformer Models For Enhanced Natural Language Processing - Techniques And Applications","P. S; G. M. Karthik; T. Sripriya; E. Rajasekaran; S. M. Periannasamy; M. Zubair Aslam M A","Department of Computer Science Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Information Security, School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of ECE, Jeppiaar Institute of Technology, Chennai, Tamil Nadu, India; Department of Science and Humanities, V.S.B Engineering College, Karur, Tamil Nadu, India; Department of Electronics and Communication Engineering, Mallareddy Engineering College for Women, Maisammaguda, Hyderabad; Department of AI & DS, Dhanalakshmi College of Engineering, Chennai, Tamil Nadu, India","2024 12th International Conference on Internet of Everything, Microwave, Embedded, Communication and Networks (IEMECON)","23 Jan 2025","2024","","","1","6","Modern technologies are needed to strengthen network security defenses because of the increase in cyber attacks in recent years. Because deep learning in particular allows for real-time threat identification and thorough performance evaluation, artificial intelligence (AI) has become a powerful tool for improving cybersecurity measures. This study examines how deep learning methods can be used in AI cybersecurity frameworks, with an emphasis on how well they can detect and counteract changing cyberthreats. The use of convolutional neural networks (CNNs) and deep neural networks (DNNs) for anomaly detection and pattern identification in network traffic is specifically discussed. The study also investigates the integration of AI-driven analytics to assess the performance and efficacy of security protocols, offering insights into optimizing defensive strategies against sophisticated cyber attacks. By leveraging AI capabilities, organizations can achieve proactive threat management, enhance incident response times, and fortify their networks against emerging cyber threats. This abstract sets the stage for a comprehensive exploration of AI's role in cybersecurity, highlighting its transformative impact on network security operations.","","979-8-3503-8731-5","10.1109/IEMECON62401.2024.10846252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10846252","Convolutional neural networks;NLP;cyber security;real-time threat detection;recurrent neural networks","Deep learning;Performance evaluation;Standards organizations;Network security;Natural language processing;Real-time systems;Time factors;Convolutional neural networks;Artificial intelligence;Cyberattack","","","","19","IEEE","23 Jan 2025","","","IEEE","IEEE Conferences"
"Leveraging LLM-Powered Intelligent Chatbots for Intent-Based Networking in 5G Modem Reconfiguration","M. Fontana; D. Berardi; S. D’Urso; F. Sciarrone; B. Martini","Dept. of Engineering and Sciences, Universitas Mercatorum, Rome, Italy; Dept. of Engineering and Sciences, Universitas Mercatorum, Rome, Italy; Dept. of Engineering and Sciences, Universitas Mercatorum, Rome, Italy; Dept. of Engineering and Sciences, Universitas Mercatorum, Rome, Italy; Dept. of Engineering and Sciences, Universitas Mercatorum, Rome, Italy",2025 IEEE 11th International Conference on Network Softwarization (NetSoft),"21 Jul 2025","2025","","","209","213","Intent-Based Networking (IBN) has simplified network management and orchestration at a high level, but configuring User Equipment (UE), like 5G modems, is still a complex and demanding task due to dynamic requirements and intricate device-specific settings, and scalability challenges, especially when dealing with distributed, edge-based devices. This paper explores the potential of using Intelligent Chatbots powered by Generative Artificial Intelligence and Large Language Models (LLMs) operating as co-pilots to automate and optimize modem configurations. We propose a scalable chatbot system that translates user intents into actionable configurations, enhancing security, performance, and adaptability. To this end, we introduce a middleware that bridges LLMs with 5G Modem interfaces, eliminating retraining needs while ensuring engaging, real-time interaction with users. Additionally, we analyze key challenges in integrating LLM-based chatbots with UE and discuss the benefits of query caching in optimizing response times. Our findings highlight the potential of Intelligent Chatbots in extending IBN principles to UE, enabling a more automated and user-friendly approach to network configuration.","2693-9789","979-8-3315-4345-7","10.1109/NetSoft64993.2025.11080642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11080642","Intent Based Networking (IBN);Large Language Models (LLM);5G/6G networks","Translation;5G mobile communication;Large language models;Scalability;Chatbots;Modems;Real-time systems;Time factors;Security;Middleware","","","","20","IEEE","21 Jul 2025","","","IEEE","IEEE Conferences"
"A Holistic Review of Fuzzing for Vulnerability Assessment in Industrial Network Protocols","A. R. Aldysty; N. Moustafa; E. Lakshika","School of Systems and Computing, University of New South Wales, Canberra, ACT, Australia; School of Systems and Computing, University of New South Wales, Canberra, ACT, Australia; School of Systems and Computing, University of New South Wales, Canberra, ACT, Australia",IEEE Open Journal of the Communications Society,"28 May 2025","2025","6","","4437","4461","Industrial control systems (ICSs) are considered the backbone of the industry field due to their essential role in supervising and handling crucial manufacturing operations in critical infrastructures such as power grids, water supply systems, and manufacturing processes. ICS systems were not initially designed with robust security measures, making them vulnerable to potential attacks. Accordingly, these attacks can lead to severe consequences, including disrupting services, causing economic damage, and compromising public safety. Notably, the security of Industrial Control Systems depends on the robustness of Industrial Network Protocols (INPs). Therefore, exposing and addressing their vulnerabilities is essential to strengthening these critical infrastructures and proactively mitigating cyber threats. Fuzzing has emerged as a powerful technique for uncovering security flaws in network protocols by systematically generating malformed inputs to trigger unexpected behavior. In this paper, we address a critical area in industrial cybersecurity by examining recent advancements in fuzzing methods for industrial network protocols. Our work provides a comprehensive overview of the fuzzing process, identifies key vulnerabilities in INPs, especially within the widely used Modbus protocol, and highlights the need for more advanced fuzzing strategies. Thus, we present a systematic machine learning-based fuzzing framework tailored to the unique characteristics of industrial protocols, leveraging proven methodologies from existing literature. By evaluating the strengths and limitations of state-of-the-art approaches, we offer valuable insights into the key challenges associated with applying fuzzing to discover vulnerabilities in industrial protocols, such as maintaining message integrity, implementing intelligent log analysis, and addressing the lack of explainability in fuzzing outcomes. Crucially, we also explore how the capabilities of large language models (LLMs), including their comprehensive knowledge bases, contextual understanding, and knowledge consolidation, can be harnessed to overcome these challenges and enhance the effectiveness of fuzzing in industrial environments, which we demonstrate through a mini case study. Lastly, this paper provides actionable guidance for future research and development in securing industrial network protocols.","2644-125X","","10.1109/OJCOMS.2025.3569291","UNSW Canberra HDR’s Scholarships; Australian Research Council’s Discovery Early Career Researcher Award (DECRA)(grant numbers:DE230100116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11002567","Fuzzing;industrial control systems;industrial network protocol;network protocol fuzzing;vulnerability;machine learning;large language models","Fuzzing;Protocols;Security;Industrial control;Surveys;Machine learning;Indium phosphide;III-V semiconductor materials;Systematics;Measurement","","","","163","CCBYNCND","12 May 2025","","","IEEE","IEEE Journals"
"Autonomous Cyber Incident Response Using Reasoning and Action","S. Baral; S. Saha; A. Haque","Department of Computer Science, Western University, London, Canada; Department of Computer Science, University of Northern British Columbia, Prince George, Canada; Department of Computer Science, Western University, London, Canada",2025 International Wireless Communications and Mobile Computing (IWCMC),"2 Jul 2025","2025","","","1392","1397","The increasing complexity and frequency of cyber threats necessitate autonomous security solutions capable of real-time detection, reasoning, and response. This paper introduces an autonomous cyber incident response framework that integrates Reasoning and Acting (ReAct) agents with Large Language Models (LLMs) to enhance cybersecurity decision-making. The proposed system features a cloud-based testbed, real-time monitoring tools (Wazuh, Suricata), and a NATS messaging system for seamless threat detection and mitigation. The ReAct agent, powered by a fine-tuned LLM, iteratively analyzes security alerts, generates context-aware mitigation strategies, and autonomously executes response actions via integrated cybersecurity tools such as firewalls. The framework demonstrates its effectiveness in real-time cyberattack mitigation, including port scanning, botnet intrusions, and SSH brute-force attacks. By leveraging LangGraph-guided decision loops and Chain-of-Thought (CoT) reasoning, the system dynamically adapts to evolving threats while reducing reliance on human intervention. Evaluations in a simulated environment highlight the scalability of the architecture and its ability to achieve low-latency, autonomous threat mitigation. The findings highlight the potential of LLM-driven security automation in modern cyber defense strategies, paving the way for future advancements in mitigating phishing, malware, and insider threats.","2376-6506","979-8-3315-0887-6","10.1109/IWCMC65282.2025.11059476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059476","Autonomous Cyber Defense;Reasoning and Acting Agents;Large Language Models;Real-Time Threat Mitigation;Automated Incident Response","Wireless communication;Cloud computing;Prevention and mitigation;Large language models;Phishing;Decision making;Cognition;Real-time systems;Malware;Cyberattack","","","","12","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Reinforcement Learning-powered Effectiveness and Efficiency Few-shot Jailbreaking Attack LLMs","X. Tang; Z. Yao; J. Wen; Y. Dong; J. Han; S. Hu","Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences",2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA),"20 Feb 2025","2024","","","1974","1981","The widespread use of large language models (LLMs) has brought about security risks, including biases, discrimination, and ethical concerns. Reinforcement Learning from Human Feedback (RLHF), as a method to improve model security, still faces challenges such as objective management and misaligned generalization, leading to the emergence of jailbreak attacks. Existing methods implement jailbreak attacks by optimizing adversarial prompts or leveraging the in-context learning capabilities of LLMs, but they are limited in terms of efficiency and scalability. This paper proposes a reinforcement learning-based few-shot example selection method to enhance the effectiveness and efficiency of these attacks. The proposed method extends the GPT-2 architecture with an example selection module and employs strategies such as experience replay and entropy penalty to accelerate convergence and avoid local optima. Experimental results demonstrate that, compared to existing methods, this approach achieves a 100% increase in attack success rate on Vicuna-7B and a 2.4-second reduction in the time cost per harmful instruction generation on GPT-3.5.","2158-9208","979-8-3315-0971-2","10.1109/ISPA63168.2024.00269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885191","Large language model;Jailbreak;Reinforcement Learning","Costs;Large language models;Design methodology;Scalability;Reinforcement learning;Entropy;Security;Protection;Optimization;Faces","","","","28","IEEE","20 Feb 2025","","","IEEE","IEEE Conferences"
"Contribution to the modeling and simulation of multiagent systems for energy saving in the habitat","D. Saba; H. E. Degha; B. Berbaoui; F. Z. Laallam; R. Maouedj","Unité de Recherche en Energies Renouvelables en Milieu Saharien, Centre de Développement des Energies Renouvelables, CDER, Adrar, Algeria; Fac.Faculté des nouvelles technologies de l'information et de la communication, Lab.Laboratoire de l'Intelligence Artificielle et les Technologies de l'Information, Ouargla, Algérie; Unité de Recherche en Energies Renouvelables en Milieu Saharien, Centre de Développement des Energies Renouvelables, CDER, Adrar, Algeria; Fac.Faculté des nouvelles technologies de l'information et de la communication, Lab.Laboratoire de l'Intelligence Artificielle et les Technologies de l'Information, Ouargla, Algérie; Unité de Recherche en Energies Renouvelables en Milieu Saharien, Centre de Développement des Energies Renouvelables, CDER, Adrar, Algeria",2017 International Conference on Mathematics and Information Technology (ICMIT),"18 Jan 2018","2017","","","204","208","Intelligent habitat is the technology that integrates intelligence in a private environment (home, building, office, ...) to manage the daily life of a resident and reduce the energy consumed. However, home automation is the set of techniques and technologies (building physics, computing, and telecommunications) that enable automation and improvement of tasks within a residence or a workplace; it also aims to provide solutions Comfort, management of energy, security, and communication. This includes intelligent management of all electrical functions through the introduction of computers and new technologies. Around this topic, we present our contribution concerning an agent-based modeling and simulation for a residence fueled by a hybrid system with renewable energy, the objective of which is to reduce energy consumption and ensure acceptable comfort for residents. We begin our work with state of the art on works that are related to our topic, in the second section, we present the methodologies of modeling and simulation, followed by a multiagent simulation for the management of energy in the third section. The fourth section is reserved for the choice of the platform used for our solution; the multi-agent modeling is shown in the fifth section. We conclude with a conclusion that includes a review of the work done and some perspectives.","","978-1-5386-3269-7","10.1109/MATHIT.2017.8259718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259718","Intelligent Home;Domotics;Comfort;Energy Management;Multi Agent Systems;Modeling and Simulation;Hybrid Energy System;Renewable Energies","Unified modeling language;Mathematical model;Multi-agent systems;Information technology;Computational modeling;Energy management","","11","","15","IEEE","18 Jan 2018","","","IEEE","IEEE Conferences"
"A Novel Decentralized Coordination Control Scheme for the Complex Transactive Energy Prosumers","M. Ikram; Z. Ullah; M. Nasir; S. Ahmed; S. N. K. Marwat","Dept. of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Dept. of Electrical Power Engineering, University of Engineering and Technology, Peshawar, Pakistan; Deptment of Physics, Allama Iqbal Open University, Islamabad, Pakistan; Dept. of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Dept. of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan","2023 International Conference on Energy, Power, Environment, Control, and Computing (ICEPECC)","11 Aug 2023","2023","","","1","6","The significant penetration of renewable energy sources (RES) in the smart grid (SG) provides a new landscape for researchers to develop an optimal energy management model. The households with RES become prosumers to provide the surplus energy in the local community. The coordination and control of such RES prosumers are important to estimate the available energy in the system and the total demand required. In this paper, we proposed a decentralized coordination control approach for transactive energy systems (TES). The proposed TES is capable of coordinating and controlling a complex network of prosumers with limited control information. The consensusability and graph-theoretic schemes are used for prosumer RES nodes. In the proposed model, energy trading among large-scale prosumers has been demonstrated. The algorithm is capable to provide the total surplus energy available across the network and total demand in an autonomous fashion. The coordination control among prosumers is achieved through a computationally efficient approach without sharing the prosumer’s profile to preserve the security and privacy of the prosumers. To validate the proposed scheme, we perform extensive simulations on decentralized 450 prosumers. The resiliency of the proposed scheme is confirmed through dynamic and contingent communication topologies for energy trading ratios, cumulative returns, and convergence ratios. The cumulative returns improved from 0.447% to 24.8% while the energy trade among the prosumers recorded from -0.89 to 2.09. The final return is enhanced from −1.95% to 22.3% due to internal and external coordination control of nonlinear loads.","","978-1-6654-7601-0","10.1109/ICEPECC57281.2023.10209440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10209440","transactive energy systems;renewable energy systems;decentralized control;multi-agent systems;prosumer participation;consensus control;smart grid","Transactive energy;Costs;Computational modeling;Decentralized control;Estimation;Computational efficiency;Topology","","2","","22","IEEE","11 Aug 2023","","","IEEE","IEEE Conferences"
"Decentralized Federated Learning Strategy with Image Classification using ResNet Architecture","H. Du; S. Thudumu; S. Singh; S. Barnett; I. Logothetis; R. Vasa; K. Mouzakis","Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, VIC, Australia",2023 IEEE 20th Consumer Communications & Networking Conference (CCNC),"17 Mar 2023","2023","","","706","707","The rapid growth of both the Industrial Internet of Things (IIoT) and Artificial Intelligence (AI) results in a high demand for AI applications in devices. To achieve high levels of accuracy, AI applications typically require a large amount of annotated data. Accessing such data is challenging in various applications such as healthcare, finance and information security. Federated learning (FL) is one of the strategies that was proposed to overcome this challenge. Specifically, FL enables the AI model in the centralized system to be trained without any prior knowledge of the information on the devices. Recent FLs have the disadvantage that they are dependent upon a centralized system, and thus are susceptible to single points of failure. This paper proposes a strategy that employs FL in a decentralized environment where devices can communicate with each other to increase the accuracy of the AI model in each device. Furthermore, we evaluate the proposed strategy in the image classification task with the ResNet50 architecture and the CIFAR-10 dataset. The evaluation shows that the ResNet50 model trained in the decentralized environment can achieve comparable results to the model trained in the centralized environment.","2331-9860","978-1-6654-9734-3","10.1109/CCNC51644.2023.10060275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060275","Decentralized Federated Learning;Image Classification;Multi-Agent Systems","Privacy;Federated learning;Information security;Finance;Medical services;Artificial intelligence;Task analysis","","2","","7","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"MRL-PoS: A Multi-agent Reinforcement Learning based Proof of Stake Consensus Algorithm for Blockchain","T. Islam; F. H. Bappy; T. Shaila Zaman; M. S. Islam Sajid; M. Mehedi Ahsan Pritom","School of Information Studies (iSchool), Syracuse University, Syracuse, NY, USA; School of Information Studies (iSchool), Syracuse University, Syracuse, NY, USA; Computer and Information Science, SUNY Polytechnic Institute, NY, USA; Computer and Information Sciences, Towson University, Towson, MD, USA; Computer Science, Tennessee Tech University, Cookeville, TN, USA",2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC),"13 Feb 2024","2024","","","0409","0413","The core of a blockchain network is its consensus algorithm. Starting with the Proof-of-Work, there have been various versions of consensus algorithms, such as Proof-of-Stake (PoS), Proof-of-Authority (PoA), and Practical Byzantine Fault Tolerance (PBFT). Each of these algorithms focuses on different aspects to ensure efficient and reliable processing of transactions. Blockchain operates in a decentralized manner where there is no central authority and the network is composed of diverse users. This openness creates the potential for malicious nodes to disrupt the network in various ways. Therefore, it is crucial to embed a mechanism within the blockchain network to constantly monitor, identify, and eliminate these malicious nodes. However, there is no one-size-fits-all mechanism to identify all malicious nodes. Hence, the dynamic adaptability of the blockchain network is important to maintain security and reliability at all times. This paper introduces MRL-PoS, a Proof-of-Stake consensus algorithm based on multi-agent reinforcement learning. MRL-PoS employs reinforcement learning for dynamically adjusting to the behavior of all users. It incorporates a system of rewards and penalties to eliminate malicious nodes and incentivize honest ones. Additionally, MRL-PoS has the capability to learn and respond to new malicious tactics by continually training its agents.","","979-8-3503-6013-4","10.1109/CCWC60891.2024.10427777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10427777","Distributed Consensus;Blockchain;Reinforcement Learning;Multi-agent Systems;Proof-of-Stake","Training;Heuristic algorithms;Consensus algorithm;Reinforcement learning;Reliability engineering;Security;Resilience","","2","","20","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"A Multi-Agent System Based on Dynamic Load Balancing for Collaborative Intrusion Detection","N. Hocine; C. Zitouni","Department of computer sciences, CSTL laboratory, University of Mostagnem, Mostaganem, Algeria; Faculty of Computing and Telecommunications, Poznan University of Technology, Poznan, Poland",2023 International Conference on Networking and Advanced Systems (ICNAS),"4 Dec 2023","2023","","","1","6","Intrusion detection systems contribute to the improvement of the security of systems as well as the confidentiality and integrity of data. These systems are based on traffic analysis, which makes their performance and response time sensitive to the density of network traffic and distributed denial of service attacks. In this paper, we suggest a new collaborative intrusion detection system based on a multi-agent system. The intrusion detection technique relies on dynamic load balancing of traffic analysis to enhance the performance of intrusion detection, especially distributed denial of service attacks. In particular, mobile agents collaborate to analyze traffic using decision trees, support vector machines, and neural networks. The results of the experiment, using NSL-KDD public dataset, show that the proposed intrusion detection system architecture improved the performance and the scalability of intrusion detection compared with state of the art techniques.","","979-8-3503-1917-0","10.1109/ICNAS59892.2023.10330527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330527","collaborative intrusion detection;multi-agent systems;machine learning","Support vector machines;Scalability;Intrusion detection;Collaboration;Systems architecture;Telecommunication traffic;Load management","","1","","20","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Building Reliable IoT Ecosystems: A Generative AI-Enabled Federated Learning-Based Trust Management Approach","I. Ud Din; A. Almogren; Z. Han; M. Guizani","Department of Information Technology, University of Haripur, Haripur, Pakistan; Department of Computer Science, Chair of Cyber Security, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Machine Learning Department, Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE",IEEE Internet of Things Journal,"8 May 2025","2025","12","10","13353","13366","In the rapidly evolving domain of the Internet of Vehicles (IoV), ensuring robust trust management, privacy, and security presents significant challenges. This article proposes a novel approach integrating generative AI (GAI) and federated learning (FL) to address these challenges. FL allows distributed learning across vehicles without the need to share data, enhancing privacy compared to centralized methods. Our approach enhances trust management by raising the level of accuracy in detecting anomalies and preserving data privacy. As a result, the effectiveness of the proposed approach in practical real-world urban settings is illustrated by comprehensive evaluations using the CityPulse dataset. The results show a 20% improvement in trust scores under normal conditions, a 92% anomaly detection accuracy, and acceptable latency despite the added security measures. Additionally, 3-D visualizations illustrate the system’s robustness and scalability. This solution aligns with the objectives of 6G wireless communications, laying the groundwork for future intelligent, ultrareliable, and secure vehicular networks. Future research will focus on expanding the application of GAI and FL for real-time decision-making in large-scale IoV networks and optimizing cryptographic protocols.","2327-4662","","10.1109/JIOT.2024.3511634","Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia through the Vice Deanship of Scientific Research Chairs: Chair of Cyber Security; NSF(grant numbers:ECCS-2302469); Toyota Motor Corporation; Amazon; Japan Science and Technology Agency (JST) Adopting Sustainable Partnerships for Innovative Research Ecosystem (ASPIRE)(grant numbers:JPMJAP2326); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778271","Blockchain security;decentralized networks;generative artificial intelligence (GAI);Internet of Vehicles (IoV);trust management","Security;Trust management;Internet of Things;Data privacy;Privacy;Data models;Vehicle dynamics;Heuristic algorithms;Computational modeling;Training","","","","29","IEEE","4 Dec 2024","","","IEEE","IEEE Journals"
"The Multi Agent Nets Architecture as Base for Modelling Smart Home for Elderly","A. Bouaita; Y. Kissoum; S. Mazouzi","Computer Science Department, Faculty of Sciences, University 20 Août 1955, Skikda, Algeria; Computer Science Department, Faculty of Sciences, University 20 Août 1955, Skikda, Algeria; Computer Science Department, Faculty of Sciences, University 20 Août 1955, Skikda, Algeria",2022 International Symposium on iNnovative Informatics of Biskra (ISNIB),"28 Mar 2023","2022","","","1","6","With the miniaturization of computer components and sensors, as well as the multiplication of communications capabilities, computing is experiencing major changes paving the way for the era of ambient intelligence. Among the central characteristics of an ambient system, is the context awareness. It allows services to adapt to a user's needs without a need of clarification. Moreover, among the general population really interested by the development of this technology are elderlies with reduced autonomy. The number of this type of person is constantly increasing. Placing these people in hospitals is, in some cases, expensive or “immoral”. One possible alternative is to keep them at home while ensuring care, comfort and safety. To reach such an objective, we propose an approach which is based on the multi agent nets architecture for modelling and simulating different services of an elderly smart home (security, comfort and economy services). The aim is to restore independent living at home for people who should normally be placed in health care institutions.","","979-8-3503-2065-7","10.1109/ISNIB57382.2022.10076104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076104","Ambient Intelligence;Context awareness;Smart home;Multi agent systems;Nets within nets","Visualization;Biological system modeling;Sociology;Semantics;Smart homes;Computer architecture;Writing","","","","27","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving","D. Fu; W. Lei; L. Wen; P. Cai; S. Mao; M. Dou; B. Shi; Y. Qiao","Shanghai Artificial Intelligence Laboratory; College of Control Science and Engineering, Zhejiang University; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory",2024 IEEE Intelligent Vehicles Symposium (IV),"15 Jul 2024","2024","","","1084","1090","The emergence of Multimodal Large Language Models ((M)LLMs) has ushered in new avenues in artificial intelligence, particularly for autonomous driving by offering enhanced understanding and reasoning capabilities. This paper introduces LimSim++, an extended version of LimSim designed for the application of (M)LLMs in autonomous driving. Acknowledging the limitations of existing simulation platforms, LimSim++ addresses the need for a long-term closed-loop infrastructure supporting continuous learning and improved generalization in autonomous driving. The platform offers extended-duration, multi-scenario simulations, providing crucial information for (M)LLM-driven vehicles. Users can engage in prompt engineering, model evaluation, and framework enhancement, making LimSim++ a versatile tool for research and practice. This paper additionally introduces a baseline (M)LLM-driven framework, systematically validated through quantitative experiments across diverse scenarios. The open-source resources of LimSim++ are available at: https://pjlab-adg.github.io/limsim-plus/.","2642-7214","979-8-3503-4881-1","10.1109/IV55156.2024.10588848","Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10588848","","Large language models;Decision making;Random access memory;Cognition;Prompt engineering;Autonomous vehicles","","8","","38","IEEE","15 Jul 2024","","","IEEE","IEEE Conferences"
"Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future of Edemorcacy","R. Karanjai; B. Shor; A. Austin; R. Kennedy; Y. Lu; L. Xu; W. Shi","University of Houston, Houston, TX, USA; University of Houston, Houston, TX, USA; University of Houston, Houston, TX, USA; Ohio State University, Columbus, OH, USA; University of Houston, Houston, TX, USA; Kent State University, Kent, OH, USA; University of Houston, Houston, TX, USA",2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG),"21 Jul 2025","2025","","","222","230","This paper investigates the use of Large Language Models (LLMs) to synthesize public opinion data, addressing challenges in traditional survey methods like declining response rates and non-response bias. We introduce a novel technique: role creation through knowledge injection, a form of in-context learning that leverages Retrieval-Augmented Generation (RAG) alongside HEXACO personality profiles and demographic data to generate personalized prompts dynamically. This method allows LLMs to simulate diverse opinions more accurately than existing prompt engineering approaches. We compare our results with pre-trained models with standard few-shot prompts. Experiments using questions from the Cooperative Election Study (CES) demonstrate that our role-creation approach significantly improves the alignment of LLM-generated opinions with realworld human survey responses, increasing answer adherence. In addition, we discuss challenges, limitations and future research directions.","2573-1998","979-8-3315-9809-9","10.1109/ICEDEG65568.2025.11081685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081685","LLM;public opinion simulation;survey methodology;knowledge injection;personality modeling;demographic profiling","Surveys;Electric potential;Costs;Accuracy;Voting;Large language models;Retrieval augmented generation;Prompt engineering;Standards","","","","57","IEEE","21 Jul 2025","","","IEEE","IEEE Conferences"
"Data-Driven Attack Detection and Resilient Control for Heterogeneous Nonlinear Nonaffine MASs","C. Yang; W. -W. Che","School of Automation, Shandong Key Laboratory of Industrial Control Technology, Qingdao University, Qingdao, China; State Key Laboratory of Synthetical Automation for Process Industries, College of Information Science and Engineering, Northeastern University, Shenyang, China",IEEE Transactions on Network Science and Engineering,"","2025","PP","99","1","12","The data-driven attack detection and resilient control problems for heterogeneous nonlinear nonaffine multi-agent systems (MASs) in the presence of false data injection (FDI) attacks are investigated in this paper. The heterogeneous nonlinear nonaffine MASs are firstly translated to an equivalent linear data model by using the dynamic linearization method. Then, based on the obtained linear data model, a novel attack detector, by using the nonlinear autoregressive with exogenous input neural network (NARXNN), is designed to detect whether MASs are under FDI attacks. Further, a data-driven resilient switched control scheme with the attack compensation mechanism is designed to achieve the leaderless consensus control objective. Finally, a simulation is given to illustrate the efficiency of the proposed method by comparisons.","2327-4697","","10.1109/TNSE.2025.3565691","National Natural Science Foundation of China(grant numbers:62273191,U1966202,62233015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993337","Attack detection and attack compensation mechanisms;data-driven resilient control;false data injection attacks;heterogeneous nonlinear multi-agent systems;network security","Topology;Network topology;Detectors;Switches;Event detection;Denial-of-service attack;Computational modeling;Adaptation models;Predictive models;Multi-agent systems","","","","","IEEE","9 May 2025","","","IEEE","IEEE Early Access Articles"
"Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)","T. Ahmed; K. S. Pai; P. Devanbu; E. T. Barr","University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University College London & Google Brain, London, UK",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2720","2732","Large Language Models (LLM) are a new class of computation engines, “programmed” via prompt engineering. Researchers are still learning how to best “program” these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously collect semantics facts, from the code, while working. Mostly these are shallow, simple facts arising from a quick read. For a function, such facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc. One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them implicitly capable of doing this simple level of “code analysis” and extracting such information, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly. actually helps. Prior work shows that LLM performance on code summarization benefits from embedding a few code & summary exemplars in the prompt, before the code to be summarized. While summarization performance has steadily progressed since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization. We find that adding semantic facts to the code in the prompt actually does help! This approach improves performance in several different settings suggested by prior work, including for three different Large Language Models. In most cases, we see improvements, as measured by a range of commonly-used metrics; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU 11Scores of 30–40 BLEU are considered “Good” to “Understandable” for natural language translation; see https://cloud.google.com/translate/automl/docs/evaluate.. In addition, we have also found that including semantic facts yields a substantial enhancement in LLMs' line completion performance.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548617","LLM;Code Summarization;Program Analysis;Prompt Engineering","Measurement;Codes;Semantics;Natural languages;Process control;Writing;Transformers","","21","","70","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"FinanceQA-Agent: A High-Precision Comprehensive Financial Technology Question-Answering Intelligent System Based on Vector Databases","X. Liu; J. Zhu","School of Instrument Science and Engineering, Southeast University, Nanjing, China; Information Technology Operations Center, Bank of China, Hefei, China",2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA),"4 Mar 2025","2024","","","576","582","In response to the escalating complexity of financial operations and the pressing need for intelligent decision support, FinanceQA-Agent emerges as an avant-garde Financial Technology (FinTech) solution. This system integrates state-of-the-art natural language processing with advanced vector encoding to craft a high-precision, robust question-answering platform. Utilizing intranet isolation and load balancing, it ensures unparalleled security and stability, while its meticulously designed knowledge base and prompt engineering elevate the conversational accuracy and naturalness. The research methodology encompasses a multifaceted approach, including the deployment of large language models and semantic vector computations, underpinned by a comprehensive system architecture that facilitates scalability and maintenance. Pivotal to our findings is the system's remarkable capability to distill and generate precise financial insights, thereby significantly enhancing the FinTech domain's intelligence and operational efficiency. In conclusion, FinanceQA-Agent represents a transformative stride in FinTech, propelling the industry towards a future characterized by exceptional intelligence, efficiency, and security through its sophisticated question-answering prowess.","","979-8-3503-5526-0","10.1109/AEECA62331.2024.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10898710","Large Language Models;Question-Answering Intelligent System;FinTech;Vector Semantics;Vector Databases","Databases;Fintech;Scalability;Semantics;Systems architecture;Propulsion;Vectors;Stability analysis;Security;Intelligent systems","","","","16","IEEE","4 Mar 2025","","","IEEE","IEEE Conferences"
"Is GPT a Computational Model of Emotion?","A. N. Tak; J. Gratch","Institute for Creative Technologies University of Southern California, Playa Vista, CA, USA; Institute for Creative Technologies University of Southern California, Playa Vista, CA, USA",2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII),"15 Jan 2024","2023","","","1","8","This paper investigates the emotional reasoning abilities of the GPT family of large language models. We advocate a component perspective on evaluation that decomposes models into different aspects of emotional reasoning (appraisal derivation, affect/intensity derivation, and consequent derivation). We report two studies. A correlational study examines how the model reasons about autobiographical memories. An experimental study systematically varies aspects of situations in ways previously shown to impact emotion intensity and coping tendencies. Results demonstrate, even without prompt engineering, GPT predictions closely match human-provided appraisals and emotion labels, though GPT struggled to predict emotion intensity and coping responses. GPT-4 performed best on the first study but performed poorly on the second (though it yielded the best results following minor prompt engineering). The evaluation raises questions about how to utilize the strengths and mitigate the weaknesses of such models, including dealing with variability in responses. More fundamentally, these studies highlight the benefits of the componential perspective on model evaluation.","2156-8111","979-8-3503-2743-4","10.1109/ACII59096.2023.10388119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10388119","affective computing;GPT-3.5;GPT-4;large language models;appraisal theory","Emotion recognition;Affective computing;Computational modeling;Cognition;Appraisal","","12","","37","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"Prescribed-Time Consensus Tracking for High-Order MASs With Privacy Protection via Fully Actuated System Approach","Y. Wang; W. Sun; S. -F. Su","School of Mathematics Science, Liaocheng University, Liaocheng, China; School of Mathematics Science, Liaocheng University, Liaocheng, China; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan",IEEE Transactions on Automation Science and Engineering,"30 May 2025","2025","22","","15599","15609","This study addresses the adaptive prescribed-time consensus tracking control problem for high-order multi-agent nonlinear systems with an improved privacy protection mechanism. A distinctive feature of the control method lies in the utilization of the fully actuated system approach to study high-order multi-agent systems, enabling system control without the need to simplify the high-order systems into the first-order systems. For agents requiring state information protection, the flexible privacy protection treats the output mask function as the transformation function, thereby protecting the privacy of all signals in the systems and allowing users to define the protection time. In addition, a prescribed-time scale function suitable for high-order systems is proposed by incorporating a constant term to avoid the singularity issue. This prescribed-time tracking control strategy ensures that the synchronization error converges to the prescribed region within the prescribed time, and prescribed time aligns with user-defined time in the privacy protection mechanism. Finally, the superiority of the proposed control method is verified through a numerical simulation comparison with different privacy protection method. Note to Practitioners—This paper aims to develop prescribed-time control algorithm for high-order multi-agent systems with privacy protection via the fully actuated system approach. In the field of automation, the sensitivity of information exchange among agents is extremely high, and any carelessness may lead to the leakage of original data details, posing a serious threat to the overall performance and stability of the system. Therefore, the adoption of advanced privacy protection technologies is particularly crucial, as it not only effectively safeguards personal privacy rights but also maintains the security and stability of the system. The fully actuated system approach enables a more precise characterization of the cooperation relationships and dynamic behavioral characteristics among agents, laying a solid foundation for designing more efficient control strategies. Furthermore, the introduction of prescribed-time control technology allows users to achieve the required control accuracy within a prescribed time, thereby minimizing the unnecessary expenditure of industrial resources and boosting resource efficiency in automation.","1558-3783","","10.1109/TASE.2025.3570513","Outstanding Youth Foundation of Shandong Province(grant numbers:ZR2024YQ033); National Natural Science Foundation of China(grant numbers:62473185); Science Center Program of National Natural Science Foundation of China(grant numbers:62188101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005564","High-order multi-agent systems;fully actuated system approach;privacy protection;consensus tracking control","Protection;Privacy;Convergence;Synchronization;Sun;Control design;Automation;Multi-agent systems;Information exchange;Accuracy","","","","44","IEEE","15 May 2025","","","IEEE","IEEE Journals"
"Visual Prompt Engineering for Enhancing Facial Recognition Systems Robustness Against Evasion Attacks","S. Gupta; K. Raja; R. Passerone","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy",IEEE Access,"22 Oct 2024","2024","12","","152212","152223","Deep learning has unequivocally emerged as the backbone of simple to highly sensitive systems demanding artificial intelligence across diverse domains. For instance, foundation models based on deep neural networks (DNNs) can play a crucial role in the design of security-sensitive systems, such as facial recognition systems (FRS). Despite achieving exceptional accuracy and human-like performance, DNNs tend to be severely sensitive to adversarial attacks. While DNNs are deemed irreplaceable in the artificial intelligence domain, the vulnerability of DNNs against adversarial examples can be detrimental to sensitive systems robustness. The paper presents a pilot study introducing an attack-defense framework aimed at enhancing the robustness of FRS against evasion attacks. Our generative adversarial network (GAN) based attack successfully deceives FRS, demonstrating that they are not only vulnerable against synthetic images visibly comparable to real user images (i.e., best-match scenarios) but also to partially constructed user images (i.e., average-match scenarios). Based on our analysis, we propose a novel solution that extends the visual prompt engineering (VPE) concept for detecting synthetic images to secure downstream tasks in FRS. The VPE detection module achieves an accuracy of 97.92% in the average-match scenario and 87.08% in the best-match scenario on our generated dataset. Furthermore, we use the Trueface postsocial dataset to validate the efficacy of the detection module obtaining an accuracy of 91.96%. Our experimental evaluation shows that VPE can effectively tackle the GAN attacks from average-match to best-match scenarios, thus enhancing the overall robustness of a security-sensitive system against evasion attacks.","2169-3536","","10.1109/ACCESS.2024.3479949","Autonomous Province of Trento with the AI@TN project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716379","Facial-recognition systems;deep learning;evasion attacks;robustness;synthetic","Robustness;Face recognition;Training;Accuracy;Visualization;Prompt engineering;Generative adversarial networks;Biological system modeling;Feature extraction;Closed box;Deep learning;Prompt engineering","","","","58","CCBYNCND","14 Oct 2024","","","IEEE","IEEE Journals"
"CubeTesterAI: Automated JUnit Test Generation Using the LLaMA Model","D. Gorla; S. Kumar; P. N. Roselli Lorenzini; A. Alipourfaz","Dept. of Computer Science, “Sapienza” University of Rome, Italy; PCCube, Italy; PCCube, Italy; PCCube, Italy","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","565","576","This paper presents an approach to automating JUnit test generation for Java applications using the Spring Boot framework, leveraging the LLaMA (Large Language Model Architecture) model to enhance the efficiency and accuracy of the testing process. The resulting tool, called CubeTesterAI, includes a user-friendly web interface and the integration of a CI/CD pipeline using GitLab and Docker. These components streamline the automated test generation process, allowing developers to generate JUnit tests directly from their code snippets with minimal manual intervention. The final implementation executes the LLaMA models through RunPod, an online GPU service, which also enhances the privacy of our tool. Using the advanced natural language processing capabilities of the LLaMA model, CubeTesterAI is able to generate test cases that provide high code coverage and accurate validation of software functionalities in Java-based Spring Boot applications. Furthermore, it efficiently manages resource-intensive operations and refines the generated tests to address common issues like missing imports and handling of private methods. By comparing CubeTesterAI with some state-of-the-art tools, we show that our proposal consistently demonstrates competitive and, in many cases, better performance in terms of code coverage in different real-life Java programs.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10988978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988978","Automated test generation;AI-assisted software testing;JUnit tests;Large Language Models;LLaMA","Software testing;Java;Privacy;Codes;Accuracy;Large language models;Pipelines;Software;Test pattern generators;Proposals","","","","45","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
