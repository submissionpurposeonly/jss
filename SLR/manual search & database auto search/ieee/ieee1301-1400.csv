"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Reimagining Enterprise Data Management using Generative Artificial Intelligence","S. Varma; S. Shivam; B. Ray; S. Biswas","ZS Associates, Pune, India; IEEE Computer Society; ZS Associates, Pune, India; ZS Associates, Pune, India",2024 11th IEEE Swiss Conference on Data Science (SDS),"18 Sep 2024","2024","","","107","114","Enterprise Data Management (EDM) is a comprehensive approach encompassing data acquisition, profiling, standardization, quality assurance, and transformation, along with governance, to optimize the lifecycle of an organization’s data assets and facilitate meaningful analysis. The recent rise of Large Language Models (LLMs) and Generative Artificial Intelligence has fundamentally transformed data-related tasks. In this study, we delve into the integration of LLMs and Generative AI within EDM, proposing a collaborative approach that incorporates human input for computationally intensive processes. Our proposed pipeline strategically utilizes advanced Large Language Models to tackle challenges at each stage of the Enterprise Data Management process, significantly enhancing overall efficiency. Through the implementation of a case study in the pharmaceutical domain, we replicate conventional steps taken before creating business reports to enhance sales strategies, demonstrating that the proposed pipeline significantly reduces the time needed for the entire EDM process. Additionally, a comparison between various Open Source LLM models and OpenAI GPT-3.5 reveals GPT-3.5’s superior performance in code generation tasks, especially in scenarios requiring complex query generation. The proposed pipeline demonstrated satisfactory performance across various stages, including tasks such as source-totarget identification and primary key identification, as well as in other phases. The study concludes that the proposed pipeline, utilizing LLMs and Generative AI models, holds promising potential for optimizing and transforming data management workflows, providing efficient and effective solutions for organizations.","2835-3420","979-8-3503-0929-4","10.1109/SDS60720.2024.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675953","Generative Artificial Intelligence;Enterprise Data Management;Large Language Models;Pharmaceutical Data","Quality assurance;Generative AI;Large language models;Pipelines;Standards organizations;Standardization;Organizations","","","","13","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"Large Language Models in Wearable Devices: Applications, Challenges, and Future Directions","P. Arava; A. Singh; A. Ehtesham; S. Kumar","Department of Computer Science, Cleveland State University, USA; Department of Computer Science, Cleveland State University, USA; Kent State University, USA; Northeastern University, USA",2025 IEEE World AI IoT Congress (AIIoT),"12 Aug 2025","2025","","","1003","1009","The intersection of wearable technology and Large Language Models (LLMs) is enabling new possibilities in health monitoring, fitness coaching, gesture control, and personalized care. This survey presents a comprehensive overview of current research efforts that integrate LLMs with wearable systems to analyze wearable data—including motion sensors, biosignals, and vital signs—to generate personalized insights within wearable platforms such as smartwatches, neural interfaces, and fitness ecosystems. We examine state-of-the-art methods that reflect these trends, focusing on system design, data modalities, and human–AI interaction mechanisms. Key use cases, model architectures, sensor integrations, and application scenarios are reviewed. We also discuss challenges related to privacy, real-time processing, personalization, and the feasibility of on-device inference.","","979-8-3315-2508-8","10.1109/AIIoT65859.2025.11105286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105286","","Surveys;Privacy;Large language models;Natural languages;Transforms;Real-time systems;Biomedical monitoring;Wearable devices;Monitoring;System analysis and design","","","","26","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Prompt-Based Generation Strategy for Imbalanced Information Security Rating Dataset Augmentation","Y. Han; S. Shim; D. K. Gajulamandyam; H. Chang","Dept. of Security Convergence, Graduate School, Chung-Ang University, Seoul, South Korea; Dept. of Applied Data Science, San Jose State University, San Jose, CA, United States; Dept. of Applied Data Science, San Jose State University, San Jose, CA, United States; Dept. of Industrial Security, Chung-Ang University, Seoul, South Korea",2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE),"16 May 2025","2024","","","117","122","As information leakage due to internal and external threats continues to escalate in the era of technological dominance, safeguarding confidential information managed by companies and organizations has become a critical issue across industries. Information security rating involves evaluating the sensitivity of information by identifying key details within it, typically following decision-making processes to classify data as either confidential or public. While existing research on security rating has primarily focused on advancing training models, there has been limited attention to addressing the issue of imbalanced secret data, which can lead to overfitting. To mitigate this issue, this paper proposes a prompt-based technique to augment the minority “Secret” class, specifically for the WikiLeaks dataset. The proposed methodology consists of three phases: first, enhancing state-of-the-art augmentation prompts with additional constraints; second, tuning few-shot generation prompts using a sliding-window approach centered on the frequency-weighted median to generate augmented data that aligns with the distribution of the training dataset; and third, training a fine-tuned large language model using Llama 3.1 8B with LoRA to perform security rating on the augmented data. Experimental results demonstrate that the proposed methodology yields incremental improvements, achieving 98% accuracy with one-shot generation and 99% accuracy with few-shot generation. To the best of our knowledge, this paper contributes by being the first study to generate highquality “Secret” data for the domain-specific task of information security rating and enhances security rating performance by introducing our proposed augmentation method. In future work, we aim to further optimize the fine-tuning of large language models to apply security rating data for real-world scenarios.","2831-7203","979-8-3315-1704-5","10.1109/AIxDKE63520.2024.00029","Ministry of Science, ICT, Korea(grant numbers:2024-00425650); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990101","information security rating;few-shot generation;imbalanced data augmentation;data classification using LLMs","Training;Knowledge engineering;Accuracy;Sensitivity;Large language models;Information security;Information leakage;Data models;Tuning;Overfitting","","","","11","IEEE","16 May 2025","","","IEEE","IEEE Conferences"
"Detection and Defense Against Prominent Attacks on Preconditioned LLM-Integrated Virtual Assistants","C. F. Chan; D. W. Yip; A. Esmradi","Logistic and Supply Chain MultiTech R&D Centre (LSCM), Hong Kong; Logistic and Supply Chain MultiTech R&D Centre (LSCM), Hong Kong; Logistic and Supply Chain MultiTech R&D Centre (LSCM), Hong Kong",2023 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE),"5 Apr 2024","2023","","","1","5","The emergence of LLM (Large Language Model)-integrated virtual assistants has brought about a rapid transformation in communication dynamics. During virtual assistant development, some developers prefer to leverage the system message, also known as an initial prompt or custom prompt, for preconditioning purposes. However, it is important to recognize that an excessive reliance on this functionality raises the risk of manipulation by malicious actors who can exploit it with carefully crafted prompts. Such malicious manipulation poses a significant threat, potentially compromising the accuracy and reliability of the virtual assistant's responses. Consequently, safeguarding the virtual assistants with detection and defense mechanisms becomes of paramount importance to ensure their safety and integrity. In this study, we explored three detection and defense mechanisms aimed at countering attacks that target the system message. These mechanisms include inserting a reference key, utilizing an LLM evaluator, and implementing a Self-Reminder. To showcase the efficacy of these mechanisms, they were tested against prominent attack techniques. Our findings demonstrate that the investigated mechanisms are capable of accurately identifying and counteracting the attacks. The effectiveness of these mechanisms underscores their potential in safeguarding the integrity and reliability of virtual assistants, reinforcing the importance of their implementation in real-world scenarios. By prioritizing the security of virtual assistants, organizations can maintain user trust, preserve the integrity of the application, and uphold the high standards expected in this era of transformative technologies.","","979-8-3503-4107-2","10.1109/CSDE59766.2023.10487759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487759","Large Language Models;Preconditioning;Cyber Security","Virtual assistants;Standards organizations;Finance;Organizations;Medical services;Data engineering;Data models","","3","","20","IEEE","5 Apr 2024","","","IEEE","IEEE Conferences"
"NetBench: A Large-Scale and Comprehensive Network Traffic Benchmark Dataset for Foundation Models","C. Qian; X. Li; Q. Wang; G. Zhou; H. Shao","Department of Computer Science, William & Mary; Department of Computer Science, William & Mary; NA; Department of Computer Science, William & Mary; Department of Computer Science, William & Mary",2024 IEEE International Workshop on Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys),"15 Jul 2024","2024","","","20","25","In computer networking, network traffic refers to the amount of data transmitted in the form of packets between internetworked computers or Cyber- Physical Systems. Monitoring and analyzing network traffic is crucial for ensuring the performance, security, and reliability of a network. However, a significant challenge in network traffic analysis is to process diverse data packets including both ciphertext and plaintext. While many methods have been adopted to analyze network traffic, they often rely on different datasets for performance evaluation. This inconsistency results in substantial manual data processing efforts and unfair comparisons. Moreover, some data processing methods may cause data leakage due to improper separation of training and testing data. To address these issues, we introduce the NetBench, a large-scale and comprehensive bench-mark dataset for assessing machine learning models, especially foundation models, in both network traffic classification and generation tasks. NetBench is built upon seven publicly available datasets and encompasses a broad spectrum of 20 tasks, including 15 classification tasks and 5 generation tasks. Furthermore, we evaluate eight State-Of-The-Art (SOTA) classification models (including two foundation models) and two generative models using our benchmark. The results show that foundation models significantly outperform the traditional deep learning methods in traffic classification. We believe NetBench will facilitate fair comparisons among various approaches and advance the development of foundation models for network traffic. Our benchmark is available at https://github.com/WM-JayLab/NetBench.","","979-8-3503-6345-6","10.1109/FMSys62467.2024.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590213","Benchmark Dataset;Network Traffic;Foundation Models","Training;Performance evaluation;Telecommunication traffic;Manuals;Benchmark testing;Data processing;Reliability","","2","","22","IEEE","15 Jul 2024","","","IEEE","IEEE Conferences"
"A Retrospective on Whole Test Suite Generation: On the Role of SBST in the Age of LLMs","G. Fraser; A. Arcuri","University of Passau, Passau, Germany; Kristiania University College, Oslo, Norway",IEEE Transactions on Software Engineering,"17 Mar 2025","2025","51","3","874","878","This paper presents a retrospective of the article “Whole Test Suite Generation”, published in the IEEE Transactions on Software Engineering, in 2012. We summarize its main contributions, and discuss how this work impacted the research field of Search-Based Software Testing (SBST) in the last 12 years. The novel techniques presented in the paper were implemented in the tool EvoSuite, which has been so far the state-of-the-art in unit test generation for Java programs using SBST. SBST has shown practical and impactful applications, creating the foundations to open the doors to tackle several other software testing problems besides unit testing, like for example system testing of Web APIs with EvoMaster. We conclude our retrospective with our reflections on what lies ahead, especially considering the important role that SBST still plays even in the age of Large Language Models (LLMs).","1939-3520","","10.1109/TSE.2025.3539458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876166","EvoSuite;SBST;LLM;Pynguin;EvoMaster","Test pattern generators;Java;Software engineering;Search problems;Software algorithms;Software testing;Optimization;System testing;Python;Software","","","","44","IEEE","5 Feb 2025","","","IEEE","IEEE Journals"
"RTLCoder: Fully Open-Source and Efficient LLM-Assisted RTL Code Generation Technique","S. Liu; W. Fang; Y. Lu; J. Wang; Q. Zhang; H. Zhang; Z. Xie","Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"20 Mar 2025","2025","44","4","1448","1461","The automatic generation of RTL code (e.g., Verilog) using natural language instructions and large language models (LLMs) has attracted significant research interest recently. However, most existing approaches heavily rely on commercial LLMs, such as ChatGPT, while open-source LLMs tailored for this specific design generation task exhibit notably inferior performance. The absence of high-quality open-source solutions restricts the flexibility and data privacy of this emerging technique. In this study, we present a new customized LLM solution with a modest parameter count of only 7B, achieving better performance than GPT-3.5 on all representative benchmarks for RTL code generation. Especially, it outperforms GPT-4 in VerilogEval Machine benchmark. This remarkable balance between accuracy and efficiency is made possible by leveraging our new RTL code dataset and a customized LLM algorithm, both of which have been made fully open-source. Furthermore, we have successfully quantized our LLM to 4-bit with a total size of 4 GB, enabling it to function on a single laptop with only slight performance degradation. This efficiency allows the RTL generator to serve as a local assistant for engineers, ensuring all design privacy concerns are addressed.","1937-4151","","10.1109/TCAD.2024.3483089","Hong Kong Research Grants Council (RGC) ECS(grant numbers:26208723); National Natural Science Foundation of China(grant numbers:62304192,92364102); ACCESS—AI Chip Center for Emerging Smart Systems, sponsored by InnoHK funding, Hong Kong, SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720939","Dataset generation;hardware code generation;Verilog;large language model;preference finetuning","Codes;Hardware design languages;Training;Integrated circuit modeling;Data models;Natural languages;Hardware;Data collection;Benchmark testing;Privacy","","4","","41","IEEE","17 Oct 2024","","","IEEE","IEEE Journals"
"Automated Generation of Accessibility Test Reports from Recorded User Transcripts","S. F. Huq; M. Tafreshipour; K. Kalcevich; S. Malek","University of California, Irvine, Irvine, California, USA; University of California, Irvine, Irvine, California, USA; Fable Tech Labs Inc., Toronto, Ontario, Canada; University of California, Irvine, Irvine, California, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","204","216","Testing for accessibility is a significant step when developing software, as it ensures that all users, including those with disabilities, can effectively engage with web and mobile applications. While automated tools exist to detect accessibility issues in software, none are as comprehensive and effective as the process of user testing, where testers with various disabilities evaluate the application for accessibility and usability issues. However, user testing is not popular with software developers as it requires conducting lengthy interviews with users and later parsing through large recordings to derive the issues to fix. In this paper, we explore how large language models (LLMs) like GPT 4.0, which have shown promising results in context comprehension and semantic text generation, can mitigate this issue and streamline the user testing process. Our solution, called Reca11, takes in auto-generated transcripts from user testing video recordings and extracts the accessibility and usability issues mentioned by the tester. Our systematic prompt engineering determines the optimal configuration of input, instruction, context and demonstrations for best results. We evaluate Reca11's effectiveness on 36 user testing sessions across three applications. Based on the findings, we investigate the strengths and weaknesses of using LLMs in this space.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00043","National Science Foundation(grant numbers:2211790,1823262,2106306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029798","software accessibility;large language models;crowd-sourced software testing","Software testing;Systematics;Large language models;Semantics;Software;Reproducibility of results;Usability;Video recording;Testing;Software engineering","","","","67","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Explainable Anomaly Detection in Network Traffic Using LLM","K. Jerabek; J. Koumar; J. Setinský; J. Pesek","Brno University of Technology, Czech Republic; Czech Technical University in Prague, Prague, Czech Republic; Brno University of Technology, Czech Republic; Czech Technical University in Prague, Prague, Czech Republic",NOMS 2025-2025 IEEE Network Operations and Management Symposium,"15 Jul 2025","2025","","","1","6","Network anomaly detection is essential for modern cybersecurity, yet existing systems often generate numerous alerts without clear explanations, leading to inefficiencies and high false-positive rates. This paper proposes a novel approach that integrates Large Language Models (LLMs) with an anomaly detection framework to enhance explainability in network traffic analysis. Instead of directly detecting anomalies, the LLM only interprets already flagged anomaly events, providing insights into their potential root causes. Our method reduces LLM over-usage while improving decision-making for security analysts. We evaluated our approach using real-world network traffic data, demonstrating its ability to enhance situational awareness, reduce false positives, and support more effective cybersecurity practices.","2374-9709","979-8-3315-3163-8","10.1109/NOMS57970.2025.11073574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073574","anomaly detection;network security;network traffic monitoring;time series;large language models;explainable security","Large language models;Decision making;Time series analysis;Telecommunication traffic;Network security;Fatigue;Computer security;Anomaly detection;Monitoring","","","","16","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Intelligent Conversational AI for Microsoft Teams with Actionable Insights","D. D; C. Prasad; G. J","Department of Computer Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of Technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of Technology, Bangalore, India",2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS),"1 Jan 2025","2024","","","1","5","The proposed work presents the development process of a personalized AI assistant, leveraging advanced technologies like Azure OpenAI Services. The project entails significant development effort, adaptable from large to XL scales based on data intricacies and project scope. It offers versatile integration options, deploying seamlessly within or outside the Microsoft tenant ecosystem, catering to diverse environments and workflows. Utilizing natural language command interpretation, the AI assistant provides intuitive interfaces across various domains. Emphasis is placed on ethical considerations, including user privacy, algorithmic transparency, and bias mitigation. Additionally, the project incorporates prompt engineering in AI to optimize prompt selection for more effective generative AI outcomes. This holistic approach aims to revolutionize user experiences and operational efficiency across industries, marking a significant advancement in AI-driven technologies. Incorporating prompt engineering into AI involves designing and optimizing prompts to guide the model towards generating desired outputs effectively. This approach aims to enhance user experiences and operational efficiency by tailoring AI responses to specific objectives and contexts. By fine-tuning prompts, developers can improve the relevance and quality of generated outputs, leading to significant advancements in AI-driven technologies across industries.","2767-1097","979-8-3315-0546-2","10.1109/CSITSS64042.2024.10817069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817069","CHATBOTS;AI;ML;NLP;Deep Learning;Prompt Engineering;QA Systems","Industries;Privacy;Conversational artificial intelligence;Prevention and mitigation;Refining;Natural languages;Real-time systems;Prompt engineering;Iterative methods;Artificial intelligence","","","","20","IEEE","1 Jan 2025","","","IEEE","IEEE Conferences"
"Impact Analysis of DoS attacks on Different MAS Control architectures in Cyber-Physical Testbed","K. Katuri; H. T. Nguyen; E. Anagnostou","Eversource Energy Center, University of Connecticut, Storrs, CT, USA; Eversource Energy Center, University of Connecticut, Storrs, CT, USA; Eversource Energy Center, University of Connecticut, Storrs, CT, USA",2023 IEEE Texas Power and Energy Conference (TPEC),"31 Mar 2023","2023","","","1","6","The constant integration of distributed energy re-sources (DER) and smart devices with advanced communication features have not only transformed the power grid into a cyber-physical system (CPS) but has also proven the constant risks associated with vulnerabilities from each of these devices. These changes in addition to the complex communication security of the power grid have resulted in the raise of cyberattacks on the power grid. Through this research, a CPS testbed with two different multi-agent systems (MAS) based secondary control architectures is developed in the real-time environment using RTDS to analyze the impact of different cyberattacks on the power systems. For the cyber layer implementation, multiple single-board computers (SBC) are used. With the help of an over-voltage relay in the Hardware-in-the-loop (HiL) setup, the physical impacts of Denial of Service (DoS) attacks on both centralized and distributed control architectures are studied. The results have shown that the distributed MAS architecture is more resilient to the DoS attacks and the system has managed to reach stable operation even while under attack.","","978-1-6654-9071-9","10.1109/TPEC56611.2023.10078661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10078661","Centralized control;Cyber-Physical testbed;Multi Agent System;Raspberry Pi;Hardware-in-the-Loop","Decentralized control;Computer architecture;Microgrids;Power system stability;Physical layer;Real-time systems;Security","","2","","18","IEEE","31 Mar 2023","","","IEEE","IEEE Conferences"
"Generative AI on AWS Labs","O. Bergeret; A. Abbasi; J. Farvault",NA; NA; NA,GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS,"","2025","","","295","310","<p>This chapter guides us through practical, hands‐on exercises using Generative artificial intelligence (AI) on AWS, enabling us to gain valuable firsthand experience with these technologies. The workshop is designed to help introduce Generative AI concepts through dozens of hands‐on exercises. The workshop will guide the participants to build simple Generative AI demo applications while learning key concepts of Generative AI. Labs include prompt engineering, security and guardrails, chatbots, retrieval‐augmented generation, image generation/editing, and multimodal capabilities. This workshop offers two options for the readers, primarily based on the skillset of the workshop attendees. They are: Option 1: PartyRock Prompt Engineering Guide (for Non‐Technical and Technical Audiences) and Option 2: Amazon Bedrock Labs (for Technical Audiences). Within this series of labs, we will go through some of the most common Generative AI usage patterns we are seeing with our customers across the globe.</p>","","9781394281305","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10982311.pdf&bkn=10964414&pdfType=chapter","","Conferences;Prompt engineering;Prototypes;Costs;Codes;Chatbots;Buildings;Python;Pricing;Image synthesis","","","","","","2 May 2025","","","Wiley","Wiley AI eBook Chapters"
"Exploring Research and Tools in AI Security: A Systematic Mapping Study","S. Narula; M. Ghasemigol; J. Carnerero-Cano; A. Minnich; E. Lupu; D. Takabi","Department of Computer Science, Old Dominion University, Norfolk, VA, USA; School of Cybersecurity, Old Dominion University, Norfolk, VA, USA; IBM Research Europe, Dublin, Ireland; Microsoft AI Red Team, Redmond, WA, USA; Department of Computing, Imperial College London, London, U.K.; School of Cybersecurity, Old Dominion University, Norfolk, VA, USA",IEEE Access,"16 May 2025","2025","13","","84057","84080","With the pervasive integration of artificial intelligence (AI) in various facets of modern technology, the importance of AI security has been thrust into the spotlight. The field is rapidly evolving, with new challenges and solutions emerging at a swift pace. However, the breadth and depth of AI security research have not been comprehensively mapped in recent times, presenting a crucial need for an extensive review and synthesis of existing literature. Given the increasing reliance on AI in critical domains such as healthcare, finance, and national security, ensuring the resilience and trustworthiness of these systems is imperative. This survey fulfills the pressing need for a structured and comprehensive overview of the current research landscape, enabling researchers to address emerging threats and vulnerabilities effectively. This paper presents a systematic mapping study (SMS), aimed at identifying and classifying the prevailing research topics, tools, and frameworks in the field of AI security. A total of 123 studies were meticulously selected and analyzed, leading to the identification of key metrics, tools, standards, and research themes that are currently shaping the landscape of AI security research. This effort not only aids in distilling the collective wisdom of the research community but also sets a firm foundation for future work in this critical area. The findings from this SMS will serve as an invaluable guide for researchers and practitioners alike, enabling them to navigate the complexities of AI security and fostering the development of innovative, robust security solutions. This study also highlights significant gaps in the current literature, thereby outlining potential directions for new research initiatives.","2169-3536","","10.1109/ACCESS.2025.3567195","Commonwealth Cyber Initiative (CCI); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988535","AI security;generative AI security;AI risk assessment;detection and defense;ethical and societal","Artificial intelligence;Security;Systematics;Reviews;Surveys;Standards;Privacy;Ethics;Search problems;Data models","","","","162","CCBY","5 May 2025","","","IEEE","IEEE Journals"
"AI-Assisted Bug Detection in Open-Source Software","P. Liu; R. Luo; C. Jiang; T. Gao; Y. Li","Faculty of Business Information, Shanghai Business School, Shanghai, China; Faculty of Business Information, Shanghai Business School, Shanghai, China; Faculty of Business Information, Shanghai Business School, Shanghai, China; Faculty of Business Information, Shanghai Business School, Shanghai, China; School of Information and Electrical Engineering, Ludong University, Yantai, China",2024 11th International Conference on Dependable Systems and Their Applications (DSA),"1 Jan 2025","2024","","","428","429","With the rapid development of internet technology, open-source software mirror sites have become indispensable tools for developers and tech enthusiasts, serving as crucial platforms for resource acquisition. We selected and tested two open-source applications by downloading them from the Tsinghua University Open Source Software Mirror Site and the Nanjing University Open Source Software Mirror Site. By implementing black-box testing strategies, we identified several bugs and design flaws in the software. Furthermore, we utilized large language models such as ChatGPT-3.5, Gemini, Kimi, Llama, ERNIE Bot, and Tongyi Qianwen to analyze the potential causes of these issues, exploring new approaches to AI-assisted software quality assurance. Through comparative analysis of feedback from multiple interactions with these large language models, we systematically evaluated their effectiveness in the field of software testing. This study provides empirical evidence for optimizing model applications and enhancing testing efficiency.","2767-6684","979-8-3315-3239-0","10.1109/DSA63982.2024.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818277","Large language models;open-source software;software bug analysis;AI-assisted testing","Software testing;Fault diagnosis;Analytical models;Large language models;Computer bugs;Closed box;Software quality;Chatbots;Mirrors;Open source software","","","","10","IEEE","1 Jan 2025","","","IEEE","IEEE Conferences"
"DGA domain detection using pretrained character based transformer models","B. Gogoi; T. Ahmed","National Informatics Centre, RCoEAS, Guwahati, Guwahati, Assam, India; National Informatics Centre, RCoEAS, Guwahati, Guwahati, Assam, India",2023 IEEE Guwahati Subsection Conference (GCON),"21 Jul 2023","2023","","","01","06","DGAs (Domain Generation Algorithms) are a class of algorithms used by Malwares for generating pseudorandom domain names. The generated pseudorandom domain names are used by Malwares for communicating with C&Cs (Command and Control Centre) to receive updates and other critical information. The pseudorandom nature of the generated domain names makes it harder for traditional security measures like firewalls to detect the communication between Malwares and the C&Cs. Other traditional defense mechanisms like blocklists are also not effective as it is difficult and time-consuming to maintain an ever-growing list of malicious domains. To eliminate these deficiencies of the traditional approach, many machine learning and deep learning approach have been proposed for the detection of DGA-generated domain names. In this paper, we proposed a pretrained transformer-based approach to detecting DGA-generated domain names. Our approach aims to see if a given domain name is a DGA-generated domain name or a benign domain name based only on the domain name. The proposed approach was tested on a 1 million dataset containing DGA-generated and benign domain names. The results demonstrated a remarkable accuracy of 0.99, affirming the effectiveness of pretrained transformer-based models in the binary classification of domain names into benign and DGA categories.","","979-8-3503-3778-5","10.1109/GCON58516.2023.10183602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183602","DGA detection;Transformers;Transfer Learning;Deep Learning;Cyber Security","Deep learning;Command and control systems;Firewalls (computing);Transformers;Malware;Blocklists;Security","","8","","14","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"The Impact of Quantum Computing on Cybersecurity: Creating Quantum-Resistant Cryptography for Sustainable Digital Security Solutions","S. Kottur; K. Velusamy; P. Deepalakshmi","IT Infrastructure Architect/IT Systems, V-Soft Consulting Group, Inc, Louisville, KY, United States of America; UBS Business Solutions US LLC, Morrisville, NC, USA; School of Computing, Kalasalingam Academy of Research and Education, Krishnankoil, Tamil Nadu, India","2025 International Conference on Electronics, Computing, Communication and Control Technology (ICECCC)","11 Jul 2025","2025","","","1","6","A new era of digital security may be on the horizon as well as the disruption of current cryptographic methods brought about by the arrival of quantum computing, which represents a dramatic change in the cybersecurity landscape. Many existing cryptographic systems, like RSA and ECC, rely on solving complicated mathematical problems; quantum computers, with their unparalleled processing capability, are capable of doing just that (Elliptic Curve Cryptography). Concerns over the security of sensitive information, online identities, and communications in the post-quantum era are heightened by these vulnerabilities. In order to protect digital infrastructures, this study investigates the potential effects of quantum computing on cybersecurity and the critical need for encryption that is immune to quantum attacks. The creation of new cryptographic algorithms that are resistant to quantum assaults is becoming increasingly urgent as the field of quantum computing advances, posing an existential danger to traditional encryption systems. A number of possible methods for protecting data against quantum computers are discussed in the study. These methods include code-based cryptmography, lattice-based cryptography, hash-based cryptography, and multivariate polynomial cryptography. Scalability, computing efficiency, and compatibility with existing systems are some of the possible obstacles to moving to quantum-resistant systems that are covered in the article. By delving deeply into the effects of quantum computing on cybersecurity, this study highlights the significance of getting ready for a quantum future and the function of quantum-safe encryption in making sure that digital security solutions can withstand the rise of quantum technology.","","979-8-3315-2162-2","10.1109/ICECCC65144.2025.11064247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064247","Multi-Agent Systems;Cooperative Strategies;Reinforcement Learning;Autonomous Vehicles;Robot Navigation;Path Planning;Multi-Agent Coordination","Computers;Quantum computing;Scalability;Standardization;Elliptic curve cryptography;Polynomials;Encryption;Cryptography;Computer security;Cryptographic protocols","","","","17","IEEE","11 Jul 2025","","","IEEE","IEEE Conferences"
"An AI-supported Agent-based Security Model for the Internet of Things","L. Babun; L. P. Rondon; D. P. Syed; J. S. Chavis","Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA",2024 IEEE Future Networks World Forum (FNWF),"12 Jun 2025","2024","","","967","974","This paper proposes an agent-based security model that facilitates the integration of AI-supported analysis capabilities into IoT security research efforts. We aim to contribute to more secure IoT systems by combining flexible mechanisms to generate reliable, high quality, and diverse IoT data with Artificial Intelligence. The novel security model permits designing solutions that better adapt to changes in the IoT environment and that target a broader range of threats and attacks to IoT systems. The model focuses on improving the performance of traditional security solutions for the IoT in a practical and scalable way.","2770-7679","979-8-3503-7949-5","10.1109/FNWF63303.2024.11028713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028713","Internet of Things;Artificial Intelligence;Large-Language Models;security;privacy","Analytical models;Adaptation models;Privacy;Computational modeling;Diversity reception;Machine learning;Security;Internet of Things;Reliability;Artificial intelligence","","","","49","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"PrismPrompt: Layering Prompt-Enhanced Cloud-Edge Collaborative Language Model Toward Healthcare","S. Qiao; H. Xu; C. Cao; W. Gong; S. Chen; J. Liu","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Artificial Intelligence and Data Science, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",IEEE Network,"14 Jul 2025","2025","39","4","105","111","The rapid evolution of large language models (LLMs) has opened new avenues for enhancing healthcare delivery, particularly through cloud-edge collaborative frameworks. This paper introduces PrismPrompt, a novel system that leverages prompt-based engineering to optimize cloud-edge collaboration in medical applications. By integrating cloud-based LLMs with edge devices, PrismPrompt addresses the challenges of computational limitations and data privacy in healthcare environments. The system utilizes a hierarchical prompt strategy and an incremental expert decision-making process to enhance the retrieval and application of medical knowledge. Key innovations include a retriever module that accurately extracts and retrieves relevant information from cloud models and a decision maker that synthesizes expert opinions to ensure accurate and context-aware medical advice. Experimental results demonstrate that PrismPrompt outperforms existing models in terms of accuracy, highlighting its potential to improve real-time medical decision-making while preserving the computational feasibility on edge devices. This work provides a promising step towards the broader adoption of cloud-edge collaborative LLMs in healthcare, offering scalable and privacy-conscious solutions for modern medical challenges.","1558-156X","","10.1109/MNET.2025.3532857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849638","Cloud-Edge Collaboration;Large Language Models;Prompt Engineering;Healthcare","Medical diagnostic imaging;Computational modeling;Accuracy;Medical services;Collaboration;Large language models;Context modeling;Analytical models;Prompt engineering;Cloud computing;Edge computing","","","","15","IEEE","22 Jan 2025","","","IEEE","IEEE Magazines"
"Icing on the Cake: Automatic Code Summarization at Ericsson","G. Sridhara; S. Roychowdhury; S. Soman; R. H. G.; R. Britto","Ericsson, GAIA, Bangalore, India; Ericsson, GAIA, Bangalore, India; Ericsson, GAIA, Bangalore, India; Ericsson, GAIA, Bangalore, India; Ericsson, SA BOS & Blekinge Institute of Technology, Karlskrona, Sweden",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","689","700","This paper presents our findings on the automatic summarization of Java methods within Ericsson, a global telecommunications company. We evaluate the performance of an approach called Automatic Semantic Augmentation of Prompts (ASAP), which uses a Large Language Model (LLM) to generate leading summary comments (Javadocs) for Java methods. ASAP enhances the LLM's prompt context by integrating static program analysis and information retrieval techniques to identify similar exemplar methods along with their developer-written Javadocs, and serves as the baseline in our study. In contrast, we explore and compare the performance of four simpler approaches that do not require static program analysis, information retrieval, or the presence of exemplars as in the ASAP method. Our methods rely solely on the Java method body as input, making them lightweight and more suitable for rapid deployment in commercial software development environments. We conducted experiments on an Ericsson software project and replicated the study using two widely-used open-source Java projects, Guava and Elasticsearch, to ensure the reliability of our results. Performance was measured across eight metrics that capture various aspects of similarity. Notably, one of our simpler approaches performed as well as or better than the ASAP method on both the Ericsson project and the open-source projects. Additionally, we performed an ablation study to examine the impact of method names on Javadoc summary generation across our four proposed approaches and the ASAP method. By masking the method names and observing the generated summaries, we found that our approaches were statistically significantly less influenced by the absence of method names compared to the baseline. This suggests that our methods are more robust to variations in method names and may derive summaries more comprehensively from the method body than the ASAP approach.","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795074","Automated Code Summarization;Large Language Models;Generative AI;Program Comprehension;Software Maintenance;Industry Study","Measurement;Java;Software maintenance;Codes;Semantics;Text summarization;Information retrieval;Telecommunications;Software reliability;Software development management","","","","43","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Generative AI in E-maintenance: Myth or Reality?","J. Ćelić; T. Bronzin; M. Horvat; A. Jović; A. Stipić; B. Prole; M. Maričević; I. Pavlović; K. Pap; M. Mikota; N. Jelača","Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; CITUS, Zagreb, Croatia; Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Dept. of. El., Microelectronics., Comp, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; CITUS, Zagreb, Croatia; CITUS, Zagreb, Croatia; Faculty of Graphic Arts, University of Zagreb, Zagreb, Croatia; Faculty of Graphic Arts, University of Zagreb, Zagreb, Croatia; Faculty of Graphic Arts, University of Zagreb, Zagreb, Croatia; Faculty of Graphic Arts, University of Zagreb, Zagreb, Croatia; Faculty of Graphic Arts, University of Zagreb, Zagreb, Croatia",2024 47th MIPRO ICT and Electronics Convention (MIPRO),"28 Jun 2024","2024","","","1911","1919","With increasing requirements for reliability, availability, efficiency, effectiveness, productivity, and security of the system, the importance of diagnostics and maintenance is also increasing. E-maintenance as a leading concept for maintenance management has so far primarily involved the use of domain-specific technical language processing (TLP) techniques on historical case data. Due to its popularity, generative AI (GAI) with large language models (LLMs) is starting to be used more and more in various technical areas, thus starting to take an increasingly important place in diagnostics and maintenance. Starting from the fact that the rapid development of information and communication technologies (ICT) was the main factor in the emergence and development of the concept of e-maintenance, the importance of the potential more serious application of all forms of generative AI in the context is clear. This is especially pronounced in cases of difficult or impossible access to the location of components or an uncertain situation related to the type of process (e.g., nuclear, aeronautical, space, offshore). Autonomous vehicles, vessels, and aircraft (as an indispensable part of today’s intelligent transport systems) are certainly a leading example of these cases. Regardless of the level of autonomy, these systems are extremely complex and difficult to maintain and represent a clear challenge for the application of new approaches. Therefore, the authors of the paper propose the use of middleware that would enable the integration of various GAI tools, algorithms, and models to increase the effectiveness of diagnostics and maintenance as close as possible to real-time. However, the exact extent of the possibilities and limitations of this approach has yet to be determined.","2623-8764","979-8-3503-8250-1","10.1109/MIPRO60963.2024.10569282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569282","diagnostics;maintenance;e-maintenance;AI;generative AI;intelligent transport systems;middleware","Productivity;Adaptation models;Generative AI;Process control;Real-time systems;Maintenance;Information and communication technology","","1","","79","IEEE","28 Jun 2024","","","IEEE","IEEE Conferences"
"Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks","D. Kang; X. Li; I. Stoica; C. Guestrin; M. Zaharia; T. Hashimoto",UIUC; Stanford; Berkeley; Stanford; Berkeley; Stanford,2024 IEEE Security and Privacy Workshops (SPW),"4 Jul 2024","2024","","","132","143","Recent advances in instruction-following large language models (LLMs) have led to dramatic improvements in a range of NLP tasks. Unfortunately, we find that the same improved capabilities amplify the dual-use risks for malicious purposes of these models. Dual-use is difficult to prevent as instruction-following capabilities now enable standard attacks from computer security. The capabilities of these instruction-following LLMs provide strong economic incentives for dual-use by malicious actors. In particular, we show that instruction-following LLMs can produce targeted malicious content, including hate speech and scams, bypassing in-the-wild defenses implemented by LLM API vendors. Our analysis shows that this content can be generated economically and at cost of $125-500 \times$ cheaper than human effort alone. Together, our findings suggest that LLMs will increasingly attract more sophisticated adversaries and attacks, and addressing these attacks may require new approaches to mitigations.","2770-8411","979-8-3503-5487-4","10.1109/SPW63631.2024.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579515","","Training;Threat modeling;Privacy;Computational modeling;Biological system modeling;Hate speech;Computer security","","33","","47","IEEE","4 Jul 2024","","","IEEE","IEEE Conferences"
"Leveraging Local LLMs for Secure In-System Task Automation With Prompt-Based Agent Classification","S. Sriram; C. H. Karthikeya; K. P. Kishore Kumar; N. Vijayaraj; T. Murugan","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; College of Information and Technology, United Arab Emirates University, Al Ain, United Arab Emirates",IEEE Access,"3 Dec 2024","2024","12","","177038","177049","Recent progress in the field of intelligence has led to the creation of powerful large language models (LLMs). While these models show promise in improving personal computing experiences concerns surrounding data privacy and security have hindered their integration with sensitive personal information. In this study, a new framework is proposed to merge LLMs with personal file systems, enabling intelligent data interaction while maintaining strict privacy safeguards. The methodology organizes tasks based on LLM agents, which apply designated tags to the tasks before sending them to specific LLM modules. Every module is has its own function, including file search, document summarization, code interpretation, and general tasks, to make certain that all processing happens locally on the user’s device. Findings indicate high accuracy across agents: classification agent managed to get an accuracy rating of 86%, document summarization reached a BERT score of 0.9243. The key point of this framework is that it splits the LLM system into modules, which enables future development by integrating new task-specific modules as required. Findings suggest that integrating local LLMs can significantly improve interactions with file systems without compromising data privacy.","2169-3536","","10.1109/ACCESS.2024.3505298","Amrita Vishwa Vidyapeetham University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766449","File system;few-shot prompting;LangChain;LLM;prompt engineering","Codes;File systems;Data models;Computational modeling;Accuracy;Data privacy;Automation;Tuning;Large language models;Vectors","","2","","36","CCBY","25 Nov 2024","","","IEEE","IEEE Journals"
"SecureLLAMA: Secure FPGAs Using LLAMA Large Language Models","M. Alqarni; A. Azim","Ontario Tech University, Oshawa, ON, Canada; Ontario Tech University, Oshawa, ON, Canada",IEEE Transactions on Artificial Intelligence,"31 Jul 2025","2025","6","8","2266","2280","Field-programmable gate arrays (FPGAs) are increasingly utilized in critical applications across sectors such as infrastructure, defense, and autonomous systems. However, the inherent flexibility of FPGAs introduces significant security vulnerabilities, particularly in the hardware description languages (HDLs) used to program them. This article introduces SecureLLAMA, an enhanced version of the LLAMA2 model, specifically designed to detect and mitigate FPGA vulnerabilities. Leveraging a novel dataset “FPGAvul” which includes both real-world examples and synthetically generated vulnerabilities. Our dataset FPGAvul addresses vulnerabilities such as initialization errors, clock domain crossing issues, insecure state machines, resource sharing conflicts, and buffer overflows. SecureLLAMA demonstrates superior accuracy in identifying and addressing security flaws in FPGA configurations. Comprehensive evaluation shows that SecureLLAMA significantly improves the detection of vulnerabilities, providing a robust solution for securing FPGAs in embedded systems. The findings of this research have the potential to advance FPGA security practices, ensuring their safe integration in critical environments where reliability is essential.","2691-4581","","10.1109/TAI.2025.3544590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10899860","Cyber security;embedded system;FPGA;hardware description language (HDL) dataset;vulnerability detection","Field programmable gate arrays;Security;Binary sequences;Hardware;Codes;Hardware design languages;Internet of Things;Encryption;Prevention and mitigation;Embedded systems","","","","60","IEEE","21 Feb 2025","","","IEEE","IEEE Journals"
"Research on the Construction and Application of Earthquake Emergency Information Knowledge Graph Based on Large Language Models","W. Zhou; M. Huang; S. Liu; Q. You; F. Meng","Institute of Disaster Prevention, Langfang, China; Institute of Disaster Prevention, Langfang, China; Institute of Disaster Prevention, Langfang, China; Institute of Disaster Prevention, Langfang, China; Sichuan Disaster Reduction Center, Chengdu, China",IEEE Access,"25 Jul 2025","2025","13","","127742","127757","To address the challenges of semantic parsing of multi-source heterogeneous information and the delayed emergency response decisions caused by insufficient relational reasoning capabilities in earthquake emergency management, this study proposes a domain knowledge extraction method for earthquakes based on a large language model combined with a three-level prompt engineering system (TPES-LLM) of “instruction fine-tuning - demand awareness - case matching. ”The method deploys a local large language model using LangChain +QWEN2.5-7B, integrates earthquake domain knowledge through LoRa fine-tuning based on earthquake experts’ classifications and industry standards, and injects seismic knowledge into the model. The multi-head attention mechanism weights are optimized based on the co-occurrence frequency of historical earthquake entities, and demand-aware knowledge identifies key textual features that significantly impact knowledge extraction. Training is performed on 36 known earthquake disaster events to learn the association patterns of entities, relationships, and events hidden within the earthquake case data for case matching. This method significantly enhances the accuracy of entity recognition and the efficiency of relation extraction for complex disaster-related texts. Additionally, a bidirectional graph attention network (Bi-GAT) is designed to enable bidirectional propagation and dynamic aggregation of node features. The path confidence constraint algorithm (PCCA) is used to achieve deep semantic associations of earthquake disaster elements. Based on the Neo4j graph database, an earthquake emergency knowledge graph is constructed. Experimental results from real earthquake events such as the 2022 Luding 6.8-magnitude earthquake, the 2024 Jishishan 6.2-magnitude earthquake, and the 2025 Dingri 6.8-magnitude earthquake show that the accuracy of intelligent Q&A retrieval for the earthquake emergency knowledge graph reaches 89.62%, 87.28%, and 90.23%, respectively. The earthquake emergency knowledge graph based on large language models constructed in this study provides intelligent decision support for earthquake emergencies, with significant application value.","2169-3536","","10.1109/ACCESS.2025.3586370","Science and Technology Innovation Program for Postgraduate Students in Institute of Disaster Prevention (IDP) subsidized by the Fundamental Research Funds for the Central Universities(grant numbers:ZY20250324); Sichuan Province Key Research and Development Project “Construction and Demonstration of Earthquake Emergency Response Assistance System Based on Digital Twin Technology”(grant numbers:2023YFS0437); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11075653","TPES-LLM;NLP;Bi-GAT;PCCA;Neo4j","Earthquakes;Disasters;Semantics;Emergency services;Cognition;Feature extraction;Data mining;Knowledge graphs;Large language models;Correlation","","","","43","CCBY","10 Jul 2025","","","IEEE","IEEE Journals"
"SPICED+: Syntactical Bug Pattern Identification and Correction of Trojans in A/MS Circuits Using LLM-Enhanced Detection","J. Chaudhuri; D. Thapar; A. Chaudhuri; F. Firouzi; K. Chakrabarty","School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; NVIDIA Corporation, Santa Clara, CA, USA; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"21 Mar 2025","2025","33","4","1118","1131","Analog and mixed-signal (A/MS) integrated circuits (ICs) are crucial in modern electronics, playing key roles in signal processing, amplification, sensing, and power management. Many IC companies outsource manufacturing to third-party foundries, creating security risks such as syntactical bugs and stealthy analog Trojans. Traditional Trojan detection methods, including embedding circuit watermarks and hardware-based monitoring, impose significant area and power overheads while failing to effectively identify and localize the Trojans. To overcome these shortcomings, we present SPICED+, a software-based framework designed for syntactical bug pattern identification and the correction of Trojans in A/MS circuits, leveraging large language model (LLM)-enhanced detection. It uses LLM-aided techniques to detect, localize, and iteratively correct analog Trojans in SPICE netlists, without requiring explicit model training, and thus incurs zero area overhead. The framework leverages chain-of-thought reasoning and few-shot learning to guide the LLMs in understanding and applying anomaly detection rules, enabling accurate identification and correction of Trojan-impacted nodes. With the proposed method, we achieve an average Trojan coverage of 93.3%, average Trojan correction rate of 91.2%, and an average false-positive rate of 1.4%.","1557-9999","","10.1109/TVLSI.2025.3527382","National Science Foundation(grant numbers:CNS-2310142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843334","Anomaly detection;hardware security;large language models (LLMs);SPICE;Trojan horse","Trojan horses;Circuits;Computer bugs;SPICE;Codes;Prevention and mitigation;Hardware design languages;Syntactics;Fabrication;Watermarking","","2","","34","IEEE","15 Jan 2025","","","IEEE","IEEE Journals"
"Large Language Models for Cybersecurity: New Opportunities","D. M. Divakaran; S. T. Peddinti","Institute for Infocomm Research (I2R), A*STAR, Singapore, Singapore; Google, Sunnyvale, CA, USA",IEEE Security & Privacy,"","2024","PP","99","2","9","With the emergence of powerful, versatile, and beneficial large language models (LLMs), we take a fresh look at cybersecurity, specifically exploring and summarizing the potential of LLMs in addressing challenging problems in the security and safety domains.","1558-4046","","10.1109/MSEC.2024.3504512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803029","","Phishing;Codes;Artificial intelligence;Electronic mail;Safety;Computer bugs;Software development management;Internet;Data models;Companies","","1","","","IEEE","16 Dec 2024","","","IEEE","IEEE Early Access Articles"
"Test Wars: A Comparative Study of SBST, Symbolic Execution, and LLM-Based Approaches to Unit Test Generation","A. Abdullin; P. Derakhshanfar; A. Panichella","JetBrains Research, TV Delft, Amsterdam, The Netherlands; JetBrains Research, Amsterdam, The Netherlands; TU Delft, Delft, The Netherlands","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","221","232","Generating tests automatically is a key and ongoing area of focus in software engineering research. The emergence of Large Language Models (LLMs) has opened up new op-portunities, given their ability to perform a wide spectrum of tasks. However, the effectiveness of LLM -based approaches compared to traditional techniques such as search-based software testing (SBST) and symbolic execution remains uncertain. In this paper, we perform an extensive study of automatic test generation approaches based on three tools: EvoSuite for SBST, Kex for symbolic execution, and TestSpark for LLM-based test generation. We evaluate tools' performance on the GitBug Java dataset and compare them using various execution-based and feature-based metrics. Our results show that while LLM-based test generation is promising, it falls behind traditional methods w.r.t. coverage. However, it significantly outperforms them in mutation scores, suggesting that LLMs provide a deeper semantic understanding of code. LLM-based approach performed worse than SBST and symbolic execution-based approaches w.r.t. fault detection capabilities. Additionally, our feature-based analysis shows that all tools are affected by the complexity and internal dependencies of the class under test (CUT), with LLM-based approaches being especially sensitive to the CUT size.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10989033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989033","automatic test generation;symbolic execution;concolic testing;large language models;search-based software testing","Software testing;Measurement;Java;Codes;Large language models;Fault detection;Semantics;Computer bugs;Test pattern generators;Software engineering","","1","","62","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"Spear or Shield: The Role of Generative AI in Intelligent Network Services","H. Du; D. Niyato; J. Kang; Z. Xiong; K. -Y. Lam; Y. Fang; Y. Li","Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong, SAR, China; College of Computing and Data Science, Nanyang Technological University, Singapore; School of Automation, Guangdong University of Technology, China; School of Electronics, Electrical Engineering and Computer Science (EEECS), Queen’s University Belfast, Belfast, U.K.; Digital Trust Centre Singapore and the College of Computing and Data Science, Nanyang Technological University, Singapore; Department of Computer Science, Hong Kong JC STEM Lab of Smart City, City University of Hong Kong, Hong Kong, China; School of Electrical and Information Engineering, University of Sydney, Sydney, NSW, Australia",IEEE Network,"","2025","PP","99","1","1","Generative AI (GenAI) models have been rapidly advancing, with a wide range of applications including intelligent networks and mobile AI-generated content (AIGC) services. However, GenAI create opportunities for novel security challenges due to its wide range of services applications and potential capabilities. In this paper, we examine the challenges and opportunities of GenAI in the realm of the security of intelligent network services, acting as both a “spear” for potential attacks and a “shield” as an integral part of various defense mechanisms. First, we present a comprehensive overview of the GenAI landscape, highlighting its applications and the techniques underpinning these advancements, especially large language and diffusion models. Then, we investigate the dynamic interplay between GenAI’s spear and shield roles, highlighting two primary categories of potential GenAI-related attacks and their respective defense strategies within wireless networks. A case study illustrates the impact of GenAI defense strategies on energy consumption in an image request scenario under data poisoning attack. Our results show that by employing an AI-optimized diffusion defense mechanism, energy can be reduced by 8.7%, and retransmission count can be decreased from 32 images, without defense, to just 6 images, showcasing the effectiveness of GenAI in enhancing network security.","1558-156X","","10.1109/MNET.2025.3594769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106440","Generative AI;network security;large language mdoel;diffusion model;AI safety;digital trust","Artificial intelligence;Diffusion models;Security;Wireless networks;Training;Network security;Intelligent networks;Generative AI;Robustness;Data models","","","","","IEEE","1 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Prompt Engineering: An efficient way for Content Creation using Prompt Chaining","S. K. K; S. Bose; B. Tyagi; P. Sharma; A. Sharma","Computer Science Department, NMAMIT (NITTE Deemed to be University), Karkala, India; Mittal School of Business, Lovely Professional University, Phagwara, Punjab; KIET Group of Institutions, Ghaziabad; KIET Group of Institutions, Delhi-NCR; KCLIMT, Jalandhar",2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG),"13 Mar 2025","2024","","","1","6","In tasks related to creative writing or content generation, individuals can employ prompt chaining to construct a narrative, shape characters, or explore various storytelling avenues. AI has become a key element in content creation, transforming how content is generated, optimized, and refined. Prompt engineering is the meticulous crafting and optimization of queries or instructions to elicit precise and valuable responses from generative AI models. This strategic approach translates human intentions and business needs into actionable outcomes, ensuring alignment with desired objectives. The presented application highlights the use of prompt engineering in the domain of content creation.","","979-8-3315-1898-1","10.1109/ICTBIG64922.2024.10911772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911772","Prompt Engineering;Content Creation;Prompt Chaining;ChatGPT;Copilot;Midjourney;Speed;model;rue base;AI","Translation;Shape;MIMICs;Government;Coherence;Writing;Prompt engineering;Optimization;Creativity;Context modeling","","","","16","IEEE","13 Mar 2025","","","IEEE","IEEE Conferences"
"Multiagent Active Energy Complex Management System Architecture","A. Zhavoronkov; K. Aksyonov","Ural Federal University, Ekaterinburg, Russia; Ural Federal University, Ekaterinburg, Russia",2021 International Conference on Information Technology and Nanotechnology (ITNT),"24 Dec 2021","2021","","","1","4","The architecture of a multi-agent microgrid control system is proposed. An experimental study is carried out, and a scheme of interaction of software intelligent agents used in the construction of a distributed control system for an active energy complex is presented. An example of a decisionmaking diagram is shown. The multi-agent structure of the control system construction is justified. Recommendations on the use of multi-agent system design frameworks are given. The specification FIPA-ACL is considered as a priority. The paper provides a brief overview of current technologies for creating multi-agent systems for microgrid. The composite structure of the control system is presented, and its main components are described. A time diagram is proposed to highlight individual functional layers of the system, and a proposal for intersystem interaction is also made. The application of the FIPA-ACL language in the interaction of agents is considered. The simulation study was conducted in the MATLAB environment. Taking into account the conducted research, the architecture of the system is proposed, its description is given, and interaction with related information systems is considered. The proposed architecture satisfies the legal acts of the Russian Federation on the creation of active energy complexes.","","978-1-6654-3217-7","10.1109/ITNT52450.2021.9649206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649206","Active energy complex;multi-agent systems;distributed control;solution search diagram","Machine learning algorithms;Systems architecture;Microgrids;Computer architecture;Software;Resource management;Proposals","","","","12","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"LLM2FedLLM - A Tool for Simulating Federated LLMs for Software Engineering Tasks","J. Kumar; S. Gandu; S. Chimalakonda","Department of Computer Science and Engineering, Research in Intelligent Software & Human Analytics (RISHA) Lab, Indian Institute of Technology, Tirupati, India; Department of Computer Science and Engineering, Research in Intelligent Software & Human Analytics (RISHA) Lab, Indian Institute of Technology, Tirupati, India; Department of Computer Science and Engineering, Research in Intelligent Software & Human Analytics (RISHA) Lab, Indian Institute of Technology, Tirupati, India",2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC),"17 Jun 2025","2025","","","414","418","The paper introduces LLM2FedLLM, a tool designed for Software Engineering (SE) researchers to simulate fine-tuning Large Language Models (LLMs) within a federated learning (FL) framework. Unlike existing FL frameworks that facilitate real client collaboration, our simulator provides a controlled environment for experimenting with FL scenarios on a single machine. The LLM2FedLLM Simulator addresses SE code tasks, such as code summarization, code review, and code translation, within a federated learning framework by first partitioning the selected code dataset into heterogeneous subsets for multiple clients. It then fine-tunes the chosen LLM and evaluates its performance against vanilla, centralized, and individual client models using various metrics. The tool supports several federated aggregation methods and PEFT for supervised learning, with the flexibility to easily integrate additional techniques. The evaluation of our tool on Python code summarization showed that FedLLM performs comparably to centralized models and outperforms individual clients, particularly in low-data scenarios. Our tool aims to facilitate research advances in secure collaborative training simulations within the SE community. https://youtu.be/-byKkaiBchw.","2643-7171","979-8-3315-0223-2","10.1109/ICPC66645.2025.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025883","Federated Learning (FL);Simulator;Large","Training;Measurement;Codes;Translation;Federated learning;Reviews;Supervised learning;Collaboration;Software engineering;Python","","","","13","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Approach to Forming Vulnerability Datasets for Fine-Tuning AI Agents","K. Gladkikh; A. A. Zakharov","Information security department, Tyumen State University, Tyumen, Russia; Information security department, Tyumen State University, Tyumen, Russia",2025 International Russian Smart Industry Conference (SmartIndustryCon),"9 May 2025","2025","","","771","776","This study addresses the problem of identifying vulnerabilities in open-source code by exploring existing methods of code analysis and evaluating the feasibility of automating security assessments using large language models (LLMs). We propose an approach for constructing high-quality datasets to fine-tune LLMs for software security analysis. Our methodology involves collecting and processing vulnerability data, filtering and curating security-related code changes, and structuring datasets to optimize model fine-tuning. We present an algorithm for aggregating vulnerability data sources and constructing a dataset specifically for training security-focused LLMs. To validate our approach, we fine-tune models from the Qwen family for software vulnerability detection in Python codebases during development and testing. Our findings demonstrate that the proposed method enables the development of intelligent, continuously adaptable AI agents capable of identifying and analyzing emerging zero-day vulnerabilities, not only in Python but also in other structurally similar programming languages.","","979-8-3315-1124-1","10.1109/SmartIndustryCon65166.2025.10986048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10986048","vulnerability detection;large language models;dataset curation;machine learning security;code analysis;Python vulnerabilities;static code analysis","Training;Adaptation models;Codes;Filtering;Large language models;Soft sensors;Software algorithms;Python;Testing;Software development management","","","","21","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
"ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation","Y. Tang; Z. Liu; Z. Zhou; X. Luo","University of Glasgow, Glasgow, U.K.; ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong SAR, China",IEEE Transactions on Software Engineering,"14 Jun 2024","2024","50","6","1340","1359","Recent advancements in large language models (LLMs) have demonstrated exceptional success in a wide range of general domain tasks, such as question answering and following instructions. Moreover, LLMs have shown potential in various software engineering applications. In this study, we present a systematic comparison of test suites generated by the ChatGPT LLM and the state-of-the-art SBST tool EvoSuite. Our comparison is based on several critical factors, including correctness, readability, code coverage, and bug detection capability. By highlighting the strengths and weaknesses of LLMs (specifically ChatGPT) in generating unit test cases compared to EvoSuite, this work provides valuable insights into the performance of LLMs in solving software engineering problems. Overall, our findings underscore the potential of LLMs in software engineering and pave the way for further research in this area.","1939-3520","","10.1109/TSE.2024.3382365","Hong Kong RGC Project(grant numbers:PolyU15224121); HKPolyU(grant numbers:ZGGG); National Natural Science Foundation of China(grant numbers:62202306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10485640","ChatGPT;search-based software testing;large language models","Chatbots;Codes;Task analysis;Software;Question answering (information retrieval);Computer bugs;Benchmark testing","","29","","86","IEEE","29 Mar 2024","","","IEEE","IEEE Journals"
"Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A Comparative Analysis","J. Brokman; O. Hofman; O. Rachmil; I. Singh; V. Pahuja; R. Sabapathy; A. Priya; A. Giloni; R. Vainshtein; H. Kojima",Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research; Fujitsu Research,2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE),"13 Jun 2025","2025","","","1","8","We present a comparative analysis of open-source tools that scan conversational large language models (LLMs) for vulnerabilities, in short - scanners. As LLMs become integral to various applications, they also present potential attack surfaces, exposed to security risks such as information leakage and jail-break attacks. AI red-teaming, adapted from traditional cyberse-curity, is recognized by governments and companies as essential - often emphasizing the challenge of continuously evolving threats. Our study evaluates prominent, cutting-edge scanners - Garak, Giskard, PyRIT, and CyberSecEval - that address this challenge by automating red-teaming processes. We detail the distinctive features and practical use of these scanners, outline unifying principles of their design and perform quantitative evaluations to compare them. These evaluations uncover significant reliability issues in detecting successful attacks, highlighting a fundamental gap for future development. Additionally, we contribute a foundational labeled dataset, which serves as an initial step to bridge this gap. Based on the above, we provide suggestions for future regulations and standardization, as well as strategic recommendations to assist organizations in scanner selection, considering customizability, test-suite comprehensiveness and industry-specific use cases.","","979-8-3315-1466-2","10.1109/RAIE66699.2025.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029414","Large Language Models (LLMs);Vulnerability Scanners;Fuzzers;Red-teaming;Comparative Analysis","Large language models;Conferences;Standards organizations;Government;Standardization;Companies;Information leakage;Regulation;Security;Reliability","","","","46","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"AugmenTest: Enhancing Tests with LLM-Driven Oracles","S. M. Khandaker; F. Kifetew; D. Prandi; A. Susi","Software Engineering Unit, Fondazione Bruno Kessler, Trento, Italy; Software Engineering Unit, Fondazione Bruno Kessler, Trento, Italy; Software Engineering Unit, Fondazione Bruno Kessler, Trento, Italy; Software Engineering Unit, Fondazione Bruno Kessler, Trento, Italy","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","279","289","Automated test generation is crucial for ensuring the reliability and robustness of software applications while at the same time reducing the effort needed. While significant progress has been made in test generation research, generating valid test oracles still remains an open problem. To address this challenge, we present AugmenTest, an approach leveraging Large Language Models (LLMs) to infer correct test oracles based on available documentation of the software under test. Unlike most existing methods that rely on code, AugmenTest utilizes the semantic capabilities of LLMs to infer the intended behavior of a method from documentation and developer comments, without looking at the code. AugmenTest includes four variants: Simple Prompt, Extended Prompt, RAG with a generic prompt (without the context of class or method under test), and RAG with Simple Prompt, each offering different levels of contextual information to the LLMs. To evaluate our work, we selected 142 Java classes and generated multiple mutants for each. We then generated tests from these mutants, focusing only on tests that passed on the mutant but failed on the original class, to ensure that the tests effectively captured bugs. This resulted in 203 unique tests with distinct bugs, which were then used to evaluate AugmenTest. Results show that in the most conservative scenario, AugmenTest's Extended Prompt consistently outperformed the Simple Prompt, achieving a success rate of 30% for generating correct assertions. In comparison, the state-of-the-art TOGA approach achieved 8.2%. Contrary to our expectations, the RAG-based approaches did not lead to improvements, with performance of 18.2% success rate for the most conservative scenario. Our study demonstrates the potential of LLMs in improving the reliability of automated test generation tools, while also highlighting areas for future enhancement.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10988926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988926","Test Oracles;Large Language Models;Assertion Generation;Context-Aware Testing;Software Testing;Retrieval-Augmented Generation","Software testing;Codes;Large language models;Computer bugs;Semantics;Documentation;Software;Robustness;Software reliability;Test pattern generators","","","","21","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"Optimizing AIGC Services by Prompt Engineering and Edge Computing: A Generative Diffusion Model-Based Contract Theory Approach","D. Ye; S. Cai; H. Du; J. Kang; Y. Liu; R. Yu; D. Niyato","School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Department of Electrical and Electronic Engineering, University of Hong Kong, Pok Fu Lam, Hong Kong SAR, China; School of Automation, Guangdong University of Technology, Guangzhou, China; College of Computing and Data Science, Nanyang Technological University, Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; College of Computing and Data Science, Nanyang Technological University, Singapore",IEEE Transactions on Vehicular Technology,"15 Jan 2025","2025","74","1","571","586","The development of Generative AI (GAI) and AI-generated content (AIGC) has been significantly improved by pretrained foundation models and prompt-based methods. To boost the quality and reduce the latency of AIGC generation, prompt engineering and edge computing are introduced, demanding a multi-dimensional resource allocation approach. Thus, we use the generative diffusion model (GDM) and contract theory to design a two-stage, multi-dimensional resource allocation framework. In the first stage, we employ an approximation approach to quantitatively assess the relationship between the level of prompt optimization, the number of diffusion denoising steps, and the quality of AIGC generation. Based on the quality function, we formulate models for the utilities of an AI-generated content Service Provider (ASP) and users, leading to a non-convex quality-based contract problem optimizing the level of prompt optimization and the number of diffusion denoising steps. To address the time-consuming process of solving the non-convex problem due to variable cost of the ASP and gain preferences of the users, a GDM-based scheme is proposed to optimize quality-based contract items. In the second stage, for each group of users who choose the same quality-based contract items, a non-convex latency-based contract problem optimizing the CPU cycle frequency and network transmission rate is formulated, then the GDM-based scheme is also applied to find the optimal latency-based contract items. Numerical results show that the proposed GDM-based contract generation scheme is very advantageous in improving the quality of AIGC generation and decreasing the latency of AIGC generation, compared to other standard schemes.","1939-9359","","10.1109/TVT.2024.3463420","Key Area R & D Program of Guangdong Province(grant numbers:2022B0701180001); National Natural Science Foundation of China(grant numbers:62102099); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2023A1515140137); National Natural Science Foundation of China(grant numbers:U22A2054); National Research Foundation Singapore and Infocomm Media Development Authority through Future Communications Research & Development Programme; Defence Science Organisation National Laboratories through AI Singapore Programme(grant numbers:FCP-NTU-RG-2022-010,FCP-ASTAR-TG-2022-003,RG87/22); Singapore Ministry of Education Tier 1; NTU Centre for Computational Technologies in Finance; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707303","Edge computing;prompt engineering;AI-generated content;contract theory;generative diffusion model","Contracts;Optimization;Noise reduction;Image synthesis;Costs;Prompt engineering;Time-frequency analysis;Resource management;Quality of experience;Energy consumption","","6","","33","IEEE","8 Oct 2024","","","IEEE","IEEE Journals"
"LLM-based kidney disease diagnostic framework for Pathologists","M. Z. Syeda; S. U. K. Bukhari; M. Hussain; W. A. Khan; S. S. H. Shah","College of Science and Engineering, University of Derby, Derby, United Kingdom; Idrak Artificial Intelligence Limited, Idrak AI Ltd, London, United Kingdom; College of Science and Engineering, University of Derby, Derby, United Kingdom; College of Science and Engineering, University of Derby, Derby, United Kingdom; Faculty of Medicine, Northern Border University, Arar, Kingdom of Saudi Arabia",2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"17 Dec 2024","2024","","","1","4","Large language models revolutionize the recent paradigm in the medical field and its contributing to various applications, diversified from clinical decision support to information extraction and summarization. The substantial linguistic understanding and contextual awareness allow language models to process and evaluate decision tasks. Concurrently, it addresses the challenges encountered by pathologists in disease diagnosis by adeptly retrieving precise and accurate facts from an external knowledge base. In this paper, we propose a framework which incorporates advanced retrieval augmented generation with prompt engineering techniques, contain prompting levels and structured prompts, which enables the model to extract refine, and customize responses. The model has been equipped with a large corpus of several kidney diseases clinical data which is collected from the vast information sources of kidney diagnostic books. The utilization of varied prompt techniques, exemplified by standard prompts like few-shots and the Reasoning Act (ReAct), manifests notable improvements in disease diagnosis responses. Structured prompts are designed to provide pathologists with specific instructions for formulating questions that effectively enhance the performance of the model. In the evaluation of prompt performance, three key metrics are employed answer relevance, faithfulness, and context relevance. Notably, in the context relevance metric, an optimal performance score of 1.0 was attained indicating perfect alignment with the conversational context.","2694-0604","979-8-3503-7149-9","10.1109/EMBC53108.2024.10782599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10782599","natural language processing;large language models;retrieval augmented generation;information retrieval;decision support;kidney diseases","Measurement;Large language models;Biological system modeling;Retrieval augmented generation;Medical diagnosis;Prompt engineering;Kidney;Standards;Medical diagnostic imaging;Diseases","Humans;Kidney Diseases;Pathologists;Natural Language Processing","","","11","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Tracing Feature Tests to Textual Requirements","M. Dahiya; M. Li; G. Horton; T. Scherz; N. Niu","University of Cincinnati, CincinnatiOH, USA; Avon High School, Avon, CT, USA; University of Cincinnati, CincinnatiOH, USA; University of Cincinnati, CincinnatiOH, USA; University of Cincinnati, CincinnatiOH, USA",2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI),"8 Oct 2024","2024","","","120","125","Software features deliver values to the end users, and thus their qualities shall be assured. While the mainstream quality assurance technique is software testing, its adequacy can only be assessed by tracing the testing artifacts to system requirements. In this paper, we report an in-depth case study aiming to trace all the feature tests of a Web application to textual requirements. To that end, we experiment two automated trace recovery methods: vector space model and transformer-based semantic embedding. The tracing results, unfortunately, are not satisfactory. We then explore the use of large language models, OpenAI’s ChatGPT in particular. We engage the original developers into evaluating the tracing and ChatGPT-prompting results. Our study reveals the promises of exploiting large language models to assist in software tracing activities.","2835-5776","979-8-3503-5118-7","10.1109/IRI62200.2024.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703827","requirements traceability;software testing;trace recovery;large language models","Software testing;Quality assurance;Large language models;Semantics;Data science;Chatbots;Transformers;Software;Vectors;Rough surfaces","","3","","31","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Mask Privacy Preservation Prescribed-Time Consensus Control for Nonlinear Multi-Agent Systems","J. Yuan; W. Sun; Y. Sun; S. -F. Su","School of Mathematics Science, Liaocheng University, Liaocheng, China; School of Mathematics Science, Liaocheng University, Liaocheng, China; Institute of Rail Transit, Tongji University, Shanghai, China; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan",IEEE Transactions on Automation Science and Engineering,"11 Apr 2025","2025","22","","11554","11563","In this study, we propose an innovative prescribed-time consensus control strategy for nonlinear strict-feedback multi-agent systems (MASs) with privacy protection requirements. Firstly, compared with the existing privacy protection strategies, the mask function adopted in this paper remains unknown to all agents, including the sender, thus greatly improving the security level of information transmission. Secondly, the existing related research results basically overlook prescribed-time control in the context of privacy preservation, based on the backstepping method, a prescribed time performance function is adopted in this paper, so that the systems can make the tracking error within the defined accuracy range within a user-defined time. Finally, through the verification of MATLAB simulation experiments, the proposed control strategy not only effectively realizes the privacy-preserving consensus control of multi-agent systems, but also shows better control performance compared with the existing schemes. Note to Practitioners—This paper aims to develop a mask privacy protection prescribed-time control algorithm for information transmission between multiple agents. In the automation industry, the demand for privacy protection in multi-agent systems is critical, necessitating the implementation of robust measures during agent collaboration and data sharing to safeguard data confidentiality. Employing advanced privacy-preserving technologies is essential to prevent the exposure of sensitive information, thereby ensuring the security of corporate secrets and operational integrity, in compliance with the evolving stringent privacy regulations. In addition, prescribed-time control enables users to achieve preset accuracy within a predefined time, reducing industrial resource consumption and improving resource utilization in the automation industry.","1558-3783","","10.1109/TASE.2025.3535924","National Natural Science Foundation of China(grant numbers:62473185); Outstanding Youth Foundation of Shandong Province(grant numbers:ZR2024YQ033); Guangyue Young Scholar Innovation Team of Liaocheng University(grant numbers:LCUGYTD2022-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857430","Privacy-preserving;prescribed-time control;vanishing mask function;consensus control","Privacy;Protection;Consensus control;Sun;Encryption;Automation;Accuracy;Noise;Multi-agent systems;Differential privacy","","1","","37","IEEE","29 Jan 2025","","","IEEE","IEEE Journals"
"The Design and Implementation of APLOS: An Automated PoLicy DOcument Summarisation System","S. Sowe; T. Kiel; A. Neumann; Y. Mou; V. Peristeras; S. Decker","Department of Computer Science, Informatik 5, RWTH Aachen University, Aachen, Germany; Department of Computer Science, Informatik 5, RWTH Aachen University, Aachen, Germany; Department of Computer Science, Informatik 5, RWTH Aachen University, Aachen, Germany; Department of Computer Science, Informatik 5, RWTH Aachen University, Aachen, Germany; School for Science and Technology, International Hellenic University, Thessaloniki, Greece; Department of Computer Science, Informatik 5, RWTH Aachen University, Aachen, Germany",2024 2nd International Conference on Foundation and Large Language Models (FLLM),"28 Jan 2025","2024","","","345","356","Many institutions write and publish policy documents to inform stakeholders or citizens about priority areas and legislations or regulations governing issues such as the environment, agriculture, food safety and business operations, to mention a few. These documents are often lengthy, have different formats, are full of jargon, may have many versions, and require domain knowledge to understand the policy issue. These characteristics make it challenging to develop a personalised tool for users to generate concise summaries based on their domain knowledge, refine the summaries without compromising the original meaning of the policy, and find related policies. To solve these problems, we leverage advances in foundation models (FMs) and Large Language Models (LLMs) to develop a tool called ""APLOS"" for summarising and gaining insights from policy documents. The architecture, implementation, and natural language processing challenges we faced in developing the tool and the future directions we are undertaking to address the challenges are presented and discussed.","","979-8-3503-5479-9","10.1109/FLLM63129.2024.10852442","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852442","Natural Language Processing;Document Analysis;Summarisation;Large Language Models;Policy Documents;Prompt Engineering","Frequency modulation;Foundation models;Large language models;Legislation;Portable document format;Regulation;Natural language processing;Food safety;Stakeholders;Next generation networking","","","","66","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"On the (In)Security of LLM App Stores","X. Hou; Y. Zhao; H. Wang","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China",2025 IEEE Symposium on Security and Privacy (SP),"16 Jun 2025","2025","","","317","335","LLM app stores have seen rapid growth, leading to the proliferation of numerous custom LLM apps. However, this expansion raises security concerns. In this study, we propose a three-layer concern framework to identify the potential security risks of LLM apps, i.e., LLM apps with abusive potential, LLM apps with malicious intent, and LLM apps with backdoors. Over five months, we collected 786,036 LLM apps from six major app stores: GPT Store, FlowGPT, Poe, Coze, Cici, and Character.AI. Our research integrates static and dynamic analysis, and uses a complementary approach to detect harmful content, combining a self-refining LLM-based toxic content detector with rule-based pattern matching. Additionally, we constructed a large-scale toxic word dictionary (i.e., ToxicDict) comprising over 31,783 entries. We used these methods to uncover that 15,414 apps had misleading descriptions, 1,366 collected sensitive personal information against their privacy policies, and 15,996 generated harmful content such as hate speech, self-harm, extremism, etc. Additionally, we evaluated the potential for LLM apps to facilitate malicious activities, finding that 616 apps could be used for malware generation, phishing, etc. We reported these security risks to relevant platforms, including OpenAI and Quora, which acknowledged and appreciated our findings. The platforms are actively investigating the flagged apps; as of the submission of this paper, 1,643 apps have been removed from the GPT Store.","2375-1207","979-8-3315-2236-0","10.1109/SP61157.2025.00117","National Natural Science Foundation of China(grant numbers:62072046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023302","large language models;llm;llm app;security","Privacy;Dictionaries;Phishing;Hate speech;Ecosystems;Detectors;Malware;Security;Pattern matching","","","","80","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Benchmarking Generative AI Models for Deep Learning Test Input Generation","M. Maryam; M. Biagiola; A. Stocco; V. Riccio","University of Udine, Udine, Italy; Università della Svizzera italiana, Lugano, Switzerland; Technical University of Munich, fortiss, Munich, Germany; University of Udine, Udine, Italy","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","174","185","Test Input Generators (TIGs) are crucial to assess the ability of Deep Learning (DL) image classifiers to provide correct predictions for inputs beyond their training and test sets. Recent advancements in Generative AI(GenAI) models have made them a powerful tool for creating and manipulating synthetic images, although these advancements also imply increased complexity and resource demands for training. In this work, we benchmark and combine different GenAI models with TIGs, assessing their effectiveness, efficiency, and quality of the generated test images, in terms of domain validity and label preservation. We conduct an empirical study involving three different GenAI architectures (VAEs, GANs, Diffusion Models), five classification tasks of increasing complexity, and 364 human evaluations. Our results show that simpler architectures, such as VAEs, are sufficient for less complex datasets like MNIST. However, when dealing with feature-rich datasets, such as ImageNet, more sophisticated architectures like Diffusion Models achieve superior performance by generating a higher number of valid, misclassification-inducing inputs.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10989043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989043","Software Testing;Generative AI;Deep Learning","Deep learning;Software testing;Training;Generative AI;Computer architecture;Benchmark testing;Diffusion models;Generators;Complexity theory","","","","81","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"Personalized Meal Planning in Inpatient Clinical Dietetics Using Generative Artificial Intelligence: System Description","L. Kopitar; G. Stiglic; L. Bedrac; J. Bian","Faculty of Health Sciences, Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Health Sciences, University of Maribor, Maribor, Slovenia; The NU B.V., Leiden, The Netherlands; Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, FL, USA",2024 IEEE 12th International Conference on Healthcare Informatics (ICHI),"22 Aug 2024","2024","","","326","331","This study addresses the limitations of traditional prescribed meal plans, which lack personalization and often prove monotonous and challenging for patients to follow. We propose a novel approach employing generative artificial intelligence in the context of a learning health system, with an emphasis on inpatient clinical dietetics. The system incorporates two key models: the Meal Plan Generation Model, MeaIGM, and the Meal Plan Image Generation Model, MealImageGM, leveraging state-of-the-art large language models. Patient information from electronic health records and clinical dietetics guidelines are incorporated into prompts for MeaIGM, which is refined through nutritionist validations and users' feedback. On the other hand, MealImageGM generates visual representations of meal plans to enhance patient engagement, utilizing crowd-sourced feedback to optimize image generation prompts. The overall system process includes extracting data from electronic health records, pre-designed user meal generation prompts, and the generation of personalized meal plans and images. Nutritionists play a crucial role in monitoring patient adherence and preferences, contributing to a continuous learning health system cycle. The proposed framework ensures clinically appropriate and personalized meal plans, aligning with dynamic dietary recommendations. The study emphasizes the importance of patient-physician co-creation for constant optimization and highlights the potential positive impact on health outcomes.","2575-2634","979-8-3503-8373-7","10.1109/ICHI61247.2024.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628741","LLM;meal plan;generative AI;system;prompt engineering;EHR","Visualization;Image synthesis;Generative AI;Medical services;Learning (artificial intelligence);Planning;Electronic medical records","","3","","32","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Data Analysis with LLMs: Text, tables, images and sound","I. Trummer",Manning Publications,"Data Analysis with LLMs: Text, tables, images and sound","","2025","","","","","Speed up common data science tasks with AI assistants like ChatGPT and Large Language Models (LLMs) from Anthropic, Cohere, Open AI, Google, Hugging Face, and more! Data Analysis with LLMs teaches you to use the new generation of AI assistants and Large Language Models (LLMs) to aid and accelerate common data science tasks. Learn how to use LLMs to:  Analyze text, tables, images, and audio files Extract information from multi-modal data lakes Classify, cluster, transform, and query multimodal data Build natural language query interfaces over structured data sources Use LangChain to build complex data analysis pipelines Prompt engineering and model configuration  All practical, Data Analysis with LLMs takes you from your first prompts through advanced techniques like creating LLM-based agents for data analysis and fine-tuning existing models. You’ll learn how to extract data, build natural language query interfaces, and much more.","","9781633437647","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10981887.pdf&bkn=10981886&pdfType=book","Python;AI;LLMs;OpenAI;cluster;classify;transform;query;ChatGPT;LangChain;pipelines;templates;prompt engineering;text;tables;images;audio;configuration;model selection;no-code;tuning;plain English","","","","","","","1 May 2025","","","Manning","Manning eBooks"
"A Smart Approach using Multi–agent System for Big Data Security","D. Kassimi; O. Kazar; E. Barka; A. Merizig; Z. Houhamdi; B. Athamena; M. Zaoui","Department of Computer Science, University Center Aflou, Laghouat, Algeria; Department of Information Systems and Security, UAE University, Al Ain, United Arab Emirates; Department of Information Systems and Security, UAE University, Al Ain, United Arab Emirates; Department of Computer Science, University of Biskra, Biskra, Algeria; Cybersecurity Department, Al Ain University, Al Ain, United Arab Emirates; Business Administration Department, Al Ain University, Al Ain, United Arab Emirates; Department of Computer Science, University of Biskra, Biskra, Algeria","2022 9th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","13 Mar 2023","2022","","","1","7","With the evaluation of technology and the appearance of new tools that help store the information we create, especially in Banking, business intelligence, and even Education as Datawarehouse, Big data, and cloud computing. Those new tools create another obstacle: how we can secure and protect the information and the data stored in them. This paper treats the problem of Big Data security and privacy using mobile and stationary agents’ technologies. The main important security proprieties in big data are integrity, authentication, privacy, and access control. For integrity, the problem lies in checking the integrity of data and if this data is good and can be used since the Big Data is receiving data from different sours and different formats (structured, semi–structured, and non-structured). In access control, we need to consider the users’ secrecy, monitor the authorities, and properly apply the confidentiality requirement. The problem with authentication is to authenticate each user over the network, while big data collect sensitive data from trusted or untrusted users. While the privacy policy problem revolves around data collection and the use of transparency. To answer the previous needs for security in big data, we have proposed a smart approach using multi–agent systems (MAS) as a model for our solution.","2832-3033","979-8-3503-2045-9","10.1109/IOTSMS58070.2022.10062015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062015","big data;security and privacy;multi–agent system;mobile agent;Hadoop;Pentaho","Access control;Data privacy;Cloud computing;Authentication;Intrusion detection;Big Data;Safety","","","","17","IEEE","13 Mar 2023","","","IEEE","IEEE Conferences"
"Reimagining the Data Landscape: A Multi-Agent Paradigm for Data Interfacing","H. Renney; M. Nethercott; O. Williams; J. Evetts; J. Lang","Kaze Technologies, Kaze Consulting, Bath, UK; Kaze Technologies, Kaze Consulting, Bath, UK; Kaze Technologies, Kaze Consulting, Bath, UK; Department of Computer Science, University of Bath, Bath, UK; Kaze Technologies, Kaze Consulting, Bath, UK",2025 8th International Conference on Data Science and Machine Learning Applications (CDMA),"7 Mar 2025","2025","","","114","119","The concept of using multi-agent systems is an area of contemporary artificial intelligence (AI) that dates back as far as the 1970s. At the time, these concepts were discussed in a primarily theoretical capacity, with the idea that once AI agents with sufficient reasoning abilities were achieved, novel multi-agent systems could be tried and tested. With the emergence of a combination of key enabling technologies, including the transformer, large language models (LLMs), and access to considerable compute power, conceptual multi-agent designs are now possible to investigate in practice. Reflecting on these observations, a multi-agent approach for effectively navigating domain-specific landscapes is formalised. The paradigm draws from the observations seen in research, industry developments and community support for creating multi-agent networks composed of specialist agents to target domain-specific problems. The paradigm focuses particularly on data interfacing across multiple distinct datasets at once. Using the proposed paradigm, an example is developed for a Cyber Intelligence use case along with suggestive results from a small preliminary user experience study. The paper concludes by discussing this paradigm's strengths and weaknesses and speculates where future developments may progress.","","979-8-3315-3969-6","10.1109/CDMA61895.2025.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908782","LLM;Multi-Agent;SQL;RAG;Agentic AI;Cyber Security","Industries;Reviews;Navigation;Machine learning;Transformers;Cognition;User experience;Security;Multiaccess communication;Multi-agent systems","","","","38","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection","Z. Qiang Wang; H. Wang; A. El Saddik","Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",IEEE Access,"6 Nov 2024","2024","12","","160396","160417","Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD’s superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper.","2169-3536","","10.1109/ACCESS.2024.3482988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10721229","Cybersecurity;insider threat;deep learning;transformer;BERT;RoBERTa;XLNet;DistilBERT;GPT;data augmentation;artificial intelligence;machine learning;pre-trained LLM;PETuning;adapter;LoRA;BitFit;LLM;NLP","Data models;Adaptation models;Threat assessment;Tuning;Security;Organizations;Costs;Computational modeling;Transfer learning;Deep learning;Computer security;Data augmentation;Artificial intelligence;Machine learning","","2","","63","CCBYNCND","17 Oct 2024","","","IEEE","IEEE Journals"
"Leveraging Natural Language Processing in Conversational AI Agents to Improve Healthcare Security","J. V. Suman; F. S. Mahammad; M. Sunil Kumar; B. Sai Chandana; S. Majji","Department of ECE, GMR Institute of Technology, Rajam, Andhra Pradesh, India; Department of Computer Science Engineering, Santhiram Engineering College Nandyal, Nandyal, Andhra Pradesh, India; Department of Computer Science and Engineering, School of Computing, Mohan Babu University (erstwhile Sree Vidyanikethan Engineering College), Tirupathi, AP, India; School of Computer Science and Engineering, Amaravathi, India; Department of ECE, GRIET, Hyderabad, India",Conversational Artificial Intelligence,"","2024","","","699","711","Summary <p>While the widespread adoption of healthcare information technology has many positive outcomes, it has also presented new obstacles for protecting patient information. Natural language processing (NLP)‐enabled conversational artificial intelligence (AI) agents are becoming increasingly useful in the healthcare industry as a means to improve both patient encounters and administrative workflows. Due to its sensitive nature, healthcare data must be protected by strict security procedures. This research delves into NLP in conversational AI agents’ potential for enhancing healthcare's security infrastructure. We talk about how entity recognition, sentiment analysis, and anomaly detection are just some of the NLP‐driven tactics that may be used to strengthen healthcare data security. Furthermore, we evaluate preexisting security architectures and suggest novel methods to better protect the privacy and safety of patients’ information during conversations. Healthcare institutions may improve the quality and safety of healthcare services in the digital age by employing NLP capabilities to strike a balance between personalized patient involvement and tight security regulations.</p>","","9781394200795","10.1002/9781394200801.ch38","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10953335.pdf&bkn=10950236&pdfType=chapter","","Natural language processing;Medical services;Chatbots;Data mining;Artificial intelligence;Industries;Companies;Cancer;Oral communication;Social networking (online)","","3","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Mitigation and Resiliency of Multi-Agent Systems Subject to Malicious Cyber Attacks on Communication Links","M. Taheri; K. Khorasani; I. Shames; N. Meskin","Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Department of Electrical and Electronic Engineering, University of Melbourne, Melbourne, Australia; Department of Electrical Engineering, Qatar University, Doha, Qatar",2020 IEEE Conference on Control Technology and Applications (CCTA),"28 Sep 2020","2020","","","857","862","This paper aims at investigating a novel type of cyber attack that is injected to multi-agent systems (MAS) having an underlying directed graph. The cyber attack, which is designated as the controllability attack, is injected by the malicious adversary into the communication links among the agents. The adversary, leveraging the compromised communication links disguises the cyber attack signals and attempts to take control over the entire network of MAS. The adversary aims at achieving this by directly attacking only a subset of the multi-agents. Conditions under which the malicious hacker has control over the entire MAS network are provided. Two notions of security controllability indices are proposed and developed. These notions are utilized as metrics to evaluate the controllability that each agent provides to the adversary for executing the malicious cyber attack. Furthermore, the possibility of introducing zero dynamics cyber attacks on the MAS through compromising the communication links is also investigated. Finally, an illustrative numerical example is provided to demonstrate the effectiveness of our proposed methods.","","978-1-7281-7140-1","10.1109/CCTA41146.2020.9206392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206392","","Cyberattack;Controllability;Observers;Communication channels;Multi-agent systems;Protocols","","3","","31","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Large Language Models for Power Scheduling: A User-Centric Approach","T. Mongaillard; S. Lasaulce; O. Hicheur; C. Zhang; L. Bariah; V. S. Varma; H. Zou; Q. Zhao; M. Debbah","Université de Lorraine, CNRS, CRAN, Nancy, France; Université de Lorraine, CNRS, CRAN, Nancy, France; KU 6G Research Center, Khalifa University, Abu Dhabi, UAE; KU 6G Research Center, Khalifa University, Abu Dhabi, UAE; KU 6G Research Center, Khalifa University, Abu Dhabi, UAE; Université de Lorraine, CNRS, CRAN, Nancy, France; KU 6G Research Center, Khalifa University, Abu Dhabi, UAE; TII, Abu Dhabi, UAE; KU 6G Research Center, Khalifa University, Abu Dhabi, UAE","2024 22nd International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt)","13 Dec 2024","2024","","","321","328","While traditional optimization and scheduling schemes are designed to meet fixed, predefined system requirements, future systems are moving toward user-driven approaches and personalized services, aiming to achieve high quality-of-experience (QoE) and flexibility. This challenge is particularly pronounced in wireless and digitalized energy networks, where users' requirements have largely not been taken into consideration due to the lack of a common language between users and machines. The emergence of powerful large language models (LLMs) marks a radical departure from traditional system-centric methods into more advanced user-centric approaches by providing a natural communication interface between users and devices. In this paper, for the first time, we introduce a novel architecture for resource scheduling problems by constructing three LLM agents to convert an arbitrary user's voice request (VRQ) into a resource allocation vector. Specifically, we design an LLM intent recognition agent to translate the request into an optimization problem (OP), an LLM OP parameter identification agent, and an LLM OP solving agent. To evaluate system performance, we construct a database (EVRQ) of typical VRQs in the context of electric vehicle (EV) charging. As a proof of concept, we primarily use Llama 3 8B. Through testing with different prompt engineering scenarios, the obtained results demonstrate the efficiency of the proposed architecture. The conducted performance analysis allows key insights to be extracted. For instance, having a larger set of candidate OPs to model the real-world problem might degrade the final performance because of a higher recognition/OP classification noise level. [Paper codes and video 11https://github.com/thomasmong/llm-power-scheduling].","2690-3342","978-3-903176-65-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778356","Large language model;multi-agent;optimization;power scheduling;EV charging;smart grid;resource allocation;user-centric","Parameter estimation;Databases;Large language models;Wireless networks;System performance;Vectors;Electric vehicle charging;Performance analysis;Optimization;Testing","","2","","21","","13 Dec 2024","","","IEEE","IEEE Conferences"
"Leveraging Large Language Models for Autonomous Cyber Defense: Insights from CAGE-2 Simulations","H. Mohammadi; J. J. Davis; M. Kiely","Defence and Security Institute, The University of Adelaide, Adelaide, SA, Australia; Defence Science and Technology Group, Edinburgh, SA, Australia; Defence Science and Technology Group, Edinburgh, SA, Australia",IEEE Intelligent Systems,"12 Aug 2025","2025","40","4","29","36","The ability of large language models (LLMs) to interpret and generate human-like text, along with their inbuilt knowledge and reasoning skills, has opened the door for many new applications. We develop a novel LLM agent as an autonomous cyber defender and benchmark it using the CAGE-2 public challenge, which evaluates submitted agents in a simulated network. The agent uses a pretrained LLM to interpret a text description of the challenge and choose the best defensive action given a network observation. Its performance is on par with the most successful reinforcement learning agent submitted to CAGE-2 with the advantages of explainability and avoiding training episodes, but with the cost of requiring LLM prompt engineering. Finally, we test the LLM agent experimentally to explore how LLM temperature and prompt complexity affect performance. We show that higher complexity prompts significantly improve performance, while LLM temperature has only a minor effect.","1941-1294","","10.1109/MIS.2025.3568209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10991969","","Human-machine systems;Training;Intelligent systems;Vectors;Servers;Large language models;Data mining;Complexity theory;Benchmark testing;Prompt engineering","","","","17","IEEE","8 May 2025","","","IEEE","IEEE Magazines"
"HumanEvo: An Evolution-Aware Benchmark for More Realistic Evaluation of Repository-Level Code Generation","D. Zheng; Y. Wang; E. Shi; R. Zhang; Y. Ma; H. Zhang; Z. Zheng","Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China; Huawei Cloud Computing Technologies Co., Ltd., Beijng, China; Huawei Cloud Computing Technologies Co., Ltd., Shenzhen, China; Huawei Cloud Computing Technologies Co., Ltd., Shenzhen, China; Chongqing University; Sun Yat-sen University, Zhuhai, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1372","1384","To evaluate the repository-level code generation capabilities of Large Language Models (LLMs) in complex real-world software development scenarios, many evaluation methods have been developed. These methods typically leverage contextual code from the latest version of a project to assist LLMs in accurately generating the desired function. However, such evaluation methods fail to consider the dynamic evolution of software projects over time, which we refer to as evolution-ignored settings. This in turn results in inaccurate evaluation of LLMs' performance. In this paper, we conduct an empirical study to deeply understand LLMs' code generation performance within settings that reflect the evolution nature of software development. To achieve this, we first construct an evolution-aware repository-level code generation dataset, namely HumanEvo, equipped with an automated execution-based evaluation tool. Second, we manually categorize HumanEvo according to dependency levels to more comprehensively analyze the model's performance in generating functions with different dependency levels. Third, we conduct extensive experiments on HumanEvo with seven representative and diverse LLMs to verify the effectiveness of the proposed benchmark. We obtain several important findings through our experimental study. For example, we find that previous evolution-ignored evaluation methods result in inflated performance of LLMs, with performance overestimations ranging from 10.0% to 61.1% under different context acquisition methods, compared to the evolution-aware evaluation approach. Based on the findings, we give actionable suggestions for more realistic evaluation of LLMs on code generation. We also build a shared evolution-aware code generation toolbox to facilitate future research. The replication package including source code and datasets is anonymously available at https://github.Com/DeepSoftwareAnalytics/HumanEvo.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00228","National Natural Science Foundation of China(grant numbers:62032025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029910","","Analytical models;Codes;Source coding;Large language models;Benchmark testing;Software;Distance measurement;Software development management;Software engineering;Pragmatics","","","","73","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Implementation of energy management of a microgrid using HMAS","M. M. Legha; E. Farjah","Department of Electrical Engineering, Shiraz University, Shiraz, Iran; Department of Electrical Engineering, Shiraz University, Shiraz, Iran",2018 Smart Grid Conference (SGC),"29 Jul 2019","2018","","","1","6","In this paper, we present the implementation of an energy management system that enables users to monitor and manage energy dynamically through scheduling and controlling using a mobile application. The main focus of this paper is to improve profit, economy, and security of Micro Grid by using the agent-based systems instead of conventional methods. Also the flexibility offered by the system allows the agent or user to regulate the amount of power usage, which translates into cost savings with the overall effect of flattening of the demand peaks. The user interface on the mobile device directly communicates with the energy management system via integrated Ethernet Shield server that uses Wi-Fi communication protocol. Also communication between the Ethernet Shield and the controller arduino is based on Wi-Fi communication. Energy management system has been implemented based on multiagent systems (MAS) in JADE software environment with the capability of optimization. The test results show that the system was able to effectively control and regulate the energy in the micro-grid.","2572-6927","978-1-7281-1138-4","10.1109/SGC.2018.8777876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777876","energy management system;arduino;control relays;Wi-Fi;multi-agent systems","Energy management;Microgrids;Servers;Multi-agent systems;Sensors;Ethernet;Software","","1","","34","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Safeguarding LLM-Applications: Specify or Train?","H. Abdelkader; M. Abdelrazek; S. Singh; I. Logothetis; P. Rani; R. Vasa; J. -G. Schneider","*Deakin University, Australia; *Deakin University, Australia; *Deakin University, Australia; *Deakin University, Australia; RMIT University, Australia; *Deakin University, Australia; Monash University, Australia",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","275","276","Large Language Models (LLMs) are powerful tools used in several applications such as conversational AI, and code generation. However, significant robustness concerns arise with LLMs in production, such as hallucinations, prompt injection attacks, harmful content generation, and challenges in maintaining accurate domain-specific content moderation. Guardrails aim to mitigate these challenges by aligning LLM outputs with desired behaviors without modifying the underlying models. Nvidia NeMo Guardrails, for instance, rely on specifying acceptable/unacceptable behaviours. However, it is challenging to predict and address potential issues of LLMs in advance to create these guardrails. Also, manual updates from software engineers are often required to maintain and refine these guardrails. We introduce LLM-Guards, specialised machine learning (ML) models trained to function as protective guards. Additionally, we present an automation pipeline for training and continual fine-tuning of these guards using reinforcement learning from human feedback (RLHF). We evaluated several small LLMs, including Llama-3, Mistral, and Gemma, as LLM-Guards for challenges such as moderation and detecting off-topic queries, and compared their performance against NeMo Guardrails. The proposed Llama-3 LLM-Guard outperformed NeMo Guardrails in detecting offtopic queries, achieving an accuracy of 98.7% compared to 81%. Furthermore, the LLM-Guard detected 97.86% of harmful queries” surpassing NeMo Guardrails by 19.86%.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029997","Robustness;LLMs;Automated Guardrails","Training;Accuracy;Large language models;Pipelines;Reinforcement learning;Production;Manuals;Robustness;Software;Software engineering","","","","10","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"WatchOverGPT: A Framework for Real-Time Crime Detection and Response Using Wearable Camera and Large Language Model","A. R. Shahid; S. M. Hasan; M. W. Kankanamge; M. Z. Hossain; A. Imteaj","Secure and Trustworthy Intelligent Systems (SHIELD) Lab; Secure and Trustworthy Intelligent Systems (SHIELD) Lab; Secure and Trustworthy Intelligent Systems (SHIELD) Lab; School of Computing, Southern Illinois University, Carbondale, IL, USA; School of Computing, Southern Illinois University, Carbondale, IL, USA","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","2189","2194","In the era of Large Language Models (LLMs), the application of advanced AI technologies to data captured by wearables devices, combined with the fusion of contextual data, presents a revolutionary approach to enhancing real-time public safety, individual security, and emergency response. In this paper, we introduce WatchOverGPT, a novel framework that leverages this integration to promptly identify and respond to potential life-threatening criminal activities and safety concerns. WatchOverGPT combines the capabilities of wearable cameras, smartphones' location data, and LLM-based advanced con-versational AI communication through Generative Pre-trained Transformer (GPT). The core of this framework involves a wearable camera connected to the user's smartphone, which continuously captures and analyzes the environment for signs of distress or criminal behaviors, including human actions and the presence of weapons, coupled with location and other information from the smartphone by which GPT-based application provides an autonomous decision-making process. This paper explores the framework's design, implementation, and potential impact of LLM applications on public safety. The proposed framework aims to bridge the gap between safety threats and emergency response teams in the fight against crime through real-time data processing and AI -driven autonomous communication, enhancing the security of individuals in various settings,","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633435","Public Safety;Real-Time Crime Detection;Wearables;Large Language Models (LLMs)","Large language models;Weapons;Cameras;Emergency services;Transformers;Real-time systems;Public security","","","","32","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"Towards Efficient Fine-Tuning of Language Models With Organizational Data for Automated Software Review","M. Nashaat; J. Miller","Department of Electrical Engineering, Port Said University, Port Said, Egypt; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada",IEEE Transactions on Software Engineering,"18 Sep 2024","2024","50","9","2240","2253","Large language models like BERT and GPT possess significant capabilities and potential impacts across various applications. Software engineers often use these models for code-related tasks, including generating, debugging, and summarizing code. Nevertheless, large language models still have several flaws, including model hallucination. (e.g., generating erroneous code and producing outdated and inaccurate programs) and the substantial computational resources and energy required for training and fine-tuning. To tackle these challenges, we propose CodeMentor, a framework for few-shot learning to train large language models with the data available within the organization. We employ the framework to train a language model for code review activities, such as code refinement and review generation. The framework utilizes heuristic rules and weak supervision techniques to leverage available data, such as previous review comments, issue reports, and related code updates. Then, the framework employs the constructed dataset to fine-tune LLMs for code review tasks. Additionally, the framework integrates domain expertise by employing reinforcement learning with human feedback. This allows domain experts to assess the generated code and enhance the model performance. Also, to assess the performance of the proposed model, we evaluate it with four state-of-the-art techniques in various code review tasks. The experimental results attest that CodeMentor enhances the performance in all tasks compared to the state-of-the-art approaches, with an improvement of up to 22.3%, 43.4%, and 24.3% in code quality estimation, review generation, and bug report summarization tasks, respectively.","1939-3520","","10.1109/TSE.2024.3428324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599336","Artificial intelligence;software engineering;large language models;reinforcement learning;software reviews","Codes;Reviews;Task analysis;Data models;Large language models;Computational modeling;Training","","6","","77","IEEE","15 Jul 2024","","","IEEE","IEEE Journals"
"Empirical Evaluation of Similarity Coefficients for Multiagent Fault Localization","L. S. Passos; R. Abreu; R. J. F. Rossetti","Artificial Intelligence and Computer Science Laboratory, University of Porto, Porto, Portugal; Palo Alto Research Center, Palo Alto, CA, USA; Artificial Intelligence and Computer Science Laboratory, University of Porto, Porto, Portugal","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20 May 2017","2017","47","5","767","782","Detecting and diagnosing unwanted behavior in multiagent systems (MASs) are crucial to ascertain correct operation of agents. Current techniques assume a priori knowledge to identify unexpected behavior. However, generation of MAS models is both error-prone and time-consuming, as it exponentially increases with the number of agents and their interactions. In this paper, we describe a light-weight, automatic debugging-based technique, coined extended spectrum-based fault localization for MAS (ESFL-MAS), that shortens the diagnostic process, while only relying on minimal information about the system. ESFL-MAS uses a heuristic that quantifies the suspiciousness of an agent to be faulty. Different heuristics may have a different impact on the diagnostic quality of ESFL-MAS. Our experimental evaluation shows that 10 out of 42 heuristics (namely accuracy, coverage, Jaccard, Laplace, least contradiction, Ochiai, Rogers and Tanimoto, simple-matching, Sorensen-dice, and support) yield the best diagnostic accuracy (96.26% on average) in the context of the MAS used in our experiments.","2168-2232","","10.1109/TSMC.2016.2523905","Fundação para a Ciência e a Tecnologia; Portuguese Agency for Research and Development(grant numbers:SFRH/BD/66717/2009); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Brazilian Agency for Research and Development(grant numbers:BEX 9382-13-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458176","Fault diagnosis;multiagent systems (MASs);reliability;spectrum-based fault localization (SFL)","Java;Context;Software;Multi-agent systems;Fault diagnosis","","2","","48","IEEE","22 Apr 2016","","","IEEE","IEEE Journals"
"Securing Cloud AI Workloads: Protecting Generative AI Models from Adversarial Attacks","A. Patel; P. Pandey; H. Ragothaman; R. Molleti; A. Tanikonda",Broadcom; Tiffany & Co; Athenahealth; Options Clearing Corporation; Independent Researcher,2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC),"29 Jan 2025","2025","","","1","7","Generative artificial intelligence models have brought about advancements in fields like healthcare and finance, as well as in autonomous systems; however, they also encounter notable security vulnerabilities, primarily when operating in cloud environments. These AI models can be targeted by attacks that involve altering input data to deceive the system into generating harmful or incorrect results. This study delves into the security issues that AI systems face in cloud setups, explicitly focusing on the dangers posed by adversarial manipulation of data integrity and the challenges of utilizing shared resources within multi-user environments. The text covers methods for defending AI models, like training and defensive distillation, to make them more robust against attacks. It also delves into security measures for the cloud, such as encrypted communications and robust authentication systems to safeguard data integrity. Furthermore, the importance of AI explainability and transparency in uncovering vulnerabilities and building trust is highlighted. The outcomes of security breaches emphasize the importance of having AI systems to avoid impacts on decision-making and broader ethical and societal concerns. The document also discusses research areas such as quantum algorithms and decentralized security structures to tackle evolving risks and safeguard the future of secure AI applications that generate content.","","979-8-3315-1888-2","10.1109/ICAIC63015.2025.10848877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10848877","AI explainability;adversarial attacks;cloud security;defensive techniques;generative AI","Training;Ethics;Generative AI;Data integrity;Finance;Authentication;Transportation;Medical services;Security;Cryptography","","","","21","IEEE","29 Jan 2025","","","IEEE","IEEE Conferences"
"Generative AI in Action","A. Bahree",Manning Publications,Generative AI in Action,"","2024","","","","","Generative AI can transform your business by streamlining the process of creating text, images, and code. This book will show you how to get in on the action! Generative AI in Action is the comprehensive and concrete guide to generative AI you’ve been searching for. It introduces both AI’s fundamental principles and its practical applications in an enterprise context—from generating text and images for product catalogs and marketing campaigns, to technical reporting, and even writing software. Inside, author Amit Bahree shares his experience leading Generative AI projects at Microsoft for nearly a decade, starting well before the current GPT revolution. Inside Generative AI in Action you will find:  A practical overview of of generative AI applications Architectural patterns, integration guidance, and best practices for generative AI The latest techniques like RAG, prompt engineering, and multi-modality The challenges and risks of generative AI like hallucinations and jailbreaks How to integrate generative AI into your business and IT strategy  Generative AI in Action is full of real-world use cases for generative AI, showing you where and how to start integrating this powerful technology into your products and workflows. You’ll benefit from tried-and-tested implementation advice, as well as application architectures to deploy GenAI in production at enterprise scale.","","9781633436947","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10745289.pdf&bkn=10745288&pdfType=book","prompt engineering;model fine tuning;enterprise;safety;ethics;integration;RAG;multi-modality;LLMs;hallucinations;jailbreaks;architectural patterns;ChatGPT;Bard;Copilot","","","","","","","6 Nov 2024","","","Manning","Manning eBooks"
"A Comparative Study of Bug Triage Representation and Classification Approaches from Canonical to Large Language Models","F. T. Da Silva; F. R. De Araújo; E. C. Bezerra","Sidia R&D Institute, Manaus, Brazil; Sidia R&D Institute, Manaus, Brazil; Sidia R&D Institute, Manaus, Brazil",2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE),"6 Feb 2025","2024","","","86","93","Bug triage is the task of assigning newly reported bugs to the proper developers or team for resolution. This is a critical point in software maintenance as it directly influences the time and correct allocation that impact the efficiency and effectiveness of the software process. In a global aspect, the number of teams/developers is extensive, which brings a challenge for bug triage. Traditional approaches to assign bugs struggle with the complexity of the problem. This paper proposes a comparative assessment for different text representation combined with text classification approaches for automated bug report triage by incorporating Large Language Models (LLMs) into the classification pipeline to surpass the limitations of canonical methods. Traditional classification methods were compared with LLM-enhanced models across accuracy metric. The results demonstrate an improvement in triage accuracy when utilizing the fine-tuned LLM, highlighting their potential to provide developer-appropriate bug assignments.","","979-8-3315-2891-1","10.1109/ICAICE63571.2024.10864116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10864116","bug report triage;LLM;S-BERT","Training;Software maintenance;Accuracy;Large language models;Computer bugs;Text categorization;Pipelines;Market research;Resource management;Software development management","","","","43","IEEE","6 Feb 2025","","","IEEE","IEEE Conferences"
"Design and Implementation of a 5G Security Testbed for AI Solution Validation","M. Yoon; J. Kwon; J. Seo; K. Cho","Future Mobile Communication Research Center, GERI(Gumi Electronics & Information Technology Research Institute), Gumi, Korea; Future Mobile Communication Research Center, GERI(Gumi Electronics & Information Technology Research Institute), Gumi, Korea; Department of The Fourth Industrial Revolution & Transport, Center for Connected & Automated Driving Research, Korea Transport Institute, Sejong, Korea; Software Education Center, School of Computer Secience and Engineering, Kyungpook National University, Daegu, Korea",2024 15th International Conference on Information and Communication Technology Convergence (ICTC),"14 Jan 2025","2024","","","2219","2221","The growing adoption of 5G private networks has significantly enhanced industries such as smart factories, autonomous vehicles, and smart homes, thanks to their high-speed data transmission, low latency, and support for large-scale device connectivity. These networks have driven advancements in real-time monitoring and process automation, boosting productivity and efficiency while reducing costs. However, the deployment of 5G private networks has also introduced various security challenges, particularly with the emergence of AI-driven technologies. This paper discusses these challenges, focusing on the design and implementation of a 5G security testbed to validate AI solutions within such environments. Key security threats associated with 5G private networks include the exploitation of AI and generative AI for sophisticated phishing and spoofing attacks, the hacking of autonomous vehicles and smart homes that can compromise both safety and privacy, and security breaches in AI-based smart factory systems, which could lead to operational disruptions and economic losses. These risks emphasize the need for proactive countermeasures to ensure the integrity and security of 5G private networks. This paper verifies the security of AI-based applications implemented through a testbed using Nokia's 5G network system and provides the necessary configurations for the stable deployment of AI-based service solutions.","2162-1241","979-8-3503-6463-7","10.1109/ICTC62082.2024.10827562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827562","5G Security;AI solution testbed;5G Security testbed architecture","Industries;5G mobile communication;Phishing;Smart homes;Real-time systems;Security;Artificial intelligence;Autonomous vehicles;Smart manufacturing;Testing","","","","8","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Adversarially Enhanced Financial Misinformation: A Comparative Analysis of LLM- vs. GAN-Generated Content Exposing AI Moderation Vulnerabilities","C. Santorelli; V. G. Belmonte; R. Mastropaolo","Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mathematics, Columbia University, New York, NY, USA; Department of Computer Science, Sacred Heart University, Fairfield, CT, USA","2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)","15 Jul 2025","2025","","","250","256","As Large Language Models (LLMs) become more pervasive, their capability to generate convincing financial news poses an escalating threat to investor decision-making and market stability. However, contemporary content moderation and AIbased verification systems exhibit notable vulnerabilities when confronted with the subtle linguistic manipulations introduced by advanced prompt engineering techniques and adversarial training. This study investigated the comparative credibility, influence, and detectability of AI-generated financial headlines produced via Zero-Shot, Few-Shot (8-Shot), and Chain-of-Thought (CoT) prompting, with CoT outputs further used to train a GAN for adversarially enhanced text generation. We compiled a combined dataset of NASDAQ-listed securities and web-scraped, human authored news, generated additional AI-driven headlines under three prompting paradigms, and conducted a survey of randomly sampled headlines ($\mathbf{n} \boldsymbol{=} \mathbf{3 0 0}$) to assess the credibility, market perception impact, investment influence, and AI detectability. The analysis revealed that headlines generated through Chain-of-Thought prompting consistently scored higher in perceived authenticity, influenced investment sentiment more profoundly, and were harder for participants to classify as AI-written. The findings underscore the urgent need for adversarially robust content moderation and verification mechanisms, capable of adapting to the rapidly evolving landscape of AI-generated financial misinformation, particularly when Chain-of-Thought reasoning is leveraged to enhance GAN-generated content.","","979-8-3315-4348-8","10.1109/AIRC64931.2025.11077509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077509","Large Language Models (LLMs);Generative Adversarial Networks (GANs);AI-Generated Misinformation;Adversarial Learning;AI Content Moderation;Natural Language Processing (NLP);Misinformation Detection","Training;Surveys;Terminology;Large language models;Natural language processing;Stability analysis;Prompt engineering;Security;Fake news;Investment","","","","17","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Conscious Machines for Autonomous Agents and Cybersecurity","A. M. Kadin","Princeton Junction, NJ, USA",2021 International Conference on Rebooting Computing (ICRC),"31 Mar 2022","2021","","","99","102","Although consciousness has been difficult to define, most researchers in artificial intelligence would agree that AI systems to date have not exhibited anything resembling consciousness. But is a conscious machine possible in the near future? I suggest that a new definition of consciousness may provide a basis for developing a conscious machine. The key is pattern recognition of correlated events in time, leading to the identification of a unified self-agent. Such a conscious system can create a simplified virtual environment, revise it to reflect updated sensor inputs, and partition the environment into self, other agents, and relevant objects. It can track recent time sequences of events, predict future events based on models and patterns in memory, and attribute causality to events and agents. It can make rapid decisions based on incomplete data, and can dynamically learn new responses based on appropriate measures of success and failure. The central aspect of consciousness is the generation of a dynamic narrative, a real-time model of a self-agent pursuing goals in a virtual reality. A conscious machine of this type may be implemented using an appropriate neural network linked to episodic memories. Near-term applications may include autonomous vehicles and online agents for cybersecurity.","","978-1-6654-2332-8","10.1109/ICRC53822.2021.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743183","artificial intelligence;autonomous systems;cyberspace;pattern recognition;machine learning;computer security;virtual reality;neural networks","Solid modeling;Neural networks;Virtual environments;Predictive models;Real-time systems;Pattern recognition;Computer security","","","","10","IEEE","31 Mar 2022","","","IEEE","IEEE Conferences"
"Federated Services: A Smart Service Ecology with Federated Security for Aligned Data Supply and Scenario-Oriented Demands","X. Jia; J. Li; S. Wang; H. Qi; F. -Y. Wang; R. Qin; M. Zhang; X. Liang","Beijing Big Data Centre, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Faculty of Innovation Engineering, Macau University of Science and Technology, Macao, China; Datatang (Beijing) Technology Company Ltd., Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Beijing Big Data Centre, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",IEEE/CAA Journal of Automatica Sinica,"15 May 2025","2025","12","5","925","936","This paper introduces federated services as a smart service ecology with federated security to align distributed data supply with diversified service demands spanning digital and societal contexts. It presents the comprehensive researches on the theoretical foundation and technical system of federated services, aiming at advancing our understanding and implementation of this novel service paradigm. First, a thorough examination of the characteristics of federated security within federated services is conducted. Then, a five-layer technical framework is formulated under a decentralized intelligent architecture, ensuring secure, agile, and adaptable service provision. On this basis, the operational mechanisms underlying data federation and service confederation is analyzed, with emphasis on the smart supply-demand matching model. Furthermore, a scenario-oriented taxonomy of federated services accompanied by illustrative examples is proposed. Our work offers actionable insights and roadmap for realizing and advancing federated services, contributing to the refinement and wider adoption of this transformative service paradigm in the digital era.","2329-9274","","10.1109/JAS.2024.124860","National Key Research and Development Program of China(grant numbers:2021YFB2104800); National Natural Science Foundation of China(grant numbers:62103411,62436010,72171230); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005734","Decentralized autonomous organizations and operations;decentralized physical infrastructure networks;federated security;federated services;multimodal large language models;smart contracts","Adaptation models;Biological system modeling;Large language models;Taxonomy;Smart contracts;Distributed databases;Ecology;Data models;Security;Research and development","","","","68","","15 May 2025","","","IEEE","IEEE Journals"
"Large Language Models Empowered Autonomous Edge AI for Connected Intelligence","Y. Shen; J. Shao; X. Zhang; Z. Lin; H. Pan; D. Li; J. Zhang; K. B. Letaief","Microsoft Research Asia, China; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Microsoft Research Asia, China; Microsoft Research Asia, China; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong",IEEE Communications Magazine,"9 Oct 2024","2024","62","10","140","146","The evolution of wireless networks gravitates toward connected intelligence, a concept that envisions seamless interconnectivity among humans, objects, and intelligence in a hyper-connected cyber-physical world. Edge artificial intelligence (Edge AI) is a promising solution to achieve connected intelligence by delivering high-quality, low-latency, and privacy-preserving AI services at the network edge. This article presents a vision of autonomous edge AI systems that automatically organize, adapt, and optimize themselves to meet users' diverse requirements, leveraging the power of large language models (LLMs), that is, generative pretrained transformer (GPT). By exploiting the powerful abilities of GPT in language understanding, planning, and code generation, as well as incorporating classic wisdom such as task-oriented communication and edge federated learning, we present a versatile framework that efficiently coordinates edge AI models to cater to users' personal demands while automatically generating code to train new models in a privacy-preserving manner. Experimental results demonstrate the system's remarkable ability to accurately comprehend user demands, efficiently execute AI models with minimal cost, and effectively create high-performance AI models at edge servers.","1558-1896","","10.1109/MCOM.001.2300550","NSFC/RGC Collaborative Research Scheme(grant numbers:CRS_HKUST603/22); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384606","","Artificial intelligence;Codes;Sensors;Adaptation models;Task analysis;Servers;Computational modeling;Large language models","","55","","15","IEEE","8 Jan 2024","","","IEEE","IEEE Magazines"
"A Chat about Boring Problems: Studying GPT-Based Text Normalization","Y. Zhang; T. M. Bartley; M. Graterol-Fuenmayor; V. Lavrukhin; E. Bakhturina; B. Ginsburg","Nvidia Corporation; Graduate Center, City University of New York; Nvidia Corporation; Nvidia Corporation; Nvidia Corporation; Nvidia Corporation","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","10921","10925","Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language modeling. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM-based text normalization to achieve error rates approximately 40% lower than production-level normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we identify strengths and weaknesses of LLM-based TN, opening opportunities for future work.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447169","Text-normalization;GPT;large-language-models;in-context learning;finite state automata;text-to-speech","Degradation;Error analysis;Taxonomy;Signal processing;Cognition;Acoustics;Noise measurement","","1","","23","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"TCR: Data Annotation and Model Training for Datasets in the Telecommunications Field","X. Wang; X. Xia","School of Computer Science and Technology, DongHua University, Shanghai, China; School of Computer Science and Technology, DongHua University, Shanghai, China",2024 Boao New Power System International Forum - Power System and New Energy Technology Innovation Forum (NPSIF),"19 Feb 2025","2024","","","1008","1011","In the telecommunications sector, ensuring the quality of customer service interactions, particularly in sales behavior, is of paramount importance. This study introduces a novel approach for evaluating customer service representatives' compliance with promotional standards, and we present the TCR dataset. By collaborating with telecom industry professionals, we identified critical requirements for quality inspection and utilized GPT-4o with advanced prompt engineering techniques to annotate extensive conversational datasets. These annotated datasets were then validated and refined through manual checks to ensure accuracy and diversity. Inspired by the Chain-of-Thought methodology, we prompted the model to generate explanations, thereby enhancing the reliability of the annotations. Key evaluation metrics included the accuracy of package cost and content introduction, customer inquiry handling, and resolution. The outputs were standardized in JSON format, enabling seamless data processing and model fine-tuning for downstream tasks. The results demonstrate that large language models hold great potential in optimizing data annotation and supporting efficient quality inspection workflows in telecom scenarios, providing a scalable solution for domain-specific applications.","","979-8-3315-0455-7","10.1109/NPSIF64134.2024.10883621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10883621","Telecommunications;Customer Service Quality;Large Language Models;Data Annotation","Training;Technological innovation;Accuracy;Annotations;Customer services;Inspection;Data models;Telecommunications;Reliability;Standards","","","","23","IEEE","19 Feb 2025","","","IEEE","IEEE Conferences"
"A Systematic Review of Generative Artificial Intelligence in Education","J. Zhang; D. Sun","DaLian University of Technology Graduate School of Education, Dalian, China; DaLian University of Technology Graduate School of Education, Dalian, China",2025 7th International Conference on Computer Science and Technologies in Education (CSTE),"29 Jul 2025","2025","","","552","556","The emergence of generative artificial intelligence has had a profound impact on education. This study, based on the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) method, analyzes 281 studies on the application of generative artificial intelligence in education. The results of this study can assist researchers in better understanding: (1) What are the key characteristics of the literature on generative artificial intelligence in education? (2) What is the current state of research on generative artificial intelligence in education? (3) How can generative artificial intelligence empower education to promote high-quality educational development? By examining these questions, we found that generative artificial intelligence in education presents contradictions—diverse demands and limited practice. Therefore, future efforts should focus on constructing region-specific large language models, educational corpora, and prompt engineering, thus further promoting the high-quality development of education.","","979-8-3315-1166-1","10.1109/CSTE64638.2025.11092288","Ministry of Education; Ministry of Education; Dalian University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092288","Generative artificial intelligence;Large language models;AI education;Literature review","Computer science;Generative AI;Large language models;Education;Benchmark testing;Prompt engineering;Systematic literature review","","","","22","IEEE","29 Jul 2025","","","IEEE","IEEE Conferences"
"LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations","Z. Ye; T. H. M. Le; M. A. Babar","CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","629","641","Security misconfigurations in Container Orchestrators (COs) can pose serious threats to software systems. While Static Analysis Tools (SATs) can effectively detect these security vulnerabilities, the industry currently lacks automated solutions capable of fixing these misconfigurations. The emergence of Large Language Models (LLMs), with their proven capabilities in code understanding and generation, presents an opportunity to address this limitation. This study introduces LLMSecConfig, an innovative framework that bridges this gap by combining SATs with LLMs. Our approach leverages advanced prompting techniques and Retrieval-Augmented Generation (RAG) to automatically repair security misconfigurations while preserving operational functionality. Evaluation of 1,000 real-world Kubernetes configurations achieved a 94% success rate while maintaining a low rate of introducing new misconfigurations.Our work makes a promising step towards automated container security management, reducing the manual effort required for configuration maintenance.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025712","Container;Container Orchestrator;Configuration;Security;Large Language Models;Prompt Template;Retrieval-Augmented Generation","Industries;Large language models;Security management;Retrieval augmented generation;Static analysis;Manuals;Containers;Maintenance engineering;Software systems;Maintenance","","","","59","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Enhancing Text-to-SQL Translation for Financial System Design","Y. Song; S. Ezzini; X. Tang; C. Lothritz; J. Klein; T. Bissyandé; A. Boytsov; U. Ble; A. Goujon","University of Luxembourg, Luxembourg; Lancaster University, United Kingdom; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; Banque BGL BNP Paribas, Luxembourg; Banque BGL BNP Paribas, Luxembourg; Banque BGL BNP Paribas, Luxembourg",2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"18 Jun 2024","2024","","","252","262","Text-to-SQL, the task of translating natural language questions into SQL queries, is part of various business processes. Its automation, which is an emerging challenge, will empower software practitioners to seamlessly interact with relational databases using natural language, thereby bridging the gap between business needs and software capabilities. In this paper, we consider Large Language Models (LLMs), which have achieved state of the art for various NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation methodologies, as well as input optimization (e.g., prompting). In light of the empirical observations that we have made, we propose two novel metrics that were designed to adequately measure the similarity between SQL queries. Overall, we share with the community various findings, notably on how to select the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based edit distance constitutes a reliable metric for assessing the similarity between generated SQL queries and the oracle for benchmarking Text2SQL approaches. This metric is important as it relieves researchers from the need to perform computationally expensive experiments such as executing generated queries as done in prior works. Our work implements financial domain use cases and, therefore contributes to the advancement of Text2SQL systems and their practical adoption in this domain.","2832-7659","979-8-4007-0501-4","10.1145/3639477.3639732","Luxembourg's National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554719","Text-to-SQL;Large Language Models;Evaluation Metrics;Natural Language Processing","Measurement;Structured Query Language;Natural languages;Training data;Standardization;Benchmark testing;Software","","3","","34","CCBY","18 Jun 2024","","","IEEE","IEEE Conferences"
"Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers","Y. Shi; H. Zhang; C. Wan; X. Gu",Shanghai Jiao Tong University; Chongqing University; East China Normal University; Shanghai Jiao Tong University,2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1628","1639","Large language models have catalyzed an unprece-dented wave in code generation. While achieving significant advances, they blur the distinctions between machine- and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPthave proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine- and human-authored code. Through a rigorous analysis of code attributes such as lexical diversity, conciseness, and naturalness, we expose unique patterns inherent to each source. We particularly notice that the syntactic segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose DetectCodeGPT, a novel method for detecting machine-generated code, which improves DetectGPT by capturing the distinct stylized patterns of code. Diverging from conventional techniques that depend on external LLMs for perturbations, DetectCodeGPT perturbs the code corpus by strategically inserting spaces and newlines, ensuring both efficacy and efficiency. Experiment results show that our approach significantly outperforms state-of-the-art techniques in detecting machine-generated code. 1.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029948","machine-generated code detection;large language models;code generation;empirical analysis","Codes;Perturbation methods;Large language models;Source coding;Syntactics;Programming;Software;Software engineering","","2","","65","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Leveraging LLMs and Knowledge Graphs to Design Secure Automation Systems","A. M. Hosseini; W. Kastner; T. Sauter","Institute of Computer Engineering, TU Wien, Vienna, Austria; Institute of Computer Technology, TU Wien, Vienna, Austria; Institute of Computer Engineering, TU Wien, Vienna, Austria",IEEE Open Journal of the Industrial Electronics Society,"17 Mar 2025","2025","6","","380","395","The digital transformation of Industrial Control Systems (ICSs) within the Industry 4.0 paradigm is essential for industrial organizations to remain competitive, while cybersecurity is an enabler. However, security measures, often implemented late in the engineering process, lead to costly and complicated implementations. Thus, this article is concerned with the “security by design” principle in ICSs and facilitates compliance with ICS security standards, which can be legally mandated for some critical systems or adopted by asset owners to protect their assets. Current methods for compliance demand manual efforts from security experts, making the compliance process time-consuming and costly. To address this, we propose a framework for leveraging large language models (LLMs) combined with knowledge graphs to automate the interpretation of security requirements and system architecture as two main elements of the design phase. Our knowledge graph-augmented LLM framework converts system architectures into human natural language, enhancing the automation of various security analyses, especially those that need to handle textual requirements. The framework enables validating applicable security requirements provided by IEC 62443-3-3 (a widely-used ICS security standard) concerning system designs through a question-and-answer interface. To evaluate the framework, various questions with reference responses from human experts were prepared in the context of a use case, and the quality of the LLMs' responses was measured across various metrics. Moreover, we compared the framework with a baseline approach based on formal queries. The results show that the proposed framework effectively automates security tasks and offers a user-friendly interface accessible to nonexperts.","2644-1284","","10.1109/OJIES.2025.3545811","TÜV AUSTRIA \#SafeSecLab Research Lab; TU Wien and TÜV AUSTRIA; Technische Universität Wien Bibliothek; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904297","Industrial control system (ICS);security by design;knowledge graph;large language model (LLM);ontology","Security;Ontologies;Knowledge graphs;Computer security;IEC Standards;Systems architecture;Cyberattack;Cognition;Natural languages;Large language models","","","","56","CCBYNCND","26 Feb 2025","","","IEEE","IEEE Journals"
"Enforcing Web Security Constraints for LLM-driven Robot Agents for Online Transactions","S. P. Shah; A. V. Deshpande","School of Computer and Information Sciences, University of the Cumberlands, Kentucky, USA; School of Computer and Information Sciences, University of the Cumberlands, Kentucky, USA","2024 International Conference on Distributed Systems, Computer Networks and Cybersecurity (ICDSCNC)","1 Apr 2025","2024","","","1","6","The integration of Large Language Models (LLMs) into autonomous robotic agents for conducting online transactions poses significant cybersecurity challenges. This study aims to enforce robust cybersecurity constraints to mitigate the risks associated with data breaches, transaction fraud, and system manipulation. The background focuses on the rise of LLM-driven robotic systems in e-commerce, finance, and service industries, alongside the vulnerabilities they introduce. A novel security architecture combining blockchain technology with multi-factor authentication (MFA) and real-time anomaly detection was implemented to safeguard transactions. Key performance metrics such as transaction integrity, response time, and breach detection accuracy were evaluated, showing improved security and system performance. The results highlight that the proposed architecture reduced fraudulent transactions by 90%, improved breach detection accuracy to 98%, and ensured secure transaction validation within a latency of 0.05 seconds. These findings emphasize the importance of cybersecurity in the deployment of LLM-driven robotic systems and suggest a framework adaptable to various online platforms.","","979-8-3503-7544-2","10.1109/ICDSCNC62492.2024.10939862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10939862","Large Language Models;cybersecurity challenges;multi-factor authentication (MFA);real-time anomaly detection","Industries;Multi-factor authentication;Accuracy;Service robots;System performance;Large language models;Real-time systems;Blockchains;Fraud;Anomaly detection","","","","26","IEEE","1 Apr 2025","","","IEEE","IEEE Conferences"
"Distributed Formation Control via Mixed Barycentric Coordinate and Distance-Based Approach","K. Fathian; D. I. Rachinskii; M. W. Spong; T. H. Summers; N. R. Gans","Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mathematical Sciences, University of Texas at Dallas, Richardson, TX, USA; Department of Systems Engineering, University of Texas at Dallas, Richardson, TX, USA; Department of Mechanical Engineering, University of Texas at Dallas, Richardson, TX, USA; UT Arlington Research Institute, University of Texas at Arlington, Arlington, TX, USA",2019 American Control Conference (ACC),"29 Aug 2019","2019","","","51","58","We present a distributed control strategy for a team of agents to autonomously achieve a desired planar formation. Our control strategy is based on combining the barycentric coordinate-based (BCB) and the distance-based (DB) approach. In the BCB approach, the almost global convergence of the agents to the desired formation shape is guaranteed, however, the formation scale cannot be controlled. In the DB method, the scale of the achieved formation is controlled, however, the convergence is local and in general stable undesired equilibria exist. By combining these methods via imposing a timescale separation between their respective dynamics, our proposed control strategy retains the advantages of each approach and avoids their shortcomings. We analyze the stability properties of the proposed control and prove that the desired formation is an almost globally stable equilibrium. We provide simulations to typify the theoretical results and compare our method with a leader-follower BCB (LF-BCB) approach that can be used to control the formation scale in the BCB strategy. In particular, we demonstrate that unlike the LF-BCB approach, our method is far more robust to measurement inaccuracies.","2378-5861","978-1-5386-7926-5","10.23919/ACC.2019.8814890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8814890","Multi-agent systems;distributed formation control;agent-based systems","","","12","","35","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Robust Distributed Formation Control of Agents With Higher-Order Dynamics","K. Fathian; T. H. Summers; N. R. Gans","Department of Electrical Engineering, University of Texas at Dallas, Richardson, TX, USA; Department of Mechanical Engineering, University of Texas at Dallas, Richardson, TX, USA; Department of Electrical Engineering, University of Texas at Dallas, Richardson, TX, USA",IEEE Control Systems Letters,"13 Jun 2018","2018","2","3","495","500","We present a distributed control strategy for agents with a variety of holonomic dynamics to autonomously achieve a desired formation. The proposed control is fully distributed, and can be implemented locally on agents using the relative position measurements. Furthermore, agents do not need to communicate or have a common sense of orientation. Our strategy allows control gains designed for agents with single-integrator dynamics to be used directly for agents with higher-order linear (or linearizable) holonomic dynamics. We provide rigorous mathematical analysis to prove convergence of the agents to the desired formation. The proposed method is applied to quadrotors with linearized dynamics, and simulations are provided to typify the theoretical results.","2475-1456","","10.1109/LCSYS.2018.2841941","OSD Sponsored Autonomy Research Pilot Initiative; RW Autonomy Initiative; Air Force Research Laboratory(grant numbers:FA8651-17-1-0001); Army Research Office(grant numbers:W911NF-17-1-0058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368300","Multi-agent systems;formation control;distributed control;agent-based systems","Robustness;Vehicle dynamics;Sensors;Eigenvalues and eigenfunctions;Topology;Convergence;Dynamics","","12","","19","IEEE","29 May 2018","","","IEEE","IEEE Journals"
"Leveraging Large Language Model for Automatic Patch Correctness Assessment","X. Zhou; B. Xu; K. Kim; D. Han; H. H. Nguyen; T. Le-Cong; J. He; B. Le; D. Lo","School of Computing and Information Systems, Singapore Management University, Singapore; Department of Computer Science College of Engineering, North Carolina State University, Raleigh, NC, USA; School of Computing and Information Systems, Singapore Management University, Singapore; Department of Computer Science, Royal Holloway, University of London, Egham, U.K.; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, The University of Melbourne, Melbourne, VIC, Australia; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, The University of Melbourne, Melbourne, VIC, Australia; School of Computing and Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,"13 Nov 2024","2024","50","11","2865","2883","Automated Program Repair (APR) techniques have shown more and more promising results in fixing real-world bugs. Despite the effectiveness, APR techniques still face an overfitting problem: a generated patch can be incorrect although it passes all tests. It is time-consuming to manually evaluate the correctness of generated patches that can pass all available test cases. To address this problem, many approaches have been proposed to automatically assess the correctness of patches generated by APR techniques. These approaches are mainly evaluated within the cross-validation setting. However, for patches generated by a new or unseen APR tool, users are implicitly required to manually label a significant portion of these patches (e.g., 90% in 10-fold cross-validation) in the cross-validation setting before inferring the remaining patches (e.g., 10% in 10-fold cross-validation). To mitigate the issue, in this study, we propose LLM4PatchCorrect, the patch correctness assessment by adopting a large language model for code. Specifically, for patches generated by a new or unseen APR tool, LLM4PatchCorrect does not need labeled patches of this new or unseen APR tool for training but directly queries the large language model for code to get predictions on the correctness labels without training. In this way, LLM4PatchCorrect can reduce the manual labeling effort when building a model to automatically assess the correctness of generated patches of new APR tools. To provide knowledge regarding the automatic patch correctness assessment (APCA) task to the large language model for code, LLM4PatchCorrect leverages bug descriptions, execution traces, failing test cases, test coverage, and labeled patches generated by existing APR tools, before deciding the correctness of the unlabeled patches of a new or unseen APR tool. Additionally, LLM4PatchCorrect prioritizes labeled patches from existing APR tools that exhibit semantic similarity to those generated by new APR tools, enhancing the accuracy achieved by LLM4PatchCorrect for patches from new APR tools. Our experimental results showed that LLM4PatchCorrect can achieve an accuracy of 84.4% and an F1-score of 86.5% on average although no labeled patch of the new or unseen APR tool is available. In addition, our proposed technique significantly outperformed the prior state-of-the-art.","1939-3520","","10.1109/TSE.2024.3452252","National Research Foundation, under its Investigatorship(grant numbers:NRF-NRFI08-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659742","Automatic patch correctness assessment;large language models of code;in-context learning","Computer bugs;Codes;Task analysis;Large language models;Feature extraction;Training;Manuals","","1","","79","IEEE","30 Aug 2024","","","IEEE","IEEE Journals"
"Dynamic Event-Triggered Formation Control of Multi-Agent Systems With Non-Uniform Time-Varying Communication Delays","M. Abbasi; H. J. Marquez","Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada",IEEE Transactions on Automation Science and Engineering,"28 Mar 2025","2025","22","","8988","9000","In this study, we address the challenge of time-varying formation control in multi-agent systems (MASs) in the presence of time-varying intra- and inter-agent communication delays. To tackle time-varying delays, we equip each agent with a bank of distributed observers to estimate its own and its neighbors’ states. We apply dynamic periodic event-triggered mechanisms to both sensor-to-observer (S-O) and controller-to-actuator (C-A) channels, aiming to reduce unnecessary data transmissions in the network by relying on locally triggered sampled data in a distributed fashion to enhance resource efficiency. In the design stage, we transform the state formation control problem into an asymptotic stability problem. Using the Lyapunov-Krasovskii functional (LKF) approach, we design the event-triggering parameters such that the closed-loop system of all agents is stable and agents reach the desired formation. Numerical simulations demonstrate that our approach achieves a balance by reducing inter-agent communication frequency while maintaining the desired formation. Finally, we illustrate the effectiveness and advantages of this approach through experiments on a real-world robotic system. Note to Practitioners—In practical applications of multi-agent systems, the use of a communication network introduces some challenging issues. To name a few, periodic sampling with a high frequency relies on heavy transmission of information between components, which may result in network congestion. Factors such as limited bandwidth, signal attenuation, and packet losses contribute to delays in networked MAS. Additionally, network security, protocols, buffering, processing, and transmission times play significant roles. Since network-induced delays depend heavily on variable network conditions, they are generally non-uniform and time-varying. This paper proposes a solution for formation control in MASs, considering communication delays, and holds practical implications across various industries. It can enhance coordination for tasks such as warehouse logistics and collaborative manufacturing in autonomous robotics. Drone swarms can benefit from more efficient and reliable movement coordination, impacting surveillance and precision agriculture. In industrial automation, synchronization among machines or robotic arms can be improved for increased efficiency. A noteworthy aspect of this paper is the validation of our results through experiments on a real-world multi-robot system, demonstrating broad applicability.","1558-3783","","10.1109/TASE.2024.3494658","Natural Sciences and Engineering Research Council of Canada (NSERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10750466","Formation control;dynamic event-triggered control;multi-agent system;non-uniform communication delay;observer-based control","Delays;Formation control;Event detection;Vectors;Robots;Robot kinematics;Multi-agent systems;Time-varying systems;Eigenvalues and eigenfunctions;Trajectory","","11","","54","IEEE","12 Nov 2024","","","IEEE","IEEE Journals"
"Secure Event-Based Consensus Control for Multi-Agent Systems Under DoS Attacks and Input Saturation","Y. Zhang; Z. -G. Wu; K. -W. Kwok; T. Huang; P. Chakrabarti; L. Zhou","State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Ma Liu Shui, Hong Kong; Science Program, Texas A& M University at Qatar, Doha, Qatar; Techno India NJR Institute of Technology, Udaipur, India; School of Automation and Electrical Engineering, Zhejiang University of Science and Technology, Hangzhou, Zhejiang, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","17 Jun 2025","2025","55","7","4816","4827","The secure consensus problem is addressed for multiagent systems (MASs) suffering from saturated control input and denial-of-service (DoS) attacks. The communication networks’ open setting and sharing nature give rise to security issues and impact the performance of MASs. Malicious DoS attacks attempt to disrupt the information exchange and undermine consensus by compromising the availability of transmitted data. Moreover, the control input can be saturated as a result of physical device limitations or safety concerns. To tackle these challenges, a state-prediction-based dynamic event-triggered mechanism (DETM) control protocol is designed to guarantee the secure consensus of MASs while reducing redundant communication, avoiding continuous monitoring of adjacent states, and ensuring effective utilization of limited bandwidth resources. Zeno behavior is eliminated by confirming the existence of a positive lower bound on interevent intervals. Sufficient conditions are established for the co-design of the DETM and controller to accomplish the desired goal. Finally, a simulation is conducted to substantiate the effectiveness and validity of the proposed control protocol.","2168-2232","","10.1109/TSMC.2025.3558286","National Natural Science Foundation of China(grant numbers:62233015,62173306); Research Grants Council (RGC) of Hong Kong(grant numbers:17210023,C4026-21G,STG1/E-401/23-N); Centre for Garment Production Limited and Multi-scale Medical Robotics Center Limited, both funded by Innovation and Technology Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974713","Consensus;denial-of-service (DoS) attacks;dynamic event-triggered mechanism (DETM);multiagent system (MAS);saturated control input","Denial-of-service attack;Protocols;Event detection;Vectors;Monitoring;Communication networks;Topology;Multi-agent systems;Consensus control;Data communication","","1","","37","IEEE","23 Apr 2025","","","IEEE","IEEE Journals"
"Advanced Security Solutions for Conversational AI","R. Sikarwar; H. K. Shakya; A. Kumar; A. Rawat","Department of Computer Science Engineering, Amity University Gwalior, Gwalior, India; Department of Computer Science Engineering, Amity University Gwalior, Gwalior, India; School of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India; Apostelle Overseas Education (AOE), Ujjain, India",Conversational Artificial Intelligence,"","2024","","","287","301","Summary <p>Conversational AI refers to technologies using machine learning and natural language processing to help simulate human interactions using chatbots or virtual agents which can understand and respond to the input text and speech. Conversational AI services have been used across various platforms nowadays to provide customer support for a better user experience. However, security issues are also an important concern for chatbots which hold the sensitive information of customers. Artificial intelligence is involved in the banking sector for the prevention of fraud and negative activities associated with financial transactions. Fraudulent activities can be either internal or external. Internal fraud may be committed by employees of the banks themselves through malevolent activities. Financial attacks on banks may take place externally also for money laundering or payments, etc. Fraud detection systems are used to identify, control, and block suspicious activities in the system. Anomaly detection is one of the crucial features of artificial intelligence used for the prevention of fraud and cyber‐attacks.</p>","","9781394200795","10.1002/9781394200801.ch18","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10955364.pdf&bkn=10950236&pdfType=chapter","","Chatbots;Security;Conversational artificial intelligence;Testing;Oral communication;Machine learning;Authentication;Encryption;Social networking (online);Fraud","","1","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Security for a Multi-Agent Cyber-Physical Conveyor System using Machine Learning","G. Funchal; T. Pedrosa; M. Vallim; P. Leitao","Federal University of Technology – Parana (UTFPR); Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politècnico de Bragança, Campus de Santa Apolónia, Bragança, Portugal; Federal University of Technology – Parana (UTFPR); Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politècnico de Bragança, Campus de Santa Apolónia, Bragança, Portugal",2020 IEEE 18th International Conference on Industrial Informatics (INDIN),"27 Jul 2021","2020","1","","47","52","One main foundation of Industry 4.0 is the connectivity of devices and systems using Internet of Things (IoT) technologies, where Cyber-physical systems (CPS) act as the backbone infrastructure based on distributed and decentralized structures. This approach provides significant benefits, namely improved performance, responsiveness and reconfigurability, but also brings some problems in terms of security, as the devices and systems become vulnerable to cyberattacks. This paper describes the implementation of several mechanisms to increase the security in a self-organized cyber-physical conveyor system, based on multi-agent systems (MAS) and build up with different individual modular and intelligent conveyor modules. For this purpose, the JADE-S add-on is used to enforce more security controls, also an Intrusion Detection System (IDS) is created supported by Machine Learning (ML) techniques that analyses the communication between agents, enabling to monitor and analyse the events that occur in the system, extracting signs of intrusions, together they contribute to mitigate cyberattacks.","2378-363X","978-1-7281-4964-6","10.1109/INDIN45582.2020.9478915","European Regional Development Fund (ERDF)(grant numbers:0677_DISRUPTIVE_2_E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478915","Multi-agent systems;Cyber-physical systems;Cybersecurity;Machine Learning;Intrusion Detection Systems","Performance evaluation;Intrusion detection;Machine learning;Cyber-physical systems;Security;Internet of Things;Computer crime","","6","","21","IEEE","27 Jul 2021","","","IEEE","IEEE Conferences"
"LLM-Based Class Diagram Derivation from User Stories with Chain-of-Thought Promptings","Y. Li; J. Keung; X. Ma; C. Y. Chong; J. Zhang; Y. Liao","Department of Computer Science, City University of Hong Kong, Hong Kong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; School of Information Technology, Monash University Malaysia, Malaysia; Department of Computer Science, City University of Hong Kong, Hong Kong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","45","50","In agile requirements engineering, user stories are the primary means of capturing project requirements. However, deriving conceptual models, such as class diagrams, from user stories requires significant manual effort. This paper explores the potential of leveraging Large Language Models (LLMs) and a tailored Chain-of- Thought (CoT) prompting technique to automate this task. We conducted a comprehensive preliminary study to investigate different prompting techniques applied to the task. The study involved comparing LLM-based approaches with guided and unguided human extraction to evaluate the effectiveness of the proposed LLM-based techniques. Our findings demonstrate that LLM-based approaches, particularly when combined with well-crafted few-shot prompts, outperform guided human extraction in identifying classes. However, we also identified areas of suboptimal performance through qualitative analysis. The proposed CoT prompting technique offers a promising pathway to automate the derivation of class diagrams in agile projects, reducing the reliance on manual effort. Our study contributes valuable insights and directions for future research in this field.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633327","Requirements engineering;user story;large language models;chain of thought prompting","Accuracy;Large language models;Computational modeling;Manuals;Software;Requirements engineering;Task analysis","","3","","20","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code","C. Improta","University of Naples Federico II, Naples, Italy",2023 IEEE 34th International Symposium on Software Reliability Engineering Workshops (ISSREW),"2 Nov 2023","2023","","","128","131","AI-based code generators have gained a fundamental role in assisting developers in writing software starting from natural language (NL). However, since these large language models are trained on massive volumes of data collected from unreliable online sources (e.g., GitHub, Hugging Face), AI models become an easy target for data poisoning attacks, in which an attacker corrupts the training data by injecting a small amount of poison into it, i.e., astutely crafted malicious samples. In this position paper, we address the security of AI code generators by identifying a novel data poisoning attack that results in the generation of vulnerable code. Next, we devise an extensive evaluation of how these attacks impact state-of-the-art models for code generation. Lastly, we discuss potential solutions to overcome this threat.","","979-8-3503-1956-9","10.1109/ISSREW60843.2023.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10301284","AI-based Code Generators;Offensive Security;Data Poisoning","Codes;Toxicology;Training data;Writing;Generators;Data models;Software reliability","","5","","18","IEEE","2 Nov 2023","","","IEEE","IEEE Conferences"
"LLM-Driven, Self-Improving Framework for Security Test Automation: Leveraging Karate DSL for Augmented API Resilience","E. Marian Pasca; D. Delinschi; R. Erdei; O. Matei","Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania; Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania; Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania; Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania",IEEE Access,"4 Apr 2025","2025","13","","56861","56886","Modern software architectures heavily rely on APIs, yet face significant security challenges, particularly with Broken Object Level Authorization (BOLA) vulnerabilities, which remain the most critical API security risk according to OWASP. This paper introduces Karate-BOLA-Guard, an innovative framework leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to automate security-focused test case generation for APIs. Our approach integrates vector databases for context retrieval, multiple LLM models for test generation, and observability tools for process monitoring. Initial experiments were carried out on three deliberately vulnerable APIs (VAmPI, Crapi, and OWASP Juice Shop), with subsequent validation on fifteen additional production APIs spanning diverse domains including social media, version control systems, financial services, and transportation services. Our evaluation metrics show Llama 3 8B achieving consistent performance (Accuracy: 3.1-3.4, Interoperability: 3.7-4.3) with an average processing time of 143.76 seconds on GPU. Performance analysis revealed significant GPU acceleration benefits, with 20-25x improvement over CPU processing times. Smaller models demonstrated efficient processing, with Phi-3 Mini averaging 69.58 seconds and Mistral 72.14 seconds, while maintaining acceptable accuracy scores. Token utilization patterns showed Llama 3 8B using an average of 36,591 tokens per session, compared to Mistral’s 25,225 and Phi-3 Mini’s 31,007. Our framework’s effectiveness varied across APIs, with notably strong performance in complex platforms (Instagram: A = 4.3, I = 4.4) while maintaining consistent functionality in simpler implementations (VAmPI: A = 3.6, I = 4.3). The iterative refinement process, evaluated through comprehensive metrics including Accuracy (A), Complexity (C), and Interoperability (I), represents a significant advancement in automated API security testing, offering an efficient, accurate, and adaptable approach to detecting BOLA vulnerabilities across diverse API architectures.","2169-3536","","10.1109/ACCESS.2025.3554960","Romanian National Authority for Scientific Research and Innovation, CCCDI-UEFISCDI, within PNCDI IV(grant numbers:ERANET-CHISTERA-IV-TROCI 4/2024); project “Collaborative Framework for Smart Agriculture (COSA)”through Romania’s National Recovery and Resilience Plan PNRR-III-C9-2022-I8(grant numbers:760070); CLOUDUT Project; European Fund of Regional Development through the Competitiveness Operational Programme 2014–2020(grant numbers:235/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10942340","API security;automation testing tools;cybersecurity;restful API;software testing","Security;Testing;Retrieval augmented generation;Test pattern generators;Application programming interfaces;Accuracy;Software testing;Automation;Systematics;Computer architecture","","1","","27","CCBY","26 Mar 2025","","","IEEE","IEEE Journals"
"Artificial Intelligence Techniques-Driven Automated Localization of Software Faults","P. R. S; K. Venkatraman","Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India",2025 7th International Conference on Intelligent Sustainable Systems (ICISS),"16 Jul 2025","2025","","","1284","1287","Effective program debugging and software maintenance depend on automated software fault localization (ASSL). Manual analysis underlie traditional fault localization techniques, which are labor-intensive and prone to mistakes. Recent developments in artificial intelligence (AI) have brought interesting solutions that boost defect location and automation enhancement. A thorough investigation of AI-driven methods for Software Fault Localization (SFL) is given in this paper. It looks at Deep Learning (DL), Large Language Models (LLMs), Machine Learning (ML) techniques, and current area developments. Furthermore covered in the study are the limits of traditional methods, the benefits of AI-based approaches, and main difficulties and future directions in AI-driven fault localization.","","979-8-3315-2243-8","10.1109/ICISS63372.2025.11076249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076249","Fault localization;software;automated;Artifi-cial Intelligence;techniques","Location awareness;Deep learning;Software maintenance;Automation;Large language models;Manuals;Debugging","","","","24","IEEE","16 Jul 2025","","","IEEE","IEEE Conferences"
"Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs","B. Jin; Q. Sun; L. Chen","Guanghua School of Mangement, Peking University, Beijing, China; Guanghua School of Mangement, Peking University, Beijing, China; Guanghua School of Mangement, Peking University, Beijing, China",2025 International Conference on Information Networking (ICOIN),"14 May 2025","2025","","","487","492","In the current global economy, supply chain transparency plays a pivotal role in ensuring this security by enabling companies to monitor supplier performance and fostering accountability and responsibility. Despite the advancements in supply chain relationship datasets like Bloomberg and FactSet, supply chain transparency remains a significant challenge in emerging economies due to issues such as information asymmetry and institutional gaps in regulation.This study proposes a novel approach to enhance supply chain transparency in emerging economies by leveraging online content and large language models (LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates advanced LLMs with web crawler technology to automatically collect and analyze supply chain information. The system’s effectiveness is validated through a case study focusing on the semiconductor supply chain, a domain that has recently gained significant attention due to supply chain risks.Our results demonstrate that the proposed system provides greater applicability for emerging economies, such as mainland China, complementing the data gaps in existing datasets. However, challenges including the accurate estimation of monetary and material flows, the handling of time series data, synonyms disambiguation, and mitigating biases from online contents still remains. Future research should focus on addressing these issues to further enhance the system’s capabilities and broaden its application to other emerging economies and industries.","2996-1580","979-8-3315-0694-0","10.1109/ICOIN63865.2025.10993099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993099","LLMs;supply chain;network data;knowledge graph;information extraction","Large language models;Supply chains;Time series analysis;Knowledge graphs;Information retrieval;Robustness;Regulation;Security;Data mining;Resilience","","","","28","IEEE","14 May 2025","","","IEEE","IEEE Conferences"
"Generative AI for Secure Physical Layer Communications: A Survey","C. Zhao; H. Du; D. Niyato; J. Kang; Z. Xiong; D. I. Kim; X. Shen; K. B. Letaief","College of Computing and Data Science, Nanyang Technological University, Nanyang, Singapore; Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong, China; College of Computing and Data Science, Nanyang Technological University, Nanyang, Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; Singapore University of Technology and Design, 8 Somapah Rd, Singapore; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",IEEE Transactions on Cognitive Communications and Networking,"6 Feb 2025","2025","11","1","3","26","Generative Artificial Intelligence (GAI) stands at the forefront of AI innovation, demonstrating rapid advancement and unparalleled proficiency in generating diverse content. Beyond content creation, GAI has significant analytical abilities to learn complex data distribution, offering numerous opportunities to resolve security issues. In the realm of security from physical layer perspectives, traditional AI approaches frequently struggle, primarily due to their limited capacity to dynamically adjust to the evolving physical attributes of transmission channels and the complexity of contemporary cyber threats. This adaptability and analytical depth are precisely where GAI excels. Therefore, in this paper, we offer an extensive survey on the various applications of GAI in enhancing security within the physical layer of communication networks. We first emphasize the importance of advanced GAI models in this area, including Generative Adversarial Networks (GANs), Autoencoders (AEs), Variational Autoencoders (VAEs), and Diffusion Models (DMs). We delve into the roles of GAI in addressing challenges of physical layer security, focusing on communication confidentiality, authentication, availability, resilience, and integrity. Furthermore, we also present future research directions focusing model improvements, multi-scenario deployment, resource-efficient optimization, and secure semantic communication, highlighting the multifaceted potential of GAI to address emerging challenges in secure physical layer communications and sensing.","2332-7731","","10.1109/TCCN.2024.3438379","National Research Foundation, Singapore, and Infocomm Media Development Authority under its Future Communications Research & Development Programme, Defence Science Organisation (DSO) National Laboratories under the AI Singapore Programme (AISG Award No: AISG2-RP-2020-019 and FCP-ASTAR-TG-2022-003), Singapore Ministry of Education (MOE) Tier 1 (RG87/22), and the NTU Centre for Computational Technologies in Finance (NTU-CCTF); National Natural Science Foundation of China (NSFC)(grant numbers:62102099,U22A2054); Ministry of Education, Singapore, under its SMU-SUTD Joint(grant numbers:22-SIS-SMU-048); SUTD Kickstarter Initiative(grant numbers:SKI 20210204); National Research Foundation of Korea (NRF) Grant funded by the Korean Government (MSIT)(grant numbers:2021R1A2C2007638); MSIT under the ICT Creative Consilience program(grant numbers:IITP-2020-0-01821); IITP (Institute for ICT Planning & Evaluation); Hong Kong Research Grants Council under the Areas of Excellence scheme(grant numbers:AoE/E-601/22-R); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623395","Generative AI;physical layer communications;physical layer security;wireless sensor network;anomaly detection","Security;Artificial intelligence;Physical layer security;Surveys;Authentication;Communication networks;Resilience","","19","","171","IEEE","5 Aug 2024","","","IEEE","IEEE Journals"
"Prompt Fix: Vulnerability Automatic Repair Technology Based on Prompt Engineering","P. Liu; H. Wang; C. Zheng; Y. Zhang","Guangzhou Institute of Technology, Xidian University; Guangzhou Institute of Technology, Xidian University; Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Nanjing; University of Chinese Academy of Sciences, Xidian University, Hainan University","2024 International Conference on Computing, Networking and Communications (ICNC)","21 Jun 2024","2024","","","116","120","With the emergence of large-scale language models (LLM), the powerful capabilities of LLM in natural language processing have attracted attention. Based on programming language LLM (Programming Language Model, PLM), we use prompt templates to explore its potential in the field of automatic vulnerability repair, and combine it with a special workflow to improve its efficiency in automatic vulnerability repair tasks. Specifically, we design four prompt templates for handling vulner-able code, and design an iterative reasoning method to improve the efficiency of vulnerability fixing. We selected multiple typical LLMs for evaluation on multiple data sets. The results show that reasonable prompt templates can effectively improve the efficiency of automatic vulnerability repair, which is significantly improved compared with neural machine translation technology. In addition, we also discussed previous bug fixing related work and our work, and pointed out some of our shortcomings and directions for future improvements.","2473-7585","979-8-3503-7099-7","10.1109/ICNC59896.2024.10556123","National Key Research and Development Program(grant numbers:2023YFB3106400,2023QY1202); National Natural Science Foundation of China(grant numbers:U1836210); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556123","automatic program repair;vulnerability repair;large language model;program language model","Training;Computer languages;Codes;Computational modeling;Computer bugs;Maintenance engineering;Natural language processing","","1","","12","IEEE","21 Jun 2024","","","IEEE","IEEE Conferences"
"Leveraging RAG and LLMs for Access Control Policy Extraction From User Stories in Agile Software Development","S. Aboukadri; A. Ouaddah; A. Mezrioui; I. El Asri","STRS Laboratory/CEDOC 2TI, National Institute of Posts and Telecommunications, Rabat, Morocco; STRS Laboratory/CEDOC 2TI, National Institute of Posts and Telecommunications, Rabat, Morocco; STRS Laboratory/CEDOC 2TI, National Institute of Posts and Telecommunications, Rabat, Morocco; STRS Laboratory/CEDOC 2TI, National Institute of Posts and Telecommunications, Rabat, Morocco",IEEE Access,"11 Jul 2025","2025","13","","116462","116472","Agile development has become increasingly popular among software development teams due to its capacity to deliver and update software rapidly while accommodating evolving requirements. Within this dynamic context, access control policies are critical for ensuring the security of systems by defining who can access specific resources under given conditions. However, identifying and documenting these policies often rely on manual, time-intensive processes prone to errors and oversight. This paper proposes an innovative framework leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to automate the extraction and organization of access control policies from user stories and software documentation. The framework focuses on the early stages of the development lifecycle, capturing access control requirements as expressed in natural language artifacts. It comprises two core components: 1) a pipeline for extracting and categorizing access control policies, enabling precise mappings between roles, actions, and resources, and 2) an interactive chatbot designed to support Security Operations Center (SOC) analysts in evaluating suspicious access requests by providing contextualized insights into access policies. By integrating advanced natural language processing techniques with retrieval-based augmentation, the framework aims to reinforce access control mechanisms by improving visibility, and providing contextualized insights for security analysts.","2169-3536","","10.1109/ACCESS.2025.3586203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071540","Access control;agile software development;software requirements;RAG;LLMs","Access control;Security;Agile software development;Accuracy;Transformers;Software;Natural languages;Dynamic scheduling;Vectors;Pipelines","","","","30","CCBY","4 Jul 2025","","","IEEE","IEEE Journals"
"Reliable KMDF Instruction Set Generation for User Queries Based on Endogenous Generative LLMs","Y. Yang; Y. Lin; S. -M. Yiu","Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","242","250","This paper proposes a method for using endogenous generative large language models (LLMs) to generate reliable Microsoft Kernel Mode Driver Framework (KMDF) instruction sets for user queries in the natural language form. The reliability is defined to ensure the validity, correctness, and safety of the generated instruction sets through a multi-phase verification procedure. Three phases are designed in the verification pro-cedure, leveraging both traditional and advanced AI techniques to minimize the risk of errors and enhance the security and effi-ciency of the framework-based anti-virus programs. Meanwhile, m = 20 is figured out to be the maximum count of attempts, where $m$ is the maximum count of the attempts. With roles and layers shown clearly, security proofs like secure multi-party computation are discussed for local communication security. The experimental results demonstrate the effectiveness of our approach, showing significant improvements in the reliability of KMDF instruction set generation. Eventually, the paper presents some possible future research directions, showing its portability and extendability,","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050835","Endogenous Generative LLMs;KMDF instruction set generation;Reliability","Privacy;Instruction sets;Large language models;Natural languages;Multi-party computation;Malware;Safety;Reliability;Security;Kernel","","","","32","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Topic-Aware Sensitive Information Detection in Chinese Large Language Model","Y. Sun; R. Lu; K. Li; Y. Zheng","Xidian University, Xi’an, China; Xidian University, Xi’an, China; Xidian University, Xi’an, China; Xidian University, Xi’an, China","2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","4 Apr 2025","2024","","","908","915","With the rapid advancement of deep learning, generative AI models have emerged as a prominent area of focus. However, these developments bring potential security concerns. China’s guiding document of government on generative AI security identifies 31 specific security risks across five categories, including content that violates socialist core values and discriminatory content. Detecting the sensitivity of both user input and model-generated content has therefore become a critical challenge for the security of generative AI models. This paper proposes a robust scheme for detecting sensitive information in the Chinese languages generated from the large language models. Initially, we detect and classify the security risks outlined in the document ""Basic Security Requirements for Generative Artificial Intelligence Service"" and develop a comprehensive dataset, named Chinese Sensitive Language Detection (CSLD). Specifically, in order to leverage the semantics of languages, we introduce the topic model to pre-analyze text data and construct topic-augmented classification vectors (TACV) that supply effective contextual information for sensitive content detection. Additionally, we propose a topic-infused attention mechanism (TIAM) to provide richer contextual information and relevant topics to guide sensitive information detection. At the same time, the proposed framework is designed to integrate with various classes of Chinese pre-trained models, enabling accurate classification of sensitive content while maintaining low latency and memory usage. Furthermore, the proposed dataset surpasses existing ones in terms of coverage, data volume, and its focus on the security challenges specific to Chinese large language models. Without bells and whistles, our experiments demonstrate that our model outperforms existing models in terms of accuracy and efficiency on the CSLD dataset.","2324-9013","979-8-3315-0620-9","10.1109/TrustCom63139.2024.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10944887","generative AI security;sensitive information detection;topic analysis;transformer","Privacy;Accuracy;Sensitivity;Generative AI;Large language models;Computational modeling;Semantics;Transformers;Vectors;Security","","","","23","IEEE","4 Apr 2025","","","IEEE","IEEE Conferences"
"LLM for SoC Security: A Paradigm Shift","D. Saha; S. Tarek; K. Yahyaei; S. K. Saha; J. Zhou; M. Tehranipoor; F. Farahmandi","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",IEEE Access,"29 Oct 2024","2024","12","","155498","155521","As the ubiquity and complexity of system-on-chip (SoC) designs increase across electronic devices, incorporating security into an SoC design flow poses significant challenges. Existing security solutions are inadequate to effectively verify modern SoC designs due to their limitations in scalability, comprehensiveness, and adaptability. On the other hand, large language models (LLMs) are celebrated for their remarkable success in language understanding, advanced reasoning, and program synthesis tasks. Recognizing an opportunity, our research explores leveraging the emergent capabilities of generative pre-trained transformers (GPTs) to address the existing gaps in SoC security, aiming for a more efficient, scalable, and adaptable methodology. By integrating LLMs into the SoC security verification paradigm, we open a new frontier of possibilities and challenges to ensure the security of increasingly complex SoCs. This paper offers an in-depth analysis of existing works, presents practical case studies, and demonstrates comprehensive experiments. We also present the achievements, prospects, and challenges of employing LLM in different SoC security verification tasks.","2169-3536","","10.1109/ACCESS.2024.3427369","U.S. National Science Foundation (NSF) through Faculty Early Career Development Program (CAREER) Award(grant numbers:2339971); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596266","Hardware security;SoC security verification;hardware vulnerability;large language model","Security;Task analysis;Fuzzing;Cognition;Complexity theory;Databases;Hardware security;System-on-chip;Large language models","","41","","169","CCBYNCND","12 Jul 2024","","","IEEE","IEEE Journals"
"Transforming Healthcare with AI: Multimodal VQA Systems and LLMs","S. S. Vengatachalam; T. Rakkiannan","Computer Science and Engineering, Kongu Engineering College, Erode, India; Computer Science and Engineering, Kongu Engineering College, Erode, India",2025 10th International Conference on Signal Processing and Communication (ICSC),"24 Apr 2025","2025","","","584","590","In Multimodal Large Language Models (LLMs), Visual Question Answering in Medicine (VQA) is an essential activity that allows for clinically acceptable answers to questions concerning medical imagery. This could alleviate pressure on healthcare systems, especially in resource-limited countries. However, the medical VQA datasets available today are tiny, mostly focused on basic classification tasks, and devoid of semantic reasoning and clinical expertise. Our previous work proposed a VQA technique using three distinct relationship graphs—implicit, spatial, and semantic—based on the Medical-CXR-VQA dataset, mainly focuses on chest X-ray images that achieving 62% accuracy. By training an LLM technique, we improved label extraction accuracy to 80%. The labels were also thoroughly reviewed with two clinical specialists for greater accuracy. We then introduced a larger dataset, Medical VQA-RAD dataset (VQA-Radiology), which focuses on radiology images (including X-ray, CT scan, MRIs and Ultrasounds) that includes detailed inquiries about anomalies, locations, severity, and types. Based on this dataset, We created a novel chain-of-thought and prompt engineering bio-medical multi-modal VQA technique, refined from the Llama-3-8B model using the bespoke dataset. This approach combines curated and synthesized biological data, offering significant benefits to researchers, doctors, and biomedical professionals, by improving the comprehension and generation of content related to a wide range of biological topics.","2643-444X","979-8-3315-1189-0","10.1109/ICSC64553.2025.10968734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10968734","Medical Dataset;Visual Question Answering;Large Language Model;Multimodal model;Chain-of-thought;Prompt Engineering;Graph Learning","Visualization;Accuracy;Ultrasonic imaging;Large language models;Biological system modeling;Medical services;Question answering (information retrieval);Prompt engineering;X-ray imaging;Biomedical imaging","","","","22","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"Comprehensive Evaluation of Transformer Models for Complex Information Detection in Unstructured Documents","D. Singh; A. Terayama","Digital Platform Innovation Center, Hitachi Ltd., Tokyo, Japan; Digital Platform Innovation Center, Hitachi Ltd., Tokyo, Japan",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","7171","7176","Information detection from unstructured data, such as address detection, is crucial in many applications. Traditional approaches like regular expressions (RegEx) are computationally efficient but struggle to adapt to the variability in data formats, leading to low accuracy. In contrast, machine learning-based approaches, particularly those involving transformer-based models, have shown great promise in natural language processing due to their adaptability and high accuracy. This paper provides a comprehensive evaluation of several prominent transformer-based models Bidirectional Encoder Representations from Transformers (BERT), DistilBERT, and RoBERTa—in the context of address detection. BERT, known for its deep contextual understanding, offers high accuracy but comes with a higher computational cost. DistilBERT, a distilled version of BERT, provides a faster and more resource-efficient alternative but may sacrifice some accuracy and RoBERTa is optimized for performance. Experiments, conducted on a dataset combining the National Address Database with Wikipedia texts, revealed that RoBERTa outperformed the others, achieving 99% accuracy with a 0.0193-s inference time. In contrast, using RegEx achieved less than 10% accuracy. This evaluation highlights the effectiveness of transformer-based models, particularly RoBERTa, in detecting complex information such as addresses, while also considering resource consumption. The findings suggest that RoBERTa, strikes the best balance between accuracy and computational cost among the models tested, making it a strong candidate for broader applications in unstructured document analysis.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825282","Sensitive Information Detection;Unstructured Data Processing;Data Security and Privacy","Adaptation models;Accuracy;Text analysis;Computational modeling;Bidirectional control;Transformers;Encoding;Computational efficiency;Security;Online services","","","","19","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Hardware Trojan Detection in Open-Source Hardware Designs Using Machine Learning","V. T. Hayashi; W. Vicente Ruggiero","Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil; Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil",IEEE Access,"4 Mar 2025","2025","13","","37771","37788","The globalization of the hardware supply chain reduces costs but increases security challenges with the potential insertion of hardware trojans by third parties. Traditional detection methods face scalability limitations by relying solely on simple examples (e.g., AES). Although open-source hardware promotes transparency, it does not guarantee security. In this research, Natural Language Processing (NLP) and Machine Learning (ML) techniques were applied to identify hardware trojans in complex open hardware designs (e.g., RISC-V, MIPS). Using data from existing benchmarks (ISCAS85-89, TrustHub) and synthetic data generated with Large Language Models (LLM), a dataset of 3,808 instances was used in this research. The approach using TF-IDF and Decision Tree (DT) achieved 97.26%, surpassing the state of the art. The use of LLMs with prompt optimization achieved a recall of 99%, minimizing false negatives. A novel framework integrating NLP, ML, and LLMs was developed to enhance the security of open-source hardware.","2169-3536","","10.1109/ACCESS.2025.3546156","Graduate Program in Electrical Engineering (PPGEE) from the Escola Politécnica, Universidade de São Paulo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904479","Hardware security;hardware trojan;machine learning;natural language processing;large language models;open hardware;open source","Hardware;Trojan horses;Machine learning;Hardware design languages;Open source hardware;Benchmark testing;Static analysis;Integrated circuit modeling;Hardware security;Computer architecture","","2","","85","CCBY","26 Feb 2025","","","IEEE","IEEE Journals"
"Authentic Learning Approach for Data Poisoning Vulnerability in LLMs","M. S. Akter; M. A. Rahman; M. M. Rahman; J. Rodriguez-Cardenas; H. Shahriar; F. Wu; M. Rahman","Dept. of Intelligent Systems and Robotics, University of West Florida, Florida, USA; Dept. of Intelligent Systems and Robotics, University of West Florida, Florida, USA; Dept of Cybersecurity and Information Technology, University of West Florida, Florida, USA; Dept. of Information Systems and Security, Kennesaw State University, Kennesaw, USA; Center for Cybersecurity, University of West Florida, Florida, USA; Dept of Computer Science, Tuskegee University, Tuskegee, USA; Dept. of Computer Science and Information Technology, Clayton State University, Georgia, USA","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","1504","1505","The primary goal of authentic learning is to provide students with an engaging learning environment that offers hands-on experiences in solving real-world security challenges. Each educational theme consists of prelab activities, lab activities, and hands-on lab activities. By implementing authentic learning, we design and build portable lab for data poisoning vulnerability in LLM models on Google Colab. These hands-on labs can be accessed and practiced in real-time without the need for complex installations and configurations. This allows students to focus on learning concepts and increase their hands-on problem-solving skills.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00210","National Science Foundation(grant numbers:2100134,2100115,1946442); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633486","Authentic learning;LLM;Data Poisoning Attack;Security;Privacy;Education","Software;Real-time systems;Data models;Internet;Security;Problem-solving","","1","","5","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"The Shortcomings of Code LLMs in Modeling Code Properties","S. Pyda; D. Nichols; A. Bhatele","Department of Computer Science, University of Maryland, College Park, USA; Department of Computer Science, University of Maryland, College Park, USA; Department of Computer Science, University of Maryland, College Park, USA",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","193","199","Large language models have rapidly taken over software development tools and are now being used to generate code, write documentation, and even fix GitHub issues. Despite their success, many studies across various fields of computer science have shown that these models often struggle to reason about code properties, such as performance, security, etc. In this paper, we demonstrate the limitations of text-based learning for code properties and how structured code representations are more effective for understanding some code properties. We evaluate over several code benchmarks and demonstrate the limitations of the internal code representation within large language models.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028359","Code Representations;LLMs;Code Properties","Computer science;Codes;Large language models;Conferences;Graphics processing units;Documentation;Encoding;Security;Kernel;Software development management","","","","14","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Using Graph Theory to Produce Emergent Behaviour in Agent-Based Systems","B. Gower-Winter; G. Nitschke","Department of Computer Science, University of Cape Town, Cape Town, South Africa; Department of Computer Science, University of Cape Town, Cape Town, South Africa",2023 IEEE Symposium Series on Computational Intelligence (SSCI),"1 Jan 2024","2023","","","1690","1695","Cooperation is a defining trait of Multi-Agent Systems. At the centre of these systems lies a communication network which governs how information flows from one agent to the next. However, the design of these networks is often overlooked despite the profound impact it can have on both the task performance of the agents and the emergent phenomena they produce. In this work we aim to illustrate this by investigating whether network centrality impacts the task performance and emergent inequality (unequal distribution of resources) of resource gathering agents. We achieve this by constructing several communication networks with increasing centrality and use them with an Agent-Based Model called GATHER. Our results indicate that as the variance of the population's centrality increases, the task performance of an agent population will decrease. Furthermore, we demonstrate that simply changing the centrality of the network can produce distinct results and emergent phenomena (inequality or the lack thereof in our case). We then further support this claim by increasing the reciprocity of one of our communication networks which results in a system with greater task performance and significantly lower inequality, further illustrating the impact communication network topology can have on Multi-Agent Systems.","2472-8322","978-1-6654-3065-4","10.1109/SSCI52147.2023.10371866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371866","Agent-Based Model;Graph Theory;Centrality;Emergent Inequality;Reinforcement Learning","Network topology;Computational modeling;Sociology;Graph theory;Topology;Communication networks;Task analysis","","1","","24","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Feature Extraction and Compliance Classification of Text Files Using Large Language Models","X. Liu; Y. Liao; Z. Zhang; J. Hu; L. Huang","Institute of Science and Technology Innovation, Dongguan University of Technology, Dongguan, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China",IEEE Transactions on Computational Social Systems,"","2025","PP","99","1","12","In industries such as finance, healthcare, and new energy vehicles, data classification and grading standards ensure regulatory compliance and protect sensitive information. However, automating text file classification under these standards presents several challenges. Traditional machine learning and deep learning approaches require large labeled datasets, which are often scarce. Existing classification methods are typically domain-specific, limiting cross-domain adaptability. Moreover, many approaches simply categorize documents as regulatory or nonregulatory and assign security levels, but fail to map them accurately to specific rules. To address these challenges, this article proposes prompt-driven grading and classification algorithm (PGCA), a prompt learning-based method for text classification and grading. PGCA integrates a structured feature repository and SQL-inspired prompt templates to efficiently extract and match features from text documents, establishing mappings between text, and classification rules and grading standards. Furthermore, the integration of a preclassification strategy enables the filtration of irrelevant rules, thereby substantially reducing computational overhead. Experiments show that PGCA achieves classification accuracy between 95.0% and 99.0%, outperforming baselines such as TsF-KNN, Gen-DT, bt-SVM, AGCRCNN, and AC-BiLSTM by 4%–25%. Additionally, the preclassification stage cuts computational costs by 63.7% while keeping accuracy loss to within 1%.","2329-924X","","10.1109/TCSS.2025.3587039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103503","Data security laws and regulations;feature extraction;large language model;text classification","Standards;Data security;Text categorization;Security;Industries;Feature extraction;Biological system modeling;Accuracy;Deep learning;Medical services","","","","","IEEE","30 Jul 2025","","","IEEE","IEEE Early Access Articles"
"Translating Common Security Assertions Across Processor Designs: A RISC-V Case Study","S. Imtiaz; U. Reinsalu; T. Ghasempouri","Department of Computer Systems, Tallinn University of Technology, Tallinn, Estonia; Department of Computer Systems, Tallinn University of Technology, Tallinn, Estonia; Department of Computer Systems, Tallinn University of Technology, Tallinn, Estonia",2025 IEEE International Symposium on Circuits and Systems (ISCAS),"27 Jun 2025","2025","","","1","5","RISC-V is gaining popularity for its adaptability and cost-effectiveness in processor design. With the increasing adoption of RISC-V, the importance of implementing robust security verification has grown significantly. In the state of the art, various approaches have been developed to strengthen the security verification process. Among these methods, assertion-based security verification has proven to be a promising approach for ensuring that security features are effectively met. To this end, some approaches manually define security assertions for processor designs; however, these manual methods require significant time, cost, and human expertise. Consequently, recent approaches focus on translating pre-defined security assertions from one design to another. Nonetheless, these methods are not primarily centered on processor security, particularly RISC-V. Furthermore, many of these approaches have not been validated against real-world attacks, such as hardware Trojans. In this work, we introduce a methodology for translating security assertions across processors with different architectures, using RISC-V as a case study. Our approach reduces time and cost compared to developing security assertions manually from the outset. Our methodology was applied to five critical security modules with assertion translation achieving nearly 100% success across all modules. These results validate the efficacy of our approach and highlight its potential for enhancing security verification in modern processor designs. The effectiveness of the translated assertions was rigorously tested against hardware Trojans defined by large language models (LLMs), demonstrating their reliability in detecting security breaches.","2158-1525","979-8-3503-5683-0","10.1109/ISCAS56072.2025.11043977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11043977","Security Verification;Security Assertion;RISC-V Processor;Hardware Trojan;Register-Transfer Level (RTL)","Translation;Costs;Large language models;Manuals;Register transfer level;Hardware;Security;Trojan horses;Reliability;Integrated circuit modeling","","","","29","IEEE","27 Jun 2025","","","IEEE","IEEE Conferences"
"Semantic Sleuth: Identifying Ponzi Contracts via Large Language Models","C. Wu; J. Chen; Z. Wang; R. Liang; R. Du","Wuhan University, Wuhan, China; Wuhan University, Wuhan, China; Wuhan University, Wuhan, China; Wuhan University, Wuhan, China; Wuhan University, Wuhan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","582","593","Smart contracts, self-executing agreements directly encoded in code, are fundamental to blockchain technology, especially in decentralized finance (DeFi) and Web3. However, the rise of Ponzi schemes in smart contracts poses significant risks, leading to substantial financial losses and eroding trust in blockchain systems. Existing detection methods, such as PonziGuard, depend on large amounts of labeled data and struggle to identify unseen Ponzi schemes, limiting their reliability and generalizability. In contrast, we introduce PonziSleuth, the first LLM-driven approach for detecting Ponzi smart contracts, which requires no labeled training data. PonziSleuth utilizes advanced language understanding capabilities of LLMs to analyze smart contract source code through a novel two-step zero-shot chain-of-thought prompting technique. Our extensive evaluation on benchmark datasets and real-world contracts demonstrates that PonziSleuth delivers comparable, and often superior, performance without the extensive data requirements, achieving a balanced detection accuracy of 96.06% with GPT-3.5-turbo, 93.91% with LLAMA3, and 94.27% with Mistral. In real-world detection, PonziSleuth successfully identified 15 new Ponzi schemes from 4,597 contracts verified by Etherscan in March 2024, with a false negative rate of 0% and a false positive rate of 0.29%. These results highlight PonziSleuth’s capability to detect diverse and novel Ponzi schemes, marking a significant advancement in leveraging LLMs for enhancing blockchain security and mitigating financial scams.CCS Concepts• Security and privacy → Software security engineering; • Software and its engineering;","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764961","Smart contracts;large language model;Ponzi contracts","Adaptation models;Codes;Accuracy;Source coding;Smart contracts;Finance;Training data;Software;Blockchains;Security","","","","46","","29 Nov 2024","","","IEEE","IEEE Conferences"
