"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Understanding Regular Expression Denial of Service (ReDoS): Insights from LLM-Generated Regexes and Developer Forums","M. L. Siddiq; J. Zhang; J. C. S. Santos","University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA",2024 IEEE/ACM 32nd International Conference on Program Comprehension (ICPC),"18 Jun 2024","2024","","","190","201","Regular expression Denial of Service (ReDoS) represents an algorithmic complexity attack that exploits the processing of regular expressions (regexes) to produce a denial-of-service attack. This attack occurs when a regex’s evaluation time scales polynomially or exponentially with input length, posing significant challenges for software developers. The advent of Large Language Models (LLMs) has revolutionized the generation of regexes from natural language prompts, but not without its risks. Prior works showed that LLMs can generate code with vulnerabilities and security smells. In this paper, we examined the correctness and security of regexes generated by LLMs as well as the characteristics of LLM-generated vulnerable regexes. Our study also examined ReDoS patterns in actual software projects, aligning them with corresponding regex equivalence classes and algorithmic complexity. Moreover, we analyzed developer discussions on GitHub and StackOverflow, constructing a taxonomy to investigate their experiences and perspectives on ReDoS. In this study, we found that GPT-3.5 was the best LLM to generate regexes that are both correct and secure. We also observed that LLM-generated regexes mainly have polynomial ReDoS vulnerability patterns, and it is consistent with vulnerable regexes found in open source projects. We also found that developers’ main discussions around insecure regexes is related to mitigation strategies to remove vulnerable regexes. CCS CONCEPTS • Software and its engineering$\rightarrow$ State based definitions; • Security and privacy $\rightarrow$ Denial-of-service attacks; • Computing methodologies $\rightarrow$ Multi-task learning.","2643-7171","979-8-4007-0586-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556479","ReDoS;DoS Attack;large language models;regex generation","Privacy;Taxonomy;Software algorithms;Natural languages;Denial-of-service attack;Software;Polynomials","","3","","72","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Assessing the Performance of AI-Generated Code: A Case Study on GitHub Copilot","S. Li; Y. Cheng; J. Chen; J. Xuan; S. He; W. Shang","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; Department of Systems and Industrial Engineering, University of Arizona, Tucson, United States; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE),"3 Dec 2024","2024","","","216","227","The integration of Large Language Models (LLMs) into software development tools like GitHub Copilot holds the promise of transforming code generation processes. While AI-driven code generation presents numerous advantages for software development, code generated by large language models may introduce challenges related to security, privacy, and copyright issues. However, the performance implications of AI-generated code remain insufficiently explored. This study conducts an empirical analysis focusing on the performance regressions of code generated by GitHub Copilot across three distinct datasets: HumanEval, AixBench, and MBPP. We adopt a comprehensive methodology encompassing static and dynamic performance analyses to assess the effectiveness of the generated code. Our findings reveal that although the generated code is functionally correct, it frequently exhibits performance regressions compared to code solutions crafted by humans. We further investigate the code-level root causes responsible for these performance regressions. We identify four major root causes, i.e., inefficient function calls, inefficient looping, inefficient algorithm, and inefficient use of language features. We further identify a total of ten sub-categories of root causes attributed to the performance regressions of generated code. Additionally, we explore prompt engineering as a potential strategy for optimizing performance. The outcomes suggest that meticulous prompt designs can enhance the performance of AI-generated code. This research offers valuable insights contributing to a more comprehensive understanding of AI-assisted code generation.","2332-6549","979-8-3503-5388-4","10.1109/ISSRE62328.2024.00030","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771230","Code generation;Software performance;Github Copilot;Program analysis","Privacy;Codes;Large language models;Focusing;Software reliability;Performance analysis;Prompt engineering;Security;Software development management","","2","","63","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"A PBL-Based Mini Course Module for Teaching Computer Science Students to Utilize Generative AI for Enhanced Learning","V. A. Kusam; S. Shrestha; K. Kattan; B. Maxim; Z. Song","Dept. of Computer and Information Science, University of Michigan-Dearborn, MI, USA; Dept. of Computer and Information Science, University of Michigan-Dearborn, MI, USA; Dept. of Computer and Information Science, University of Michigan-Dearborn, MI, USA; Dept. of Computer and Information Science, University of Michigan-Dearborn, MI, USA; Dept. of Computer and Information Science, University of Michigan-Dearborn, MI, USA",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","9","This research-to-practice paper introduces a mini-course module designed to teach computer science students how to interact more efficiently with Generative AI(GAI). The rapid rise of GAI is transforming education by providing students with easy access to knowledge and answers to their questions, acting as a personal tutor. Particularly in the field of computer science, where GAI can easily generate code based on specific requirements, many instructors struggle to prevent students from using tools like ChatGPT for completing assigned programming assignments and homeworks. However, we argue that 1) the use of GAI is inevitable, necessitating a redesign of courses so that students cannot merely rely on GAI without actual learning; and 2) students' learning can be enhanced if they learn to use GAI more effectively. In this paper, we demonstrate how we integrate Project-Based Learning to design the course module in a concise yet effective manner, which not only facilitates students' learning of GAI but also enriches their learning in relation to the host course where this mini-course module is embedded. In particular, the goal of this module is to teach CS students: 1) the basic principles and workflow of GAI; 2) Prompt Engineering: how to craft questions to interact more effectively with GAI; and 3) Extending GAI: how to create interactive tools by training customized GAI models. Designed to be completed within two weeks, the mini-course module can easily be incorporated into host courses. This mini-course module was integrated into a graduate-level Artificial Intelligence course with 42 students in Winter 2024. To assess the module's impact on student learning and engagement, we conducted pre- and post-course surveys as well as student interviews. The results from the surveys and interviews highlighted key areas for improving the design of educational modules to better teach essential GAI skills. These insights focused on enhancing student engagement and learning efficiency within a concise time frame.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10893118","NSF(grant numbers:2104337); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893118","Generative AI;Course Module Design;Project Based Learning(PBL)","Surveys;Training;Codes;Navigation;Chatbots;Prompt engineering;Interviews;Programming profession","","","","35","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"CoCoNUT: Structural Code Understanding does not fall out of a tree","C. Beger; S. Dutta","Department of Computer Science, Cornell University, Ithaca, New York; Department of Computer Science, Cornell University, Ithaca, New York",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","128","136","Large Language Models (LLMs) have shown impressive performance across a wide array of tasks involving both structured and unstructured textual data. More recently, LLMs have demonstrated remarkable abilities to generate code across different programming languages. Recent results on various benchmarks for code generation, repair, or completion suggest that certain models have programming abilities comparable to or even surpass humans. In this work, we demonstrate that the high performance on such benchmarks does not correlate to humans’ innate ability to understand the structural control flow of code.For this purpose, we extract code solutions from the HumanEval benchmark, which the relevant models perform very strongly on, and trace their execution path using function calls sampled from the respective test set. Using this dataset, we investigate the ability of 7 state-of-the-art LLMs to match the execution trace and find that, despite the model’s abilities to generate semantically identical code, they possess only limited ability to trace the execution path, especially for longer traces and specific control structures. We find that even the top-performing model, Gemini 1.5 Pro can only fully correctly generate the trace of 47% of HumanEval tasks.In addition, we introduce a subset for three key structures not, or only contained to a limited extent in HumanEval: Recursion, Parallel Processing, and Object Oriented Programming principles, including concepts like Inheritance and Polymorphism. Besides OOP, we show that none of the investigated models achieve an average accuracy of over 5% on the relevant traces. Aggregating these specialized parts with the ubiquitous HumanEval tasks, we present the Benchmark CoCoNUT: Code Control Flow for Navigation Understanding and Testing, which measures a models ability to trace the execution of code upon relevant calls, including advanced structural components. We conclude that the current generation LLMs still need to significantly improve to enhance their code reasoning abilities. We hope our dataset can help researchers bridge this gap in the near future.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028290","Code Understanding;Large Language Models;Code Execution;Benchmarks","Codes;Navigation;Object oriented modeling;Large language models;Current measurement;Conferences;Benchmark testing;Parallel processing;Maintenance engineering;Object oriented programming","","","","26","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Genetic Improvement for DNN Security","H. Baxter; Y. Huang; K. Leach","Vanderbilt University, Nashville, USA; Vanderbilt University, Nashville, USA; Vanderbilt University, Nashville, USA",2024 IEEE/ACM International Workshop on Genetic Improvement (GI),"11 Sep 2024","2024","","","11","12","Genetic improvement (GI) in Deep Neural Networks (DNNs) has traditionally enhanced neural architecture and trained DNN parameters. Recently, GI has supported large language models by optimizing DNN operator scheduling on accelerator clusters. However, with the rise of adversarial AI, particularly model extraction attacks, there is an unexplored potential for GI in fortifying Machine Learning as a Service (MLaaS) models. We suggest a novel application of GI — not to improve model performance, but to diversify operator parallelism for the purpose of a moving target defense against model extraction attacks. We discuss an application of GI to create a DNN model defense strategy that uses probabilistic isolation, offering unique benefits not present in current DNN defense systems.","","979-8-4007-0573-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10666382","Computer Security;Genetic Improvement","Large language models;Conferences;Artificial neural networks;Machine learning;Computer architecture;Parallel processing;Genetics","","","","11","","11 Sep 2024","","","IEEE","IEEE Conferences"
"Design and Implementation of an AI-Driven Mental Health Chatbot: A Generative AI Model","D. Gupta; V. Swami; D. Shukla; K. Nimala","Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Chennai; Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Chennai; Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Chennai; Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Chennai","2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","12 Mar 2025","2024","","","1","7","This paper describes the development, design, and maturation of an AI-based mental health chatbot that allows a user to engage with more accessible, higher forms of mental health assistance. As developed as a retrieval-based system which leveraged predefined responses contained in a database and based upon input received from a user, it matured into a far more scalable system which included the generative AI capabilities that allowed users to achieve far more personalized, contextually relevant interactions. This deployment variant robustly leverages on the chaining framework provided by LangChain to enable chaining of prompt templates, utilizes the OllamaLLM model that uses the Llama3 language model, and fully exploits other NLP methods. Therefore, the rule-based system is migrated to a generative model that integrates both algorithms of machine learning for effective enhancement of both understanding and generating. The primary issues with this development were about the conversational context, empathetic and coherent response, and the scalability of the system. All these were achieved through advanced prompt engineering, a set of rigorous evaluation metrics like BLEU score, accuracy, precision, recall, and F1 score besides continuous user feedback for refining the performance of this model. This paper discusses methodologies to overcome the challenges and implications for the future of AI and mental health care with an emphasis on embedding technological advancements within empathetic human-computer interaction. The findings point out this chatbot is effective in providing emotional support and how AI is changing its role to improve the services of mental health.","","979-8-3315-4362-4","10.1109/ICSES63760.2024.10910363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910363","Mental Health;Chathot;AI;NLP;Generative AI;Machine Learning","Measurement;Machine learning algorithms;Databases;Scalability;Refining;Mental health;Machine learning;Chatbots;Depression;Prompt engineering","","","","12","IEEE","12 Mar 2025","","","IEEE","IEEE Conferences"
"Dynamic Resource Task Negotiation to Enable Product Agent Exploration in Multi-Agent Manufacturing Systems","I. Kovalenko; D. Ryashentseva; B. Vogel-Heuser; D. Tilbury; K. Barton","Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA; Institute of Automation and Information Systems, Technical University of Munich, Garching, Germany; Institute of Automation and Information Systems, Technical University of Munich, Garching, Germany; Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA; Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA",IEEE Robotics and Automation Letters,"24 Jun 2019","2019","4","3","2854","2861","Distributed multi-agent control has been proposed to improve the flexibility of manufacturing systems. Two important components of this control strategy are product agents, representing physical parts in the system, and resource agents, representing the system resources. Product agents request actions from resource agents to guide physical parts through the manufacturing system. Before requesting specific actions, a product agent must effectively communicate with the system's resource agents to understand the capabilities of the resources on the plant floor. In this letter, an approach to product agent exploration based on a network of resource agents is described and analyzed. In addition, results and insights from an implementation of the proposed exploration methodology in a manufacturing system are presented.","2377-3766","","10.1109/LRA.2019.2921947","National Science Foundation; Bayerische Forschungsstiftung Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733849","Agent-based systems;intelligent and flexible manufacturing;autonomous agents","Manufacturing systems;Task analysis;Autonomous agents;Dynamic scheduling;Computer architecture;Complexity theory","","31","","24","IEEE","10 Jun 2019","","","IEEE","IEEE Journals"
"Efficient Game-Theoretic Planning With Prediction Heuristic for Socially-Compliant Autonomous Driving","C. Li; T. Trinh; L. Wang; C. Liu; M. Tomizuka; W. Zhan","Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",IEEE Robotics and Automation Letters,"2 Aug 2022","2022","7","4","10248","10255","Planning under social interactions with other agents is an essential problem for autonomous driving. As the actions of the autonomous vehicle in the interactions affect and are also affected by other agents, autonomous vehicles need to efficiently infer the reaction of the other agents. Most existing approaches formulate the problem as a generalized Nash equilibrium problem solved by optimization-based methods. However, they demand too much computational resource and easily fall into the local minimum due to the non-convexity. Monte Carlo Tree Search (MCTS) successfully tackles such issues in game-theoretic problems. However, as the interaction game tree grows exponentially, the general MCTS still requires a huge amount of iterations to reach the optima. In this letter, we introduce an efficient game-theoretic trajectory planning algorithm based on general MCTS by incorporating a prediction algorithm as a heuristic. On top of it, a social-compliant reward and a Bayesian inference algorithm are designed to generate diverse driving behaviors and identify the other driver's driving preference. Results demonstrate the effectiveness of the proposed framework with datasets containing naturalistic driving behavior in highly interactive scenarios.","2377-3766","","10.1109/LRA.2022.3191241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9830854","Agent-based systems;autonomous agents;intelligent transportation systems","Behavioral sciences;Prediction algorithms;Planning;Autonomous vehicles;Trajectory;Games;Search problems","","16","","28","IEEE","15 Jul 2022","","","IEEE","IEEE Journals"
"Decoding Secret Memorization in Code LLMs Through Token-Level Characterization","Y. Nie; C. Wang; K. Wang; G. Xu; G. Xu; H. Wang","Beijing University of Posts and Telecommunications, Beijing, China; Nanyang Technological University, Singapore, Singapore; Huazhong University of Science and Technology, Wuhan, China; Harbin Institute of Technology, Shenzhen, China; Beijing University of Posts and Telecommunications, Beijing, China; Huazhong University of Science and Technology, Wuhan, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","2880","2892","Code Large Language Models (LLMs) have demonstrated remarkable capabilities in generating, understanding, and manipulating programming code. However, their training process inadvertently leads to the memorization of sensitive information, posing severe privacy risks. Existing studies on memorization in LLMs primarily rely on prompt engineering techniques, which suffer from limitations such as widespread hallucination and inefficient extraction of the target sensitive information. In this paper, we present a novel approach to characterize real and fake secrets generated by Code LLMs based on token probabilities. We identify four key characteristics that differentiate genuine secrets from hallucinated ones, providing insights into distinguishing real and fake secrets. To overcome the limitations of existing works, we propose DeSec,a two-stage method that leverages token-level features derived from the identified characteristics to guide the token decoding process. DeSec consists of constructing an offline token scoring model using a proxy Code LLM and employing the scoring model to guide the decoding process by reassigning token likelihoods. Through extensive experiments on four state-of-the-art Code LLMs using a diverse dataset, we demonstrate the superior performance of DeSec in achieving a higher plausible rate and extracting more real secrets compared to existing baselines. Our findings highlight the effectiveness of our token-level approach in enabling an extensive assessment of the privacy leakage risks associated with Code LLMs.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00229","National Key Research and Development Program of China(grant numbers:2021YFB3101500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029894","","Training;Privacy;Data privacy;Codes;Large language models;Programming;Feature extraction;Decoding;Prompt engineering;Software engineering","","","","60","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Multimodal Retrieval Augmented Generation Evaluation Benchmark","T. Sun; A. Somalwar; H. Chan","EduBeyond, British Columbia, Canada; UC Berkeley, California, USA; EduBeyond, British Columbia, Canada",2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring),"25 Sep 2024","2024","","","1","5","While advances in prompt engineering and RAG have improved LLM proficiency in field-specific, specialized tasks, there has yet to be an industry standard or accepted evaluation metric of the highly fragmented RAG solutions that are currently being deployed. Thus, in this work, we focused on building a robust LLM and RAG evaluation platform. We contribute 1) a platform that evaluates an RAG system's performance on a multimodal input context for LLM question answering and 2) MRAFE: Multimodal Retrieval Augmented Feature Extractor, which processes information from the input to our platform. Through various automated and systematic hand testing, we find that our evaluation benchmarks are useful in determining noise robustness, negative rejection, information integration, and counterfactual rejection. Such a platform would serve as a useful tool for developers iterating on retrieval systems and regulatory bodies creating AI-focused governance alike.","2577-2465","979-8-3503-8741-4","10.1109/VTC2024-Spring62846.2024.10683437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10683437","Artificial Intelligence;Machine Learning;Large Language Models;Retrieval Augmented Generation","Measurement;Industries;System performance;Benchmark testing;Feature extraction;Question answering (information retrieval);Noise robustness","","1","","39","IEEE","25 Sep 2024","","","IEEE","IEEE Conferences"
"AI-Powered 3D Printing Error Detection and Optimization System","A. A; V. T","Computer Science and Engineering, SRM Institute of Science and Technology, Chennai, India; Data Science and Business Systems, SRM Institute of Science and Technology, Chennai, India","2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)","2 Jul 2025","2025","","","1","6","Recent advancements and rising popularity of 3d printing technology have increased innovation and advancements in manufacturing vertical. But this has also brought in challenges in waste reduction particularly for materials like PLA, ABS, and PETG. Waste reduction in 3D printing is a crucial challenge due to the huge dependency on thermoplastics like PLA, ABS, and PETG. Each of these materials has distinct characteristics that influence their recyclability, disposal methods, and potential environmental impact. In another parallel, Generative AI is gaining momentum due to its ability in generate complex data based on the provided prompt and model training. This project aims to utilize the benefits and advantages of Generative AI in addressing the challenges of increasing waste in Additive manufacturing processes. Manual inspection of printing defects is inefficient and prone to human errors. AI can automate and improve this process. This paper presents an AI-powered 3D printing error detection and optimization system that leverages computer vision, deep learning, and generative AI to enhance print quality and reduce material waste. The system employs a convolutional neural network (CNN) to classify common 3D printing defects from real-time images and logistic regression model to identify the material type used for 3d printing. This is followed by a Generative AI Model that provides useful insights for the users on the recommendations to use manufacturing processes in more reliable way with a motto to reduce waste reduction during 3D printing processes. For generative AI model, Prompts are provided in such a way that it contains the printing error type and classified material type. Prompt optimization techniques like gradient-descent algorithm and genetic algorithm are considered and both are being used to create different prompt variations and most reliable prompt is sent to Generative AI model. This is to refine the defect descriptions for an LLM-powered recommendation system (Mistral 7B).","","979-8-3315-9709-2","10.1109/ICCRTEE64519.2025.11053088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053088","3D printing;defect detection;AI optimization;computer vision;deep learning;prompt engineering;generative AI;hybrid optimization;genetic algorithms;mistral 7b","Waste reduction;Deep learning;Solid modeling;Computational modeling;Three-dimensional printing;Real-time systems;Prompt engineering;Convolutional neural networks;Optimization;Genetic algorithms","","","","19","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"CalmSphere: An AI for Mental Health","D. A S; N. S; P. D. S; M. G; V. Kalaivani","Artificial Intelligence and Data Science, National Engineering College, Kovilpatti; Artificial Intelligence and Data Science, National Engineering College, Kovilpatti; Artificial Intelligence and Data Science, National Engineering College, Kovilpatti; Artificial Intelligence and Data Science, National Engineering College, Kovilpatti; Artificial Intelligence and Data Science, National Engineering College, Kovilpatti",2025 7th International Conference on Intelligent Sustainable Systems (ICISS),"16 Jul 2025","2025","","","1157","1161","Mental health is a global issue but access to professionals is limited due to cost, stigma and lack of skilled therapists. Existing AI powered mental health chatbots try to bridge the gap but suffer from many limitations like no empathy, rule based responses and inability to personalize conversations. Through a critical analysis of existing AI therapy tools, we identify key gaps in empathy and efficiency, motivating CalmSphere’s development Our research shows that most existing LLM based solutions rely on prompt engineering rather than fine tuning for therapeutic applications. This analysis is the foundation of our research and guides the development of CalmSphere.This paper introduces CalmSphere, an AI driven virtual therapist to enhance mental health support using a fine tuned Micro-LLM based on LLaMA 2-7B. Unlike traditional AI therapy models, CalmSphere uses memory driven personalization, active listening and emotion aware responses to have a more empathetic and human like conversation. The model is fine tuned using Quantized Low-Rank Adaptation (QLoRA) for efficient training and can be deployed on resource constrained systems with high performance.Also this paper presents a detailed evaluation of CalmSphere’s performance in generating contextually relevant, engaging and supportive conversations.","","979-8-3315-2243-8","10.1109/ICISS63372.2025.11076380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076380","AI Therapy;Mental Health Chatbot;Large Language Models;QLoRA;Micro-LLM","Training;Adaptation models;Ethics;Costs;Medical treatment;Mental health;Oral communication;Chatbots;Artificial intelligence;Tuning","","","","16","IEEE","16 Jul 2025","","","IEEE","IEEE Conferences"
"An Ensemble Transformer Approach with Cross-Attention for Automated Code Security Vulnerability Detection and Documentation","A. Mahmud; Y. Rawajfih; F. Wu","Computer Science, Tuskegee University, Tuskegee, USA; Computer Science, Tuskegee University, Tuskegee, USA; Computer Science, Tuskegee University, Tuskegee, USA",2025 13th International Symposium on Digital Forensics and Security (ISDFS),"2 Jun 2025","2025","","","1","6","Java vulnerability detection remains challenging due to the lack of standardized benchmarks and the complexity of framework interactions that introduce unique security risks compared to C/C++. We introduce a new Java vulnerability benchmark dataset combining the Juliet Test Suite, OWASP Benchmarks, and GitHub repositories, and develop a multi-model transformer framework that freezes pre-trained CodeBERT, GraphCodeBERT, and CodeT5 models, fusing their represen-tations via cross-attention. Our ensemble achieves near-perfect type classification (99.73 %) and 93.46 % detection accuracy on the Java dataset while remaining competitive on PRIMEVUL for C/C++ (89.58% accuracy) without extensive fine-tuning. This work advances vulnerability detection by: (1) creating a comprehensive Java vulnerability benchmark, (2) demonstrating that frozen pre-trained models can achieve strong results through cross-attention fusion, and (3) automating CWE-aligned security documentation to guide developers in remediation, demonstrating a practical and resource-efficient approach to vulnerability detection across languages.","2768-1831","979-8-3315-0993-4","10.1109/ISDFS65363.2025.11012039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012039","security;code vulnerability;vulnerability detection;transformer models;ensemble learning","Training;Java;Accuracy;Codes;Documentation;Benchmark testing;Transformers;Security;Ensemble learning;Software development management","","","","12","IEEE","2 Jun 2025","","","IEEE","IEEE Conferences"
"Utilizing NFT Technology and Generative AI for Deep Fake Detection and Media Authentication","S. Nandwani; D. A. Ostrowski","School Of Professional Studies., Northwestern University; School Of Professional Studies., Northwestern University","2024 Conference on AI, Science, Engineering, and Technology (AIxSET)","3 Dec 2024","2024","","","330","332","The proliferation of deep fake technology has raised significant concerns regarding the authenticity and integrity of digital media. This paper proposes a novel approach that leverages Non-Fungible Token (NFT) technology within blockchain combined with generative AI to detect and authenticate digital media, addressing the growing issue of deep fakes. Using NFTs, unique digital certificates of authenticity are created for each media piece and securely stored on a blockchain to ensure immutability and traceability. Generative AI models, specifically designed for anomaly detection, are employed to analyze media files and identify potential manipulations by comparing them against the original authenticated versions. This dual-layered system not only enhances the reliability of media verification but also provides a robust framework for ensuring the security and provenance of digital content. The implementation of this system demonstrates a significant improvement in detecting deep fakes, offering a practical solution to mitigate the risks associated with synthetic media. Intermediate results highlight the potential of integrating blockchain and AI technologies to establish a more secure and trustworthy digital ecosystem.","","979-8-3503-9099-5","10.1109/AIxSET62544.2024.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771073","","Training;Deepfakes;Generative AI;Biological system modeling;System performance;Scalability;Public key;Media;Security;Reliability","","1","","11","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"Practical Guide to Machine Learning, NLP, and Generative AI: Libraries, Algorithms, and Applications","T. Mariprasath; K. R. Cheepati; M. Rivera",NA; NA; NA,"Practical Guide to Machine Learning, NLP, and Generative AI: Libraries, Algorithms, and Applications","","2025","","","i","xii","This is an essential resource for beginners and experienced practitioners in machine learning. This comprehensive guide covers a broad spectrum of machine learning topics, starting with an in-depth exploration of popular machine learning libraries. Readers will gain a thorough understanding of Scikit-learn, TensorFlow, PyTorch, Keras, and other pivotal libraries like XGBoost, LightGBM, and CatBoost, which are integral for efficient model development and deployment. The book delves into various neural network architectures, providing readers with a solid foundation in understanding and applying these models. Beginning with the basics of the Perceptron and its application in digit classification, it progresses to more complex structures such as multilayer perceptrons for financial forecasting, radial basis function networks for air quality prediction, and convolutional neural networks (CNNs) for image classification. Additionally, the book covers recurrent neural networks (RNNs) and their variants like long short-term memory (LSTM) and gated recurrent units (GRUs), which are crucial for time-series analysis and sequential data applications. Supervised machine learning algorithms are meticulously explained, with practical examples to illustrate their application. The book covers logistic regression and its use in predicting sports outcomes, decision trees for plant classification, random forests for traffic prediction, and support vector machines for house price prediction. Gradient boosting machines and their applications in genomics, AdaBoost for bioinformatics data classification, and extreme gradient boosting (XGBoost) for churn prediction are also discussed, providing readers with a robust toolkit for various predictive tasks. Unsupervised learning algorithms are another significant focus of the book, introducing readers to techniques for uncovering hidden patterns in data. Hierarchical clustering for gene expression data analysis, principal component analysis (PCA) for climate predictions, and singular value decomposition (SVD) for signal denoising are thoroughly explained. The book also explores applications like robot navigation and network security, demonstrating the versatility of these techniques. Natural language processing (NLP) is comprehensively covered, highlighting its fundamental concepts and various applications. The book discusses the overview of NLP, its fundamental concepts, and its diverse applications such as chatbots, virtual assistants, clinical NLP applications, and social media analytics. Detailed sections on text pre-processing, syntactic analysis, machine translation, text classification, named entity recognition, and sentiment analysis equip readers with the knowledge to build sophisticated NLP models. The final chapters of the book explore generative AI, including generative adversarial networks (GANs) for image generation, variational autoencoders for vibrational encoder training, and autoregressive models for time series forecasting. It also delves into Markov chain models for text generation, Boltzmann machines for pattern recognition, and deep belief networks for financial forecasting. Special attention is given to the application of recurrent neural networks (RNNs) for generation tasks, such as wind power plant predictions and battery range prediction, showcasing the practical implementations of generative AI in various fields.","","9788770046527","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10850568.pdf&bkn=10850512&pdfType=chapter","","","","","","","","22 Jan 2025","","","River Publishers","River eBook Chapters"
"Developing Critical Thinking Practices Interwoven with Generative AI Usage in an Introductory Programming Course","A. Styve; O. T. Virkki; U. Naeem","Department of ICT and Natural Sciences, Norwegian University of Science and Technology (NTNU), Ålesund, Norway; Information Technology Degree Programme, Haaga-Helia University of Applied Sciences, Helsinki, Finland; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, UK",2024 IEEE Global Engineering Education Conference (EDUCON),"8 Jul 2024","2024","","","01","08","Software development has evolved significantly. In the past, developers were required to have comprehensive understanding of programming languages, algorithms, and computer architecture. However, with the emergence of the Internet, software libraries, frameworks, and forums became widely available, which utilize reusable software components that can reduce development time and costs. The advent of Generative Artificial Intelligence (AI) tools, such as ChatGPT, GitHub Copilot, and Amazon CodeWhisperer, has further enhanced the developer's toolkit, as these tools can be used for a wide variety of tasks such as code generation, documentation, commenting and reviewing. As programming is often slow and requires trial and error, novice programmers can be tempted to apply the first solution found on the Internet or proposed by an AI tool without much critical reflection or notion of responsibility. Hence, the advances of AI have raised both excitement and concerns among Information Technology (IT)/Computer Science (CS) students and educators. Yet, AI tools are here to stay, and students must learn to use them responsibly. The aim of this paper is to investigate how to design learning activities that introduce Generative AI tools (GitHub Copilot and ChatGPT) for programming while promoting critical thinking practices among students in an introductory programming course in the first semester. Students' opinions and customs were surveyed before and after the AI-based programming assignment. The results indicate that students' awareness of the possibilities and limitations of AI, as well as practices of critical thinking in programming increased. This is encouraging as critical thinking is an integral part of best programming practices.","2165-9567","979-8-3503-9402-3","10.1109/EDUCON60312.2024.10578746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578746","Generative AI;Critical Thinking;Higher Education;CS1","Software libraries;Generative AI;Software algorithms;Chatbots;Software;Reflection;Internet","","6","","50","IEEE","8 Jul 2024","","","IEEE","IEEE Conferences"
"Distributed Event-Triggered Output-Feedback Time-Varying Formation Fault-Tolerant Control for Nonlinear Multi-Agent Systems","X. Wu; N. Zhao; S. Ding; H. Wang; X. Zhao","College of Control Science and Engineering, Bohai University, Jinzhou, Liaoning, China; College of Control Science and Engineering, Bohai University, Jinzhou, Liaoning, China; College of Control Science and Engineering, Bohai University, Jinzhou, Liaoning, China; College of Mathematical Science, Bohai University, Jinzhou, Liaoning, China; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, China",IEEE Transactions on Automation Science and Engineering,"21 Feb 2025","2025","22","","3810","3821","This paper studies the event-triggered time-varying formation control problem for nonlinear multi-agent systems with actuator faults. Based on the neural network approximation technique, a neural observer is constructed to estimate the unmeasured states of systems. Then, a distributed adaptive event-triggered time-varying formation control manner is proposed utilizing the intermittent estimated states information from the agent and its neighbors. To overcome the problem that estimated states triggering leads to virtual control laws is non-differentiable, a distributed continuous control scheme under regular output-feedback is designed firstly, upon which a distributed event-triggered controller is constructed by replacing estimated states with intermittent estimated ones. It is shown that the designed event-triggered output-feedback time-varying formation fault-tolerant controller can compensate for actuator faults, and all signals in closed-loop systems are semi-globally uniformly ultimately bounded. Finally, simulation results of a practical example are given to verify the effectiveness of the proposed control manner.Note to Practitioners—Formation control has broad application prospects in modern military and civilian fields, such as combat aircraft flying formation, satellite formation, autonomous vehicle formation, etc. In formation control systems, when agents occur actuator faults, it may break the original formation and even cause collision between agents. As a result, the security of formation control systems is facing great challenges in practical engineering applications. On the other hand, communication bandwidth is limited in practical engineering systems, and how to make systems quickly form formation under the limited communication bandwidth has become a key topic. Inspired by the above discussions, a distributed state-triggered output-feedback time-varying formation fault-tolerant control scheme is designed in this paper, in which actuator faults are compensated by using adaptive technology. Meanwhile, to sufficiently save the usage of system communication resources, a dual-channel event-triggered mechanism is designed.","1558-3783","","10.1109/TASE.2024.3400325","National Natural Science Foundation of China(grant numbers:62203064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539944","Event-triggered;fault-tolerant control;time-varying formation;output-feedback","Actuators;Fault tolerant systems;Fault tolerance;Formation control;Adaptive systems;Control systems;Artificial neural networks","","41","","44","IEEE","27 May 2024","","","IEEE","IEEE Journals"
"A Diffusion Protocol for Detection of Link Failure and Utilization of Resources in Multi-Agent Systems","P. K. Pandey; B. Adhikari; S. Chakraborty","Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, India; Department of Mathematics, Indian Institute of Technology Kharagpur, Kharagpur, India; Department of Computer Science, Indian Institute of Technology Kharagpur, Kharagpur, India",IEEE Transactions on Network Science and Engineering,"1 Sep 2020","2020","7","3","1493","1507","Several applications in a large scale network depend on diffusion of information from one node to others. In this paper, we propose a diffusion protocol for networked multi-agent systems based on both the structure of the network and the priority of agents. The agents (nodes in the network) interact with their neighbors for the diffusion of information based on the weighted difference of the resources available at the neighboring nodes. We observe that the system finally reaches to a weighted agreement which is proportional to the priority of the nodes, or the degree of the nodes. We also perform a convergence analysis of the proposed protocol on both static networks as well as dynamic networks. We propose three different applications where such diffusion protocols can be used - (i) in the detection of link failure, (ii) for ensuring security and utilization of network resources, and (iii) to come up with a static fixed point convergence over a dynamic network. The impact of stability and convergence of the proposed diffusion protocol have also been analyzed through simulation results under different test scenarios. The observations from the simulation validate the theoretical findings of the diffusion protocol and its applicability under different applications.","2327-4697","","10.1109/TNSE.2019.2936468","DST, INDIA(grant numbers:DST-1401-CSE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807352","Link-failure detection;weighted-agreement;diffusion;multi-agent system;consensus;synchronization","Protocols;Convergence;Multi-agent systems;Diffusion processes;Switches;Eigenvalues and eigenfunctions;Dynamic scheduling","","10","","49","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Resilient Output Formation-Tracking of Heterogeneous Multi-Agent Systems Against Composite Attacks: A Fully-Distributed Event-Triggered Framework","X. Gong; T. Yu; G. Wen; Z. Feng; T. Huang","School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber and Science Engineering, Southeast University, Nanjing, China; Department of Systems Science, School of Mathematics, Southeast University, Nanjing, China; College of Automation, Harbin Engineering University, Harbin, China; Faculty of Computer Science and Control Engineering, Shenzhen University of Advanced Technology, Shenzhen, China",IEEE Transactions on Circuits and Systems I: Regular Papers,"","2024","PP","99","1","14","This study investigates the problem of designing countermeasures for resilient output time-varying formation-tracking of multi-agent systems (MASs) in a composite hazardous scenario consisting of various kinds of attacks, such as actuation attacks and denial-of-service (DoS) attacks. Combined with the digital twins concept, the above problem is decoupled into a DoS attack defense scheme on the Digital Twins Layer (DTL) and an actuation attack defense scheme on the Cyber-Physical Layer (CPL) by introducing a DTL with higher security and privacy. On the DTL, a novel Zeno-free event-triggered protocol with sampling state information, equipped with the backup topology countermeasure, is used to suppress the threat of DoS attacks. Note that the resilient protocol against DoS attacks is fully-distributed, which does not need prior knowledge of network algebraic connectivity and thus possesses sufficient scalability to large-scale networks. Moreover, the event-triggered mechanism can completely avoid Zeno phenomena by introducing a strict lower bound for the time interval between cascading triggered events. On the CPL, this study introduces a decentralized, adaptive, and resilient control strategy to address actuation attacks exhibiting exponentially unbounded destructiveness. It is proven that all followers can reach uniformly ultimately bounded convergence by the proposed two-layered control protocols. The effectiveness and resilience of the proposed algorithm are validated through a numerical simulation example.","1558-0806","","10.1109/TCSI.2024.3519726","National Natural Science Foundation of China(grant numbers:62325304,U22B2046,62088101,62403128); Fundamental Research Funds for the Central Universities(grant numbers:08002150138,3072024GH0404); Open Foundation of Key Laboratory of Cyberspace Security, Ministry of Education(grant numbers:KLCS20240403); Jiangsu Provincial Scientific Research Center of Applied Mathematics(grant numbers:BK20233002); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20210223,BK20241284); Hunan Provincial Natural Science Foundation of China(grant numbers:2020JJ5765); Nanjing Science and Technology Innovation Project for Overseas Scholars(grant numbers:4209012304); Start-Up Research Fund of Southeast University(grant numbers:RF1028623260); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817092","Composite attacks;fully-distributed event-triggered protocol;heterogeneous agent dynamics;resilient formation-tracking","Event detection;Protocols;Electronic mail;Topology;Digital twins;Decentralized control;Symmetric matrices;Resilience;Optimization;Multi-agent systems","","1","","","IEEE","27 Dec 2024","","","IEEE","IEEE Early Access Articles"
"Couple-Group Secure Consensus and Detection for a Kind of Heterogeneous Multi-Agent Systems With Time Delay and Cooperative-Competitive Relations Under Malicious Attacks","X. Pu; C. Liu; X. Sun","College of Mathematics and Computer Science, Tongling University, Tongling, China; School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Institute of Engineering, Chongqing, China",IEEE Access,"20 Jan 2023","2023","11","","5352","5364","In this article, the couple-group secure consensus of a kind of heterogeneous multi-agent systems (HMASs) with cooperative-competitive relation and time delays has been investigated if it receives malicious attacks. Based on cooperative-competitive relation and time delays, a new couple-group secure consensus protocol is designed. By applying the graph theory, linear algebra theory, probability theory, the linear combination theory and Getschgorin theorem, several sufficient conditions have been obtained to realize the couple-group secure consensus for this system. The obtained results also show the upper limitation of input delay can be computed if the parameters of system are given. It worth pointing out the topology of HMASs is no more needed to contain a spanning tree or meet with the balance of in or out degree in the obtained results. In additional, an adaptive function is added to speed up the convergence of consensus. Combined these obtained results with T-test, a novel detection algorithm has also been designed to determine that the nodes are security or not. Some examples have been given to prove the effectiveness of these obtained results and the improved secure detection algorithm.","2169-3536","","10.1109/ACCESS.2023.3235821","National Natural Science Foundation of China(grant numbers:61876200); Chongqing Postgraduate Research Innovation Project(grant numbers:CYS21312); Science and Technology Research Project of Chongqing Education Commission(grant numbers:KJZD-M202001901); General Projects of Chongqing Science and Technology Commission(grant numbers:cstc2020jcyj-msxmX0895); Key Research and Development Program of Anhui Province(grant numbers:202004a05020010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013675","HMASs;malicious attacks;couple-group secure consensus;time delay;cooperative-competitive relation","Delay effects;Topology;Sufficient conditions;Delay effects;Consensus protocol;Network topology;Multi-agent systems;Cooperative communication","","","","33","CCBY","10 Jan 2023","","","IEEE","IEEE Journals"
"Couple-Group Secure Consensus and Detection of Heterogeneous Multi-agent Systems with Cooperative-Competitive Relations and Deception Attacks","X. Pu; C. Liu","School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China",2023 35th Chinese Control and Decision Conference (CCDC),"1 Dec 2023","2023","","","589","595","This article investigates the couple-group secure consensus and detection of heterogeneous multi-agent systems (HMASs) with cooperative-competitive relation and deception attacks. According to cooperative-competitive relation, a new couple-group secure consensus protocol is designed. By applying the graph theory, linear algebra theory, probability theory and Getschgorin theorem, several results have been given to ensure the success of the couple-group secure consensus for this system. Based on these obtained results and T-test, a novel detection algorithm has been put forward to determine the security nodes or not. Several examples have been given to prove the effectiveness of these obtained results and the improved secure detection algorithm.","1948-9447","979-8-3503-3472-2","10.1109/CCDC58219.2023.10326990","National Natural Science Foundation of China; Chongqing Science and Technology Commission; Chongqing University of Posts and Telecommunications; Chongqing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10326990","HMASs;deception attacks;couple-group secure consensus;cooperative-competitive relation","Sufficient conditions;Frequency-domain analysis;Switches;Linear algebra;Control systems;Graph theory;Topology","","","","24","IEEE","1 Dec 2023","","","IEEE","IEEE Conferences"
"A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality","M. M. Kholoosi; M. A. Babar; R. Croft","CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia","2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)","16 Jan 2025","2024","","","107","117","Artificial Intelligence (AI) advancements have enabled the development of Large Language Models (LLMs) that can perform a variety of tasks with remarkable semantic understanding and accuracy. ChatGPT is one such LLM that has gained significant attention due to its impressive capabilities for assisting in various knowledge-intensive tasks. Due to the knowledge-intensive nature of engineering secure software, Chat-GPT’s assistance is expected to be explored for security-related tasks during the development/evolution of software. To gain an understanding of the potential of ChatGPT as an emerging technology for supporting software security, we adopted a twofold approach. Initially, we performed an empirical study to analyse the perceptions of those who had explored the use of ChatGPT for security tasks and shared their views on Twitter. It was determined that security practitioners view ChatGPT as beneficial for various software security tasks, including vulnerability detection, information retrieval, and penetration testing. Secondly, we designed an experiment aimed at investigating the practicality of this technology when deployed as an oracle in real-world settings. In particular, we focused on vulnerability detection and qualitatively examined ChatGPT outputs for given prompts within this prominent software security task. Based on our analysis, responses from ChatGPT in this task are largely filled with generic security information and may not be appropriate for industry use. To prevent data leakage, we performed this analysis on a vulnerability dataset compiled after the OpenAI data cut-off date from real-world projects covering 40 distinct vulnerability types and 12 programming languages. We assert that the findings from this study would contribute to future research aimed at developing and evaluating LLMs dedicated to software security.","","979-8-3503-8674-5","10.1109/TPS-ISA62245.2024.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835695","security;software vulnerability;large language model","Industries;Privacy;Accuracy;Systematics;Social networking (online);Semantics;Chatbots;Software;Security;Penetration testing","","","","45","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Secure Consensus Control on Multi-Agent Systems Based on Improved PBFT and Raft Blockchain Consensus Algorithms","J. Zhu; C. Lu; J. Li; F. -Y. Wang","College of Automation Engineering Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Automation Engineering Nanjing University of Aeronautics and Astronautics, Nanjing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Chinese Academy of Sciences, Beijing",IEEE/CAA Journal of Automatica Sinica,"1 Jul 2025","2025","12","7","1407","1417","There has been significant recent research on secure control problems that arise from the open and complex real-world industrial environments. This paper focuses on addressing the issue of secure consensus control in multi-agent systems (MASs) under malicious attacks, utilizing the practical Byzantine fault tolerance (PBFT) and Raft consensus algorithm in blockchain. Unlike existing secure consensus control algorithms that have strict requirements for topology and high communication costs, our approach introduces a node grouping methodology based on system topology. Additionally, we utilize the PBFT consensus algorithm for intergroup leader identity verification, effectively reducing the communication complexity of PBFT in large-scale networks. Furthermore, we enhance the Raft algorithm through cryptographic validation during followers' log replication, which enhances the security of the system. Our proposed consensus process not only identifies the identities of malicious agents but also ensures consensus among normal agents. Through extensive simulations, we demonstrate robust convergence, particularly in scenarios with the relaxed topological requirements. Comparative experiments also validate the algorithm's lower consensus latency and improved efficiency compared to direct PBFT utilization for identity verification and classical secure consensus control method mean subsequence reduced (MSR) algorithm.","2329-9274","","10.1109/JAS.2025.125300","Fundamental Research Funds for the Central Universities(grant numbers:NS2024021); National Natural Science Foundation of China(grant numbers:62103411); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11062708","Byzantine attacks;practical Byzantine fault tolerance (PBFT);Raft;secure consensus control","Fault tolerance;Privacy;Uncertainty;Network topology;Fault tolerant systems;Consensus algorithm;Consensus control;Blockchains;Topology;Multi-agent systems","","","","30","","1 Jul 2025","","","IEEE","IEEE Journals"
"On ChatGPT: Perspectives from Software Engineering Students","K. Hanifi; O. Cetin; C. Yilmaz","Ericsson Research Turkey, Istanbul, Turkey; Sabanci University, Istanbul, Turkey; Sabanci University, Istanbul, Turkey","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","25 Dec 2023","2023","","","196","205","ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students’ reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students’ awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT’s productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications.","2693-9177","979-8-3503-1958-3","10.1109/QRS60937.2023.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366692","ChatGPT;software engineering;academic education;generative AI;Large Language Models","Surveys;Software quality;Chatbots;Reliability engineering;Reflection;Software reliability;Security","","3","","29","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"On Prompt Sensitivity of ChatGPT in Affective Computing","M. M. Amin; B. W. Schuller","EIHW - Chair of Embedded Intelligence for Health Care and Wellbeing, University of Augsburg, Germany; EIHW - Chair of Embedded Intelligence for Health Care and Wellbeing, University of Augsburg, Germany",2024 12th International Conference on Affective Computing and Intelligent Interaction (ACII),"24 Apr 2025","2024","","","203","209","Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top- $p$ parameter in Nucleus sampling, dictating how conservative or creative the model should be during generation. Furthermore, we explore the efficacy of several prompting ideas, where we explore how giving different incentives or structures affect the performance. Our evaluation takes into consideration performance measures on the affective computing tasks, and the effectiveness of the model to follow the stated instructions, hence generating easy-to-parse responses to be smoothly used in downstream applications.","2156-8111","979-8-3315-1643-7","10.1109/ACII63134.2024.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10970364","Prompt Engineering;Prompting;ChatGPT;Foundation Models;Affective Computing","Temperature sensors;Temperature measurement;Affective computing;Sentiment analysis;Toxicology;Foundation models;Sensitivity analysis;Computational modeling;Chatbots;Prompt engineering","","1","","26","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"Optimizing Patient-Manager Interactions in Chronic Care Using Generative Artificial Intelligence QA Dialogue Systems","H. -W. Hu; F. -Y. Chen; Y. -C. Chen; M. -H. Lee; J. -Y. Yang; C. -W. Lin; W. -M. Lin","Department of Information and Communications Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Department of Artificial Intelligence in Healthcare, International Academia of Biomedical Innovation Technology, Reno, USA; MedTech Commercialization Center, Show Chwan Memorial Hospital, Changhua, Taiwan; Taipei Dialysis Clinic, Taipei, Taiwan; International Academia of Biomedical Innovation Technology, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Executive, LaplaceAI Co.Ltd., Taipei, Taiwan","2024 IEEE 6th Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)","20 Feb 2025","2024","","","96","99","Chronic disease management requires continuous care to prevent exacerbations, yet providing 24/7 accessible medical advice is a significant challenge for care providers. The current model of periodic patient visits with standard dialogue responses fails to adequately address the individualized needs of patients and caregivers. This lack of personalized guidance undermines treatment adherence and satisfaction. To bridge this gap, we developed a novel approach leveraging generative AI (GAI) to optimize patient-manager interactions. Focusing on prevalent chronic conditions such as diabetes, chronic kidney disease, and dementia, we created intelligent dialogue agents that deliver tailored, actionable nursing recommendations aligning with each case's unique circumstances. The developed methodology began by curating a corpus of 30 frequently asked questions on home care, emotional support, and social factors from online patient data across the three diseases. We employed prompt engineering to precisely define the virtual roles of nurses and physicians while implementing a “Rephrase and Respond” (RAR) protocol to enhance query comprehension and generate reliable solutions. The RAR approach solves problems by question restating, followed by contextualized recommendations from the language model. Clinical expert feedback iteratively refined the system's outputs. The evaluation result showed an average gain of 10% in response and an increase of 5% in readability after optimization. The optimized RAR method of large language models effectively improved the quality of nursing advice for chronic disease, aligned with patients' emotional and social needs. The RAR method in medical advisory areas, including chronic disease management and rehabilitation care, enhances the quality and practicality of nursing advice in these domains.","","979-8-3503-9613-3","10.1109/ECBIOS61468.2024.10885472","Industrial Technology Research Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885472","generative artificial intelligence;remote case management;prompt engineering;role-aligned R","Protocols;Large language models;Medical services;Reliability engineering;Social factors;Prompt engineering;Sustainable development;Standards;Optimization;Diseases","","","","11","IEEE","20 Feb 2025","","","IEEE","IEEE Conferences"
"Privacy-Diffusion: Privacy-Preserving Stable Diffusion Without Homomorphic Encryption","P. -C. Hsu; Z. Yu; S. Mise; H. Miyaji","Animechain.ai Inc., California, USA; Amazon, California, USA; Animechain.ai Inc., Tokyo, Japan; Ritsumeikan University, Osaka, Japan",2025 IEEE International Conference on Consumer Electronics (ICCE),"26 Mar 2025","2025","","","1","4","Text-to-image generation is trending in the generative AI field. Stable Diffusion is the state-of-the-art among open-source projects. Many artists and service providers customize the diffusion model for special textures. However, there is no protection for the privacy of the user's input text prompt, output image, and the customized model on the server. Privacy is crucial for user trust and protecting intellectual property. Existing privacy-preserving diffusion models use fully homomorphic encryption (FHE), which is time-consuming and can degrade image quality. We propose Privacy-Diffusion, a framework that preserves privacy without FHE by leveraging the irreversible properties of neural network layers and the property that in the diffusion process, the predicted noise is a normalized Gaussian distribution. Our framework protects clients' input text prompts and generated images from the server and safeguards customized models from clients. Compared with existing research HE-diffusion which spent 200% extra time and visible quality loss, our protocol can reach the same security level with only 4% extra time and has no quality loss. To our knowledge, we are the first to achieve this goal without FHE while maintaining high-quality image output.","2158-4001","979-8-3315-2116-5","10.1109/ICCE63647.2025.10929778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929778","AI Security;Privacy ML;Stable Diffusion;Generative AI","Privacy;Protocols;Generative AI;Noise;Text to image;Diffusion models;Servers;Security;Homomorphic encryption;Protection","","2","","19","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Anonymous-Diffusion: Blockchain-Based Privacy-Preserving Stable Diffusion","P. -C. Hsu; Z. Yu; N. Ghafoori; S. Mise; H. Miyaji","Animechain.ai Inc., California, USA; Amazon, California, USA; Osaka University, Osaka, Japan; Animechain.ai Inc., Tokyo, Japan; Ritsumeikan University, Osaka, Japan",2025 1st International Conference on Consumer Technology (ICCT-Pacific),"30 May 2025","2025","","","1","4","The field of generative AI is currently seeing a surge in text-to-image generation. Among open-source projects, Stable Diffusion stands out as the state-of-the-art. Artists and service providers often customize diffusion models for unique textures. However, there is a lack of privacy protection for users' input text prompts, output images, and customized models on servers. Ensuring privacy is essential for user trust and safeguarding intellectual property. Current privacy-preserving diffusion models rely on fully homomorphic encryption (FHE), which is time-intensive and can compromise image quality. We introduce Anonymous-Diffusion, a diffusion as a service (DAAS) framework. This framework maintains privacy without using FHE by exploiting the irreversible nature of neural network layers and the characteristic that predicted noise in the diffusion process follows a normalized Gaussian distribution. Furthermore, we ensure anonymity by Smart Contract and Blockchain. User can use this service on demand anonymously. In comparison to existing research like HE-diffusion, which incurs a 200% time overhead and noticeable quality degradation, our protocol achieves the same level of security with only a 4% time overhead and no loss in image quality. To our knowledge, this is the first solution to achieve these results without FHE while preserving high-quality image output.","","979-8-3315-0412-0","10.1109/ICCT-Pacific63901.2025.11012859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012859","AI Security;Privacy ML;Stable Diffusion;Generative AI","Image quality;Privacy;Generative AI;Smart contracts;Text to image;Surge protection;Diffusion models;Servers;Security;Surges","","","","19","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Toward a Network Intrusion Detection System for Geographic Data","S. Ouiazzane; M. Addou; F. Barramou","Team (ASYR) - Laboratory of Systems Engineering (LaGeS), Hassania School of Public Works EHTP, Casablanca, Morocco; Team (ASYR) - Laboratory of Systems Engineering (LaGeS), Hassania School of Public Works EHTP, Casablanca, Morocco; Team (ASYR) - Laboratory of Systems Engineering (LaGeS), Hassania School of Public Works EHTP, Casablanca, Morocco",2020 IEEE International conference of Moroccan Geomatics (Morgeo),"22 Jun 2020","2020","","","1","7","The objective of this paper is to propose a model of a distributed intrusion detection system based on the multi-agent paradigm and the distributed file system (HDFS). Multi-agent systems (MAS) are very suitable to intrusion detection systems as they can address the issue of geographic data security in terms of autonomy, distribution and performance. The proposed system is based on a set of autonomous agents that cooperate and collaborate with each other to effectively detect intrusions and suspicious activities that may impact geographic information systems. Our system allows the detection of known and unknown computer attacks without any human intervention (Security Experts) unlike traditional intrusion detection systems that rely on knowledge bases as a mechanism to detect known attacks. The proposed model allows a real time detection of known and unknown attacks within large networks hosting geographic data.","","978-1-7281-5806-8","10.1109/Morgeo49228.2020.9121878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121878","Intrusion detection;MAS;Multi Agent System;Big Data;Security;IDS;DIDS;autonomy;distribution;Anomaly detection;Big networks;Geographical System;GIS.","Geomagnetism;File systems;Data security;Conferences;Knowledge based systems;Network intrusion detection;Real-time systems","","3","","31","IEEE","22 Jun 2020","","","IEEE","IEEE Conferences"
"What does CLIP know about a red circle? Visual prompt engineering for VLMs","A. Shtedritski; C. Rupprecht; A. Vedaldi","Visual Geometry Group, University of Oxford; Visual Geometry Group, University of Oxford; Visual Geometry Group, University of Oxford",2023 IEEE/CVF International Conference on Computer Vision (ICCV),"15 Jan 2024","2023","","","11953","11963","Large-scale Vision-Language Models, such as CLIP, learn powerful image-text representations that have found numerous applications, from zero-shot classification to text-to-image generation. Despite that, their capabilities for solving novel discriminative tasks via prompting fall behind those of large language models, such as GPT-3. Here we explore the idea of visual prompt engineering for solving computer vision tasks beyond classification by editing in image space instead of text. In particular, we discover an emergent ability of CLIP, where, by simply drawing a red circle around an object, we can direct the model’s attention to that region, while also maintaining global information. We show the power of this simple approach by achieving state-of-the-art in zero-shot referring expressions comprehension and strong performance in keypoint localization tasks. Finally, we draw attention to some potential ethical concerns of large language-vision models.","2380-7504","979-8-3503-0718-4","10.1109/ICCV51070.2023.01101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10376723","","Location awareness;Visualization;Computer vision;Ethics;Analytical models;Computational modeling;Training data","","56","","66","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"Generative AI for Software Test Modelling with a focus on ERP Software","A. Garg; D. Sharma","Department of Computer Science and Engineering, Amity University, Noida, India; Department of Computer Science and Engineering, Amity University, Noida, India","2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)","20 Mar 2024","2023","","","187","193","Generative AI in this context refers to the type of artificial intelligence that can generate content or give new information based on patterns it has learned. In the case of software testing, it refers to the use of generative AI to model or for the creation of test scenarios, test cases or objects for ERP (Enterprise Resource Planning) software. The special focus on ERP software means that generative AI-based techniques have been particularly designed and optimized for the purpose of software testing. It does take into account the unique features and complexity of the ERP systems which allows for more effective and accurate testing. The problem with the existing chatbots is that they are not integrated with generative AI and the training is either not properly done or the data used for training is biased. The objective of this work is to develop a chatbot integrated with the generative AI-based framework and develop training data to cater to user needs. Methods and tools used in this approach are the OpenAI's API used for integrating chatbot with the generative AI-based software, Postman API has also been used to send and receive API requests and prompts and completions to be generated using Python code. The result of this approach is that a chatbot has been developed which develops test cases and scenarios, requests sent and received successfully and prompts and completions have been successfully generated using Python code. To state it simply, generative AI for software test modelling with a focus on ERP software means creating test cases and scenarios using AI and generating them automatically which helps testers ensure that the software is working correctly and meets the needs of the business operations.","","979-8-3503-4438-7","10.1109/ICAICCIT60255.2023.10466102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10466102","","Training;Software testing;Codes;Generative AI;Training data;Software quality;Chatbots","","2","","11","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Using LLM for Mining and Testing Constraints in API Testing","M. -H. Huynh; Q. -T. Le; T. N. Nguyen; V. Nguyen","Katalon LLC, Ho Chi Minh City, Vietnam; Katalon LLC, Ho Chi Minh City, Vietnam; Computer Science Department, University of Texas at Dallas, Texas, USA; University of Science, VNU-HCM Katalon LLC, Ho Chi Minh City, Vietnam",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","2486","2487","CCS Concepts• Software and its engineering → Software testing and debugging","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765048","Large Language Models;API Testing","Software testing;Debugging;Software;Data mining;Test pattern generators;Software engineering","","","","10","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Concern-Based Management of Software Design Complexity","J. Lefever","Drexel University, Philadelphia, USA",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","102","106","Managing design-level complexity in industrial software systems remains challenging, often resulting in error-prone, difficult-to-maintain codebases. Despite extensive research on metrics and refactoring tools, architects frequently rely more on intuition than on algorithmic approaches, highlighting the need for approaches that better align with expert judgment. This research proposes that large language models (LLMs), trained specifically to generate a “concern space,” can organize program entities based on shared concerns, facilitating more meaningful metrics, refactoring suggestions, and system-level design views. Initial work with ConcernBERT, a purpose-trained LLM, shows significant advancements in representing cohesion over traditional concept-based methods. ConcernBERT uses a contrastive learning approach, where embeddings are learned by positioning entities addressing similar concerns close together while distancing unrelated ones. Complementing this, the Deicide algorithm identifies responsibility modules within classes, generating decomposition recommendations that align with historical maintenance patterns. Preliminary results are promising: ConcernBERT demonstrates strong performance in embedding entities by concern, closely aligning with expert-annotated ground truth. Future efforts will focus on applying these techniques across entire software systems.","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024332","software maintainability;software design;metrics;refactoring","Software design;Large language models;Software algorithms;Contrastive learning;Software systems;Extraterrestrial measurements;Complexity theory;Maintenance;System-level design;Software engineering","","","","33","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"LLM-Based Framework for Administrative Task Automation in Healthcare","S. A. Gebreab; K. Salah; R. Jayaraman; M. Habib ur Rehman; S. Ellaham","Dept. of Computer & Communication Engineering, Khalifa University, Abu Dhabi, UAE; Dept. of Computer & Communication Engineering, Khalifa University, Abu Dhabi, UAE; Dept. of Management Science & Engineering, Khalifa University, Abu Dhabi, UAE; Dept. of Biomedical Engineering & Imaging Sciences, King's College London, London, UK; Improvement Dept., Heart & Vascular Institute & Continuous, Cleveland Clinic, Abu Dhabi, UAE",2024 12th International Symposium on Digital Forensics and Security (ISDFS),"15 May 2024","2024","","","1","7","Artificial Intelligence (AI) has been transformative in the healthcare sector, leading to enhanced precision in medical diagnosis, more effective treatment options, and a significant improvement in patient safety. However, computer-based administrative tasks, such as retrieval of medical and health records, patient registration, medical billing, filing and documentation, and appointment scheduling, still impose a heavy burden on healthcare professionals, causing a reduced quality of care and efficiency. In light of these challenges, this paper proposes a large language model (LLM)-based multi-agent framework designed to automate some of the administrative work in clinical settings. In our proposed solution, these LLM agents coordinate to parse instructions, breakdown tasks, and execute a sequence of actions in a workflow. They are equipped to not only execute documentation process at the database level but also operate directly on web-based electronic medical record (EMR) platforms. Moreover, the framework integrates data sources through a retrieval-augmented generation (RAG) system to allow streamlined interaction with patient information and medical records, mediated through an agent interface. The framework is designed with security in mind to defend against malicious prompts. We demonstrate the practicality of our solution by testing on various complex tasks that require the use of multiple tools and an EMR website. The result show the framework's effectiveness in handling diverse healthcare administrative tasks.","2768-1831","979-8-3503-3036-6","10.1109/ISDFS60797.2024.10527275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527275","large language models;autonomous agents;health-care;electronic medical record;task automation;retrieval aug-mented generation","Processor scheduling;Soft sensors;Documentation;Safety;Security;Medical diagnosis;Task analysis","","19","","26","IEEE","15 May 2024","","","IEEE","IEEE Conferences"
"Agent-based tool for model-based test case generation and execution","J. Ramírez-Méndez; C. Quesada-López; M. Jenkins","Universidad de Costa Rica, San Pedro, Costa Rica; Universidad de Costa Rica, San Pedro, Costa Rica; Universidad de Costa Rica, San Pedro, Costa Rica",2021 IEEE V Jornadas Costarricenses de Investigación en Computación e Informática (JoCICI),"14 Jun 2022","2021","","","1","6","Model-Based Testing (MBT) aims to automate test case generation and execution from abstract models representing the behavior of the system under test (SUT). MBT stages parallelization and monitoring could improve the overall process performance in complex systems and resource shortages. Agent-based software testing (ABST) consists of intelligent agents applied to complex software testing tasks. ABST approaches could enhance software testing due to multi-agent systems autonomy, independence, parallel activation, and decision-making features. This study presents an agent-based tool for MBT case generation and execution. The tool comprises two components: the MBT component based on the MBT4J tool and a JADE multi-agent component. The multi-agent component implements a coordinator agent (CA), a monitor agent (MA), and several test case generation and execution agents (TGEA). The responsibilities of agents include test case planning, generation and execution, and results synthesis. The results suggest that low levels of TGEA achieve acceptable coverage metrics in straightforward models. Productivity provides the best results in the first execution cycles.","","978-1-6654-9832-6","10.1109/JoCICI54528.2021.9794354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794354","intelligent agents;software testing;model-based testing (MBT);agent-based testing (ABST)","Software testing;Productivity;Measurement;Computational modeling;Decision making;Planning;Intelligent agents","","1","","0","IEEE","14 Jun 2022","","","IEEE","IEEE Conferences"
"Sinema: Semantics-driven Intelligent Network Management using AI assistance","T. Sulthana; A. S. Jourabchi; S. Song; B. -Y. Choi","School of Science and Engineering, University of Missouri-Kansas City, Kansas City, Missouri, USA; School of Science and Engineering, University of Missouri-Kansas City, Kansas City, Missouri, USA; School of Science and Engineering, University of Missouri-Kansas City, Kansas City, Missouri, USA; School of Science and Engineering, University of Missouri-Kansas City, Kansas City, Missouri, USA",2024 IEEE 10th International Conference on Collaboration and Internet Computing (CIC),"15 Jan 2025","2024","","","35","43","The growing complexity of network infrastructures has resulted in the generation of vast amounts of network management data, presenting significant challenges in efficient and effective network reliability and security management. Traditional log analysis techniques are increasingly insufficient to handle this complexity, necessitating the development of more advanced solutions. In this paper, we propose Sinema, a novel approach that integrates a knowledge graph with an AI-agent for network management data analysis. The system transforms raw Syslog data into a structured graph format, enabling sophisticated querying and analysis. Sinema’s performance is evaluated across two key dimensions: retrieval and analysis. Regarding the efficiency of data retrieval, quantitative performance metrics are used to assess query accuracy and completeness. As for the effectiveness of analysis, a qualitative measure is employed, focusing on the diversity and correctness of the analysis questions the system can answer. The evaluation results demonstrate Sinema’s robustness in handling complex queries and its capability to provide accurate insights, contributing a scalable and efficient framework for network management data analysis that enhances proactive network management and threat detection.","","979-8-3503-8670-7","10.1109/CIC62241.2024.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835770","Network Management;Autonomous Agents;Large Language Models;Knowledge Graphs;GraphRAG;Syslog","Measurement;Data analysis;Accuracy;Security management;Transforms;Knowledge graphs;Threat assessment;Robustness;Complexity theory;Internet","","1","","20","IEEE","15 Jan 2025","","","IEEE","IEEE Conferences"
"7 Unraveling the Challenges: Navigating the Barriers to Generative AI Success","A. Banafa",NA,Artificial Intelligence in Action: Real-World Applications and Innovations,"","2025","","","41","46","This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly ""casual AI,"" and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.","","9788770046190","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948921.pdf&bkn=10948919&pdfType=chapter","","","","","","","","3 Apr 2025","","","River Publishers","River eBook Chapters"
"38 The Rise of the AI Whisperers: New Jobs in the Age of Generative AI","A. Banafa",NA,Artificial Intelligence in Action: Real-World Applications and Innovations,"","2025","","","245","252","This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly ""casual AI,"" and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.","","9788770046190","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948966.pdf&bkn=10948919&pdfType=chapter","","","","","","","","3 Apr 2025","","","River Publishers","River eBook Chapters"
"1 Generative AI and Other Types of AI","A. Banafa",NA,Artificial Intelligence in Action: Real-World Applications and Innovations,"","2025","","","3","10","This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly ""casual AI,"" and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.","","9788770046190","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948957.pdf&bkn=10948919&pdfType=chapter","","","","","","","","3 Apr 2025","","","River Publishers","River eBook Chapters"
"2 Challenges in Learning Generative AI","A. Banafa",NA,Artificial Intelligence in Action: Real-World Applications and Innovations,"","2025","","","11","14","This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly ""casual AI,"" and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.","","9788770046190","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948963.pdf&bkn=10948919&pdfType=chapter","","","","","","","","3 Apr 2025","","","River Publishers","River eBook Chapters"
"Probing the Situational Reasoning Capabilities of ChatGPT","A. Salfinger; L. Snidaro","Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy; Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy",2025 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA),"15 Jul 2025","2025","","","87","94","Information exchanged in naturalistic human communication is implicitly grounded in its situational context. In particular, messages exchanged via social media on on-going events, like large-scale crisis events, often assume that the actual situational context is shared by the correspondents and thus not made explicit in the message text itself. Since these messages cannot be accurately interpreted without factoring in this situational context, Natural Language Processing (NLP) is a challenging task in these domains. The breakthrough capabilities on fine-grained contextual understanding and Natural Language Inference (NLI) of the recently introduced Large Language Models (LLMs), however, suggest novel avenues for tackling this problem. In the present work, we thus aim to analyze current LLMs' situation understanding and situational inference capabilities, seeking to answer the question: How well do LLMs understand situational context? We contribute i) a formalization of situational context as a conditioning factor affecting the outcome of the target task, and ii) an empirical examination of formulating this situation conditioning as a prompt engineering problem, explored on the target task of Named Entity Recognition (NER) on social media analysis for crisis computing.","2379-1675","979-8-3315-3308-3","10.1109/CogSIMA64436.2025.11079493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11079493","Large Language Models;Crisis Computing;Situation Awareness;Soft Fusion;High-Level Information Fusion","Social networking (online);Large language models;Named entity recognition;Chatbots;Cognition;Prompt engineering","","","","24","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"LLM-Assisted Generation of SWRL Rules from Natural Language","A. Soularidis; K. Kotis; M. Lamolle; Z. Mejdoul; G. Lortal; G. Vouros","Depart. of Cultural Technology and Communication, i-Lab, University of Aegean, Mytilene, Greece; Depart. of Cultural Technology and Communication, i-Lab, University of Aegean, Mytilene, Greece; Laboratoire d’ Intelligence Artificielle et Sémantique des Données (LIASD), Université Paris8, Montreuil, France; Thales, cortAIx Labs, IUT de Montreuil Université Paris8, Palaiseau, France; Thales, cortAIx Labs, Thalès Research Technology, Palaiseau, France; Depart. of Digital Systems, AI-Lab, University of Piraeus, Piraeus, Greece",2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE),"16 May 2025","2024","","","7","12","Recently, Large Language Models (LLMs) have attracted great attention due to their remarkable performance in human-like text generation and reasoning skills (although their memory and hallucination problems still remain key issues to tackle more efficiently). LLMs have been applied to various application domains, including Knowledge Graph (KG) generation, question and answering over KGs and text-to-SPARQL translation. In this work, we investigate the capabilities of LLMs in text-to-SWRL translation, i.e., translation of Natural Language (NL) rules into Semantic Web Rule Language (SWRL) rules, put in the context of an industrial Ontology Engineering (OE) environment called GLUON, presenting our first experimental results. The aim of this work is to identify the level of automation that is adequate for the LLM to generate well-formed SWRL rules, towards the development of an LLM-based framework, as a plugin to the GLUON OE environment. In this direction we leverage and combine the reasoning capabilities of GPT-4o model, the Retrieval-Augmented Generation (RAG) technology, and prompt engineering. We employ quantitative and qualitative metrics to evaluate the generated SWRL rules, focusing on the correct syntax and the level of human intervention.","2831-7203","979-8-3315-1704-5","10.1109/AIxDKE63520.2024.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990088","SWRL;Large Language Models (LLM);Retrieval-Augmented Generation (RAG);Ontology Engineering","Semantic Web;Translation;Automation;Large language models;Retrieval augmented generation;Memory management;Ontologies;Syntactics;Cognition;Prompt engineering","","","","8","IEEE","16 May 2025","","","IEEE","IEEE Conferences"
"ComplexCodeEval: A Benchmark for Evaluating Large Code Models on More Complex Code","J. Feng; J. Liu; C. Gao; C. Y. Chong; C. Wang; S. Gao; X. Xia","University of Electronic Science and Technology of China, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Huawei, Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; Huawei, Shenzhen, China; Huawei, Shenzhen, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1895","1906","In recent years, with the widespread attention of academia and industry on the application of large language models (LLMs) to code-related tasks, an increasing number of large code models (LCMs) have been proposed and corresponding evaluation benchmarks have continually emerged. Although existing evaluation benchmarks are helpful for comparing different LCMs, they may not reflect the performance of LCMs in various development scenarios. Specifically, they might evaluate model performance in only one type of scenario (e.g., code generation or code completion), whereas real development contexts are diverse and may involve multiple tasks such as code generation, code completion, API recommendation, and test function generation. Additionally, the questions may not originate from actual development practices, failing to capture the programming challenges faced by developers during the development processTo address the aforementioned issues, we propose ComplexCodeEval, a new benchmark for evaluating the performance of LCMs in various development scenarios. ComplexCodeEval includes 3,897 Java samples from 1,055 high-star GitHub repositories and 7,184 Python samples from 2,107 high-star repositories. Each function sample in ComplexCodeEval contains multiple annotations (e.g., function signatures, docstrings and reference APIs) to accommodate various downstream tasks. Furthermore, to better reflect diverse development scenarios, each function sample is required to originate from a repository that depends on at least one selected library (based on popularity), and each function sample must invoke at least one API from the selected library. Additionally, each function sample has multiple timestamps to avoid data leakage. Based on ComplexCodeEval, we evaluate the performance of ten LCMs across four tasks (i.e., code generation, code completion, API recommendation, and test case generation) to explore their performance in complex development environments. Furthermore, we conduct an in-depth analysis of the impact of context and data leakage on model performance. Our experimental results reveal several key findings. For instance, LCMs exhibit varying performance across different coding tasks. Additionally, rich contextual information can greatly enhance the performance of LCMs. Moreover, using leaked data for evaluation may lead to an overestimation of model performance, resulting in inaccurate evaluation outcomes that deviate from the performance in practiceCCS Concepts• Software and its engineering → Automatic programming.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764817","Large Language Models;Code Intelligence;Benchmark","Codes;Pipelines;Benchmark testing;Data models;Libraries;Software;Context modeling;Software engineering;Software development management;Python","","","","37","","29 Nov 2024","","","IEEE","IEEE Conferences"
"I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots","G. A. Abbo; T. Belpaeme","IDLab-AIRO, Ghent University - imec, Ghent, Belgium; IDLab-AIRO, Ghent University - imec, Ghent, Belgium",2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI),"30 Apr 2025","2025","","","1176","1180","In the rapidly evolving landscape of human-robot interaction, the integration of vision capabilities into conversational agents stands as a crucial advancement. This paper presents a ready-to-use implementation of a dialogue manager that leverages the latest progress in Large Language Models (e.g., GPT-4o mini) to enhance the traditional text-based prompts with real-time visual input. LLMs are used to interpret both textual prompts and visual stimuli, creating a more contextually aware conversational agent. The system's prompt engineering, incorporating dialogue with summarisation of the images, en-sures a balance between context preservation and computational efficiency. Six interactions with a Furhat robot powered by this system are reported, illustrating and discussing the results obtained. The system can be customised and is available as a stand-alone application, a Furhat robot implementation, and a ROS2 package.","","979-8-3503-7893-1","10.1109/HRI61500.2025.10973830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973830","Large Language Model;Vision Language Model;Dialogue;HRI;Conversation;Prompt Engineering;ROS","Visualization;Image resolution;Limiting;Large language models;Machine vision;Social robots;Human-robot interaction;Oral communication;Real-time systems;Prompt engineering","","","","19","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"Toward an Embedded Multi-agent System Methodology and Positioning on Testing","C. Barnier; O. -E. -K. Aktouf; A. Mercier; J. -P. Jamont","Grenoble, INP, LCIS, Univ. Grenoble Alpes, Valence, France; Grenoble, INP, LCIS, Univ. Grenoble Alpes, Valence, France; Grenoble, INP, LCIS, Univ. Grenoble Alpes, Valence, France; Grenoble, INP, LCIS, Univ. Grenoble Alpes, Valence, France",2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW),"16 Nov 2017","2017","","","239","244","Like all systems, multi-agent systems need to be verified during the design cycle. But the test of multi-agent systems is more diffi-cult than the test of classic software. Indeed, it implies to test more than agent functionalities: individual agent behavior, inter-action between agents and global system need to be tested. Sever-al testing methods compensate these difficulties, but do not cover all the aspects of multi-agent systems. In this paper, we compare software testing and multi-agent systems testing and particularly in embedded context. Then major multi-agent system testing techniques are analyzed, with the AEIO facets for multi-agent systems. Finally, we propose a strategy to conduct the testing activity for embedded MAS.","","978-1-5386-2387-9","10.1109/ISSREW.2017.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109290","MAS Testing;Embedded Multi-Agent Testing;Interaction Protocol Testing","Embedded systems;Organizations;Multi-agent systems;Hardware;Software testing","","7","","31","IEEE","16 Nov 2017","","","IEEE","IEEE Conferences"
"Enhancing Physical Layer Communication Security Through Generative AI with Mixture of Experts","C. Zhao; H. Du; D. Niyato; J. Kang; Z. Xiong; D. I. Kim; X. Shen; K. B. Letaief","Nanyang Technological University, Singapore; University of Hong Kong, Hong Kong, China; Nanyang Technological University, Singapore; Guangdong University of Technology, China; Singapore University of Technology and Design, Singapore; Sungkyunkwan University, South Korea; University of Waterloo, Canada; Hong Kong University of Science and Technology, Hong Kong",IEEE Wireless Communications,"27 May 2025","2025","32","3","176","184","AI technologies have become increasingly adopted in wireless communications. As an emerging type of AI technologies, generative artificial intelligence (GAI) is gaining attention in communication security. Due to its powerful learning ability, GAI models have demonstrated superiority over conventional AI methods. However, GAI still has several limitations, including high computational complexity and limited adaptability. Mixture of experts (MoE) technology, which uses multiple expert models for prediction through a gate mechanism, proposes possible solutions. In this article, we first review GAI model applications in physical layer communication security, discuss limitations, and explore how MoE can help GAI overcome these limitations. Furthermore, we propose an MoE-enabled GAI framework for network optimization problems for communication security. To demonstrate the framework's effectiveness, we provide a case study in a cooperative-friendly jamming scenario. The experimental results show that the MoE-enabled framework effectively assists the GAI algorithm, solves its limitations, and enhances communication security.","1558-0687","","10.1109/MWC.001.2400150","National Research Foundation; Infocomm Media Development Authority; National Natural Science Foundation of China(grant numbers:62102099); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2023A151514 0137); National Research Foundation of Korea(grant numbers:2021R1A2C2007638); MSIT; ITRC(grant numbers:IITP-2023-RS-2023-002S8639); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10839236","","Wireless communication;Adaptation models;Generative AI;Computational modeling;Physical layer;Safety;Security;Jamming;Optimization","","2","","15","IEEE","13 Jan 2025","","","IEEE","IEEE Magazines"
"Software Vulnerability Detection with GPT and In-Context Learning","Z. Liu; Q. Liao; W. Gu; C. Gao","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",2023 8th International Conference on Data Science in Cyberspace (DSC),"8 Jan 2024","2023","","","229","236","Code vulnerability detection is a software security analysis technique that focuses on recognizing and resolving possible code vulnerabilities and weaknesses. Its primary objective is to mitigate the chances of malicious attacks and system failures. Vulnerabilities encompass mistakes, defects, or insecure programming methodologies found within the code, which can lead to security risks, service denials, data leaks, and various other concerns. Previous research has predominantly focused on deep learning models such as VulDeePecker, Russell, and SySeVR. With the advent of large language models, impressive advancements have been made in various domains, including natural language generation, text classification, and sentiment analysis. However, there is currently no effective method for utilizing large language models in vulnerability detection. Therefore, this study explores and validates the application of such models for code vulnerability detection. In this paper we present a context-based learning approach to enhance the capability of code vulnerability detection named VUL-GPT. Our method combines code retrieval and code analysis, leveraging in-context learning to improve the performance of the GPT model in vulnerability detection. Specifically, we use GPT to generate analysis content for the test code and employ code retrieval methods such as BM-25 and TF-IDF to retrieve the most similar code snippet and its vulnerability information from the training set. Subsequently, we input them along with the test code and its analysis into the GPT model, leveraging the contextual learning ability of the large language model for vulnerability detection. Our experiments demonstrate that combining with code retrieval and code analysis, the GPT models can detect code vulnerability detection more effectively.","","979-8-3503-3103-5","10.1109/DSC59305.2023.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10381286","large language models;in-content learning;code retrieval","Training;Deep learning;Analytical models;Sentiment analysis;Codes;Text categorization;Software","","9","","43","IEEE","8 Jan 2024","","","IEEE","IEEE Conferences"
"Petri Nets Based Verification of Epistemic Logic and Its Application on Protocols of Privacy and Security","L. He; G. Liu","Department of Computer Science, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China",2020 IEEE World Congress on Services (SERVICES),"21 Dec 2020","2020","","","25","28","Epistemic logic can specify many design requirements of privacy and security of multi-agent systems (MAS). The existing model checkers of epistemic logic use some programming languages to describe MAS, induce Kripke models as the behavioral representation of MAS, apply Ordered Binary Decision Diagrams (OBDD) to encode Kripke models to solve their state explosion problem and verify epistemic logic based on the encoded Kripke models. However, these programming languages are usually non-intuitive. More seriously, their OBDD-based model checking processes are often time-consuming due to their dynamic variable ordering for OBDD. Therefore, we define Knowledge-oriented Petri Nets (KPN) to intuitively describe MAS, induce similar reachability graphs as the behavioral representation of KPN, apply OBDD to encode all reachable states, and finally verify epistemic logic. Although we also use OBDD, we adopt a heuristic method for the computation of a static variable order instead of dynamic variable ordering. More importantly, while verifying an epistemic formula, we dynamically generate its needed similar relations, which makes our model checking process much more efficient. In this paper, we introduce our work.","2642-939X","978-1-7281-8203-2","10.1109/SERVICES48979.2020.00019","National Key Research and Development Program of China(grant numbers:2017YF-B1001804); Fundamental Research Funds for the Central Universities of China(grant numbers:22120190198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284162","model checking;epistemic logic;CTLK;Petri nets;OBDD","Privacy;Computer languages;Protocols;Petri nets;Model checking;Tools;Security","","2","","13","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"Azure OpenAI Essentials: A practical guide to unlocking generative AI-powered innovation with Azure OpenAI","A. Mukherjee; A. Saladi; M. Casalaina",NA; NA; NA,Azure OpenAI Essentials: A practical guide to unlocking generative AI-powered innovation with Azure OpenAI,"","2025","","","","","Build innovative, scalable, and ethical AI solutions by harnessing the full potential of generative AI with this exhaustive guideKey FeaturesExplore the capabilities of Azure OpenAI’s LLMsCraft end-to-end applications by utilizing the synergy of Azure OpenAI and Cognitive ServicesDesign enterprise-grade GenAI solutions with effective prompt engineering, fine-tuning, and AI safety measuresPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionFind out what makes Azure OpenAI a robust platform for building AI-driven solutions that can transform how businesses operate. Written by seasoned experts from Microsoft, this book will guide you in understanding Azure OpenAI from fundamentals through to advanced concepts and best practices. The book begins with an introduction to large language models (LLMs) and the Azure OpenAI Service, detailing how to access, use, and optimize its models. You'll learn how to design and implement AI-driven solutions, such as question-answering systems, contact center analytics, and GPT-powered search applications. Additionally, the chapters walk you through advanced concepts, including embeddings, fine-tuning models, prompt engineering, and building custom AI applications using LangChain and Semantic Kernel. You'll explore real-world use cases such as QnA systems, document summarizers, and SQLGPT for database querying, as well as gain insights into securing and operationalizing these solutions in enterprises. By the end of this book, you'll be ready to design, develop, and deploy scalable AI solutions, ensuring business success through intelligent automation and data-driven insights.What you will learnUnderstand the concept of large language models and their capabilitiesInteract with different models in Azure OpenAI using APIs or web interfacesUse content filters and mitigations to prevent harmful content generationDevelop solutions with Azure OpenAI for content generation, summarization, semantic search, NLU, code and image generation and analysisIntegrate Azure OpenAI with other Azure Cognitive services for enhanced functionalityApply best practices for data privacy, security, and prompt engineering with Azure OpenAIWho this book is forThis book is for software developers, data scientists, AI engineers, ML engineers, system architects, LLM engineers, IT professionals, product managers, and business professionals who want to learn how to use Azure OpenAI to create innovative solutions with generative AI. To fully benefit from this book, you must have both an Azure subscription and Azure OpenAI access, along with knowledge of Python.","","9781805122654","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10948558.pdf&bkn=10948557&pdfType=book","","","","","","","","3 Apr 2025","","","Packt Publishing","Packt Publishing eBooks"
"MAFOSS: Multi-Agent Framework using Open-Source Software","E. Jones; D. Adra; M. S. Miah","Electrical and Computer Engineering Department, Bradley University, USA; Electrical and Computer Engineering Department, Bradley University, USA; Electrical and Computer Engineering Department, Bradley University, USA",2019 7th International Conference on Mechatronics Engineering (ICOM),"9 Jan 2020","2019","","","1","6","This paper presents a new multi-agent framework using open-source software (MAFOSS). The proposed framework is a modular and cost-effective open-source hardware and software platform that is intended to help develop multiagent systems for research and education. Numerous multi-agent platforms have been developed in the literature to date that are used in various robotic applications, such as surveillance, target localization, cooperative estimation, among others. However, most of them are either tailored towards particular applications or driven by expensive software and hardware. The proposed MAFOSS system is developed for robotic applications, where a team of mobile agents (robots) is deployed to achieve a common goal. A major contribution of the MAFOSS system is the development of an open-hardware platform for differential-drive mobile robots (herein called “eduMOD” mobile robots). The software architecture of the current framework mostly relies on the robot operating system (ROS). Regardless of internal hardware and/or software architecture, appropriate actions can be applied to actuators of an individual or a team of mobile agents for controlling their motions. A few case studies have been conducted to evaluate the performance of MAFOSS.","","978-1-7281-2971-6","10.1109/ICOM47790.2019.8952052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952052","MAFOSS;multi-agent systems;mobile robots;motion control;sensors","Software architecture;Software algorithms;Mobile agents;Estimation;Robot sensing systems;Mobile robots;Motion control;Open source software;Multi-agent systems;Testing","","1","","16","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Large Language Model-enabled Vulnerability Investigation: A Review","Z. Pan; J. Liu; Y. Dai; W. Fan","Jiangsu Intelligent Connected, Vehicle Innovation Center; Xi'an Jiaotong, -Liverpool University; Tsinghua University Suzhou, Automotive Research Institute; Jiangsu Intelligent Connected, Vehicle Innovation Center",2024 International Conference on Intelligent Computing and Next Generation Networks (ICNGN),"14 Feb 2025","2024","","","01","05","In recent years, the integration of large language models (LLMs) into cybersecurity has demonstrated significant potential in enhancing vulnerability analysis. This paper provides a comprehensive review of current literature, focusing on the applications of LLMs in vulnerability discovery, exploitation, and validation. We examine various LLM-powered frameworks that have automated aspects of vulnerability analysis, reduced the time required for vulnerability identification, and improved the precision of vulnerability assessment. In addition, we discuss LLM-driven advancements in security vulnerability exploitation and validation, which facilitate more efficient and accurate mitigation. The contributions of this review include an extensive synthesis of existing studies, a proposed framework that high-lights the role of LLMs across different stages of the vulnerability lifecycle, and an outline of future research directions in LLM-based cybersecurity. Our findings aim to guide researchers and practitioners in developing robust, scalable, and automated cybersecurity solutions powered by LLMs.","","979-8-3315-2922-2","10.1109/ICNGN63705.2024.10871716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871716","Large Language Models;Vulnerability Discovery;Vulnerability Validation;Vulnerability Exploitation","Ethics;Accuracy;Reviews;Computational modeling;Scalability;Prevention and mitigation;Large language models;Robustness;Computer security;Next generation networking","","","","40","IEEE","14 Feb 2025","","","IEEE","IEEE Conferences"
"Multi-Agent-Based Technique for Fault Location, Isolation, and Service Restoration","H. F. Habib; T. Youssef; M. H. Cintuglu; O. A. Mohammed","Energy Systems Research Laboratory, Florida International University, Miami, FL, USA; Energy Systems Research Laboratory, Florida International University, Miami, FL, USA; Energy Systems Research Laboratory, Florida International University, Miami, FL, USA; Energy Systems Research Laboratory, Florida International University, Miami, FL, USA",IEEE Transactions on Industry Applications,"19 May 2017","2017","53","3","1841","1851","This paper proposes a communication-assisted fault localization, isolation, and restoration method for microgrids based on a multi-agent system. The proposed system comprises distributed agents, located in the middle and at the two ends of a protection section, which will detect a fault through phase angle comparison of current signals at both sides of a given distribution line. The agents then send trips signal to corresponding circuit breakers accordingly. The importance of the proposed protection technique is twofold. First, it eliminates the use of voltage transformers and thus reduces costs. Second, it does not require transfer of data along long distances, which decreases the delay time for fault isolation. Power restoration processes following the fault clearance considering voltage, frequency, and power flow constraints in the microgrid under study were also performed. Simulation of the proposed protection methodology was presented followed by experimental verification. The experimental results showed excellent agreement with the simulated protection scheme.","1939-9367","","10.1109/TIA.2017.2671427","U.S. Department of Energy; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858773","Information and communication technology;microgrid;multi-agent systems (MAS);protection;synchrophasor","Circuit faults;Microgrids;Current measurement;Transmission line measurements;Relays;Circuit breakers;Phasor measurement units","","95","","38","IEEE","17 Feb 2017","","","IEEE","IEEE Journals"
"Research Report: Testing and Evaluating Artificial Intelligence Applications","P. Lintilhac; J. Ackerman; G. Cybenko","Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA",2024 IEEE Security and Privacy Workshops (SPW),"4 Jul 2024","2024","","","231","238","In this paper, we describe and demonstrate TEAIS (Test and Evaluation of AI systems), a principled approach for assessing the performance of large language models. We walkthrough an educational example of TEAIS, where we leverage ideas from property testing of functions on the boolean hypercube to probabilistically verify a relevant security property of a PDF malware classifier. As part of this, we develop a novel property tester for monotonicity that works much like a mutation fuzzer. While the results in this report are preliminary, we hope to spark discussion around the challenges and opportunities associated with the testing and evaluation of complex AI systems.","2770-8411","979-8-3503-5487-4","10.1109/SPW63631.2024.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579534","Large Language Models;Deep Learning;Security","Privacy;Conferences;Fuzzing;Probabilistic logic;Hypercubes;Malware;Security","","1","","39","IEEE","4 Jul 2024","","","IEEE","IEEE Conferences"
"Swiss Cheese Model for AI Safety: A Taxonomy and Reference Architecture for Multi-Layered Guardrails of Foundation Model Based Agents","M. Shamsujjoha; Q. Lu; D. Zhao; L. Zhu","Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia",2025 IEEE 22nd International Conference on Software Architecture (ICSA),"30 Apr 2025","2025","","","37","48","Foundation Model (FM)-based agents are revolutionizing application development across various domains. However, their rapidly growing capabilities and autonomy have raised significant concerns about AI safety. Researchers are exploring better ways to design guardrails to ensure that the runtime behavior of FM-based agents remains within specific boundaries. Nevertheless, designing effective runtime guardrails is challenging due to the agents’ autonomous and non-deterministic behavior. The involvement of multiple pipeline stages and agent artifacts, such as goals, plans, tools, at runtime further complicates these issues. Addressing these challenges at runtime requires multilayered guardrails that operate effectively at various levels of the agent architecture. Therefore, in this paper, based on the results of a systematic literature review, we present a comprehensive taxonomy of runtime guardrails for FM-based agents to identify the key quality attributes for guardrails and design dimensions. Inspired by the Swiss Cheese Model, we also propose a reference architecture for designing multi-layered runtime guardrails for FM-based agents, which includes three dimensions: quality attributes, pipelines, and artifacts. The proposed taxonomy and reference architecture provide concrete and robust guidance for researchers and practitioners to build AI-safety-by-design from a software architecture perspective.","2835-7043","979-8-3315-2090-8","10.1109/ICSA65012.2025.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978931","Foundation Model;Large Language Models;LLM;Agent;Guardrails;Safeguard;AI Safety;Software Architecture;Taxonomy;Swiss Cheese Model;Responsible AI","Runtime;Dairy products;Software architecture;Foundation models;Large language models;Taxonomy;Pipelines;Computer architecture;Safety;Systematic literature review","","","","72","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"MLLMIE: Multiple Large Language Model Information Extraction in Ancient Medical Texts","F. Wang; D. Shi; X. Cui","School of Electronics and Information Engineering, Anhui Jianzhu University Mass Spectrometry Key Technology R&D and Clinical Application of Anhui Province Jointly Constructed Discipline Key Experiments, Hefei, China; School of Electronics and Information Engineering, Anhui Jianzhu University Mass Spectrometry Key Technology R&D and Clinical Application of Anhui Province Jointly Constructed Discipline Key Experiments, Hefei, China; School of Electronics and Information Engineering, Anhui Jianzhu University, Hefei, China",2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP),"20 Dec 2024","2024","","","1","6","Ancient medical texts, which reflect traditional cultural practices, can play an important role in the promotion of medical traditions. Nevertheless, the complexity of extracting information from classical Chinese medical texts and the potential inconsistencies and hallucinations in large language models during information extraction present significant challenges. In domains such as medicine, where the precision of information extraction is of paramount importance, the paper augmented existing methodologies for information extraction from large language models and proposed a novel approach, designated as Multiple Large Language Model Information Extraction (MLLMIE). The method initially defined a pattern layer to explicitly delineate the concepts, terms, and their interrelationships within the text. Subsequently, it employed prompt engineering to extract information from multiple models, thereby obtaining candidate medical ancient text knowledge results. Finally, the model validation layer was employed to filter the candidate results, thereby obtaining the final medical ancient text knowledge. The method attains F1 scores of 92.68% for named entity recognition and 94.91% for relation extraction in ancient medical texts, thereby demonstrating high-quality medical ancient text information extraction. This method effectively enhances the accuracy of ancient medical text information extraction and facilitates the discovery and application of ancient medical text knowledge.","","979-8-3503-5497-3","10.1109/MLNLP63328.2024.10800300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10800300","Large Language Models;Ancient Medical text;Named entity recognition;Relation extraction","Knowledge engineering;Large language models;Instruments;Named entity recognition;Machine learning;Information retrieval;Information filters;Data mining;Cultural differences;Prompt engineering","","","","24","IEEE","20 Dec 2024","","","IEEE","IEEE Conferences"
"TestMigrationsInPy: A Dataset of Test Migrations from Unittest to Pytest","A. Alves; A. Hora","Department of Computer Science, UFMG, Belo Horizonte, Brazil; Department of Computer Science, UFMG, Belo Horizonte, Brazil",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","841","845","Unittest and pytest are the most popular testing frameworks in Python. Overall, pytest provides some advantages, including simpler assertion, reuse of fixtures, and interoperability. Due to such benefits, multiple projects in the Python ecosystem have migrated from unittest to pytest. To facilitate the migration, pytest can also run unittest tests, thus, the migration can happen gradually over time. However, the migration can be time-consuming and take a long time to conclude. In this context, projects would benefit from automated solutions to support the migration process. In this paper, we propose TestMigrationsInPy, a dataset of test migrations from unittest to pytest. TestMigrationsInPy contains 923 real-world migrations performed by developers. Future research proposing novel solutions to migrate frameworks in Python can rely on TestMigrationsInPy as a ground truth. Moreover, as TestMigrationsInPy includes information about the migration type (e.g., changes in assertions or fixtures), our dataset enables novel solutions to be verified effectively, for instance, from simpler assertion migrations to more complex fixture migrations. TestMigrationsInPy is publicly available at: https://github.com/altinoalvesjunior/TestMigrationsInPy.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00122","EMI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025664","Software Testing;Framework Migration;LLMs;Software Repository Mining;unittest;pytest","Software testing;Codes;Fixtures;Ecosystems;Software;Data mining;Interoperability;Python","","","","41","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation","F. Cassano; J. Gouwar; D. Nguyen; S. Nguyen; L. Phipps-Costin; D. Pinckney; M. -H. Yee; Y. Zi; C. J. Anderson; M. Q. Feldman; A. Guha; M. Greenberg; A. Jangda","Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Hanover High School, Hanover, NH, USA; Computer Science, Wellesley College, Wellesley, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Wellesley College, Wellesley, MA, USA; Computer Science, Oberlin College, Oberlin, OH, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Stevens Institute of Technology, Hoboken, NJ, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,"17 Jul 2023","2023","49","7","3675","3691","Large language models have demonstrated the ability to generate both natural language and programming language text. Although contemporary code generation models are trained on corpora with several programming languages, they are tested using benchmarks that are typically monolingual. The most widely used code generation benchmarks only target Python, so there is little quantitative evidence of how code generation models perform on other programming languages. We propose MultiPL-E, a system for translating unit test-driven code generation benchmarks to new languages. We create the first massively multilingual code generation benchmark by using MultiPL-E to translate two popular Python code generation benchmarks to 18 additional programming languages. We use MultiPL-E to extend the HumanEval benchmark (Chen et al., 2021) and MBPP benchmark (Austin et al., 2021) to 18 languages that encompass a range of programming paradigms and popularity. Using these new parallel benchmarks, we evaluate the multi-language performance of three state-of-the-art code generation models: Codex (Chen et al., 2021), CodeGen (Nijkamp et al., 2022) and InCoder (Fried et al., 2022). We find that Codex matches or even exceeds its performance on Python for several other languages. The range of programming languages represented in MultiPL-E allow us to explore the impact of language frequency and language features on model performance. Finally, the MultiPL-E approach of compiling code generation benchmarks to new programming languages is both scalable and extensible, making it straightforward to evaluate new models, benchmarks, and languages.","1939-3520","","10.1109/TSE.2023.3267446","National Science Foundation(grant numbers:CCF-2052696); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103177","B.2.3 reliability, testing, and fault-tolerance;I.5.1.D neural nets","Codes;Benchmark testing;Python;Programming;Natural languages;Task analysis;Syntactics","","57","","42","CCBY","17 Apr 2023","","","IEEE","IEEE Journals"
"A Multi-Agent Model for Network Intrusion Detection","S. OUIAZZANE; M. ADDOU; F. BARRAMOU","ASYR RT, LaGeS Laboratory, Hassania School of Public Works, Casablanca, Morocco; ASYR RT, LaGeS Laboratory, Hassania School of Public Works, Casablanca, Morocco; ASYR RT, LaGeS Laboratory, Hassania School of Public Works, Casablanca, Morocco",2019 1st International Conference on Smart Systems and Data Science (ICSSD),"20 Feb 2020","2019","","","1","5","The objective of this paper is to propose a distributed intrusion detection model based on a multi agent system. Mutli Agent Systems (MAS) are very suitable for intrusion detection systems as they meet the characteristics required by the networks and Big Data issues. The MAS agents cooperate and communicate with each other to ensure the effective detection of network intrusions without the intervention of an expert as used to be in the classical intrusion detection systems relying on signature matching to detect known attacks. The proposed model helped to detect known and unknown attacks within big computer infrastructure by responding to the network requirements in terms of distribution, autonomy, responsiveness and communication. The proposed model is capable of achieving a good and a real time intrusion detection using multi-agents paradigm and Hadoop Distributed File System (HDFS).","","978-1-7281-4368-2","10.1109/ICSSD47982.2019.9003119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003119","Intrusion detection;MAS;Multi Agent System;Big Data;Security;IDS;DIDS;autonomy;distribution;Anomaly detection;Big networks","Intrusion detection;Big Data;Computer security;Anomaly detection;Databases;Multi-agent systems","","12","","20","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Robust Vulnerability Detection in Solidity-Based Ethereum Smart Contracts Using Fine-Tuned Transformer Encoder Models","T. -T. -H. Le; J. Kim; S. Lee; H. Kim","Blockchain Platform Research Center, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea",IEEE Access,"28 Oct 2024","2024","12","","154700","154717","The rapid expansion of blockchain technology, particularly Ethereum, has driven widespread adoption of smart contracts. However, the security of these contracts remains a critical concern due to the increasing frequency and complexity of vulnerabilities. This paper presents a comprehensive approach to detecting vulnerabilities in Ethereum smart contracts using pre-trained Large Language Models (LLMs). We apply transformer-based LLMs, leveraging their ability to understand and analyze Solidity code to identify potential security flaws. Our methodology involves fine-tuning eight distinct pre-trained LLM models on curated datasets varying in types and distributions of vulnerabilities, including multi-class vulnerabilities. The datasets-SB Curate, Benmark Solidity Smart Contract, and ScrawID-were selected to ensure a thorough evaluation of model performance across different vulnerability types. We employed over-sampling techniques to address class imbalances, resulting in more reliable training outcomes. We extensively evaluate these models using precision, recall, accuracy, F1 score, and Receiver Operating Characteristics (ROC) curve metrics. Our results demonstrate that the transformer encoder architecture, with its multi-head attention and feed-forward mechanisms, effectively captures the nuances of smart contract vulnerabilities. The models show promising potential in enhancing the security and reliability of Ethereum smart contracts, offering a robust solution to challenges posed by software vulnerabilities in the blockchain ecosystem.","2169-3536","","10.1109/ACCESS.2024.3482389","MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center)(grant numbers:(IITP-2024-RS-2020-II201797)); IITP (Institute for Information & Communications Technology Planning & Evaluation)(grant numbers:(IITP-2024-RS-2020-II201797)); IITP (Institute for Information & Communications Technology Planning & Evaluation); MSIT (Ministry of Science and ICT), Korea; Convergence security core talent training business (Pusan National University); Convergence security core talent training business (Pusan National University)(grant numbers:(No.RS-2022-II221201)); IITP (Institute for Information & Communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720785","Ethereum smart contracts;large language models;multi-class imbalance;multi-class classification;smart contract vulnerability;solidity code","Smart contracts;Codes;Transformers;Security;Solid modeling;Analytical models;Training;Encoding;Biological system modeling;Large language models","","5","","52","CCBYNCND","17 Oct 2024","","","IEEE","IEEE Journals"
"Qiskit HumanEval: An Evaluation Benchmark for Quantum Code Generative Models","S. Vishwakarma; F. Harkins; S. Golecha; V. S. Bajpe; N. Dupuis; L. Buratti; D. Kremer; I. Faro; R. Puri; J. Cruz-Benito","IBM Quantum, Yorktown Heights, NY, USA; IBM Quantum, Yorktown Heights, NY, USA; IBM Quantum, Gurugram, Haryana, India; IBM Quantum, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Zurich, Rüschlikon, Switzerland; IBM Quantum, Yorktown Heights, NY, USA; IBM Quantum, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Quantum, Yorktown Heights, NY, USA",2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"10 Jan 2025","2024","01","","1169","1176","Quantum programs are typically developed using quantum Software Development Kits (SDKs). The rapid advancement of quantum computing necessitates new tools to streamline this development process, and one such tool could be Generative Artificial intelligence (GenAI). In this study, we introduce and use the Qiskit HumanEval dataset, a hand-curated collection of tasks designed to benchmark the ability of Large Language Models (LLMs) to produce quantum code using Qiskit – a quantum SDK. This dataset consists of more than 100 quantum computing tasks, each accompanied by a prompt, a canonical solution, a comprehensive test case, and a difficulty scale to evaluate the correctness of the generated solutions. We systematically assess the performance of a set of LLMs against the Qiskit HumanEval dataset's tasks and focus on the models ability in producing executable quantum code. Our findings not only demonstrate the feasibility of using LLMs for generating quantum code but also establish a new benchmark for ongoing advancements in the field and encourage further exploration and development of GenAI-driven tools for quantum code generation.","","979-8-3315-4137-8","10.1109/QCE60285.2024.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821459","Qiskit;Large Language Models;Evaluation benchmarks;Qiskit HumanEval;HumanEval","Codes;Quantum computing;Generative AI;Computational modeling;Large language models;Benchmark testing;Software development management","","1","","25","IEEE","10 Jan 2025","","","IEEE","IEEE Conferences"
"Smart Contract Vulnerability Detection Based on Prompt-guided ChatGPT","J. Ma; S. Feng; J. Zeng; J. Lu; J. Chen","School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China",2024 International Conference on Networking and Network Applications (NaNA),"20 Sep 2024","2024","","","321","326","Millions of smart contracts are deployed on various blockchain platforms, involving extensive digital assets. However, vulnerabilities within these smart contracts have resulted in substantial exploitation and asset losses. Traditional methods for detecting smart contract vulnerabilities are limited by their narrow detection range and enormous computational cost. This paper investigates how large language models (LLMs), particularly ChatGPT 4, can be leveraged to detect vulnerabilities in smart contracts. We conduct a comprehensive survey of several existing detection methods for smart contract vulnerabilities. Meanwhile, we design a variety of prompt information, and added contract opcodes and expert rules as auxiliary information. Utilizing ChatGPT, we evaluate the effectiveness of the large language model in identifying vulnerabilities across two datasets. The experimental results demonstrate that ChatGPT, informed by specific prompts, can effectively pinpoint vulnerabilities, highlighting the utility of LLMs in enhancing the security of smart contracts.","","979-8-3503-7677-7","10.1109/NaNA63151.2024.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679877","Smart Contracts;Vulnerability Detection;Large Language Models;ChatGPT;Prompt Information","Surveys;Large language models;Smart contracts;Chatbots;Computational efficiency;Blockchains;Security","","1","","24","IEEE","20 Sep 2024","","","IEEE","IEEE Conferences"
"RHEA: Residential Home Energy Advisor","N. V. Gkalinikis; C. Nalmpantis; D. Vrakas; S. Chatzigeorgiou; C. Athanasiadis; D. Doukas","School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; NET2GRID BV, Thessaloniki, Greece; NET2GRID BV, Thessaloniki, Greece; NET2GRID BV, Thessaloniki, Greece",2025 10th International Conference on Smart and Sustainable Technologies (SpliTech),"30 Jul 2025","2025","","","1","6","Large language models (LLMs) can learn how to solve many common knowledge tasks such as language translation, code generation or dialogue generation. To provide a response, the LLMs combine the knowledge that was acquired from training along with the user’s input. Although this approach covers many cases, it would be valuable if the models could also use data from different sources, such as meter measurements. Incorporating such data could open up new avenues for using LLMs in data-centric applications like energy management systems. One way towards this direction is with the use of external tools such as APIs, which can retrieve and process relevant data for each task. This scenario is explored in current research with the creation of RHEA, an autonomous home energy advisor. RHEA is designed to monitor, control, and provide insight into the energy usage of electrical home appliances. This is accomplished by enabling a pre-trained LLM to generate calls to external energy analytics APIs, which process energy measurements obtained by the user’s home. The assistant is built on top of a known pretrained LLM that was fine-tuned to learn how to generate calls to three specific energy-related external tools only when needed while maintaining its capabilities gained from the original training. Additionally, the fine-tuning enables the assistant to generalize and learn to generate calls to similar APIs with minimal examples and without requiring further training.","","978-953-290-142-9","10.23919/SpliTech65624.2025.11091692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091692","artificial-intelligence;deep-learning;energy-transition;large-language-models;transformers;smart-home;smart-assistant","Training;Meters;Home appliances;Translation;Large language models;Energy measurement;Transformers;Data models;Energy management systems;Monitoring","","","","44","","30 Jul 2025","","","IEEE","IEEE Conferences"
"6G Comprehensive Intelligence: Network Operations and Optimization Based on Large Language Models","S. Long; F. Tang; Y. Li; T. Tan; Z. Jin; M. Zhao; N. Kato","School of Computer, Central South University, Changsha, China; School of Computer, Central South University, Changsha, China; School of Computer, Central South University, Changsha, China; School of Computer, Central South University, Changsha, China; School of Computer, Central South University, Changsha, China; School of Computer, Central South University, Changsha, China; Institute of Electronics and Communications, Tohoku University, Sendai, Japan",IEEE Network,"14 Jul 2025","2025","39","4","192","201","The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application scenarios, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.","1558-156X","","10.1109/MNET.2024.3470774","National Natural Science Foundation of China(grant numbers:62302527); the Postdoctoral Fellowship Program of CPSF(grant numbers:GZC20233160); Natural Science Foundation of Hunan Province(grant numbers:2023jj40774); Changsha Municipal Natural Science Foundation(grant numbers:kq2208284); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10700707","6G;Large Language Model;Network health assessment;Network performance optimization","Large language models;6G mobile communication;Optimization;Monitoring;Data models;Transformers;Fault diagnosis;Training;Protection;Long short term memory;Quality assessment;Medical services;Performance evaluation","","16","","15","IEEE","30 Sep 2024","","","IEEE","IEEE Magazines"
"System Design for Coordinated Multi-robot Assistance Deployment in Smart Spaces","P. Papadakis; C. Lohr; M. Lujak; A. Karami; I. Kanellos; G. Lozenguez; A. Fleury","IMT Atlantique Bretagne-Pays de la Loire, France; IMT Atlantique Bretagne-Pays de la Loire, France; IMT Lille Douai, Computer Sciences and Automatic Control dpt. and Univ. Lille, Lille, France; University of Lyon 2, Lyon, France; IMT Atlantique Bretagne-Pays de la Loire, France; IMT Lille Douai, Computer Sciences and Automatic Control dpt. and Univ. Lille, Lille, France; IMT Lille Douai, Computer Sciences and Automatic Control dpt. and Univ. Lille, Lille, France",2018 Second IEEE International Conference on Robotic Computing (IRC),"5 Apr 2018","2018","","","324","329","In this work, we set the bases of the integration of ambient intelligence (AmI) with mobile robot teams (MRT), aiming to enhance ambient assisted living services addressing a variety of tasks. We argue that people with reduced mobility can benefit from a synergy between AmI and MRT in various aspects. Towards this direction, we identify principal functionalities such an integrated system should provide in connection to relevant previous works and the way by which synergy could be accomplished, from low-level behavioural to higher-level task planning of a multi-layered system architecture.","","978-1-5386-4652-6","10.1109/IRC.2018.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329932","smart space;ambient assisted living;multi agent systems;service robots","Robot kinematics;Task analysis;Monitoring;Semantics;Logic gates;Interoperability","","6","","32","IEEE","5 Apr 2018","","","IEEE","IEEE Conferences"
"(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs","W. Ma; C. Yang; C. Kästner",The Hong Kong University of Science and Technology; Carnegie Mellon University; Carnegie Mellon University,2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN),"18 Jun 2024","2024","","","166","171","Large Language Models (LLMs) are increasingly integrated into software applications. Downstream application developers often access LLMs through APIs provided as a service. However, LLM APIs are often updated silently and scheduled to be deprecated, forcing users to continuously adapt to evolving models. This can cause performance regression and affect prompt design choices, as evidenced by our case study on toxicity detection. Based on our case study, we emphasize the need for and re-examine the concept of regression testing for evolving LLM APIs. We argue that regression testing LLMs requires fundamental changes to traditional testing approaches, due to different correctness notions, prompting brittleness, and non-determinism in LLM APIs.CCS CONCEPTS•Software and its engineering → Software testing and debugging.","","979-8-4007-0591-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556117","Large Language Models (LLM);regression testing","Software testing;Adaptation models;Toxicology;Debugging;Software;Software engineering","","5","","46","CCBY","18 Jun 2024","","","IEEE","IEEE Conferences"
"LLM-Powered Agentic AI Approach to Securing EV Charging Systems Against Cyber Threats","R. Honnalli; J. Farooq","Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA","2025 IEEE 26th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)","12 Jun 2025","2025","","","266","274","Electric vehicle (EV) charging systems are increasingly vulnerable to both cyber and physical attacks, posing significant risks to grid stability and operational security. Detecting such attacks remains a major challenge due to the complex nature of charging infrastructure and the scarcity of labeled attack data. Traditional machine learning (ML) models have demonstrated promise in intrusion and anomaly detection, however, their effectiveness is often limited by the lack of diverse real-world attack datasets, making them less reliable in detecting stealthy or emerging threats. To address these limitations, we leverage pretrained large language models (LLMs) enhanced with retrieval-augmented generation (RAG) for real-time anomaly detection in EV charging networks. The proposed system integrates domain-specific knowledge with live charging session data, enabling accurate classification of malicious activities such as billing fraud, energy theft, and communication tampering. Experimental results demonstrate that LLM-based detection improves classification accuracy while reducing false positives compared to traditional ML approaches. The developed methodology is adaptable across various cybersecurity applications, making it applicable to a wide range of attack scenarios beyond EV infrastructure. By combining AI-driven anomaly detection with real-time contextual analysis, this approach enhances the resilience of EV charging networks against evolving threats, ensuring secure and reliable operations.","2770-0542","979-8-3315-3832-3","10.1109/WoWMoM65615.2025.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11027017","Electric vehicle supply equipment (EVSE);large language model (LLM);generative pretrained model (GPT)","Accuracy;Biological system modeling;Large language models;Electric vehicle charging;Real-time systems;Threat assessment;Reliability;Computer security;Anomaly detection;Resilience","","","","35","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Trends towards Bio-Inspired Security Countermeasures for Cloud Environments","S. N. Mthunzi; E. Benkhelifa","Faculty of Computing, Staffordshire University, Stoke-on-Trent, UK; Faculty of Computing, Staffordshire University, Stoke-on-Trent, UK",2017 IEEE 2nd International Workshops on Foundations and Applications of Self* Systems (FAS*W),"12 Oct 2017","2017","","","341","347","Security challenges in cloud environments remain largely catastrophic due to the nature of the cloud; complex, heterogeneous, widely accessible over the internet, and virtualised resource sharing. Static and boundary-based conventional security approaches are clearly not effective as the sole countermeasures. Instead, countermeasures need to be intelligent with a high degree of autonomous, self-managing and self-organised, and highly adaptive to cope with dynamism of the cloud, and an emerging and sophisticated threat domain. Though not extensively used in cloud security countermeasures, nature is abounding with complex patterns emanating from interactions among autonomous agents. Its continuous coordination and information sharing enables self-organisation, whereby changes in forms of order occur without a central point of control. Nature's multifaceted superiority enables biological systems to adapt and survive through awareness, adaptation, learning and evolution. The concepts described nature's inherently multifunctional capabilities such as robustness, sophistication, and adaptability. This paper identifies common trends towards bio-inspired approaches for cloud security challenges. Its surveys the use of bio-inspired approaches in computing; cloud and non-cloud, and evaluates their strengths and weaknesses.","","978-1-5090-6558-5","10.1109/FAS-W.2017.170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8064146","bio-inspired;cloud computing;cloud security;reliability;autonous security coutermeasures;Adaptive Computing","Cloud computing;Security;Immune system;Biological system modeling;Computational modeling;Adaptation models","","1","","65","IEEE","12 Oct 2017","","","IEEE","IEEE Conferences"
"PICBench: Benchmarking LLMs for Photonic Integrated Circuits Design","Y. Wu; X. Yu; H. Chen; Y. Luo; Y. Tong; Y. Ma",HKUST(GZ); HKUST(GZ); HKUST(GZ); HKUST(GZ); HKUST(GZ); HKUST(GZ),"2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","6","While large language models (LLMs) have shown remarkable potential in automating various tasks in digital chip design, the field of Photonic Integrated Circuits (PICs)-a promising solution to advanced chip designs-remains relatively unexplored in this context. The design of PICs is time-consuming and prone to errors due to the extensive and repetitive nature of code involved in photonic chip design. In this paper, we introduce PICBench, the first benchmarking and evaluation framework specifically designed to automate PIC design generation using LLMs, where the generated output takes the form of a netlist. Our benchmark consists of dozens of meticulously crafted PIC design problems, spanning from fundamental device designs to more complex circuit-level designs. It automatically evaluates both the syntax and functionality of generated PIC designs by comparing simulation outputs with expert-written solutions, leveraging an open-source simulator. We evaluate a range of existing LLMs, while also conducting comparative tests on various prompt engineering techniques to enhance LLM performance in automated PIC design. The results reveal the challenges and potential of LLMs in the PIC design domain, offering insights into the key areas that require further research and development to optimize automation in this field. Our benchmark and evaluation code is available at https://github.com/PICDA/PICBench.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10992854","Guangzhou Municipal Science and Technology Project(grant numbers:2023A03J0013); Natural Science Foundation of Guangdong Province(grant numbers:2024A1515012438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992854","","Codes;Automation;Photonic integrated circuits;Benchmark testing;Syntactics;Prompt engineering;Integrated circuit modeling;Chip scale packaging;Research and development;Photonics","","","","17","","21 May 2025","","","IEEE","IEEE Conferences"
"Securing Intelligent Transportation Systems: A Dual-Framework Approach for Privacy Protection and Cybersecurity Using Generative AI","M. A. Khan; A. Alasiry; M. Marzougui; I. Bayhan; S. S. Kuna; G. S. N. Rao; S. A. Algamdi; H. Aldossary","Department of Artificial Intelligence, Prince Mohammad Bin Fahd University, Dhahran, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; Tourist Guiding Department, Bolu Abant Izzet Baysal University at Golkoy, Bolu, Türkiye; Holly Springs, NC, USA; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; Department of Software Engineering, College of Computer Science and Engineering, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Department of Computer Science, College of Science and Humanities, Imam Abdulrahman Bin Faisal University, Jubail, Saudi Arabia",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","12","Integrating Generative AI (GenAI) into Intelligent Transportation Systems (ITS) raises both enormous opportunities and major worries, especially in the areas of privacy and cybersecurity, which are already at the forefront of these developments. Developing and implementing robust security measures to secure sensitive data and address new cyber threats is of utmost importance, especially with the growing dependence on AI technology in transportation networks. This article looks at GenAI and how it may improve ITS intelligence and efficiency while addressing the risks of using it a lot. It delves into the difficulties of protecting AI-driven systems against hostile assaults (AI-MA), particularly emphasizing transportation infrastructure security, intrusion detection, and data privacy. The research stresses the significance of modern encryption methods, real-time monitoring threats, and adaptive security frameworks to ensure ITS are secure and resilient. In addition, it delves into how transportation systems are affected by ever-changing cyber threats, offering proactive security solutions to combat these dangers and strengthen ITS. This paper’s overarching goal is to lay out a course of action for integrating GenAI into ITS in a way that strikes a good balance between fostering innovation and ensuring privacy and security via thorough analysis. The proposed AI-MA model achieves a high threat detection accuracy of 96.2%, a privacy protection score of 91.8%, a computational efficiency of 92.9%, a resilience score of 97.8%, and a network reliability ratio of 92.6% compared to other existing models.","1558-0016","","10.1109/TITS.2025.3591007","Deanship of Research and Graduate Studies at King Khalid University through Large Research Project(grant numbers:RGP2/471/46); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119052","GenAI;privacy protection;security protocols;cyber threats;intelligent transportation system","Security;Computer security;Privacy;Real-time systems;Encryption;Protection;Generative AI;Monitoring;Data privacy;Artificial intelligence","","","","","IEEE","6 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Conversational AI","V. Bhardwaj; B. K. Dhaliwal; S. K. Sarangi; T. M. Thiyagu; A. Patidar; D. Pithawa","School of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering, Lovely Professional University, Jalandhar, Punjab, India; Coordinator and Adjunct Professor, Utkal University, Bhubaneswar, India; Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, Tamil Nadu, India; Department of Information Technology, Shri Vaishnav Vidhyapeeth Vishwavidyalya, Indore, India; Department of Computer Science Engineering, Shri Vaishnav Vidyapeeth Vishwavidyalaya, Indore, India",Conversational Artificial Intelligence,"","2024","","","435","457","Summary <p>Artificial intelligence (AI) of the conversational variety enables users to communicate with software programs in a manner similar to that of other people. AI that allows users to interact with chatbots or virtual agents is referred to as conversational AI. Using vast volumes of data, machine learning, and natural language processing, they recognize audio and text inputs and translate their contents into other languages to simulate human interactions.</p> <p>Conversational AI Agents: Physical or virtual agents who can assist just about anyone from Mark Zuckerberg to a normal person like you and me in a variety of tasks ranging from a fully automated house like one of the Mark where Jarvis works based on the voice commands to telling today's weather to a normal person or even doing small talk. However, who doesn't love to have his/her house same as the Mark Zuckerberg's; where everything happens based on voice command? Just say something and consider it as done. But everything comes at a cost; in this case, convenience comes at a cost of privacy and various security risks (some are known, and some are still unknown). So, in this paper, we will discuss some of the security risks (threats and vulnerabilities) that a hacker or someone with malicious intentions could exploit to cause loss, damage, or destruction of an asset of the user or the organization along with probable solutions to the security vulnerabilities. We will also discuss the privacy laws made to protect the user's data and how the General Data Protection Regulation affects the chatbot and the process of data collected by various organizations. Lastly, we will discuss the best practices to follow to ensure chatbot's security.</p>","","9781394200795","10.1002/9781394200801.ch26","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951917.pdf&bkn=10950236&pdfType=chapter","","Chatbots;Security;Conversational artificial intelligence;Artificial intelligence;Privacy;Oral communication;Virtual assistants;Industries;History;Best practices","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey","T. -H. Vu; S. Kumar Jagatheesaperumal; M. -D. Nguyen; N. Van Huynh; S. Kim; Q. -V. Pham","Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan, Republic of Korea; Department of Electronics and Communication Engineering, Mepco Schlenk Engineering College, Sivakasi, India; Department of Information Convergence Engineering, Pusan National University, Busan, Republic of Korea; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K.; School of Electronic Engineering, Kyonggi University, Suwon, Republic of Korea; School of Computer Science and Statistics, Trinity College Dublin, Dublin 2, Ireland",IEEE Internet of Things Journal,"10 Jan 2025","2025","12","2","1266","1290","The success of artificial intelligence (AI) in multiple disciplines and vertical domains in recent years has promoted the evolution of mobile networking and the future Internet toward an AI-integrated Internet of Things (IoT) era. Nevertheless, most AI techniques rely on data generated by physical devices (e.g., mobile devices and network nodes) or specific applications (e.g., fitness trackers and mobile gaming). Therefore, generative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a powerful AI paradigm; thanks to its ability to efficiently learn complex data distributions and generate synthetic data to represent the original data in various forms. This impressive feature is projected to transform the management of mobile networking and diversify the current services and applications provided. On this basis, this work presents a concise tutorial on the role of GAIs in mobile and wireless networking. In particular, this survey first provides the fundamentals of GAI and representative GAI models, serving as an essential preliminary to the understanding of GAI’s applications in mobile and wireless networking. Then, this work provides a comprehensive review of state-of-the-art studies and GAI applications in network management, wireless security, semantic communication, and lessons learned from the open literature. Finally, this work summarizes the current research on GAI for mobile and wireless networking by outlining important challenges that need to be resolved to facilitate the development and applicability of GAI in this edge-cutting area.","2327-4662","","10.1109/JIOT.2024.3487627","Research Program through the National Research Foundation of Korea(grant numbers:NRF-2023R1A2C1003546); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10737408","Artificial intelligence (AI);generative AI (GAI);Internet of Things (IoT);machine learning (ML);mobile networking;wireless networks","Artificial intelligence;Security;Communication system security;Data models;Wireless sensor networks;Wireless networks;Surveys;Generative adversarial networks;Internet of Things;Training","","12","","237","IEEE","29 Oct 2024","","","IEEE","IEEE Journals"
"Generative AI for Software Security Analysis: Fundamentals, Applications, and Challenges","A. Ding; G. Li; X. Yi; X. Lin; J. Li; C. Zhang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Advanced Institute of Industrial Technology, Tokyo, Japan",IEEE Software,"4 Oct 2024","2024","41","6","46","54","This article delves into the potential opportunities and challenges that generative AI introduces to software security analysis based on its fundamentals and applications. In addition, a simple case is used to demonstrate the validity of our outlook.","1937-4194","","10.1109/MS.2024.3416036","National Nature Science Foundation of China(grant numbers:62202303,U20B2048,62202302); JSPS KAKENHI(grant numbers:JP22K17884); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10634314","","Computer Security;Task analysis;Codes;Analytical models;Data models;Artificial intelligence;Generative AI;Binary codes;Software development management;Software engineering","","5","","15","IEEE","13 Aug 2024","","","IEEE","IEEE Magazines"
"Generative AI for Synthetic Data Generation in IoT-Based Healthcare Systems","S. P. Bharathi; P. G. Subin; R. Hariharan; T. S. Balaji; S. Balaji","School of Electronics Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India; Department of ECE, SRM Institute of Science and Technology, Chennai, Tamilnadu, India; Department of Electrical and Electronics Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha University, Chennai, Tamilnadu, India; Department of Electronics and Communication Engineering, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India; Department of Electronics and Communication Engineering, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Chennai, Tamilnadu, India",2024 Second International Conference Computational and Characterization Techniques in Engineering & Sciences (IC3TES),"17 Feb 2025","2024","","","1","5","Due to adoption of IoT in healthcare systems, patients’ care has been improved by monitoring and constant data acquiring in real time. Nevertheless, some issues like data privacy and security and data accessibility impede the usage of IoT data. To this end, this research outlines a robust framework for the generation of synthetic data with the help of generative AI methods, namely GANs and VAEs appropriate for the context of IoT-based healthcare applications. The framework also tackles the privacy issue since the methods used, namely differential privacy, protects information of an individual while maintaining usefulness. Some of the activities include data collection and preparation, model training and development, synthetic data generation, plus testing, and validation techniques. The generated synthetic data captures similar characteristics as the original data as well as important patterns that can be used to improve model building exercising and validating. Altogether the experimental results show how the synthetic data with the same characteristics can be useful in different healthcare situations while keeping high fidelities and utility. This paper demonstrates ways in which synthetic data can revolutionalize healthcare through secure opening of data for innovation and quality improvement of patients’ care.","","979-8-3503-6469-9","10.1109/IC3TES62412.2024.10877492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10877492","Generative AI;synthetic data;IoT-based healthcare;privacy preservation","Training;Technological innovation;Differential privacy;Generative AI;Medical services;Predictive models;Data models;Security;Synthetic data;Testing","","1","","15","IEEE","17 Feb 2025","","","IEEE","IEEE Conferences"
"Generative AI for Predictive Safety in Smart Cities AI/ML Applications for Urban Risk Management","H. Narne","Sr. Software Engineer Dazzlon Computer Services, Dallas, TX, USA","2025 International Conference on Engineering, Technology & Management (ICETM)","3 Jul 2025","2025","","","1","7","The quick expansion of cities has given public safety preservation and risk management challenging issues. Smart cities provide predictive safety measures using artificial intelligence (AI) and machine learning (ML), enabling proactive reactions to foreseen hazards. Focusing on real-time hazard detection, anomaly prediction, and emergency response optimization, this work studies urban risk management applications of Generative AI. Among deep learning systems, generative adversarial networks (GANs) and variational autoencoders (VAEs) allow cities to reproduce various risk situations and provide prediction techniques for crime prevention, traffic accident avoidance, and catastrophe readiness. Artificial intelligence-based predictive analytics increase situational awareness and support urban officials in making choices. This work also covers ethical questions, data privacy difficulties, and artificial intelligence system scalability for security in smart cities. The outcomes highlight how transformational generative artificial intelligence is in changing urban risk management and providing the road for more resilient and safer cities.","","979-8-3315-6668-5","10.1109/ICETM63734.2025.11051553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11051553","Smart cities;Generative AI;Predictive safety;Urban risk management;Machine learning;Deep learning;Emergency response;Anomaly detection;Artificial Intelligence;Public safety","Data privacy;Accuracy;Smart cities;Generative AI;Scalability;Hazards;Data models;Real-time systems;Safety;Risk management","","","","17","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"PrivNet—Generative AI-Augmented Quantum Privacy Framework for Vehicular Networks","K. A. Awan; K. Cengiz; I. Alrashdi; M. Abdelhaq; M. Uddin; H. Alsufyani; R. Alsaqour; C. Iwendi","Department of Information Technology, The University of Haripur, Harīpur, Pakistan; Department of Electrical Engineering, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia; Department of Computer Science, College of Computer and Information Sciences, Al Jouf University, Sakaka, Saudi Arabia; College of Computer and Information Sciences, Department of Information Technology, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; College of Computing and IT, University of Doha for Science and Technology, Doha, Qatar; Department of Computer Science, College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; Department of Information Technology, College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; Centre of Intelligence of Things, University of Bolton, Bolton, U.K.",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","10","Vehicular networks face increasing challenges to ensure security, privacy, and efficiency in dynamic communication environments. Current solutions often lack adaptability to evolving threats and efficient mechanisms for preserving privacy and reducing computational overhead. This study proposes PrivNet, a framework that integrates generative AI with advanced cryptographic and trust mechanisms to address these limitations. The framework comprises the Quantum-Augmented Holographic Cryptographic System (QAHCS) for dynamic and secure key generation, the Neural Overlap Privacy System (NOPS) for adaptive pseudonym morphing and entropy-driven identity obfuscation, and the Self-Supervised Generative Anomaly Detection (SS-GAI) module for real-time threat modeling and counter-anomaly injection. The system also incorporates Hyperledger Mesh for energy-efficient and secure transaction validation. Simulations were performed using NSL-KDD, CICIDS2017, and Car-Hacking/VeReMi datasets for 300 minutes. The results demonstrate a 12% improvement in detection accuracy, a 23% improvement in energy efficiency, and a 22% reduction in resource utilization.","1558-0016","","10.1109/TITS.2025.3589871","Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia(grant numbers:PNURSP2025R97); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11099560","Intelligent transport systems;generative AI;quantum computing;anomaly detection;data integrity;privacy preservation","Mathematical models;Vehicle dynamics;Encryption;Security;Anomaly detection;Privacy;Interference;Scalability;Distributed ledger;Chaotic communication","","","","","IEEE","29 Jul 2025","","","IEEE","IEEE Early Access Articles"
"An Advanced Generative AI-Based Anomaly Detection in IEC61850-Based Communication Messages in Smart Grids","A. Zaboli; Y. -H. Kim; J. Hong","Department of Electrical and Computer Engineering, University of Michigan–Dearborn, Dearborn, MI, USA; Department of AI Data Engineering, Korea National University of Transportation, Uiwang-si, Gyeonggi-do, South Korea; Department of Electrical and Computer Engineering, University of Michigan–Dearborn, Dearborn, MI, USA",IEEE Access,"28 May 2025","2025","13","","89997","90016","Security incidents in digital substations can create notable difficulties for the consistent and stable functioning of power systems. To address these issues, implementing defense and mitigation strategies is essential. Identifying and detecting irregularities in information and communication technology (ICT) is vital to maintaining secure interactions between devices in digital substations. This paper proposes a task-oriented dialogue (ToD) system for anomaly detection (AD) in multicast message datasets, such as generic object-oriented substation events (GOOSE) and sampled values (SV) in digital substations using generative AI (GenAI). The proposed ToD model demonstrates significant advantages over the human-in-the-loop (HITL) approach, particularly in error rate, adaptability, and scalability. Specifically, compared to HITL, the ToD model achieves a reduction in false positives (FPs) of up to 20% and enhances the accuracy of AD by up to 17.5%, resulting in a general accuracy of 97.5%. Moreover, the system shows a substantial improvement in advanced evaluation metrics, including a Matthews Correlation Coefficient (MCC) of 0.95, highlighting its robust capability to accurately differentiate between normal and anomalous events. The ToD model adapts effectively to new attack scenarios without extensive retraining, unlike traditional machine learning (ML) models or HITL, which require frequent updates. This adaptability significantly reduces implementation time compared to HITL, as the model requires fewer manual interventions and updates. These findings are supported by a comparative analysis using standard and advanced evaluation metrics. The generation and extraction of datasets of IEC 61850 communications were performed using a hardware-in-the-loop (HIL) testbed, ensuring the robustness of the proposed approach in practical scenarios.","2169-3536","","10.1109/ACCESS.2025.3571881","Korea Institute of Energy Technology Evaluation and Planning (KETEP) and the Ministry of Trade, Industry and Energy (MOTIE), South Korea(grant numbers:20221A10100011); National Research Foundation of Korea (NRF) funded by Korean Government [Ministry of Science and ICT (MSIT)](grant numbers:2022R1F1A1074975); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008602","Cybersecurity;digital substations;generative AI;GOOSE;human-in-the-loop;anomaly detection;smart grids;SV;task-oriented dialogue","Substations;Adaptation models;Power system stability;Smart grids;Scalability;Object oriented modeling;Feature extraction;Accuracy;Measurement;Computer crime","","","","53","CCBYNCND","21 May 2025","","","IEEE","IEEE Journals"
"Write-Curate-Verify: A Case Study of Leveraging Generative AI for Scenario Writing in Scenario-Based Learning","S. Bai; D. E. Gonda; K. F. Hew","Department of Mathematics and Information Technology, Education University of Hong Kong, Hong Kong SAR, China; Faculty of Education, University of Hong Kong, Hong Kong SAR, China; Faculty of Education, University of Hong Kong, Hong Kong SAR, China",IEEE Transactions on Learning Technologies,"10 Apr 2024","2024","17","","1301","1312","This case study explored the use of generative artificial intelligence (GenAI), specifically chat generative pretraining transformer (ChatGPT), in writing scenarios for scenario-based learning (SBL). Our research addressed three key questions: 1) how do teachers leverage GenAI to write scenarios for SBL purposes? 2) what is the quality of GenAI-generated SBL scenarios and tasks? and 3) how does GenAI-supported SBL affect students’ motivation, learning performance, and learning perceptions? A three-step prompting engineering process (write the prompts, curate the output, and verify the output, WCV) was established during the teacher interaction with GenAI in the scenario writing. Findings revealed that by using the WCV approach, ChatGPT enabled the efficient creation of quality scenarios for SBL purposes in a short timeframe. Moreover, students exhibited increased intrinsic motivation, learning performance, and positive attitudes toward GenAI-supported scenarios. We also suggest guidelines for using the WCV prompt engineering process in scenario writing.","1939-1382","","10.1109/TLT.2024.3378306","Faculty-Level Teaching Development; The Education University of Hong Kong(grant numbers:T0266); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474179","Generative artificial intelligence (GenAI);intrinsic motivation;prompt engineering;scenario-based learning (SBL)","Writing;Chatbots;Task analysis;Visualization;Education;Encoding;Testing","","21","","49","IEEE","18 Mar 2024","","","IEEE","IEEE Journals"
"Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues","D. Cipollone; C. Wang; M. Scazzariello; S. Ferlin; M. Izadi; D. Kostić; M. Chiesa",Delft University of Technology; KTH Royal Institute of Technology; RISE Research Institutes of Sweden; Red Hat; Delft University of Technology; KTH Royal Institute of Technology; KTH Royal Institute of Technology,2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","41","48","In today’s digital landscape, the importance of timely and accurate vulnerability detection has significantly increased. This paper presents a novel approach that leverages transformer-based models and machine learning techniques to automate the identification of software vulnerabilities by analyzing GitHub issues. We introduce a new dataset specifically designed for classifying GitHub issues relevant to vulnerability detection. We then examine various classification techniques to determine their effectiveness. The results demonstrate the potential of this approach for real-world application in early vulnerability detection, which could substantially reduce the window of exploitation for software vulnerabilities. This research makes a key contribution to the field by providing a scalable and computationally efficient framework for automated detection, enabling the prevention of compromised software usage before official notifications. This work has the potential to enhance the security of open-source software ecosystems.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028308","Vulnerability Detection;Transformer-based Models;Large Language Models;LLMs;Embedding Models","Analytical models;Codes;Biological system modeling;Large language models;Ecosystems;Transformers;Computational efficiency;Security;Open source software;Software development management","","","","26","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"InterviewIQ: AI-Powered Chatbot for Upskilling Candidates in Technical and HR Interviews","R. A. M; A. R; V. P","Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India; Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India; Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India","2025 International Conference on Intelligent Control, Computing and Communications (IC3)","16 Apr 2025","2025","","","392","397","The job security one wants is very difficult to get as job seekers often struggle in technical and HR interviews owing to lack of proper preparation and even minimal feedback. Platforms are abundant on aptitude and coding tests, which forget realistic interview simulations. To overcome the gap, InterviewIQ uses AI-powered mock interviews mimicking real-life technical and HR interactions. NLP powers the questions on this platform to be dynamic in relation to the candidate's answers. For every session, feedback is provided about the candidate's technical skills, communication, and sentiment that was there during the interaction, allowing them to learn and realize their strengths and areas for improvement. Offering a chance for personal practice, and also actionable insights for InterviewIQ, enables them to be better prepared and give higher chances in actual interviews.","","979-8-3315-2749-5","10.1109/IC363308.2025.10956589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10956589","AI-Driven Assessment;Mock Interview;Large Language Models (LLMS);Natural Language Processing (NLP);Personalized Feedback;Skill Enhancement","Large language models;Chatbots;Encoding;Security;Interviews;Intelligent control","","","","14","IEEE","16 Apr 2025","","","IEEE","IEEE Conferences"
"A First Look at AI Trends in Value-Aligned Software Engineering Publications: Human-LLM Insights","D. Mougouei; A. Azarnik; M. Fahmideh; E. Mougouei; H. K. Dam; A. A. Khan; S. Rafi; J. A. Khan; A. Ahmad","Deakin University, Geelong, Australia; Universiti Teknologi Malaysia, Johor Bahru, Malaysia; University of Southern Queensland, Springfield, Australia; Islamic Azad University Najafabad, Esfahan, Iran; University of Wollongong, Wollongong, Australia; University of Oulu, Oulu, Finland; Edinburgh Napier University, Edinburgh, United Kingdom; University of Hertfordshire, Hatfield, United Kingdom; Lancaster University, Leipzig, Germany",2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS),"10 Jun 2025","2025","","","82","93","Recent criticism of social media platforms by the U.S. Senate Judiciary Committee for neglecting child safety exemplifies how software can undermine human values. This is further complicated by the growing integration of Artificial Intelligence (AI) in software, which introduces inherent challenges such as biases and limited transparency. However, AI also presents opportunities to embed human values into software. To explore these opportunities, we have utilized the reasoning abilities of ChatGPT, a large language model (LLM), in combination with human expertise, to study the use of AI in publications that address human values, across some of the leading software engineering (SE) venues from 2022 to 2023. Our findings confirm the use of AI concepts - mainly General Machine Learning - in around 33 % of these valuealigned publications. The value alignments largely concern pragmatic aspects of Achievement and (personal) Security, while the majority of the values receive less attention. The socially focused values of Conformity and Tradition and the personally focused value of Hedonism are rarely addressed in the SE publications.","2832-7616","979-8-3315-3707-4","10.1109/ICSE-SEIS66351.2025.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023907","Software Engineering;Artificial Intelligence (AI);Human Values;Value-Aligned Publications;Large Language Models (LLMs);ChatGPT","Social networking (online);Large language models;Chatbots;Market research;Software;Safety;Security;Artificial intelligence;Software engineering;Pragmatics","","","","72","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"From Vulnerabilities to Improvements- A Deep Dive into Adversarial Testing of AI Models","B. Hannon; Y. Kumar; P. Sorial; J. J. Li; P. Morreale","Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA; Department of Computer Science and Technology, Kean University, Union, NJ, USA","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","2645","2649","The security vulnerabilities inherent in large language models (LLMs), such as OpenAI's ChatGPT-3.5 and ChatGPT -4, Bing Bot, and Google's Bard, are explored in this paper. The focus is on the susceptibility of these models to malicious prompting and the potential for generating unethical content. An investigation is conducted into the responses these models provide when tasked with completing a movie script involving a character disseminating information about murder, weapons, and drugs. The analysis reveals that, despite the presence of filters designed to prevent the generation of unethical or harmful content, these models can be manipulated through malicious prompts to produce inappropriate and even illegal responses. This discovery underscores the urgent need for a comprehensive understanding of these vulnerabilities, as well as the development of effective measures to enhance the security and reliability of LLMs. This paper offers valuable insights into the security vulnerabilities that arise when these models are prompted to generate malicious content.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00422","NSF(grant numbers:1834620,1928452,2137791); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487199","prompt engineering;chatbots;ChatGPT;Bard;security vulnerabilities in chatbots;risk mitigation;adversarial attacks","Filters;Computational modeling;Weapons;Chatbots;Motion pictures;Internet;Security","","5","","25","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Human Evaluation of GPT for Scalable Python Programming Exercise Generation","M. F. Akbar Khan; M. Ramsdell; H. Nguyen; H. Karimi","Department of Computer Science, Utah State University; Department of Computer Science, Utah State University; School of Education, University of North Carolina at Chapel Hill; Department of Computer Science, Utah State University",2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA),"24 Oct 2024","2024","","","1","10","Online coding platforms (OCPs) often offer a limited selection of exercises, which can restrict the scope of Computer Science (CS) education. This study investigates the capabilities of Large Language Models (LLMs), particularly GPT-4 Turbo, in broadening this scope by autonomously generating Python programming exercises. These exercises are tailored to the CS1 curriculum-an introductory course in computer science. Utilizing curriculum-driven prompt engineering, we developed a dataset of 11,700 exercises, characterized by a variety of cate-gories, types, and difficulty levels. These exercises are distributed across 78 unique topics, which were derived from the CS1 course catalogs of leading universities and supplemented with online educational resources. To evaluate the effectiveness of GPT-4 Turbo in generating CSI Python programming exercises, we conducted a user study involving both students and instruc-tors. The study focused on several metrics: exercise quality, curriculum relevance, understandability, appropriate difficulty level, and the generation of useful hints. Our findings indicate that GPT-4 Turbo can produce high-quality, educationally effective programming exercises at scale, provided that the prompts are systematically crafted. Based on insights from the user study, adjustments to prompt design are recommended to optimize exercise generation. Our research concludes that GPT-4 Turbo can be seamlessly integrated into AI-driven OCPs, offering a scalable, cost and time-effective method to enhance CS edu-cation. This is achieved through targeted prompt engineering and thorough data preprocessing to mitigate inconsistencies. The code is available online: https://github.com/DSAatUSU/GPT_CS1400_Exercise_Generation","2766-4112","979-8-3503-6494-1","10.1109/DSAA61799.2024.10722841","National Science Foundation(grant numbers:EES-2321304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722841","Large Language Models;GPT;Python Exercises Generation;Human Evaluation Computer Science Education","Measurement;Large language models;Education;Data science;Encoding;Computer science education;Prompt engineering;Programming profession;Standards;Python","","1","","33","IEEE","24 Oct 2024","","","IEEE","IEEE Conferences"
"VulnerAI: GPT Based Web Application Vulnerability Detection","S. S. Saimbhi; K. O. Akpinar","Department of Cybersecurity, Rochester Institute of Technology, Rochester, United States; Department of Cybersecurity, Rochester Institute of Technology, Dubai, United Arab Emirates","2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)","9 Jan 2025","2024","","","1","6","Software vulnerabilities have been a major threat to everyone and have been exploited to gain unauthorized access to the systems. These vulnerabilities directly impact the confidentiality, integrity, and availability of these software systems. Traditional vulnerability detection tools are not effective and are unable to detect new and emerging vulnerabilities. There have been various incidents that were reported due to vulnerabilities in the web application that resulted in huge losses. It is vital to have accurate vulnerability detection tools. In this paper, the authors investigate and present the tool VulnerAI that can be used for vulnerability detection. VulnerAI uses the power of Generative Pre-trained Transformer (GPT) to provide users with the security insights of their code. The authors analyzed vulnerable PHP code snippets using GPT to identify potential security vulnerabilities. The authors also aim to demonstrate that GPT is a satisfactory tool for vulnerability detection, despite its reliability and use in solving many other tasks.","","979-8-3503-5348-8","10.1109/ICAMAC62387.2024.10828788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828788","vulnerability analysis;GPT(generative pre-trained transformer);software vulnerabilities;static analysis;LLM (Large Language Models);OpenAI","Analytical models;Codes;Accuracy;Metaverse;Generative Pre-trainer transformer;Transformers;Software systems;Reliability;Computer security;Artificial intelligence","","","","16","IEEE","9 Jan 2025","","","IEEE","IEEE Conferences"
"Vulnerability Classification on Source Code Using Text Mining and Deep Learning Techniques","I. Kalouptsoglou; M. Siavvas; A. Ampatzoglou; D. Kehagias; A. Chatzigeorgiou","Centre for Research and Technology Hellas, Thessaloniki, Greece; Centre for Research and Technology Hellas, Thessaloniki, Greece; University of Macedonia, Thessaloniki, Greece; Centre for Research and Technology Hellas, Thessaloniki, Greece; University of Macedonia, Thessaloniki, Greece","2024 IEEE 24th International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","29 Oct 2024","2024","","","47","56","Nowadays, security testing is an integral part of the testing activities during the software development life-cycle. Over the years, various techniques have been proposed to identify security issues in the source code, especially vulnerabilities, which can be exploited and cause severe damages. Recently, Machine Learning (ML) techniques capable of predicting vulnerable software components and indicating high-risk areas have appeared, among others, accelerating the effort demanding and time consuming process of vulnerability localization. For effective subsequent vulnerability elimination, there is a need for automating the process of labeling detected vulnerabilities in vulnerability categories i.e., identifying the type of the vulnerability. Several techniques have been proposed over the years for automating the labeling process of vulnerabilities. However, the vast majority of the proposed methods attempt to identify the type of vulnerabilities based on their textual description that is provided by experts, such as the description provided by the vulnerability report in the National Vulnerability Database, and not on their actual source code, hindering their full automation and the vulnerability categorization from the software testing phase. This work examines the vulnerability classification directly from the source code during the vulnerability detection step. Moreover, this way, a vulnerability detection method will be able to provide complete information and interpretation of its findings. Leveraging the advances in the field of Artificial Intelligence and Natural Language Processing, we construct and compare several multi-class classification models for categorizing vulnerable code snippets. The results highlight the importance of the context-aware embeddings of the pre-trained Transformer-based models, as well as the significance of transfer learning from a programming language-related domain.","2693-9371","979-8-3503-6565-8","10.1109/QRS-C63300.2024.00017","European Union's Horizon Europe Research and Innovation(grant numbers:101120270); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10727022","security testing;vulnerability classification;natural language processing;contextual word embedding;large language models;transfer learning","Text mining;Software testing;Source coding;Transfer learning;Software quality;Transformers;Software reliability;Security;Labeling;Software development management","","1","","51","IEEE","29 Oct 2024","","","IEEE","IEEE Conferences"
"A Generative AI-Based Framework for Decentralized Finance and Cryptocurrency Fraud Prevention","S. Vavikar; D. A. Ostrowski",Purdue University Global; Purdue University Global,2025 19th International Conference on Semantic Computing (ICSC),"19 Jun 2025","2025","","","302","305","Although aligned with security-based principles, Blockchain networks have maintained some exposure to fraudulent transactions. This paper introduces a novel methodology and framework for effectively characterizing fraud within blockchain networks and a method for prevention. To leverage the transparency of the blockchain, suitable starting data can be acquired to characterize potentially nefarious transactions. The framework presented applies generative AI at two levels: to support the characterization of synthetic training data for scenarios that may yet be deployed and to generate suitable testing scenarios for constructing effective techniques to safeguard transactions.","2472-9671","979-8-3315-2426-5","10.1109/ICSC64641.2025.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036144","blockchain;cryptocurrency","Accuracy;Generative AI;Scalability;Prevention and mitigation;Smart contracts;Finance;Bitcoin;Decentralized applications;Fraud;Blockchains","","","","16","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Extracting Formal Specifications From Documents Using LLMS for Test Automation","H. Li; Z. Dong; S. Wang; H. Zhang; L. Shen; X. Peng; D. She","Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; The Hong Kong University of Science and Technology, Hong Kong, China",2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC),"17 Jun 2025","2025","","","1","12","Automated test generation plays a crucial role in ensuring software security. It heavily relies on formal specifications to validate the correctness of the system behavior. However, the main approach to defining these formal specifications is through manual analysis of software documents, which requires a significant amount of engineering effort from experienced researchers and engineers. Meanwhile, system update further increases the human labor cost to maintain a corresponding formal specification, making the manual analysis approach a time-consuming and error-prone task. Recent advances in Large Language Models (LLMs) have demonstrated promising capabilities in natural language understanding. Yet, the feasibility of using LLMs to automate the extraction of formal specifications from software documents remains unexplored. We conduct an empirical study by constructing a comprehensive dataset comprising 603 specifications from 37 documents across three representative open-source software. We then evaluate the most recent LLMs' capabilities in extracting formal specifications from documents in an end-to-end fashion, including GPT-4o, Claude, and Llama. Our study demonstrates the application of LLMs in formal specification extraction tasks while identifying two major limitations: specification oversimplification and specification fabrication. We attribute these deficiencies to the LLMs' inherent limitations in processing and expressive capabilities, as well as their tendency to fabricate fictional information. Inspired by human cognitive processes, we propose a novel two-stage method, annotation-then-conversion, to address these challenges. Our method decomposes the task into sentence annotation and temporal logic conversion, reducing the demands on LLMs' processing and expressive capabilities for each subtask. Furthermore, by generating verifiable sentence-specification pairs, our method enables effective fact-checking, thereby mitigating hallucination effects. Our method demonstrates significant improvements over the end-to-end method, with a 29.2 % increase in the number of correctly extracted specifications and a 14.0 % improvement in average accuracy. In particular, our best-performing LLM achieves an accuracy of $\mathbf{7 1. 6 \%}$.","2643-7171","979-8-3315-0223-2","10.1109/ICPC66645.2025.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025943","","Fabrication;Accuracy;Text analysis;Large language models;Manuals;Software reliability;Formal specifications;Test pattern generators;Security;Software engineering","","","","54","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Improving LLM-Based Verilog Code Generation with Data Augmentation and RL","K. Min; S. Park; H. Park; J. Cho; S. Kang","Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, Republic of Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, Republic of Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, Republic of Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, Republic of Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, Republic of Korea","2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","7","Large language models (LLMs) have recently attracted significant attention for their potential in Verilog code generation. However, existing LLM-based methods face several challenges, including data scarcity and the high computational cost of generating prompts for fine-tuning. Motivated by these challenges, we explore methods to augment training datasets, develop more efficient and effective prompts for fine-tuning, and implement training methods incorporating electronic design automation (EDA) tools. Our proposed framework for fine-tuning LLMs for Verilog code generation includes (1) abstract syntax tree (AST)-based data augmentation, (2) output-relevant code masking, a prompt generation method based on the logical structure of Verilog code, and (3) reinforcement learning with tool feedback (RLTF), a fine-tuning method using EDA tool results. Experimental studies confirm that our framework significantly improves syntax and functional correctness, outperforming commercial and non-commercial models on open-source benchmarks.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10992897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992897","","Training;Analytical models;Codes;Large language models;Reinforcement learning;Syntactics;Data augmentation;Data models;Iterative methods;Hardware design languages","","","","31","","21 May 2025","","","IEEE","IEEE Conferences"
"ORANSight-2.0: Foundational LLMs for O-RAN","P. Gajjar; V. K. Shah","NextG Wireless Lab, North Carolina State University, USA; NextG Wireless Lab, North Carolina State University, USA",IEEE Transactions on Machine Learning in Communications and Networking,"","2025","PP","99","1","1","Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative to develop specialized foundational LLMs tailored for O-RAN. Built on 18 models spanning five open-source LLM frameworks — Mistral, Qwen, Llama, Phi, and Gemma — ORANSight-2.0 fine-tunes models ranging from 1B to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance in O-RAN-specific tasks. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG)-based instruction-tuning framework that employs two LLM agents — a Mistral-based Question Generator and a Qwen-based Answer Generator — to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack. Additionally, we leverage ORAN-Bench-13K, an existing benchmark for assessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate that ORANSight-2.0 models outperform general-purpose and closed-source models, such as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on srsRANBench, achieving superior performance while maintaining lower computational and energy costs. We also experiment with RAG-augmented variants of ORANSight-2.0 models and observe that RAG augmentation improves performance by an average of 6.35% across benchmarks, achieving the best overall cumulative score of 0.854, which is 12.37% better than the leading closed-source alternative. We thoroughly evaluate the energy characteristics of ORANSight-2.0, demonstrating its efficiency in training, inference, and inference with RAG augmentation, ensuring optimal performance while maintaining low computational and energy costs. Additionally, the best ORANSight-2.0 configuration is compared against the available telecom LLMs, where our proposed model outperformed them with an average improvement of 27.96%.","2831-316X","","10.1109/TMLCN.2025.3592658","Public Wireless Supply Chain Innovation Fund(grant numbers:26-60-IF010,51-60-IF007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096935","O-RAN;ORANSight;5G;LLM;ORANBench;srsRANBench;QLoRA;Foundational Models","Open RAN;Computational modeling;Adaptation models;Telecommunications;Benchmark testing;Training;Codes;Biological system modeling;Retrieval augmented generation;Data models","","","","","CCBY","25 Jul 2025","","","IEEE","IEEE Early Access Articles"
"SecLoRA: Efficient Privacy-Preserving LLMs Tuning","M. Bian","School of Cyber Science and Engineering, Qufu Normal University, Qufu, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Currently, the advent of ubiquitous Large Language Models (LLMs) seamlessly provides cloud-based services for Internet of Things devices with intrinsic traits. Low-Rank Adaptation (LoRA) is designed for fine-tuning large-scale models in a computation-efficient manner, yet the initial LoRA parameters delay model convergence rates and the risks of sensitive data coupled with proprietary models can not be ignored. Prior works on privacy-preserving LoRA training only focus on the privacy of local data or prediction results and sacrifice somewhat utility degradation for appropriate privacy protection. To accomplish faster training convergence rates and a higher security level, we design a pre-optimizing algorithm for local LoRA parameters, and propose an efficient scheme (SecLoRA) for secure LLMs tuning. SecLoRA leverages inner product functional encryption and matrix permutation techniques to ensure the privacy of local sensitive data and fine-tuned model parameters while also guaranteeing the reliability of prediction results to resist the tampering attacks. Convergence analysis corroborates the feasibility of local pre-optimizing algorithm. Compared with related works, we provide security analysis of SecLoRA to prove the higher level of security in terms of model privacy, prediction privacy, and prediction integrity. Extensive evaluations on numerous LLMs and public benchmarks indicate that local parameter pre-optimizing algorithm achieves a 20% 40% reduction in training time, while SecLoRA quantitatively outperforms the related works across multiple evaluation criteria.","2327-4662","","10.1109/JIOT.2025.3588837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11079951","Large language model;low-rank adaptation;training convergence rates;inner product functional encryption;reliability","Training;Computational modeling;LoRa;Data privacy;Adaptation models;Convergence;Tuning;Security;Privacy;Data models","","","","","IEEE","14 Jul 2025","","","IEEE","IEEE Early Access Articles"
"LLMs for Generation of Architectural Components: An Exploratory Empirical Study in the Serverless World","S. Arun; M. Tedla; K. Vaidhyanathan","SERC, IIIT, Hyderabad, India; SERC, IIIT, Hyderabad, India; SERC, IIIT, Hyderabad, India",2025 IEEE 22nd International Conference on Software Architecture (ICSA),"30 Apr 2025","2025","","","25","36","Recently, the exponential growth in capability and pervasiveness of Large Language Models (LLMs) has led to significant work done in the field of code generation. However, this generation has been limited to code snippets. Going one step further, our desideratum is to automatically generate architectural components. This would not only speed up development time, but would also enable us to eventually completely skip the development phase, moving directly from design decisions to deployment. To this end, we conduct an exploratory study on the capability of LLMs to generate architectural components for Functions as a Service (FaaS), commonly known as serverless functions. The small size of their architectural components make this architectural style amenable for generation using current LLMs compared to other styles like monoliths and microservices. We perform the study by systematically selecting open source serverless repositories, masking a serverless function and utilizing state of the art LLMs provided with varying levels of context information about the overall system to generate the masked function. We evaluate correctness through existing tests present in the repositories and use metrics from the Software Engineering (SE) and Natural Language Processing (NLP) domains to evaluate code quality and the degree of similarity between human and LLM generated code respectively. Along with our findings, we also present a discussion on the path forward for using GenAI in architectural component generation.","2835-7043","979-8-3315-2090-8","10.1109/ICSA65012.2025.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978918","Architectural Component Generation;LLM;Serverless","Measurement;Codes;Software architecture;Large language models;Microservice architectures;Natural language processing","","","","55","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"LLMs to Secure Consumer Networks: Open Problems and Future Directions","H. Moudoud; Z. A. E. Houda; B. Brik","Universite du Quebec en Outaouais, Canada; Institut National de la Recherche Scientifique, Canada; Sharjah University, United Arab Emirates",IEEE Consumer Electronics Magazine,"","2025","PP","99","1","8","The increasing complexity of consumer networks, characterized by the rapid adoption of Internet of Things (IoT) devices and smart home technologies, exposes significant limitations in traditional security mechanisms. These challenges drive a growing interest in innovative solutions, such as generative artificial intelligence, including large language models (LLMs) to ensure the security of consumer networks from evolving cyber threats. In this paper, we present a forward-looking perspective on the role of LLMs in securing consumer networks. Then, we present a comprehensive study of attacks targeting LLMs and current defense mechanisms/strategies. Finally, we present a set of core research problems and a comprehensive research agenda that identifies future directions to advance LLM capabilities for consumer network security.","2162-2256","","10.1109/MCE.2025.3542247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887290","","Security;Filtering;Closed box;Training;Safety;Filters;Ethics;Data mining;Context modeling;Glass box","","","","","IEEE","14 Feb 2025","","","IEEE","IEEE Early Access Articles"
"Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat","S. Feng; H. Lu; J. Jiang; T. Xiong; L. Huang; Y. Liang; X. Li; Y. Deng; A. Aleti","Monash University, Melbourne, Australia; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Tencent Inc., Guangzhou, China; Monash University, Melbourne, Australia",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1973","1978","UI automation tests play a crucial role in ensuring the quality of mobile applications. Despite the growing popularity of machine learning techniques to generate these tests, they still face several challenges, such as the mismatch of UI elements. The recent advances in Large Language Models (LLMs) have addressed these issues by leveraging their semantic understanding capabilities. However, a significant gap remains in applying these models to industrial-level app testing, particularly in terms of cost optimization and knowledge limitation. To address this, we introduce CAT to create cost-effective UI automation tests for industry apps by combining machine learning and LLMs with best practices. Given the task description, CAT employs Retrieval Augmented Generation (RAG) to source examples of industrial app usage as the few-shot learning context, assisting LLMs in generating the specific sequence of actions. CAT then employs machine learning techniques, with LLMs serving as a complementary optimizer, to map the target element on the UI screen. Our evaluations on the WeChat testing dataset demonstrate the CAT’s performance and cost-effectiveness, achieving 90% UI automation with $0.34 cost, outperforming the state-of-the-art. We have also integrated our approach into the real-world WeChat testing platform, demonstrating its usefulness in detecting 141 bugs and enhancing the developers’ testing process.CCS CONCEPTS• Software and its engineering → Software testing and debugging.","2643-1572","979-8-4007-1248-7","","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765004","UI automation test;large language model;retrieval-augmented generation;cost optimization","Software testing;Automation;Costs;Social networking (online);Computer bugs;Message services;Mobile applications;Optimization;Testing;Software engineering","","1","","37","","29 Nov 2024","","","IEEE","IEEE Conferences"
"R+R: Security Vulnerability Dataset Quality Is Critical","A. S. Yadav; J. N. Wilson","Department Of Computer Science, University Of Florida, Gainesville, FL, USA; Department Of Computer Science, University Of Florida, Gainesville, FL, USA",2024 Annual Computer Security Applications Conference (ACSAC),"18 Mar 2025","2024","","","1047","1061","Large Language Models (LLMs) are of great interest in vulnerability detection and repair. The effectiveness of these models hinges on the quality of the datasets used for both training and evaluation. Our investigation reveals that a number of studies featured in prominent software engineering conferences have employed datasets that are plagued by high duplication rates, questionable label accuracy, and incomplete samples. Using these datasets for experimentation will yield incorrect results that are significantly different from actual expected behavior. For example, the state-of-the-art VulRepair Model, which is reported to have 44% accuracy, on average yielded 9% accuracy when test-set duplicates were removed from its training set and 13% accuracy when training-set duplicates were removed from its test set. In an effort to tackle these data quality concerns, we have retrained models from several papers without duplicates and conducted an accuracy assessment of labels for the top ten most hazardous Common Weakness Enumerations (CWEs). Our findings indicate that 56% of the samples had incorrect labels and 44% comprised incomplete samples—only 31% were both accurate and complete. Finally, we employ transfer learning using a large deduplicated bug-fix corpus to show that these models can exhibit better performance if given larger amounts of high-quality pre-training data, leading us to conclude that while previous studies have over-estimated performance due to poor dataset quality, this does not demonstrate that better performance is not possible.","2576-9103","979-8-3315-2088-5","10.1109/ACSAC63791.2024.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917419","Software Security;Application Security","Training;Accuracy;Codes;Reviews;Transfer learning;Maintenance engineering;Data models;Software;Testing;Software engineering","","","","23","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"DeepLegal-CN: Research and Application of a DeepSeek-Based Large Language Model for the Legal Domain","S. Guo","University of Technology Sydney, Sydney, Australia","2025 IEEE 7th International Conference on Communications, Information System and Computer Engineering (CISCE)","10 Jul 2025","2025","","","944","947","The legal domain is one of the most linguistically intensive professional fields, characterized by complex structures, specialized terminology, and intricate logical reasoning. Legal professionals must frequently handle diverse legal documents such as regulations, judgments, contracts, and legal opinions. This complexity poses significant challenges for natural language processing (NLP), especially in understanding and generating legal texts. Recent advancements in large language models (LLMs) have demonstrated remarkable generalization capabilities across various NLP tasks, sparking interest in their application to legal scenarios. However, most existing LLMs face limitations in legal applications, especially in Chinese contexts. Proprietary models entail high inference costs and raise privacy concerns, while open-source models often lack domain-specific training on legal corpora. Moreover, the majority are trained on English datasets, limiting their adaptability to Chinese legal language, which differs significantly in expression and logic. To address these challenges, this paper proposes a legal LLM framework based on DeepSeek, a powerful open-source Chinese LLM. The framework integrates feature engineering and task-driven prompt design to enhance the model’s capability in understanding and reasoning over Chinese legal texts. We evaluate the model across multiple tasks, including legal question answering and case matching, demonstrating its effectiveness and identifying existing limitations. This study provides a novel approach for legal AI development in the Chinese context and offers valuable insights into building adaptable, domain-aware LLMs for legal applications.","2833-2423","979-8-3315-0161-7","10.1109/CISCE65916.2025.11065329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065329","LLM;Prompt Engineering;Legal Text Reasoning;Offline LLM","Training;Adaptation models;Law;Terminology;Large language models;Computational modeling;Cognition;Question answering (information retrieval);Robustness;Regulation","","","","12","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"A self-adaptation framework for dealing with the complexities of software changes","J. Wan; Q. Li; L. Wang; L. He; Y. Li","Software Engineering Institute, Xidian University, Xi'an Province, China; Software Engineering Institute, Xidian University, Xi'an Province, China; Software Engineering Institute, Xidian University, Xi'an Province, China; Software Engineering Institute, Xidian University, Xi'an Province, China; Software Engineering Institute, Xidian University, Xi'an Province, China",2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS),"23 Apr 2018","2017","","","521","524","Software Self-adaption (SA) is a promising technology to reduce the cost of software maintenance. However, the complexities of software changes such as various and producing different effects, interrelated and occurring in an unpredictable context challenge the SA. The current methods may be insufficient to provide the required self-adaptation abilities to handle all the existent complexities of changes. Thus, this paper presents a self-adaptation framework which can provide a multi-agent system for self-adaptation control to equip software system with the required adaptation abilities. we employ the hybrid control mode and construct a two-layer MAPE control structure to deal with changes hierarchically. Multi-Objective Evolutionary Algorithm and Reinforcement Learning are applied to plan an adequate strategy for these changes. Finally, in order to validate the framework, we exemplify these ideas with a meta-Search system and confirm the required self-adaptive ability.","2327-0594","978-1-5386-0497-7","10.1109/ICSESS.2017.8342969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342969","Self-adaptive systems;Search-based software engineering;Multi-agent systems;Reinforcement Learning;Multi-Objective Evolutionary Algorithm","Planning;Google;Learning (artificial intelligence);Servers;Task analysis;Complexity theory;Software","","2","","10","IEEE","23 Apr 2018","","","IEEE","IEEE Conferences"
"Can a Llama Be a Watchdog? Exploring Llama 3 and Code Llama for Static Application Security Testing","C. Curto; D. Giordano; D. G. Indelicato; V. Patatu","Department of Electrical Electronic and Computer Engineering, Università degli Studi di Catania, Catania, Italy; Department of Electrical Electronic and Computer Engineering, Università degli Studi di Catania, Catania, Italy; Darwin Technologies S.r.l., EHT S.c.p.A., Catania, Italia; EHT S.c.p.A., Catania, Italia",2024 IEEE International Conference on Cyber Security and Resilience (CSR),"24 Sep 2024","2024","","","395","400","Research in software vulnerability detection has seen significant growth, with numerous systems and techniques being developed. Deep learning approaches have become partic-ularly popular, with various architectures being adapted for this purpose. Llama 3, the newest AI model from Meta, was released in April 2024. It has been trained on an extensive text corpus and contains four times the amount of code compared to its prede-cessor, Llama 2. In contrast, Code Llama stands out as the only model in the Llama series that has been pre-trained specifically on source code. In this study, we examine the effectiveness of the Llama architectures in static security analysis tasks by fine-tuning Llama 3 and Code Llama for vulnerability classification and detection with high precision. To provide comprehensive insights, we compare their performance against three leading models-CodeBERT, PolyCoder, and NatGen-known for their effectiveness in source code analysis, using two benchmark C/C++ datasets.","","979-8-3503-7536-7","10.1109/CSR61664.2024.10679444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679444","Cybersecurity;Vulnerability Detection;Large Language Models;Transformer","Training;Analytical models;Adaptation models;Codes;Source coding;Computer architecture;Software","","","","26","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"Exploring Artificial Intelligence to Assist Kinematics Analysis of Rigid Bodies","H. R. Morano-Okuno; G. Sandoval-Benitez","Tecnologico de Monterrey, School of Engineering and Science, Mexico; Tecnologico de Monterrey, School of Engineering and Science, Mexico",2024 International Conference on Engineering and Emerging Technologies (ICEET),"12 Mar 2025","2024","","","1","6","Artificial Intelligence applications have spread to various areas of knowledge. Some of the applications of Machine Learning are Large Language Models and Natural Language Processing. An efficient way of communication between users and Artificial Intelligence information models is through Prompt Engineering. This article explores using Artificial Intelligence to assist in the kinematics analysis of rigid bodies through Prompt Engineering. The results obtained from the kinematic analysis of a Large Language Model are evaluated through a case study. Among the findings, it is determined that the results of the analysis depend on the clarity and content of details provided by the user in the creation of the Prompts used to make the queries, as well as the user's expertise in the subject of kinematic analysis of rigid bodies since it must be determined the certainty of the answers provided by Artificial Intelligence.","2831-3682","979-8-3315-3289-5","10.1109/ICEET65156.2024.10913916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913916","artificial intelligence;prompt engineering;natural language processing;kinematics analysis;rigid bodies;educational innovation;higher education;professional education;tec21 model","Technological innovation;Analytical models;Large language models;Education;Kinematics;Machine learning;Natural language processing;Prompt engineering;Artificial intelligence","","","","18","IEEE","12 Mar 2025","","","IEEE","IEEE Conferences"
"RAG Certainty: Quantifying the Certainty of Context-Based Responses by LLMs","K. Hasegawa; S. Hidano; K. Fukushima","KDDI Research, Inc., Saitama, Japan; KDDI Research, Inc., Saitama, Japan; KDDI Research, Inc., Saitama, Japan",2024 International Conference on Machine Learning and Applications (ICMLA),"4 Mar 2025","2024","","","912","917","Large language models (LLMs) have recently been employed for a wide variety of purposes. Retrieval-augmented generation (RAG), in which an LLM generates a response based on context relevant to the prompt, is often used to enable the LLM to adapt to specialized domains. However, sentences generated by a generative LLM may contain incorrect information, known as “hallucinations.” The challenge in identifying hallucinations within the RAG framework involves evaluating the certainty of both context retrieval and LLM outputs. In this paper, we propose a metric called RAG certainty to quantify the certainty of LLM outputs within a RAG framework. The proposed metric is calculated based on certainty scores from both information retrieval and response generation. Experimental results demonstrate that the proposed metric effectively reflects the certainty of information retrieval in a RAG framework. We further validated the proposed metric through a case study that assesses the predicted Common Vulnerability Scoring Sys-tem (CVSS) scores for cybersecurity vulnerabilities and found that errors are mitigated according to the proposed metric.","1946-0759","979-8-3503-7488-9","10.1109/ICMLA61862.2024.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903445","large language model;retrieval-augmented generation;certainty;security;CVSS","Measurement;Accuracy;Large language models;Retrieval augmented generation;Machine learning;Predictive models;Information retrieval;Computer security","","","","16","IEEE","4 Mar 2025","","","IEEE","IEEE Conferences"
"LLM vs HLS for RTL Code Generation: Friend or Foe?","S. Bhattacharyya; S. B. G; C. Karfa",NA; NA; NA,2024 IEEE 33rd Asian Test Symposium (ATS),"14 Mar 2025","2024","","","1","6","High-Level Synthesis (HLS) tools are widely used for the efficient transformations of behavioural code into equivalent hardware in Register Transfer Level (RTL). However, recent studies show that Large Language Models (LLMs) can be used to generate Verilog or equivalent hardware descriptions directly from behavioural descriptions, making LLMs a potential ‘foe’ for HLS. While LLMs can generate RTL code, they lack certain fine aspects like control over design constraints and optimizations and the inability to handle large behavioural designs. In this paper, we show how LLM can be a ‘friend’ of HLS in generating RTL directly from behavioural descriptions. Although HLS tools have matured over the years, making the input code synthesizable, applying correct pragmas and source code optimizations are still manual efforts in the HLS. LLMs can make hardware accelerator design with HLS easier by automating these manual steps. We show that LLMs are efficient in resolving synthesis issues and optimizing course code for HLS. We have used performance to hardware gain to evaluate the LLMs’ performance in optimizing code adhering to resource usage. We perform our experiments on image processing tasks as benchmarks and discuss where LLM can perform well as well as the issues faced by it when trying to maximize the performance to hardware gain.","2377-5386","979-8-3315-2916-1","10.1109/ATS64447.2024.10915452","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915452","High Level Synthesis;LLM;RTL","Codes;Image resolution;Source coding;Large language models;Manuals;Streaming media;Register transfer level;Hardware;Space exploration;Optimization","","","","20","IEEE","14 Mar 2025","","","IEEE","IEEE Conferences"
"Analyzing Prompt Influence on Automated Method Generation: An Empirical Study with Copilot","I. D. Fagadau; L. Mariani; D. Micucci; O. Riganelli","University of Milano - Bicocca, Milan, Italy; University of Milano - Bicocca, Milan, Italy; University of Milano - Bicocca, Milan, Italy; University of Milano - Bicocca, Milan, Italy",2024 IEEE/ACM 32nd International Conference on Program Comprehension (ICPC),"18 Jun 2024","2024","","","24","34","Generative AI is changing the way developers interact with software systems, providing services that can produce and deliver new content, crafted to satisfy the actual needs of developers. For instance, developers can ask for new code dtrectly from within their IDEs by writing natural language prompts, and integrated services based on generative AI, such as Copilot, immediately respond to prompts by providing ready-to-use code snippets. Formulating the prompt appropriately, and incorporating the useful information while avoiding any information overload, can be an important factor in obtaining the right piece of code. The task of designing good prompts is known as prompt engineering. In this paper, we systematically investigate the influence of eight prompt features on the style and the content of prompts, on the level of correctness, complexity, size, and similarity to the developers’ code of the generated code. We specifically consider the task of using Copilot with 124,800 prompts obtained by systematically combining the eight considered prompt features to generate the implementation of 200 Java methods. Results show how some prompt features, such as the presence of examples and the summary of the purpose of the method, can significantly influence the quality of the result. Ccs Concepts • Software and its engineering $\rightarrow$Integrated and visual development environments.","2643-7171","979-8-4007-0586-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556442","Prompt engineering;code generation;Copilot","Java;Visualization;Codes;Semantics;Natural languages;Oral communication;Writing","","4","","31","","18 Jun 2024","","","IEEE","IEEE Conferences"
