"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Engineering LLM Powered Multi-Agent Framework for Autonomous CloudOps","K. Parthasarathy; K. Vaidhyanathan; R. Dhar; V. Krishnamachari; A. Kakran; S. Akshathala; S. Arun; A. Karan; B. Muhammed; S. Dubey; M. Veerubhotla","MontyCloud Inc; Software Engineering Research Center, IIIT, Hyderabad, India; Software Engineering Research Center, IIIT, Hyderabad, India; MontyCloud Inc; Software Engineering Research Center, IIIT, Hyderabad, India; Software Engineering Research Center, IIIT, Hyderabad, India; Software Engineering Research Center, IIIT, Hyderabad, India; Software Engineering Research Center, IIIT, Hyderabad, India; MontyCloud Inc; MontyCloud Inc; MontyCloud Inc",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","201","211","Cloud Operations (CloudOps) is a rapidly growing field focused on the automated management and optimization of cloud infrastructure which is essential for organizations nav-igating increasingly complex cloud environments. MontyCloud Inc. is one of the major companies in the CloudOps domain that leverages autonomous bots to manage cloud compliance, security, and continuous operations. To make the platform more accessible and effective to the customers, we leveraged the use of GenAl. Developing a GenAl-based solution for autonomous CloudOps for the existing MontyCloud system presented us with various challenges such as i) diverse data sources; ii) orchestration of multiple processes and iii) handling complex workflows to automate routine tasks. To this end, we developed MOYA, a multi-agent framework that leverages GenAI and balances autonomy with the necessary human control. This framework integrates various internal and external systems and is optimized for factors like task orchestration, security, and error mitigation while producing accurate, reliable, and relevant insights by utilizing Retrieval Augmented Generation (RAG). Evaluations of our multi-agent system with the help of practitioners as well as using automated checks demonstrate enhanced accuracy, responsiveness, and effectiveness over non-agentic approaches across complex workflows.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030040","Autonomous CloudOps;LLM;AI Engineering;Multi-Agent Framework;Generative AI;Software Architecture","Accuracy;Software architecture;Generative AI;Soft sensors;Prevention and mitigation;Retrieval augmented generation;Software reliability;Security;Optimization;Multi-agent systems","","","","20","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"FeedbackFuzz: Fuzzing Processors via Intricate Program Generation with Feedback Engine","J. Wang; B. Cui; R. Dong; R. Zhai","School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","As modern processor designs become increasingly complex, detecting hardware vulnerabilities has become more challenge. Recently, hardware fuzzing techniques have shown promising results in generating complex programs for processor testing. However, the complexity of processors continues to limit the speed of vulnerability detection and the ability to achieve sufficient coverage.This paper introduces FeedbackFuzz, a novel processor fuzzer aimed at significantly accelerating vulnerability detection. FeedbackFuzz enhances detection efficiency by generating more effective test programs and optimizing the process of identifying vulnerabilities in longer programs. It designs a feedback engine for processors with out-of-order execution capabilities. Additionally, we leverage large language models (LLMs) to handle the complexity of locating vulnerabilities in lengthy programs, greatly speeding up the detection process. We evaluated FeedbackFuzz on several open-source RISC-V processors. Our evaluation demonstrates that the efficiency of FeedbackFuzz has increased by 40% compared to Cascade, with a coverage acceleration of 16.7%.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10889404","National Natural Science Foundation of China; Beijing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889404","Hardware Security;Fuzzing;RISC-V;Security Vulnerabilities;Feedback engine","Out of order;Location awareness;Fuzzing;Signal processing;Hardware;Complexity theory;Security;Speech processing;Engines;Testing","","","","28","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Overview of Generative Artificial Intelligence Security","K. Ots",NA,Securing Microsoft Azure OpenAI,"","2025","","","1","17","Summary <p>Enterprises need to be aware of the new risks that come with using generative artificial intelligence (AI) and tackle them proactively to reap the benefits. Generative AI introduces completely new risk categories and changes our established risk management approach. Generative AI introduces a new risk category of intentional malicious usage of generative AI. Alongside the positive productivity impact of generative AI usage for approved use cases, threat actor productivity is also growing at an unprecedented rate. The AI usage layer covers user accountability and data governance for generative AI application. Users need to be aware of the security, privacy, and ethical implications of using generative AI, as well as the potential threats of AI‐based attacks. The AI application security layer focuses on application design and safety systems. The AI application layer is the interface between the user and the generative AI.</p>","","9781394291113","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10955772.pdf&bkn=10955557&pdfType=chapter","","Generative AI;Artificial intelligence;Security;Data models;Grounding;Training data;Context modeling;Tuning;Virtual assistants;Probabilistic logic","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Event-Triggered Observer-Based $\mathcal {H}_\infty$ Consensus Control and Fault Detection of Multiagent Systems Under Stochastic False Data Injection Attacks","X. -G. Guo; D. -Y. Zhang; J. -L. Wang; J. H. Park; L. Guo","School of Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; School of Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Autonomous Intelligent Systems Department, Hangzhou Innovation Institute of Beihang University, Hangzhou, China; Department of Electrical Engineering, Yeungnam University, Kyongsan, South Korea; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",IEEE Transactions on Network Science and Engineering,"23 Mar 2022","2022","9","2","481","494","This paper investigates the event-triggered observer-based security consensus and fault detection problem for nonlinear multi-agent systems (MASs) under external disturbances and stochastic false data injection attacks (FDIAs) over a directed communication network. The randomly occurring FDIAs are modeled by random variables that follow the Bernoulli distribution. An observer-based event-triggered control strategy using only local measurements and information from neighboring agents is developed, where the Zeno behavior of event-triggered mechanism (ETM) is excluded. Interestingly, the observer errors are first regarded as disturbance and then attenuated by $\mathcal {H}_{\infty }$ norm bounds, together with the external disturbances. Meanwhile, it is worth highlighting here that the same information used by the state observers is also adopted to construct residuals with adaptive thresholds, whose aim is to detect faults occurring in any agents. In addition, the accuracy of the observer and the performance of the fault detection mechanism are improved by introducing the disturbance compensation mechanism. Finally, simulation results are provided to illustrate the effectiveness and advantages of the proposed strategy.","2327-4697","","10.1109/TNSE.2021.3121727","National Natural Science Foundation of China(grant numbers:62173028,61773056); Scientific and Technological Innovation Foundation of Shunde Graduate School(grant numbers:BK19AE018); Fundamental Research Funds for the Central Universities(grant numbers:FRFTP-20-09B,230201606500061,FRF-BD-19-002A); National Natural Science Foundation of China(grant numbers:62173024); Natural Science Foundation of Zhejiang Province(grant numbers:LD21F030001); National Research Foundation of Korea; Ministry of Science and Information and Communications Technology (ICT)(grant numbers:2019R1A5A8080290); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583901","Observer-based anti-disturbance control;event-triggered mechanism (ETM);fault detection mechanism;multi-agent systems (MASs);false data injection attacks (FDIAs)","Fault detection;Observers;Symmetric matrices;Topology;Network topology;Multi-agent systems;Electrical engineering","","49","","45","CCBYNCND","21 Oct 2021","","","IEEE","IEEE Journals"
"Generative Al-aided Joint Training-free Secure Semantic Communications via Multi-modal Prompts","H. Du; G. Liu; D. Niyato; J. Zhang; J. Kang; Z. Xiong; B. Ai; D. I. Kim","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Beijing Jiaotong University, China; Guangdong University of Technology, China; Singapore University of Technology and Design, Singapore; Beijing Jiaotong University, China; Sungkyunkwan University, Korea","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","12896","12900","Semantic communication (SemCom) holds promise for reducing network resource consumption while achieving the communications goal. However, the computational overheads in jointly training semantic encoders and decoders—and the subsequent deployment in network devices—are overlooked. Recent advances in Generative artificial intelligence (GAI) offer a potential solution. The robust learning abilities of GAI models indicate that semantic decoders can reconstruct source messages using a limited amount of semantic information, e.g., prompts, without joint training with the semantic encoder. A notable challenge, however, is the instability introduced by GAI’s diverse generation ability. This instability, evident in outputs like text-generated images, limits the direct application of GAI in scenarios demanding accurate message recovery, such as face image transmission. To solve the above problems, this paper proposes a GAI-aided SemCom system with multi-model prompts for accurate content decoding. Moreover, in response to security concerns, we introduce the application of covert communications aided by a friendly jammer. The system jointly optimizes the diffusion step, jamming, and transmitting power with the aid of the generative diffusion models, enabling successful and secure transmission of the source messages.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447237","National Research Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447237","Generative AI;semantic communications;prompt engineering;covert communications","Training;Wireless communication;Computational modeling;Image communication;Semantics;Signal processing;Decoding","","15","","17","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"Auction Bidding Methods for Multiagent Consensus Optimization in Supply–Demand Networks","N. Rahimi; J. Liu; A. Shishkarev; I. Buzytsky; A. G. Banerjee","University of Washington, Seattle, WA, US; University of Washington, Seattle, WA, US; Bias Intelligence, Inc., Roswell, GA, USA; Bias Intelligence, Inc., Roswell, GA, USA; University of Washington, Seattle, WA, US",IEEE Robotics and Automation Letters,"23 Sep 2018","2018","3","4","4415","4422","Multiagent systems are characterized by decentralized decision-making by the (semi)autonomous agents and localized communication or information exchange among the neighboring agents. Supply–demand networks form the backbones of both services and manufacturing industries, and need to operate as efficiently as possible to yield optimized returns. In this letter, we bring the notion of multiagent systems to clustered supply–demand networks such that each supplier acts as an agent. Consequently, we adapt consensus-based auction bidding methods to optimize the assignment of demands to the suppliers with known communication pathways and resource constraints. Results on moderately large networks show promising performance in terms of both assignment quality, as given by the overall demand delivery cost and proportion of assigned demands, and computation time.","2377-3766","","10.1109/LRA.2018.2869999","Anders Brown (University of Washington, BSME’92, MSME’94); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463627","Agent-based systems;logistics;optimal demand assignment;supply networks","Task analysis;Optimization;Supply chains;Robot sensing systems;Decision making;Manufacturing industries","","5","","23","IEEE","12 Sep 2018","","","IEEE","IEEE Journals"
"TriageHD: A Hyper-Dimensional Learning-to-Rank Framework for Dynamic Micro-Segmentation in Zero-Trust Network Security","R. Masukawa; S. Yun; S. Jeong; N. D. Bastian; M. Imani","Department of Computer Science, University of California at Irvine, Irvine, CA, USA; Department of Computer Science, University of California at Irvine, Irvine, CA, USA; Department of Computer Science, University of California at Irvine, Irvine, CA, USA; United States Military Academy, West Point, NY, USA; Department of Computer Science, University of California at Irvine, Irvine, CA, USA",IEEE Access,"8 Aug 2025","2025","13","","136806","136815","Network security faces major challenges from sophisticated cyber attacks that exploit lateral movement and evade traditional network intrusion detection mechanisms. To address these challenges, micro-segmentation has proven to be an effective defense strategy for isolating network components and limiting breach propagation. This paper presents TriageHD, a novel framework that integrates graph-based Hyper-Dimensional Computing (HDC) with a learning-to-rank algorithm to strengthen zero-trust network security. TriageHD constructs dynamic scene graphs from time-based network flow data, integrating feature representations extracted via a self-attention-based payload encoder. It employs a learning-to-rank algorithm with an approximated nDCG loss function, incorporating time-aware relevance and graph-aware HDC to prioritize nodes for segregation, thereby mitigating attack propagation. Experiments on the CIC-IDS-2017 dataset demonstrate that TriageHD outperforms state-of-the-art graph neural networks, including graph convolutional networks, graph attention networks, and graph transformer models, in threat prioritization accuracy. By providing a dynamic micro-segmentation approach, TriageHD significantly enhances automated threat detection and response. This work bridges traditional network security measures with zero-trust paradigms, laying the groundwork for future advancements in dynamic micro-segmentation.","2169-3536","","10.1109/ACCESS.2025.3592877","U.S. Military Academy (USMA) under Cooperative(grant numbers:W911NF-24-2-0200); U.S. Army Combat Capabilities Development Command (DEVCOM) C5ISR Center(grant numbers:USMA23011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096592","Zero-trust;network security;dynamic micro-segmentation;graph neural network;hyper-dimensional computing;learning-to-rank algorithm","Network security;Heuristic algorithms;Optimization;Training;Threat assessment;Standards;Logic gates;Encoding;Vectors;Surveys","","","","36","CCBY","25 Jul 2025","","","IEEE","IEEE Journals"
"Resilient Distributed Optimization Algorithm Based on Trusted Nodes against Malicious Attacks","L. Cao; W. Gao","School of Mathematics, South China University of Technology, Guangzhou, China; School of Mathematics, South China University of Technology, Guangzhou, China",2024 43rd Chinese Control Conference (CCC),"17 Sep 2024","2024","","","5943","5948","Distributed optimization problem is a category of optimization problems on multi-agent systems. In contrast to centralized optimization, it does not require a central decision-maker and has higher openness and scalability, which is more conducive to solving large-scale complex optimization problems. However, at the same time, it is more susceptible to network attacks. To withstand malicious attacks, some scholars have introduced a fault-tolerance mechanism by constructing a connected dominating set (CDS) of trusted nodes within the network. The CDS governs network decision-making to enhance the system security. In this paper, we relax this construction and propose a novel fault-tolerant mechanism. This mechanism does not require the construction of a CDS but only ensures that each node is connected to at least one trusted node. By sacrificing a little iteration time, it combats malicious attacks and avoids the algorithm moving towards a centralized approach. Then the paper leverages the new fault-tolerant mechanism to propose a resilient distributed optimization algorithm based on trusted nodes. The effectiveness of the algorithm is verified by analyzing the consensus and convergence of it. Finally, numerical experimental results show that the performance of the proposed algorithm is almost consistent to the resilient distributed optimization algorithm based on the CDS. The proposed algorithm is effective and can still operate normally even when the trusted nodes do not form a CDS.","1934-1768","978-9-8875-8158-1","10.23919/CCC63176.2024.10662289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10662289","Distributed optimization;Multi-agent systems;Trusted nodes;Malicious attacks","Fault tolerance;Filtering;Scalability;Fault tolerant systems;Decision making;Resists;Security","","","","22","","17 Sep 2024","","","IEEE","IEEE Conferences"
"Distributed Optimal Consensus Learning Control for Nonlinear MASs with Output Constraints","Z. Guo; X. -M. Li; H. Li; R. Lu","School of Automation and Guangdong Province Key Laboratory of Intelligent Decision and Cooperative Control, Guangdong University of Technology, Guangzhou, Guangdong, China; School of Automation and Guangdong Province Key Laboratory of Intelligent Decision and Cooperative Control, Guangdong University of Technology, Guangzhou, Guangdong, China; School of Automation and Guangdong Province Key Laboratory of Intelligent Decision and Cooperative Control, Guangdong University of Technology, Guangzhou, Guangdong, China; School of Automation and Guangdong Province Key Laboratory of Intelligent Decision and Cooperative Control, Guangdong University of Technology, Guangzhou, Guangdong, China",2021 6th International Conference on Robotics and Automation Engineering (ICRAE),"4 Jan 2022","2021","","","108","112","This paper proposes a distributed optimal consensus control approach based on adaptive dynamic programming for multi-agent systems (MASs) with output constraints. Considering the environment and security constraints of system outputs, a barrier function is adopted to transform the constrained system into an equivalent unconstrained system. To facilitate the controller design, a distributed observer is constructed to generate desired tracking signals for each follower by estimating the states of leader. Then, the leader-follower consensus problem of MASs with output constraints is formulated as a general optimal tracking control problem for multiple independent single systems. In the neural network (NN) training process, only a single critic NN is used to estimate the optimal cost function of each agent, and the actor NN is eliminated. A novel approximate controller including error term and NN approximation term is derived to ensure the stability of the closed-loop system and achieve the desired control performance. Finally, the effectiveness of the developed distributed optimal consensus control approach is verified by a simulation example.","","978-1-6654-0697-0","10.1109/ICRAE53653.2021.9657798","National Natural Science Foundation of China(grant numbers:62121004,62033003); China Postdoctoral Science Foundation(grant numbers:2021TQ0079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9657798","adaptive dynamic programming;critic neural network (NN);distributed observer;multi-agent systems (MASs);output constraints","Training;Optimal control;Artificial neural networks;Transforms;Consensus control;Observers;Cost function","","","","13","IEEE","4 Jan 2022","","","IEEE","IEEE Conferences"
"Forest Fire Image Classification Through Decentralized DNN Inference","D. Papaioannou; V. Mygdalis; I. Pitas","Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Faculty of Business and Economics, University of Antwerp, Antwerpen, Belgium; Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece",2024 IEEE International Conference on Image Processing Challenges and Workshops (ICIPCW),"2 Dec 2024","2024","","","4134","4140","In the realm of Natural Disaster Management (NDM), timely communication with local authorities is paramount for an effective response. To achieve this, multi-agent systems play a pivotal role by proficiently identifying and categorizing various disasters. In the field of Distributed Deep Neural Network (D-DNN) inference, such approaches often require DNN nodes to transmit their results to the cloud for inference, or they necessitate the establishment of a fixed topology network to enable inference directly on the edge, a practice prone to security risks. In this work, we propose a decentralized inference strategy tailored for fire classification tasks. In this approach, individual DNN nodes communicate within a network and enhance their predictions by considering other DNN node inference outputs that contribute to improving their individual performance. The overall coordination of the system on a specific decision is achieved through a consensus protocol, which acts as a universally accepted inference rule adopted by all DNN nodes operating within the system. We present a comprehensive experimental analysis, of the forest-fire classification task, focusing on enhancing both individual DNN node performance and the stability of the consensus protocol.","","979-8-3315-1594-2","10.1109/ICIPCW64161.2024.10769107","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10769107","Natural Disaster Management (NDM);Fire classification;Multi-Agent Systems;Decentralized DNN Inference;BFT Consensus Protocol","Decision making;Artificial neural networks;Disaster management;Forestry;Stability analysis;Consensus protocol;Topology;Security;Multi-agent systems;Resilience","","","","25","IEEE","2 Dec 2024","","","IEEE","IEEE Conferences"
"Meta-Reinforcement Learning for Adaptation in Dynamic Cyber Security Environment","S. Tiwari; A. Roshan; A. Baranwal; S. Sharma; M. Gogoi; S. Verma","Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India; Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India; Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India; Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India; Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India; Information Technology, Indian Institute of Information Technology Allahabad, Prayagraj, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","7","This article investigates the application of meta-learning in training reinforcement learning agents for fast adaptation in rapidly changing dynamic environments. The proposed meta-learning approach demonstrates promising results in multi-agent environments, outperforming baseline algorithms and achieving stable convergence. However, in single-agent settings, the meta-algorithms exhibit similar or inferior performance compared to baseline algorithms, potentially due to overfitting. Nevertheless, the meta-learning algorithms perform well in non-dynamic single-agent environments, showcasing their ability to adapt effectively. The findings highlight the potential of incorporating meta-learning approaches in multi-agent systems to enhance adaptive behaviours and optimize performance in dynamic environments.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10725126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725126","Meta Learning;Reinforcement Learning;Dynamic Environment;Cyber Security;Learning to Adapt","Metalearning;Training;Adaptation models;Heuristic algorithms;Reinforcement learning;Security;Computer crime;Multi-agent systems;Convergence","","","","23","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Towards the LLM-Based Generation of Formal Specifications from Natural-Language Contracts: Early Experiments with Symboleo","M. N. Zitouni; A. A. Anda; S. Rajpal; D. Amyot; J. Mylopoulos","School of EECS, University of Ottawa, Ottawa, Canada; School of EECS, University of Ottawa, Ottawa, Canada; School of EECS, University of Ottawa, Ottawa, Canada; School of EECS, University of Ottawa, Ottawa, Canada; School of EECS, University of Ottawa, Ottawa, Canada",2025 IEEE/ACM Requirements Engineering for AI-powered SoftwarE (RAISE),"26 Jun 2025","2025","","","1","9","Over the past decade, different domain-specific languages (DSLs) were proposed to formally specify requirements stated in legal contracts, mainly for analysis but also for code generation. Symboleo is a promising language in that area. However, writing formal specifications from natural-language contracts is a complex task, especially for legal experts who do not have formal language expertise. This paper reports on an exploratory experiment targeting the automated generation of Symboleo specifications from business contracts in English using Large Language Models (LLMs). Combinations (38) of prompt components are investigated (with/without the grammar, semantics explanations, 0 to 3 examples, and emotional prompts), mainly on GPT-4o but also to a lesser extent on 4 other LLMs. The generated specifications are manually assessed against 16 error types grouped into 3 severity levels. Early results on all LLMs show promising outcomes (even for a little-known DSL) that will likely accelerate the specification of legal contracts. However, several observed issues, especially around grammar/syntax adherence and environment variable identification (49%), suggest many areas where potential improvements should be investigated.","","979-8-3315-2619-1","10.1109/RAISE66696.2025.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050480","Code Generation;DSL;Large Language Model;Legal Contract;Requirements Specification;Symboleo","Codes;Law;Large language models;Semantics;Software;Grammar;DSL;Formal specifications;Requirements engineering;Contracts","","1","","33","IEEE","26 Jun 2025","","","IEEE","IEEE Conferences"
"An LLM-Based Modeling and Decision Optimization for User-Centric Electric Vehicle Charging","P. Ou; Y. Wang; W. Lin; J. Wu","Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China",2024 IEEE 8th Conference on Energy Internet and Energy System Integration (EI2),"15 May 2025","2024","","","4078","4083","Rapid adoption of Electric Vehicles (EVs) has significantly increased the demand for user-centric and personalized EV charging solutions. Existing charging decisions primarily rely on static optimization, involving complicated modeling and algorithms. This, however, poses a high communicative and technical barrier between users and machines, leading to a poor quality-of-experience. To this end, this paper proposes a novel large language model (LLM)-based multi-agent framework, acting as a mediator between users and devices to deliver a direct language-to-solution service. Our framework consists of three specialized agents, i.e., Agent-I, M, and -C, with each responsible for information querying, model construction, and code generation, separately. First, Agent-I extracts vehicle information and user preferences through interactive dialogues with users, and retrieves comprehensive brand and model parameters from external databases. Next, Agent-M filters out key modeling parameters, and grabs real-time electricity prices for charging. Finally, Agent-C generates the professional codes for commercial solvers, e.g., Gurobi, subsequently obtaining optimal charging solutions. Two cases with different EV brands and user preferences have then been tested to demonstrate that our framework can significantly improve user experience while maintaining the accuracy and optimality of charging decisions through a direct language-to-solution mode. This study showcases the potential of LLMs in smart charging systems and pave a way for user-centric resource optimization and scheduling.","","979-8-3315-2352-7","10.1109/EI264398.2024.10991378","Shenzhen Research Institute of Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10991378","Large language models;multi-agent collaboration;EV charging;optimization","Codes;Accuracy;Parameter estimation;Databases;Large language models;System integration;User experience;Real-time systems;Optimization;Smart charging","","","","21","IEEE","15 May 2025","","","IEEE","IEEE Conferences"
"Enhancing Reentrancy Vulnerability Detection and Repair with a Hybrid Model Framework","M. Li; X. Ren; H. Fu; Z. Li; J. Sun","State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University; College of Computer Science and Technology, Zhejiang University; State Street Technology(Zhejiang) Ltd; College of Computer Science and Technology, Zhejiang University",2024 31st Asia-Pacific Software Engineering Conference (APSEC),"25 Apr 2025","2024","","","161","170","Smart contracts bring revolutionary changes to the credit landscape. However, their security remains intensely scrutinized due to numerous hacking incidents and inherent logical challenges. One well-known and representative issue is reentrancy vulnerability, exemplified by DAO attacks that lead to substantial economic losses. Conventional approaches to detecting and repairing reentrancy vulnerability often suffer from numerous limitations, including disregarding the intricate vulnerability features and the overfitting problems associated with imbalanced datasets. Large language models are distinguished for their excellent language understanding and have achieved explosive success in artificial intelligence. However, direct prompt-based LLMs-driven approaches for reentrancy vulnerability are plagued by inefficiencies and a lack of domain-specific vulnerability knowledge. This paper proposes a hybrid framework to enhance reentrancy vulnerability detection and repair and safeguard smart contract security. This unified framework comprises two crucial modules: enhanced DL-driven vulnerability detection and knowledge-aware LLMs-driven vulnerability repair. Our approach can significantly enhance reentrancy vulnerability detection and repair efficiency by integrating advanced techniques such as feature extraction, data balancing, deep learning networks, and knowledge-aware prompting. Extensive experimental results validate the superiority of our approach over state-of-the-art baselines, emphasizing its potential to fortify the security of smart contracts and blockchain-based systems. For instance, our approach can achieve 3.51 %, 2.31 %, 0.42%, and 0.85 % improvements in accuracy, recall, precision, and F1 score while detecting reentrancy vulnerability. Additionally, our approach also can achieve a 9.62% improvement in reentrancy vulnerability repair.","2640-0715","979-8-3315-3401-1","10.1109/APSEC65559.2024.00027","National Science Foundation of China(grant numbers:62302437); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967341","Smart Contract;Vulnerability Detection and Repair;LLMs;Reentrancy","Deep learning;Codes;Large language models;Smart contracts;Maintenance engineering;Syntactics;Feature extraction;Classification algorithms;Security;Software engineering","","","","48","IEEE","25 Apr 2025","","","IEEE","IEEE Conferences"
"Cybersecurity Risks of Social Network Data Aggregation: Leveraging Machine Learning and LLMs in Cloud Environments","A. Kaplunovich","Department of Computer Science, University of Maryland, Baltimore, MD, USA","2024 International Conference on Intelligent Computing, Communication, Networking and Services (ICCNS)","11 Dec 2024","2024","","","68","75","Social networks have become an integral part of modern life, providing APIs that enable the extraction of vast amounts of user data. Individuals frequently and willingly upload personal information, including photographs, opinions, and geographical locations, across various online platforms. Motivated by the amount of this data, our study aims to quantify the extent of personal information that can be harvested using automated cloud-based serverless architectures, social network APIs, and state-of-the-art Data Science techniques. This paper serves as a compelling exposé on the fragility of digital privacy, demonstrating how easily user data can be aggregated and analyzed through contemporary cloud computing technologies. Utilizing advanced Machine Learning graph models, we extracted a multitude of data points such as geolocations, social connections, similar user profiles, and even made accurate predictions about potential influencers and missing social connections within a user's network. Scalable serverless cloud solutions like NoSQL DynamoDB were employed to store aggregated data. Our findings underscore the imperative for individuals to exercise caution in safeguarding their personal information online, as user data can be collected, aggregated, and clustered with ease using modern Generative AI LLMs, RAG and ML techniques. Moreover, our study highlights the risks associated with metadata from camera photos uploaded to social networks. This metadata often includes timestamps, geolocation coordinates, and device information, which can be exploited to track activities, movements, and locations of individuals, effectively turning smartphones into IoT devices that provide continuous data streams. This aspect adds a critical layer to the discussion on cybersecurity, as it exposes how seemingly harmless data can be leveraged for surveillance and profiling. Additionally, we urge social platforms to carefully evaluate the types of user data accessible to third parties to mitigate potential security risks.","","979-8-3503-5469-0","10.1109/ICCNS62192.2024.10776060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10776060","cybersecurity;serverless cloud;ChatGPT;social networks;NoSQL;LLM;data science;RAG","Data privacy;Cloud computing;Social networking (online);Generative AI;Biological system modeling;Geology;Machine learning;Metadata;Electronic mail;Identification of persons","","","","27","IEEE","11 Dec 2024","","","IEEE","IEEE Conferences"
"Build Financial Software with Generative AI (From Scratch)","C. Kardell; M. Brouwer",Manning Publications; Manning Publications,Build Financial Software with Generative AI (From Scratch),"","2025","","","","","Build working and regulation-compliant financial software—from scratch! The software used by banks, trading firms, and other financial services has special requirements at every level, from securing the UI to making sure backend services comply with a host of regulations. Build Financial Software with Generative AI (From Scratch) shows you how to deliver full stack financial services software—and how generative AI can make you even more productive. In Build Financial Software with Generative AI (From Scratch) you will:  Explore the core concepts of FinTech Speed development with generative AI tools Develop and deploy containerized services Create and document APIs Effectively visualize your data  In Build Financial Software with Generative AI (From Scratch) you’ll build working software for processing Automated Clearing House (ACH) files, a cornerstone technology of banking that moves trillions of dollars every year. You’ll work with generative AI technology throughout the full stack application, including researching the tech for your application, spinning up a bare bone starting project, answering domain questions, clarifying functionality, and troubleshooting. Along the way, you’ll learn what sets FinTech projects apart from normal web apps.","","9781633436626","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10981921.pdf&bkn=10981920&pdfType=book","FinTech;ChatGPT;Copilot;React;Python;containerize;Docker;database design;Automated Clearing House;visualize;security;automate;compliance;testing;regulations;banks;trading firms;backend","","","","","","","1 May 2025","","","Manning","Manning eBooks"
"GEMMV: An LLM-Based Automated Performance-Aware Framework for GEMM Verilog Generation","G. Zhang; D. Zou; K. Sun; Z. Chen; M. Wang; Z. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Integrated Circuits, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; School of Integrated Circuits, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; School of Integrated Circuits, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"25 Jun 2025","2025","15","2","325","336","Recent advancements in artificial intelligence (AI) models have intensified the need for specialized AI accelerators. The design of optimized general matrix multiplication (GEMM) module tailored for these accelerators is crucial but time-consuming and expertise-demanding, creating a demand for automating design processes. Large language models (LLMs), capable of generating high-quality designs from human instructions, show great promise in automating GEMM module creation. However, the GEMM module’s vast design space and stringent performance requirements, along with the limitations of datasets and the lack of hardware performance awareness of LLMs, have made previous LLM-based register transfer level (RTL) code generation efforts unsuitable for GEMM design. To tackle these challenges, this paper proposes an automated performance-aware LLM-based framework, GEMMV, for generating high-correctness and high-performance Verilog code for GEMM. This framework utilizes in-context learning based on GPT-4 to automatically generate high-quality and well-annotated Verilog code for different variants of the GEMM. Additionally, it leverages in-context learning to obtain performance awareness by integrating a multi-level performance model (MLPM) with fine-tuned LLMs. The Verilog code generated by this framework reduces latency by 3.1x and improves syntax correctness by 65% and functionality correctness by 70% compared to earlier efforts.","2156-3365","","10.1109/JETCAS.2025.3568712","National Key Research and Development Program of China(grant numbers:2022YFB4400600); National Natural Science Foundation of China(grant numbers:62404256); Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:149); Key Project of Shenzhen Basic Research Program(grant numbers:JCYJ20241206180301003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994474","AI accelerators;design automation;LLMs;fine-tuning;GEMM","Adders;Hardware design languages;Codes;Hardware;Artificial intelligence;AI accelerators;Register transfer level;Training;Syntactics;Optimization","","","","44","IEEE","9 May 2025","","","IEEE","IEEE Journals"
"Toward a Multi-Agent System Architecture for Insight & Cybersecurity in Cyber-Physical Networks","W. M. S. Stout","Sandia National Laboratories, Albuquerque, New Mexico, USA",2018 International Carnahan Conference on Security Technology (ICCST),"23 Dec 2018","2018","","","1","5","Operational Technology (OT) networks existed well before the dawn of the Internet, and had enjoyed security through being air-gapped and isolated. However, the interconnectedness of the world has found its way into these OT networks, exposing their vulnerabilities for cyber attacks. As the global Internet continues to grow, it becomes more and more embedded with the physical world. The Internet of Things is one such example of how IT is blurring the cyber-physical boundaries. The eventuality will be a convergence of IT and OT. Until that day comes, cyber practitioners must still deal with the primitive security features of OT networks, maintain a foothold on enterprise and cloud networks, and attempt to instill sound security practices in burgeoning IoT networks. In this paper, we propose a new method to bring cyber security to OT and IoT-based networks, through Multi-agent Systems (MAS). MAS are flexible enough to integrate with fixed legacy networks, such as ICS, as well with be burned into newer devices and software, such as IoT and IT networks. In this paper, we discuss the features of MAS, the opportunities that exist to benefit cyber security, and a proposed architecture for a OT-based MAS.","2153-0742","978-1-5386-7931-9","10.1109/CCST.2018.8585632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585632","multi-agent system;IoT;OT;ICS;cyber security","Multi-agent systems;Integrated circuits;Internet of Things;Organizations","","3","","30","IEEE","23 Dec 2018","","","IEEE","IEEE Conferences"
"A Large Language Model-Based Agent for Automated Bidding Strategy Generation in Electricity Markets","R. Zou; X. Zhou; Y. Cheng; W. Liu; X. Wang; J. Zhao; X. Cai","School of Data Science, The Chinese University of Hong Kong (Shenzhen), Shenzhen, China; School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, Singapore; School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen); AIRS, Shenzhen, China; School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, Singapore; School of Electrical and Computer Engineering, The University of Sydney, Sydney, Australia; School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen), Shenzhen, China; Power Dispatch Control Department, Power Dispatch Control Center of Guangdong Power Grid Co., Ltd., Guangzhou, China",2025 IEEE International Conference on Power and Integrated Energy Systems (ICPIES),"14 Jul 2025","2025","","","475","480","As electricity markets become increasingly complex due to evolving market structures and the integration of renewable energy, optimizing bidding strategies for power generators has become essential to ensure competitiveness and efficiency. However, traditional bidding methods often struggle to adapt to market fluctuations and the inherent uncertainty of renewable energy generation. To address these challenges, we explore the potential of Large Language Models (LLMs) in developing intelligent and adaptive bidding strategies. This paper proposes a new agent for automated bidding strategy generation with systematic prompt engineering adopting the Chain of Thought (CoT) and auto-debug mechanism based on reflection. Experimental results demonstrate that our approach improves the accuracy, adaptability, and efficiency of automated bidding strategy generation in dynamic electricity markets. This paper highlights the potential of LLMs in energy trading, paving the way for more intelligent and autonomous decision-making agents.","","979-8-3315-1185-2","10.1109/ICPIES65420.2025.11070004","National Natural Science Foundation of China; Guangdong Power Grid Company; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11070004","large language model;bidding strategy generation;electricity market;prompt engineering;agent","Renewable energy sources;Fluctuations;Accuracy;Uncertainty;Systematics;Large language models;Decision making;Electricity supply industry;Prompt engineering;Context modeling","","","","16","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"SyncIntellects: Orchestrating LLM Inference with Progressive Prediction and QoS-Friendly Control","X. Lin; Z. Zhang; P. Yue; H. Li; J. Zhang; B. Fan; H. Su; X. Gong","Nankai University, Tianjin, China; Nankai University, Tianjin, China; State Grid Tianjin Electronic Power Company, Tianjin, China; Nankai University, Tianjin, China; Nankai University, Tianjin, China; Nankai University, Tianjin, China; National University of Defense Technology, Hunan, China; Nankai University, Tianjin, China",2024 IEEE/ACM 32nd International Symposium on Quality of Service (IWQoS),"26 Sep 2024","2024","","","1","10","Large Language Models (LLMs) have shown impressive capabilities, especially in the realm of Human-Machine Chat Systems. Nevertheless, these models entail significant computational expenses, particularly when generating tokens. As a remedy to enhance system throughput and hardware utilization, batch scheduling is commonly adopted. This method involves initiating a batch of inference requests concurrently and then waiting for their completion. A significant challenge encountered with task-batching is the need to group requests with similar response lengths. However, accurately predicting response length proves to be a daunting task, and the inherent variability in response length leads to suboptimal resource utilization.In this paper, we introduce SyncIntellects, a framework designed to orchestrate Large Language Model (LLM) Inference with fine-grained response length prediction and Quality of Service (QoS)-Friendly length control. Specifically, SyncIntellects enhances response length prediction by leveraging embedding information during token generation through a transformer-based model. Subsequently, a dynamic response length controller based on Prompt Engineering techniques is employed to ensure alignment of response lengths without compromising the QoS of the responses. We have implemented SyncIntellects and seamlessly integrated it with a chatbot engine based on the llama2 7B model. We conduct comprehensive experiments on an NVIDIA A100-based testbed, and the results demonstrate a significant reduction in latency by 17.76% on average, along with an increase in throughput by 9.34%.","2766-8568","979-8-3503-5012-8","10.1109/IWQoS61813.2024.10682949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10682949","LLM;batch schedule;response length prediction;QoS;Prompt Engineering","Processor scheduling;Large language models;Human-machine systems;Quality of service;Predictive models;Throughput;Transformers","","","","50","IEEE","26 Sep 2024","","","IEEE","IEEE Conferences"
"AI-Driven Secure Coding: Revolutionizing Source Code Defense","M. N. -U. -R. Chowdhury; M. S. S. Chowdhury; F. F. Neha; A. Haque; M. S. Hossen","Department of Computer Science, New Mexico Tech, Socorro, NM, USA; Department of Computer Science, Utah State University, Logan, Utah, USA; Department of Applied Mathematics, University of Dhaka, Dhaka, Bangladesh; Department of Computer Science, New Mexico Tech, Socorro, New Mexico, USA; Department of Computer Science, New Mexico Tech, Socorro, New Mexico, USA",2024 International Conference on Signal Processing and Advance Research in Computing (SPARC),"10 Jan 2025","2024","1","","1","7","Secure coding is a paramount practice in software development, serving to safeguard applications against vulnerabilities and security breaches. Traditionally, this process has relied on manual analysis, a method that can be time-consuming and might overlook potential issues. This paper reviews the integration of Artificial Intelligence (AI), specifically Large Language Models (LLMs), into secure coding practices, presenting an innovative approach to bolster code quality and security. The research explores the dynamic relationship between LLMs and secure coding. LLMs, equipped with advanced natural language processing (NLP) and machine learning (ML) capabilities, possess the unique ability to comprehend code context and accurately identify vulnerabilities. They function as invaluable assistants to developers and security professionals, providing real-time guidance, offering remediation strategies, and amplifying human capabilities. While LLMs offer substantial promise, they are not without challenges. Their interpretive understanding can sometimes result in false positives and negatives. The paper underscores the importance of combining LLM insights with established security practices to establish a comprehensive and robust approach to code security.","","979-8-3503-8520-5","10.1109/SPARC61891.2024.10828840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828840","Source code security;AI language models;Vulnerability detection;Secure coding;Natural language processing;Software development tools","Ethics;Technological innovation;Privacy;Codes;Source coding;Transforms;Signal processing;Natural language processing;Security;Software development management","","","","36","IEEE","10 Jan 2025","","","IEEE","IEEE Conferences"
"6 Generative AI","T. Mariprasath; K. R. Cheepati; M. Rivera",NA; NA; NA,"Practical Guide to Machine Learning, NLP, and Generative AI: Libraries, Algorithms, and Applications","","2025","","","121","156","This is an essential resource for beginners and experienced practitioners in machine learning. This comprehensive guide covers a broad spectrum of machine learning topics, starting with an in-depth exploration of popular machine learning libraries. Readers will gain a thorough understanding of Scikit-learn, TensorFlow, PyTorch, Keras, and other pivotal libraries like XGBoost, LightGBM, and CatBoost, which are integral for efficient model development and deployment. The book delves into various neural network architectures, providing readers with a solid foundation in understanding and applying these models. Beginning with the basics of the Perceptron and its application in digit classification, it progresses to more complex structures such as multilayer perceptrons for financial forecasting, radial basis function networks for air quality prediction, and convolutional neural networks (CNNs) for image classification. Additionally, the book covers recurrent neural networks (RNNs) and their variants like long short-term memory (LSTM) and gated recurrent units (GRUs), which are crucial for time-series analysis and sequential data applications. Supervised machine learning algorithms are meticulously explained, with practical examples to illustrate their application. The book covers logistic regression and its use in predicting sports outcomes, decision trees for plant classification, random forests for traffic prediction, and support vector machines for house price prediction. Gradient boosting machines and their applications in genomics, AdaBoost for bioinformatics data classification, and extreme gradient boosting (XGBoost) for churn prediction are also discussed, providing readers with a robust toolkit for various predictive tasks. Unsupervised learning algorithms are another significant focus of the book, introducing readers to techniques for uncovering hidden patterns in data. Hierarchical clustering for gene expression data analysis, principal component analysis (PCA) for climate predictions, and singular value decomposition (SVD) for signal denoising are thoroughly explained. The book also explores applications like robot navigation and network security, demonstrating the versatility of these techniques. Natural language processing (NLP) is comprehensively covered, highlighting its fundamental concepts and various applications. The book discusses the overview of NLP, its fundamental concepts, and its diverse applications such as chatbots, virtual assistants, clinical NLP applications, and social media analytics. Detailed sections on text pre-processing, syntactic analysis, machine translation, text classification, named entity recognition, and sentiment analysis equip readers with the knowledge to build sophisticated NLP models. The final chapters of the book explore generative AI, including generative adversarial networks (GANs) for image generation, variational autoencoders for vibrational encoder training, and autoregressive models for time series forecasting. It also delves into Markov chain models for text generation, Boltzmann machines for pattern recognition, and deep belief networks for financial forecasting. Special attention is given to the application of recurrent neural networks (RNNs) for generation tasks, such as wind power plant predictions and battery range prediction, showcasing the practical implementations of generative AI in various fields.","","9788770046527","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10850536.pdf&bkn=10850512&pdfType=chapter","","","","","","","","22 Jan 2025","","","River Publishers","River eBook Chapters"
"Research on Large Language Model Cross-Cloud Privacy Protection and Collaborative Training Based on Federated Learning","Z. Yang; Y. Jin; Y. Zhang; J. Liu; X. Xu","University of Illinois at Urbana-Champaign, Champaign, IL, USA; University of Illinois at Urbana-Champaign, Champaign, IL, USA; Computer Science Department, University of Illinois Urbana-Champaign, Champaign, IL, USA; Computer Science Department, University of Illinois Urbana-Champaign, Champaign, IL, USA; Computer Science Department, University of Illinois Urbana-Champaign, Champaign, IL, USA","2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)","23 Jun 2025","2025","","","1","4","The fast development of large language models (LLMs) and popularization of cloud computing have led to increasing concerns on privacy safeguarding and data security of cross-cloud model deployment and training as the key challenges. We present a new framework for addressing these issues along with enabling privacy preserving collaboration on training between distributed clouds based on federated learning. Our mechanism encompasses cutting-edge cryptographic primitives, dynamic model aggregation techniques, and cross-cloud data harmonization solutions to enhance security, efficiency, and scalability to the traditional federated learning paradigm. Furthermore, we proposed a hybrid aggregation scheme to mitigate the threat of Data Leakage and to optimize the aggregation of model updates, thus achieving substantial enhancement on the model effectiveness and stability. Experimental results demonstrate that the training efficiency, privacy protection, and model accuracy of the proposed model compare favorably to those of the traditional federated learning method.","","979-8-3315-2228-5","10.1109/AINIT65432.2025.11035133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035133","Large language model;Federated learning;Privacy protection;Cross-cloud collaborative training;Data security","Training;Cloud computing;Data privacy;Privacy;Federated learning;Large language models;Scalability;Collaboration;Data models;Protection","","7","","10","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Real-Time IoT Cybersecurity using Machine Learning-based AI Threat Detection System to Train Generative Robots","P. Srilakshmi; K. R. Chaganti; T. Suryam; S. J. I; D. Chaithanya; J. Kavitha","Department of CSE, G Pulla Reddy Engineering College; Dept. of Computer and Information Systems, University of the Cumberlands; Department of CSE (DATA SCIENCE), Vignan Institute of Technology and Science; Department of AI&ML, Malla Reddy University; Department of CSE, CVR College of Engineering; Department of CSE, Sanketika Vidya Parishad Engineering College",2025 5th International Conference on Trends in Material Science and Inventive Materials (ICTMIM),"12 May 2025","2025","","","1124","1130","Existing security protocols encounter major cybersecurity difficulties because the online devices' growing popularity continues to spread across networks. These security protocols are ineffective because they do not properly handle current cyber threats. The main goal of this study involves developing enhanced IoT cybersecurity through the development of a threat detection system which brings together adversarial training and deep learning models (CNN-LSTM) and Federated Learning (FL). The system enables distributed Internet of Things devices to work on security model development through Federated Learning while maintaining total privacy of their information. Security procedures controlled by generative artificial intelligence robots alongside real-time attack protection functions decrease security response durations. Through its Federated CNN-LSTM model the system upholds a 1.2% false positive rate alongside a 98.3% accuracy evaluation and 160 milliseconds of exact threat tracking time. The designed system sustains a minimal occurrence of incorrect alarm activations. The developed system provides real-time security for the Internet of Things framework because it enables adaptive protection systems while preserving user privacy in current IoT settings.","","979-8-3315-0148-8","10.1109/ICTMIM65579.2025.10988029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988029","IoT cybersecurity;Machine learning;Federated learning;Generative AI;AI-driven threat detection;CNN-LSTM;Adversarial training;Real-time security;Edge computing","Training;Privacy;Protocols;Federated learning;Real-time systems;Threat assessment;Internet of Things;Computer security;Protection;Robots","","","","21","IEEE","12 May 2025","","","IEEE","IEEE Conferences"
"Challenges and Opportunities to Enable Large-Scale Computing via Heterogeneous Chiplets","Z. Yang; S. Ji; X. Chen; J. Zhuang; W. Zhang; D. Jani; P. Zhou",University of Pittsburgh; University of Pittsburgh; University of Pittsburgh; University of Pittsburgh; Lightelligence; Meta; University of Pittsburgh,2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC),"25 Mar 2024","2024","","","765","770","Fast-evolving artificial intelligence (AI) algorithms such as large language models have been driving the ever-increasing computing demands in today’s data centers. Heterogeneous computing with domain-specific architectures (DSAs) brings many opportunities when scaling up and scaling out the computing system. In particular, heterogeneous chiplet architecture is favored to keep scaling up and scaling out the system as well as to reduce the design complexity and the cost stemming from the traditional monolithic chip design. However, how to interconnect computing resources and orchestrate heterogeneous chiplets is the key to success. In this paper, we first discuss the diversity and evolving demands of different AI workloads. We discuss how chiplet brings better cost efficiency and shorter time to market. Then we discuss the challenges in establishing chiplet interface standards, packaging, and security issues. We further discuss the software programming challenges in chiplet systems.","2153-697X","979-8-3503-9354-5","10.1109/ASP-DAC58780.2024.10473961","University of Pittsburgh; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473961","Chiplet;interconnect;advanced packaging;security;programming abstraction;heterogeneous computing;large language model (LLM);generative AI","Technological innovation;Costs;Computational modeling;Time to market;Multichip modules;Computer architecture;Programming","","4","","71","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"Cryptographic Strength of Encryption in a Multi-Agent System","A. V. Voronova; A. A. Zhilenkov","Department of Cyber-Physical Systems, St. Petersburg State Marine Technical University, St. Petersburg, Russia; Department of Cyber-Physical Systems, St. Petersburg State Marine Technical University, St. Petersburg, Russia",2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus),"9 Apr 2021","2021","","","739","741","The article deals with the main problems and types of threats to information security of multi-agent systems. The analysis of information security risks characteristic of this class of systems is carried out, and an approach to ensuring information security in multi-agent systems based on the implementation of an encryption mechanism based on dynamic chaos systems accompanied by synchronization is proposed.","2376-6565","978-1-6654-0476-1","10.1109/ElConRus51938.2021.9396113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396113","encryption;chaos;multiagent system;information security;synchronization of chaos","Chaos;Information security;Communication channels;Stability analysis;Encryption;Synchronization;Multi-agent systems","","3","","4","IEEE","9 Apr 2021","","","IEEE","IEEE Conferences"
"Iterative Optimization of Hyperparameter-based Metamorphic Transformations","G. Sudheerbabu; T. Ahmad; D. Truscan; J. Vain; I. Porres","Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland","2024 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","17 Sep 2024","2024","","","13","20","Verification and validation of a software system to ensure compliance with the specification and intended functional behaviour often pose a challenge when it lacks an explicit test oracle. We present an efficient black-box metamorphic testing approach in which test cases are automatically generated based on metamorphic transformations. The hyperparameters of several metamorphic transformations are optimized on the fly using a generative AI with a feedback loop for optimal test generation and test suite minimization. The proposed method uses several combined metamorphic relations to define test inputs and to determine the test verdict. The feedback on test quality is evaluated based on the metamorphic relation’s fitness function and used to optimize the next iterations of test generation. The effectiveness of the proposed approach is evaluated on an industrial case study of a crane’s load position system which lacks an explicit test oracle. The experimental results confirm that optimizing the morphing transformations using the feedback loop improves the effectiveness of metamorphic test input generation. The outcome of the study shows that the approach can be potentially applied for functional safety verification in software systems with a test oracle problem.","2159-4848","979-8-3503-4479-0","10.1109/ICSTW60967.2024.00016","Business Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675746","Metamorphic testing;Verification and Validation;Artificial Intelligence;Software testing;Generative AI;Test Automation","Software testing;Feedback loop;Software algorithms;Optimization methods;Software systems;Minimization;Safety","","","","18","IEEE","17 Sep 2024","","","IEEE","IEEE Conferences"
"Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and Debugging Assistants","M. S. I. Ovi; N. Anjum; T. H. Bithe; M. M. Rahman; M. S. A. Smrity","Dept. of Computer Science, George Mason University, Fairfax, Virginia, USA; Dept. of Electrical & Electronic Engineering, Rajshahi University of Engineering & Technology, Bangladesh; Dept. of Computer Science and Engineering, Green University of Bangladesh, Bangladesh; Dept. of Computer Science and Engineering, Green University of Bangladesh, Bangladesh; Dept. of Computer Science and Engineering, Green University of Bangladesh, Bangladesh",2024 27th International Conference on Computer and Information Technology (ICCIT),"10 Jun 2025","2024","","","1546","1551","With the increasing adoption of AI-driven tools in software development, large language models (LLMs) have become essential for tasks like code generation, bug fixing, and optimization. Tools like ChatGPT, GitHub Copilot, and Codeium provide valuable assistance in solving programming challenges, yet their effectiveness remains underexplored. This paper presents a comparative study of ChatGPT, Codeium, and GitHub Copilot, evaluating their performance on LeetCode problems across varying difficulty levels and categories. Key metrics such as success rates, runtime efficiency, memory usage, and error-handling capabilities are assessed. GitHub Copilot showed superior performance on easier and medium tasks, while ChatGPT excelled in memory efficiency and debugging. Codeium, though promising, struggled with more complex problems. Despite their strengths, all tools faced challenges in handling harder problems. These insights provide a deeper understanding of each tool’s capabilities and limitations, offering guidance for developers and researchers seeking to optimize AI integration in coding workflows.","2474-9656","979-8-3315-1909-4","10.1109/ICCIT64611.2024.11021727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11021727","ChatGPT;GitHub Copilot;Codeium;LeetCode;Competitive Programming;Code Generation;Problem Solving;Debugging;Error Handling","Measurement;Runtime;Codes;Memory management;Debugging;Programming;Chatbots;Problem-solving;Optimization;Software development management","","","","27","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"Web-Based Automobile Service Management System for MAS Motors LLC","A. Shahlol; A. Alix; A. Lagman","Graduate School Department, Far Eastern University – East Asia College, Manila, Philippines; Graduate School Department, Far Eastern University – East Asia College, Manila, Philippines; Graduate School Department, Far Eastern University – East Asia College, Manila, Philippines","2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)","14 Mar 2019","2018","","","1","6","This project endeavored to design and develop a Web-based Automobile Service Management System for MAS Motors LLC, an accredited Toyota dealership in Libya. The system will help reduce the manual process from the everyday activities of the service division in all branches. The system is dedicated to be used by the following individuals: (1) Service Advisers, (2) Workshop Managers, (3) Storekeepers, (4) Technicians, (5) Customers, and (6) Upper Management.The company's growth made the manual process ineffective and incompetent in handling the evolving business activities. The project aimed to provide a centralized system that will operate in all of the branches and accommodate the daily business needs.The software produced from the project was tested using Alpha and Beta software testing. The researcher also conducted an interview concerning the business process, current business difficulties, and features of the proposed system. Hewlett-Packard FURPS (Functionality, Usability, Reliability, Performance, and Supportability) model was used to assess the software quality, and questions were answered by a group of respondents. The system was found to be functional, meeting the requirements of the client.","","978-1-5386-7767-4","10.1109/HNICEM.2018.8666420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666420","Automobile Service Management;Information System;Toyota;Vehicle Maintenance","Automobiles;Companies;History;Maintenance engineering;Information technology;Reliability","","1","","13","IEEE","14 Mar 2019","","","IEEE","IEEE Conferences"
"Effective Anomaly Detection in 5G Networks via Transformer-Based Models and Contrastive Learning","S. Sheikhi; P. Kostakos; S. Pirttikangas","Center for Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; Center for Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; Center for Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland",2024 8th Cyber Security in Networking Conference (CSNet),"28 Jan 2025","2024","","","38","43","In this paper, we present a novel approach to anomaly detection in 5G networks using contrastive learning and transformer-based models. Leveraging the power of self-supervision mechanisms, we aim to enhance the detection of anomalous network activities that can compromise the secu-rity and reliability of 5G networks. The methodology involves the use of pretrained transformer models (DistilBERT, BERT, RoBERTa, and ALBERT) as encoders, followed by a projection layer to reduce the dimensionality of the embeddings. We employ a contrastive learning objective to train the models, encouraging the separation of normal and anomalous data points. The trained models are evaluated on a custom 5G testbed dataset, which simulates various normal operations and attack scenarios. Our experimental results demonstrate that DistilBERT, RoBERTa, and ALBERT achieve high accuracy, precision, recall, and Fl-score, significantly outperforming BERT. We provide a comprehensive visualization analysis of each model's performance to illustrate their effectiveness. The findings underscore the effectiveness of contrastive learning combined with transformer-based architectures in achieving robust anomaly detection in 5G networks, offering valuable insights for future research and practical implementations in enhancing network security.","2768-0029","979-8-3315-3410-3","10.1109/CSNet64211.2024.10851755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851755","5G security;Cybersecurity;Anomaly Detection;Transformer Models;LLM","5G mobile communication;Data visualization;Contrastive learning;Bidirectional control;Network security;Transformers;Encoding;Data models;Reliability;Anomaly detection","","","","20","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"Detecting Sensitive Information from Documents","S. Patel; P. Verma","Amity Institute of Information Technology, Amity University Uttar Pradesh, Lucknow, India; Amity Institute of Information Technology, Amity University Uttar Pradesh, Lucknow, India",2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA),"31 Jul 2025","2025","","","583","589","In the digital era, organizations frequently process large volumes of documents containing sensitive information, including personally identifiable information (PII), financial records, and confidential corporate data. Unauthorized exposure of such data can lead to privacy breaches, legal consequences, and reputational damage. This paper presents a systematic approach to detecting sensitive information using Natural Language Processing (NLP) and deep learning techniques, specifically finetuning BERT for Named Entity Recognition (NER). Our method leverages pre-trained transformer models to accurately identify and classify sensitive entities within documents. We compare traditional rule-based and machine learning methods with deep learning-based approaches, demonstrating the advantages of contextualized language understanding in improving detection accuracy. Additionally, we address key challenges such as context-aware identification, data obfuscation, and false positive mitigation. Experimental results show that our fine-tuned BERT model significantly enhances sensitive information detection across various document formats, making it a valuable tool for compliance monitoring, data protection, and information security.","","979-8-3315-2142-4","10.1109/ICIRCA65293.2025.11089654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11089654","Sensitive Information Detection;Named Entity Recognition (NER);BERT Fine-Tuning;Natural Language Processing (NLP);Deep Learning;Transformer Models;Text Classification;Rule-Based Pattern Matching;Compliance Monitoring;Data Obfuscation;Privacy Protection;False Positive Mitigation;Document Analysis;Information Security","Deep learning;Data privacy;Accuracy;Prevention and mitigation;Text categorization;Named entity recognition;Transformers;Data models;Monitoring;Identification of persons","","","","13","IEEE","31 Jul 2025","","","IEEE","IEEE Conferences"
"Whiskey: Large-Scale Identification of Mobile Mini-App Session Key Leakage With LLMs","Y. Chen; Y. Chen; R. Wang; T. Wang; S. Ji; H. Shan; D. Xu; Z. Pan","College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; Academy of Military Science of the People’s Liberation Army, Beijing, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China",IEEE Transactions on Information Forensics and Security,"18 Jun 2025","2025","20","","5872","5887","Mini-apps, which run on super-apps, have attracted a large number of users due to their lightweight nature and the convenience of supporting the authorized use of super-app user information. Super-apps employ encryption to protect the transmission of sensitive identity information authorized by users to the mini-app, using the session key as the key. However, we have identified a risk of session key leakage, which could be exploited to maliciously manipulate sensitive user identity information, thereby posing a significant threat to user data security. To reveal this damage, we explore potential business scenarios of session key leakage in detail. Nevertheless, the diversity in design among various mini-apps makes automated testing of these business scenarios at a large scale challenging. This diversity is reflected in the inconsistent naming of identical types of controls and the disparate execution orders of controls within the same business scenarios across different mini-apps. To overcome these challenges, we propose Whiskey, which can adaptively and intelligently optimize dynamic testing strategies for mini-apps with diverse designs using large language models to detect session key leakage at scale. We evaluated Whiskey on 157,063 WeChat mini-apps and 10,000 TikTok mini-apps, and found that 15,712 of WeChat mini-apps and 678 of TikTok mini-apps had session key leakage vulnerabilities. Further analysis showed that this leakage could lead to account takeover and promotion abuse attacks. We responsibly reported the detection results to Tencent and the mini-app vendors. At the time of submission, 17 reported issues had been assigned CNVD IDs.","1556-6021","","10.1109/TIFS.2025.3575561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11020660","Mini-apps;session key leakage;large language model;strategy intelligence optimization","Servers;Ecosystems;Testing;Social networking (online);Message services;Business;Security;Encryption;Codes;Avatars","","","","52","IEEE","2 Jun 2025","","","IEEE","IEEE Journals"
"Sampling Operation with Robotic UAV","E. Guerra; A. Grau; Y. Bolea; R. Munguia","Automatic Control Department (ESAII), Technical University of Catalonia (UPC), Barcelona, Spain; Automatic Control Department (ESAII), Technical University of Catalonia (UPC), Barcelona, Spain; Automatic Control Department (ESAII), Technical University of Catalonia (UPC), Barcelona, Spain; Department of Computer Science (CUCEI), University of Guadalajara, Guadalajara, Mexico",2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),"17 Oct 2019","2019","","","1583","1586","This work presents a solution to automatize sampling tasks in a wastewater treatment plant with open air basins. At the behest of human operators, a set of UAVs managed as a network of autonomous agents will perform sample missions by taking direct measurements (through a multiparametric probe) or capturing samples and carrying them to the laboratory with specific developed hardware. These capabilities allow the proposed solution to act as a virtual sensor network with sampling points deployed and connected at any point reachable by UAVs. The hardware prototypes are fully described, with focus on the integration of systems, and the software architecture used is analysed and fully justified. Special focus was put on the localization problem, and several solutions were evaluated. Experimental results of the prototype UAV and sampling probe built are provided to validate the hardware designs, with focus on the localizations tasks.","1946-0759","978-1-7281-0303-7","10.1109/ETFA.2019.8869292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869292","Unmanned aerial vehicle;robotic software architecture;specific tools;robotic agents","Robot sensing systems;Probes;Hardware;Task analysis;Software;Computer architecture","","1","","8","IEEE","17 Oct 2019","","","IEEE","IEEE Conferences"
"DevGPT: Studying Developer-ChatGPT Conversations","T. Xiao; C. Treude; H. Hata; K. Matsumoto","Nara Institute of Science and Technology, Japan; University of Melbourne, Australia; Shinshu University, Japan; Nara Institute of Science and Technology, Japan",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","227","230","This paper introduces DevGPT, a dataset curated to explore how software developers interact with ChatGPT, a prominent large language model (LLM). The dataset encompasses 29,778 prompts and responses from ChatGPT, including 19,106 code snippets, and is linked to corresponding software development artifacts such as source code, commits, issues, pull requests, discussions, and Hacker News threads. This comprehensive dataset is derived from shared ChatGPT conversations collected from GitHub and Hacker News, providing a rich resource for understanding the dynamics of developer interactions with ChatGPT, the nature of their inquiries, and the impact of these interactions on their work. DevGPT enables the study of developer queries, the effectiveness of ChatGPT in code generation and problem solving, and the broader implications of AI-assisted programming. By providing this dataset, the paper paves the way for novel research avenues in software engineering, particularly in understanding and improving the use of LLMs like ChatGPT by developers.CCS CONCEPTS• Information systems → Data mining.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555646","ChatGPT;LLM;Generative AI;dataset","Codes;Computer hacking;Source coding;Oral communication;Programming;Chatbots;Software","","24","","41","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Information System Security Reinforcement with WGAN-GP for Detection of Zero-Day Attacks","Z. Mu; X. Shi; S. Dogan","Institute for Digital Technologies Loughborough University, England, UK; Institute for Digital Technologies Loughborough University, England, UK; Institute for Digital Technologies Loughborough University, England, UK",2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD),"30 Jul 2024","2024","","","105","110","Growing sophistication among cyber threats has posed increasing challenges to the security and reliability of information systems, especially in the face of zero-day attacks that exploit unknown vulnerabilities. This paper introduces an innovative application of Artificial Intelligence (AI), specifically the adoption of Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP), to support Intrusion Detection Systems (IDS) to strengthen defences against such attacks. This research focuses on using the WGAN-GP to generate network traffic data in simulating the unpredictable patterns of zero-day attacks. It utilises the widely used network traffic dataset NSL-KDD to conduct data expansion. This approach leverages data generated by the WGAN-GP to train detection systems, enabling them to learn and identify subtle signatures of zero-day attacks. Experimental evaluation demonstrates that the WGAN-GP model can improve the accuracy of zero-day attack detection. In comparison to other methods, such as Convolutional Neural Networks (CNN), the detection accuracy is increased by 2.3% and 2% for binary and multi-classification, respectively. This work shows that combining IDS with advanced generative AI models, such as WGAN-GP, can significantly enhance the security of information systems in identifying and mitigating risks posed by zero-day attacks.","2769-3554","979-8-3503-8510-6","10.1109/ICAIBD62003.2024.10604482","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/W00366X/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10604482","Information System Security;IDS;WGAN-GP;Zeroday Attack","Training;Accuracy;Uncertainty;Telecommunication traffic;NSL-KDD;Security;Convolutional neural networks","","4","","21","IEEE","30 Jul 2024","","","IEEE","IEEE Conferences"
"InsightAI: Root Cause Analysis in Large Log Files with Private Data Using Large Language Model","M. Ekhlasi; A. Prakash; M. Lamothe; M. Dagenais","Computer Software Department, Polytechnique Montreal, Montreal, Canada; Ciena, Ottawa, Canada; Computer Software Department, Polytechnique Montreal, Montreal, Canada; Computer Software Department, Polytechnique Montreal, Montreal, Canada",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","31","41","[Problem] As industries increasingly depend on complex software systems, efficient log analysis is essential for maintaining reliability and privacy. However, Identifying problems through logs is often time-consuming and costly for developers. [Background] Large language models (LLMs) can automate parts of log analysis, but challenges like limited computational resources and the frequent need to retrain LLMs due to the dynamic nature of software logs persist. External LLMs, such as GPTs, along with in-context learning techniques, can help reduce some of these issues, but other challenges, including token limitations, high token costs, and data privacy, remain. [Method] To tackle these challenges, we developed an automated pipeline that extracts log files and employs in-context learning, allowing the model to efficiently adapt to changes without extensive retraining. Our approach introduces a novel flame-graph-like method that reduces token usage, thereby lowering token-related costs and response latency while maintaining high accuracy. [Results] This solution allows industries to automate log analysis, minimize system downtime, and enhance performance, all while keeping data privacy and maintaining operational efficiency. [Conclusion] Our flame-graph-like methodology reduces input tokens by 93.61 % and processing latency by 77.45 %. Our anonymization results show an improvement of 138.63 % over the baseline. This industrial experience report presents our approach to allow industries to balance token costs, maintain response accuracy, and ensure data privacy while relying on external LLMs without the need to manage computational resources directly.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030043","LLM;ChatBot;Software Logs;Token Limitation;Data Privacy;In-Context Learning;Prompt Engineering","Industries;Data privacy;Costs;Accuracy;Large language models;Pipelines;Companies;Software systems;Software reliability;Software engineering","","","","44","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Multi-Agent Approach for Enhancing Security of Protection Schemes in Cyber-Physical Energy Systems","M. S. Rahman; M. A. Mahmud; A. M. T. Oo; H. R. Pota","School of Engineering, Deakin University, Geelong, VIC, Australia; School of Engineering, Deakin University, Geelong, VIC, Australia; School of Engineering, Deakin University, Geelong, VIC, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia",IEEE Transactions on Industrial Informatics,"19 Apr 2017","2017","13","2","436","447","This paper presents a distributed multiagent scheme to detect and identify cyber threats on the protection systems of power grids. The integration of information and communication technologies into existing power grids builds critical cyber-physical energy systems, in which digital relays are networked cyber-physical components subject to various cyber threats. Cyber attacks on protection systems may mimic real faults, cause component failure, and disable the communication links. Agents utilize both cyber and physical properties to reinforce the detection technique and further distinguish cyber attacks from physical faults. This paper also introduces the problem of secure communication protocols and highlights the comparative studies for enhancing the security of the protection systems. The proposed scheme is validated using a benchmark power system under various fault and cyber attack scenarios.","1941-0050","","10.1109/TII.2016.2612645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574268","Cyber attack;cyber-physical energy system (CPES);multiagent system (MAS);protection system;short-circuit fault","Monitoring;Phasor measurement units;Security;Digital relays;Power grids","","117","","25","IEEE","22 Sep 2016","","","IEEE","IEEE Journals"
"SumLLaMA: Efficient Contrastive Representations and Fine-Tuned Adapters for Bug Report Summarization","B. Xiang; Y. Shao","Zhejiang College of Security Technology, Wenzhou, Zhejiang, China; Zhejiang College of Security Technology, Wenzhou, Zhejiang, China",IEEE Access,"6 Jun 2024","2024","12","","78562","78571","In software maintenance, concise summaries of bug reports are crucial, significantly enhancing developer efficiency and ultimately improving software quality and user experience. Large language models (LLMs) have become the standard method for bug report summarization due to their powerful representation capabilities. However, LLM-based approaches face two primary challenges: accurately modeling the contextual relationships between various components within a bug report and the risk of overfitting when fine-tuning LLMs on datasets of limited size. To address these challenges, we propose a novel approach, SumLLaMA, which leverages contrastive learning pre-training and parameter-efficient fine-tuning. Contrastive learning pre-training is employed to construct contextual relations between components in a single bug report, enabling SumLLaMA to learn sequence-level representations. For parameter-efficient fine-tuning, we fine-tune a smaller adapter instead of the entire LLM, reducing the number of parameters trained to about 1/1500 of the original model, effectively mitigating the risk of overfitting. To evaluate the effectiveness of SumLLaMA, we compare it against five baseline models, including a state-of-the-art model, on a publicly available dataset. The experimental results show that SumLLaMA outperforms all baselines by up to 26.66, 17.10, and 24.01 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, respectively, achieving a state-of-the-art result for automated bug report summarization.","2169-3536","","10.1109/ACCESS.2024.3397326","Wenzhou Municipal Science and Technology Plan Project(grant numbers:R2023138); Wenzhou Philosophy and Social Sciences Planning Annual Topic(grant numbers:23WSK208YBM); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10521511","Bug report summarization;efficient fine-tuning;software maintenance;contrastive representation","Computer bugs;Task analysis;Training;Codes;Semantics;Self-supervised learning;Vectors;Software maintenance","","1","","44","CCBYNCND","6 May 2024","","","IEEE","IEEE Journals"
"Leveraging Retrieval-Augmented Generation for Persian University Knowledge Retrieval","A. Hemmat; K. Vadaei; M. Hassan Heydari; A. Fatemi","dept. Computer Engineering, University of Isfahan, Isfahan, Iran; dept. Computer Engineering, University of Isfahan, Isfahan, Iran; dept. Computer Engineering, University of Isfahan, Isfahan, Iran; dept. Computer Engineering, University of Isfahan, Isfahan, Iran",2024 15th International Conference on Information and Knowledge Technology (IKT),"26 Feb 2025","2024","","","279","286","This paper introduces an innovative approach using Retrieval-Augmented Generation (RAG) pipelines with Large Language Models (LLMs) to enhance information retrieval and query response systems for university-related question answering. By systematically extracting data from the university's official website, primarily in Persian, and employing advanced prompt engineering techniques, we generate accurate and contextually relevant responses to user queries. We developed a comprehensive university benchmark, UniversityQuestionBench (UQB), to rigorously evaluate our system's performance. UQB focuses on Persian-language data, assessing accuracy and reliability through various metrics and real-world scenarios. Our experimental results demonstrate significant improvements in the precision and relevance of generated responses, enhancing user experiences, and reducing the time required to obtain relevant answers. In summary, this paper presents a novel application of RAG pipelines and LLMs for Persian-language data retrieval, supported by a meticulously prepared university benchmark, offering valuable insights into advanced AI techniques for academic data retrieval and setting the stage for future research in this domain.11Dataset is publicly available at https://huggingface.co/datasets/UIAIC/UQB","2476-2180","979-8-3315-2225-4","10.1109/IKT65497.2024.10892716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892716","LLMs;Local Datasets;Knowledge Retrieval;Academic Question Answering","Measurement;Accuracy;System performance;Pipelines;Retrieval augmented generation;Data retrieval;Benchmark testing;Question answering (information retrieval);Real-time systems;Reliability","","1","","28","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Lessons from Building StackSpot Al: A Contextualized AI Coding Assistant","G. Pinto; C. R. B. de Souza; J. B. Neto; A. de Souza; T. Gotto; E. Monteiro","Zup Innovation & UFPA, Belèm, PA, Brazil; UFPA, Belèm, PA, Brazil; Zup Innovation, São Paulo, SP, Brazil; Zup Innovation, São Paulo, SP, Brazil; Zup Innovation, São Paulo, SP, Brazil; StackSpot, São Paulo, SP, Brazil",2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"18 Jun 2024","2024","","","408","417","With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information. In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called StackSpot Al. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.","2832-7659","979-8-4007-0501-4","10.1145/3639477.3639751","INES; CNPq(grant numbers:420406/2023-9,442779/2023-2,465614/2014-0,308623/2022-3); FAPESPA(grant numbers:053/2021); FACEPE(grant numbers:APQ-0399-1.03/17,PRONEX APQ/0388-1.03/14); CAPES(grant numbers:88887.136410/2017-00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554711","LLM;LLM-based applications;LLM for code;LLM4code;Code LLMs;Challenges","Productivity;Codes;Writing;Chatbots;Software;Encoding;Teamwork","","1","","34","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Case Study: Apply Ontology and AIGC for Task Appoint in Smart Building Control Centers","K. -C. L. Robert; W. -J. L. Jessica","AI Research Scientist Certis Group, Singapore; Research Institute, Chung-Hwa Telecom, Taiwan","2025 4th International Conference on Artificial Intelligence, Internet and Digital Economy (ICAID)","17 Jun 2025","2025","","","22","26","Since the amazing effect of ChatGPT has been recognized by the industry, towards integrating with employees’ workflow to create more business applications. At the same time, many artificial intelligence scientists are actively looking for methods and platforms that are highly efficient and can quickly embed LLM and gain business value quickly. This study proposes two important innovations. First, it uses historical operating data to quickly and automatically generate LLMs in the company’s exclusive domain. Second, to quickly embed those models in ontology maps that to generate thinking and decision-making documents (as AIGC). In the paper, first step is use auto-insight engine to transfer input data from operational datasets. Secondly, to adjust parameters the training in deep learning framework to output models. Finally, integrate more API that they like conversation tools or other services. It can automatically generate and output high-precision event determination results in real time and can automatic notification and complete the processing flow that integrate daily report for frontline partners. In future, it will be able to develop more follow-up applications, such as artificial intelligence assistant for the security control center partner, which can determine the high level of daily incidents and automatically complete high-complexity daily operation procedures in a closed-loop security environment, and moderately connect high-level voice assistants to achieve important indicators such as health care, efficiency improvement and cost reduction.","","979-8-3315-1066-4","10.1109/ICAID65275.2025.11034402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034402","Ontology;Smart Building;LLMs;AIGC","Industries;Training;Smart buildings;Costs;Large language models;Biological system modeling;Ontologies;Predictive models;Data models;Security","","","","10","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"LLM-Driven APT Detection for 6G Wireless Networks: A Systematic Review and Taxonomy","M. Golec; Y. Khamayseh; S. B. Melhem; A. Alwarafy","School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom; The College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; The Department of Cybersecurity, College of Engineering, Al Ain University, Abu Dhabi, United Arab Emirates; The Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates",IEEE Access,"","2025","PP","99","1","1","Sixth Generation (6G) wireless networks, which are expected to be deployed in the 2030s, have already created great excitement in academia and the private sector with their extremely high communication speed and low latency rates. However, despite the ultra-low latency, high throughput, and AI-assisted orchestration capabilities they promise, they are vulnerable to stealthy and long-term Advanced Persistent Threats (APTs). Large Language Models (LLMs) stand out as an ideal candidate to fill this gap with their high success in semantic reasoning and threat intelligence. In this paper, we present a comprehensive systematic review and taxonomy study for LLM-assisted APT detection in 6G networks. We address five research questions, namely, semantic merging of fragmented logs, encrypted traffic analysis, edge distribution constraints, dataset/modeling techniques, and reproducibility trends, by leveraging most recent studies on the intersection of LLMs, APTs, and 6G wireless networks. We identify open challenges such as explainability gaps, data scarcity, edge hardware limitations, and the need for real-time slicing-aware adaptation by presenting various taxonomies such as granularity, deployment models, and kill chain stages. We then conclude the paper by providing several research gaps in 6G infrastructures for future researchers. To the best of our knowledge, this paper is the first comprehensive systematic review and classification study on LLM-based APT detection in 6G networks.","2169-3536","","10.1109/ACCESS.2025.3595665","Zayed University Research Office(grant numbers:23153); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112774","Advanced Persistent Threat (APT);Security;LLM;NLP for Security;6G Wireless Networks","6G mobile communication;Surveys;Taxonomy;Systematic literature review;Wireless networks;Systematics;Semantics;Image edge detection;Threat assessment;Reproducibility of results","","","","","CCBY","5 Aug 2025","","","IEEE","IEEE Early Access Articles"
"NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent","K. Ke","University of Illinois Urbana-Champaign, Urbana, IL, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1014","1025","Flaky tests, characterized by inconsistent results across repeated executions, present significant challenges in software testing, especially during regression testing. Recently, there has been emerging research interest in non-idempotentoutcome (NIO) flaky tests-tests that pass on the initial run but fail on subsequent executions within the same environment. Despite progress in utilizing Large Language Models (LLMs) to address flaky tests, existing methods have not tackled NIO flaky tests. The limited context window of LLMs restricts their ability to incorporate relevant source code beyond the test method itself, often overlooking crucial information needed to address state pollution, which is the root cause of NIO flakiness. This paper introduces NIODebugger, the first framework to utilize an LLM-based agent to repair flaky tests. NIODebugger features a three-phase design: detection, exploration, and fixing. In the detection phase, dynamic analysis collects stack traces and custom test execution logs from multiple test runs, which helps in understanding accumulative state pollution. During the exploration phase, the LLM-based agent provides instructions for extracting relevant source code associated with test flakiness. In the fixing phase, NIODebugger repairs the tests using the information gathered from the previous phases. NIODebugger can be integrated with multiple LLMs, achieving patching success rates ranging from 11.63% to 58.72%. Its best-performing variant, NIODebugger-GPT-4, successfully generated correct patches for 101 out of 172 previously unknown NIO tests across 20 largescale open-source projects. We submitted pull requests for all generated patches; 58 have been merged, only 1 was rejected, and the remaining 42 are pending. The Java implementation of NIODebugger is provided as a Maven plugin accessible at https://github.com/kaiyaok2/NIOInspector.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029812","flaky tests;llm-based agent;software testing","Software testing;Java;Pollution;Source coding;Large language models;Maintenance engineering;Feature extraction;Distance measurement;Software engineering","","1","","58","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Benchmarking LLM for Zero-day Vulnerabilities","L. M; V. Agarwal; S. Kamthania; P. Vutkur; M. C. S","Cloud Modules, Bengaluru, India; Ezmeral R&D, Bengaluru, India; Ezmeral R&D, Bengaluru, India; Cloud Modules, Bengaluru, India; Aruba Switching SW, Hewlett Packard Enterprise, Bengaluru, India","2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","20 Sep 2024","2024","","","1","6","Large Language Models (LLMs) have emerged as powerful tools for natural language processing tasks. This paper investigates the efficacy of various LLMs in detecting zero-day vulnerabilities, crucial for preemptive cybersecurity measures. Through benchmarking and experimentation, we analyze the performance of LLMs in unstructured querying scenarios. Our findings aim to enhance understanding of LLM capabilities and contribute to the advancement of vulnerability detection methodologies.","2766-2101","979-8-3503-8592-2","10.1109/CONECCT62155.2024.10677338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677338","security;LLM;zero-day;vulnerability","Large language models;Benchmark testing;Natural language processing;Communications technology;Computer security","","1","","7","IEEE","20 Sep 2024","","","IEEE","IEEE Conferences"
"Deep Learning Approaches for Identifying AI-Generated Text via Feature Extraction","A. Yadagiri; D. Kalita; A. Ranjan; A. K. Bostan; P. Toppo; P. Pakray","Dept of CSE, NIT Silchar, Assam, India; Dept of CSE, NIT Silchar, Assam, India; Dept of CSE, NIT Silchar, Assam, India; Dept of CSE, NIT Silchar, Assam, India; Dept of CSE, NIT Silchar, Assam, India; Dept of CSE, NIT Silchar, Assam, India",2024 IEEE Silchar Subsection Conference (SILCON 2024),"13 Mar 2025","2024","","","1","6","The launch of ChatGPT has garnered significant interest from academic and business communities due to Its capacity to manage a diverse array of human needs inquiries with clarity and comprehensiveness. This progress has fueled curiosity about ChatGPT's capabilities compared to human experts and the challenges of Identifying the difference between AI content created by humans. The development of language generation models has advanced text production to closely mimic human writing. However, this also raises concerns about the negative impacts of LLMs, such as spreading false information, plagiarism, and social security issues. The Human ChatGPT Comparison Corpus HC3-English dataset was created to address these concerns, encompassing various public domains like psychology, law, health, and finance. This study analyzed the response characteristics of ChatGPT answers and human expert answers, revealing several notable differences. An extensive examination was conducted to identify the best methods for distinguishing AI-generated and human-generated text. Differential detection systems were developed and tested, showing that our proposed model achieved superior performance with 99.59% accuracy.","","979-8-3315-4082-1","10.1109/SILCON63976.2024.10910333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910333","Large language models Artificial intelligence Natural language processing Human-AI Analysis","Accuracy;Plagiarism;Psychology;Production;Writing;Linguistics;Chatbots;Feature extraction;Transformers;Security","","","","18","IEEE","13 Mar 2025","","","IEEE","IEEE Conferences"
"GPT as a Reviewer: Automatic Evaluation of Academic Papers","B. Tas; M. Aksoy","Statistics Department, Technical University of Dortmund, Dortmund, Germany; Computer Science, Research Center Trustworthy Data Science and Security, Technical University Dortmund, Dortmund, Germany",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","487","496","This study investigates the potential of using GPT models, specifically GPT-3.5 and GPT-4 variants, as automated reviewers in academic peer review processes. Experiments were conducted using the ACL-2017 dataset, employing both zeroshot learning and in-context learning techniques across various settings, including baseline, importance assignment, and persona assignment, with different prompt designs. These settings tested the models’ effectiveness in scoring based on predefined evaluation criteria, both with and without scoring thresholds. The results highlight how various prompt strategies, settings, and threshold applications influenced model performance. Among the models, GPT-40 and GPT-40-mini showed particularly promising results. While GPT models performed well in certain areas, they still have limitations in fully capturing the complexities of peer review. Nevertheless, the findings suggest that GPT models can serve as a helpful tool to support human reviewers in the peer review process.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106156","Peer review;automatic scoring;GPT;prompt engineering;LLMs","Hands;Solid modeling;Ethics;Sensitivity;Reviews;Publishing;Computational modeling;Data models;Prompt engineering;Context modeling","","","","46","IEEE","11 Aug 2025","","","IEEE","IEEE Conferences"
"Decentralized Nonconvex Robust Optimization Over Unsafe Multiagent Systems: System Modeling, Utility, Resilience, and Privacy Analysis","J. Hu; G. Chen; H. Li; H. Cheng; X. Guo; T. Huang","School of Automation, Central South University, Changsha, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, College of Electronic and Information Engineering, Southwest University, Chongqing, China; Key Laboratory of Dependable Services Computing in Cyber Physical Society-Ministry of Education, College of Computer Science, Chongqing University, Chongqing, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong, SAR, China; Faculty of Computer Science and Control Engineering, Shenzhen University of Advanced Technology, Shenzhen, China",IEEE Transactions on Cybernetics,"24 Jul 2025","2025","55","8","3799","3810","Privacy leakage and Byzantine issues are two adverse factors to optimization and learning processes of multiagent systems (MASs). Considering an unsafe MAS with these two issues, this article targets the resolution of a category of nonconvex optimization problems under the Polyak–Łojasiewicz (P–Ł) condition. To address this problem, we first identify and construct the unsafe MAS model. Under this kind of unfavorable MASs, we mask the local gradients with Gaussian noise and adopt a resilient aggregation method, self-centered clipping (SCC), to design a differentially private (DP) and Byzantine-resilient (BR) decentralized stochastic gradient algorithm, dubbed DP-SCC-PL, aiming to address a class of nonconvex optimization problems in the presence of both privacy leakage and Byzantine issues. The convergence analysis of DP-SCC-PL is challenging, as the convergence error arises from the coupled effects of DP and BR mechanisms, as well as the nonconvex relaxation, which is resolved via seeking the contraction relationships among the disagreement measure of reliable agents before and after the SCC aggregation, together with the optimal gap. Theoretical results not only reveal the trilemma between algorithm utility, resilience, and privacy, but also show that DP-SCC-PL can achieve consensus among all reliable agents. It has also been proven that if there are no privacy issues and Byzantine agents, then the asymptotic exact convergence can be recovered. Numerical experiments verify the utility, resilience, and privacy of DP-SCC-PL by tackling a nonconvex optimization problem satisfying the P–Ł condition under various Byzantine attacks.","2168-2275","","10.1109/TCYB.2025.3573957","Research Grants Council of Hong Kong(grant numbers:CityU-11210222); Fundamental Research Funds for the Central Universities(grant numbers:SWU-XDJH202312); National Natural Science Foundation of China(grant numbers:62173278); Chongqing Science Fund for Distinguished Young Scholars(grant numbers:2024NSCQ-JQX0103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036546","Byzantine issues;decentralized robust optimization;multiagent system (MAS) security;Polyak–Łojasiewicz (P–Ł) condition;privacy preservation","Optimization;Privacy;Reliability;Resilience;Gaussian noise;Differential privacy;Convergence;Security;Multi-agent systems;Software reliability","","","","39","IEEE","13 Jun 2025","","","IEEE","IEEE Journals"
"GemmaWithLoRA: A New Approach to Click Fraud Detection","B. Dai; L. Wang; X. Zhao; Y. Guo; M. S. Obaidat","School of Information Management Beijing Information Science & Technology University, Beijing, China; School of Information Management Beijing Information Science & Technology University, Beijing, China; Information Systems Institute, Beijing Advanced Innovation Center for Materials Genome Engineering, Beijing Information Science & Technology University, Beijing, China; Beijing Advanced Innovation Center for Materials Genome Engineering and Shunde Innovation School, University of Science and Technology, Beijing, China; King Abdullah II School of Information Technology, University of Jordan, School of Engineering, Amity University School of Computing, SRM University, Amman, Jordan","2024 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)","5 Nov 2024","2024","","","1","8","With the rapid development of artificial intelligence technology, pre-trained large language models (LLMs) have demonstrated their powerful application potential in various fields. Click fraud is a serious issue in the digital advertising ecosystem, especially in the pay-per-click (PPC) model, where fraudulent activities significantly undermine the effectiveness of ads and pose security risks. While many traditional fraud detection methods have achieved relatively good accuracy, they still face poor generalization and extensive feature engineering issues. This paper explores using LLMs for click fraud detection by leveraging the powerful feature extraction capabilities and superior generalization performance of the Gemma-2b model, combined with LoRA fine-tuning technology. Extensive experiments on the TalkingData2017 dataset showed that accuracy was achieved at 83°/0, demonstrating the effectiveness of LLMs in click fraud detection tasks.","","979-8-3503-4983-2","10.1109/CCCI61916.2024.10736481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736481","LLMs;LoRA;Click Fraud Detection","Adaptation models;Accuracy;Large language models;Feature extraction;Fraud;Telecommunication computing;Reliability;Advertising;Informatics;Faces","","1","","40","IEEE","5 Nov 2024","","","IEEE","IEEE Conferences"
"Large Language Model Driven Logic Locking: A Generative Approach to Secure IC Design","J. Gandhi; D. Shekhawat; M. Santosh; J. Dofe; J. G. Pandey","CSIR- Central Electronics Engineering, Research Institute (CEERI), Pilani, India; CSIR- Central Electronics Engineering, Research Institute (CEERI), Pilani, India; CSIR- Central Electronics Engineering, Research Institute (CEERI), Pilani, India; Department of Electrical and Computer Engineering, California State University, Fullerton, CA, USA; CSIR- Central Electronics Engineering, Research Institute (CEERI), Pilani, India",2024 IEEE 33rd Asian Test Symposium (ATS),"14 Mar 2025","2024","","","1","4","Logic locking has emerged as a critical solution for secure integrated circuit design, protecting hardware intellectual property from reverse engineering, piracy, and unauthorized access. Recently, large language models (LLMs) and generative model-based logic locking emerged to automate the obfuscation process and enhance security in hardware designs. Prior research on generative pre-trained transformer-based logic obfuscation faces challenges with prompt retention and circuit connectivity in larger designs. This article presents an iterative prompt-based framework that refines the generated netlist over multiple iterations to generate an obfuscated design. Experimental evaluation demonstrates the framework’s effectiveness in generating an obfuscated netlist. The article discusses the research challenges of LLM-based logic locking and outlines future work to develop a scalable and efficient framework for secure hardware designs.","2377-5386","979-8-3315-2916-1","10.1109/ATS64447.2024.10915359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915359","Generative Pre-trained Transformers;Hardware Security;Large Language Model (LLM);Logic Locking;Secure Integrated Circuit (IC) Design","Integrated circuit synthesis;Large language models;Hardware security;Reverse engineering;Intellectual property;Transformers;Logic;Iterative methods;Integrated circuit modeling;Faces","","","","21","IEEE","14 Mar 2025","","","IEEE","IEEE Conferences"
"Exploring the Potential of Locally Run Large Language (AI) Models for Automated Grading in Introductory Computer Science Courses","S. B. Mazzone; J. Forden; D. Brylow","Computer Science, Marquette University, Milwaukee, Wisconsin; Computer Science, Marquette University, Milwaukee, Wisconsin; Computer Science, Marquette University, Milwaukee, Wisconsin",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","9","This innovative practice full paper describes the effectiveness of self-hosted large language models (LLMs) in assisting with the automatic grading of CSI assignments. Educators often rely on automated review of student code submissions in larger courses. Despite recent advancements, current systems primarily focus on assessing functionality, with important aspects such as code structure, efficiency, and style often relegated to secondary foci. LLMs provide an increasingly attractive addition to these systems to enhance those overlooked areas. Prior research has shown LLM's capable of assisting students in understanding and resolving programmer error messages, correcting syntax errors, providing enhanced explanations of code segments, or even generating code. The absence of freely available, purpose-designed LLMs for grading and providing feedback on code submissions prevents widespread adoption by educators. Remotely-hosted systems, such as fine-tuned GPT models, have shown promise, yet the associated risks of privacy breaches, ethical considerations, and recurring costs make this approach unfeasible as a universal solution. To mitigate these concerns, self-hosted open-source models are an alternative that can operate on consumer-grade hardware and prevent some privacy and security concerns. While no purpose-built solution yet exists, it is unclear if any existing models are powerful enough to facilitate automated grading. To explore these questions, we present a two-phase analysis, leveraging real grading data from a semester length, introductory CSI course with 124 students and nine programming projects. Nine stable LLM models were selected and repeatedly prompted to grade student submissions using the same context that a human teaching assistant (TA) was given. This paper analyzes 1,172,383 API requests, totaling 33.4 days of active runtime, evaluating model consistency, ability to adhere to specified constraints, and comparison to human-generated grades. The results show various models' inability to consistently grade assignments, albeit with some exceptions. The importance of providing comprehensive context to models was highlighted, as incomplete contexts resulted in worse performance. Other models struggled with longer prompts, delivering less consistent results. Despite disparities between AI-generated and human-assigned grades, the potential for refinement is clear; improved rubrics or selective fine-tuning could enhance model output. Future work will focus on analyzing models' qualitative justifications for grades, refining rubrics, training on domain-specific datasets, and fine-tuning the highest performing models to potentially improve grading accuracy.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10892816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892816","Large language model (LLMs);automated assessment tools (AATs);CSI","Training;Analytical models;Codes;Runtime;Computational modeling;Large language models;Syntactics;Complexity theory;Security;Context modeling","","","","40","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Requirements Elicitation for Machine Learning Applications: A Research Preview","T. Elvira; T. T. Procko; O. Ochoa","Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Florida, United States; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Florida, United States; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Florida, United States","2024 Conference on AI, Science, Engineering, and Technology (AIxSET)","3 Dec 2024","2024","","","218","221","The development of software systems is preceded by an important first phase, requirements elicitation, wherein developers establish the intended functionality of a system to be developed in a series of interviews with a customer. These requirements can often be raw, requiring refinement in an iterative process. Traditional software requirements are of the form 'The system shall … ‘, where each requirement is written to be clear, concise, consistent, complete, testable and traceable through development. Because Machine Learning (ML) is stochastic, or uncertain, in the face of unseen data, ML behavior cannot be precisely defined. As such, it is posited that software requirements specific to ML must delineate a window of acceptable behavior, e.g., a plus/minus value for evaluated model metrics. The provision of such is essential for the quality of future ML software systems, as the current trend of large-scale generative ML has brought about a paradigm of fine-tuning, e.g., of Large Language Models, in which pre-trained large models are taken “off the shelf” and made fit for very specific purposes. These specific purposes vary with different use cases, but they are effectively undeclared requirements. The present paper discusses requirements elicitation in the context of ML by considering the four-software engineering requirement elicitation techniques: conversational, observational, analytic and synthetic, providing future researchers with insight for eliciting quality ML requirements.","","979-8-3503-9099-5","10.1109/AIxSET62544.2024.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771003","Software Engineering;Requirements Engineering;Machine Learning","Measurement;Technological innovation;Large language models;Software algorithms;Stochastic processes;Prototypes;Machine learning;Software systems;Market research;Iterative methods","","","","23","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"Generating and Verifying Synthetic Datasets with Requirements Engineering","L. Vonderhaar; T. Elvira; O. Ochoa","Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, USA; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, USA; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, USA",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","212","221","With the rise of generative Artificial Intelligence (AI), Machine Learning (ML) developers are becoming less reliant on real data to train their models. Data insufficiency can be resolved by using synthetic data generated by a diffusion model. However, beyond ad hoc interpretation of a generative model's outputs, there is little assurance of the synthetic data's adherence to the data requirement specifications. Adherence of synthetic data to these specifications is critical given that they describe desired downstream model behavior. Therefore, without proper verification methods for this synthetic data, ML developers cannot be confident in the behavior of the downstream model. This paper presents a verification method for generating synthetic data to train downstream ML models by prompting the generative model using requirement specifications and tracing elements of the output back to the prompt. The purpose of this research is to embed requirements engineering into the data augmentation process to increase the rigor and acceptance of these generative AI models to train downstream ML models. This improves the transparency of the data augmentation process, potentially increasing the trust of stakeholders in the generated data, and the use of generative models for data augmentation in a wider range of applications. This also provides a more traditional approach to synthetic data generation to guide ML developers in augmenting their datasets, thus incorporating a more rigorous engineering process into the ML development, i.e., ML Engineering.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030042","machine learning;synthetic data;verification;data augmentation;machine learning engineering;diffusion model","Training;Reviews;Generative AI;Diffusion models;Data augmentation;Data models;Requirements engineering;Stakeholders;Synthetic data;Software engineering","","","","19","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Llm-Based Code Comment Summarization: Efficacy Evaluation and Challenges","P. Sukkasem; C. Soomlek; C. Dechsupa","Department of Computer Science, College of Computing, Khon Kaen University, Khon Kaen, Thailand; Department of Computer Science, College of Computing, Khon Kaen University, Khon Kaen, Thailand; Department of Computer Science, College of Computing, Khon Kaen University, Khon Kaen, Thailand",2025 17th International Conference on Knowledge and Smart Technology (KST),"20 May 2025","2025","","","335","340","Numerous methodologies have been introduced for code summarization and associated activities, including the utilization of large language model (LLM)-based code summarization, to aid software developers in the comprehension and maintenance of software systems. Code comment is one of the communication channels and practices that can assist developers in developing and maintaining software systems. The interpretation and comprehension of code comments can present significant challenges due to factors such as diverse writing styles and varying levels of background knowledge and experience among developers within a team. Self-admitted technical debt (SATD) is commonly indicated in code comments. This research investigates the efficacy of applying large language models to identify SATD and summarize code comments containing SATD to support code maintenance. We employed three widely used pre-trained LLMs, i.e., BART, Flan-T5, and T5 as summarizers. The experimental results indicated that 75 % of the natural language summaries generated by BART are readable with the appropriate structure and vocabulary used. However, almost all generated summaries are irrelevant to the original code comments while the T5 model can identify SATD and include it in the generated summaries. These findings highlight the potential and the limitations of using pre-trained LLMs for code comment summarization and SATD identification, paving the way for future improvements in this domain.","2473-764X","979-8-3315-2040-3","10.1109/KST65016.2025.11003343","Khon Kaen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003343","Large language model;Software maintenance;Self-admitted technical debt (SATD);Code summarization","Vocabulary;Software maintenance;Codes;Large language models;Natural languages;Communication channels;Writing;Software systems;Maintenance","","","","17","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging","A. K. Dipongkor; K. Moran","Dept. of Computer Science, University of Central Florida, Orlando, USA; Dept. of Computer Science, University of Central Florida, Orlando, USA",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","1012","1023","Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298494","Bug Triaging;Transformer;LLMs;Text-Embedding;DL4SE","Training;Software maintenance;Computer bugs;Text categorization;Manuals;Machine learning;Transformers","","6","","48","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"PrivateAIDELPHI: Adopting and Adapting Private AI for Risk Assessment of Safety Critical Systems","N. Papakonstantinou; D. Van Bossuyt; R. Bell; R. Longshore; M. Heikkilä",Fortum Power and Heat Oy; Naval Postgraduate School; Naval Postgraduate School; Naval Postgraduate School; Fortum Power and Heat Oy,2025 Annual Reliability and Maintainability Symposium (RAMS),"27 Mar 2025","2025","","","1","7","SUMMARY & CONCLUSIONS Recent advancements in generative AI and Large Language Models (LLMs) have produced tools able to convincingly answer questions and instruct humans through complex tasks. This is achieved after a computationally intensive training based on a large set of documents. Although the results can be impressive, there are cases of problematic responses. Even though there is significant motivation and interest to introduce these kind of AI tools in safety engineering processes, it is recognized that this needs to be done carefully and with human experts in control. Additionally, it is common that system design information is sensitive and cannot be shared with cloud-based AI platforms. The PrivateAIDELPHI method presented in this paper introduces “AI experts” in early risk identification and scoring for complex safety critical systems. It extends the established Delphi iterative method for reducing subjectivity and reaching consensus among experts. These AI experts are enabled by tools that can be hosted locally and without a connection to the Internet. The benefit of introducing AI experts, with the current technology is the potential to get different perspectives and trigger/inspire human experts to expand their view. The basic steps of the PrivateAIDELPHI are the definition of the questions to be answered, the preparation of the background information material and then the collaboration of human and AI experts on the identification and scoring of risks. The method includes sanity checks by humans on the AI-generated answers as well as the fact that the final risk prioritization step involves only humans. Practically the AI with its answers is used to expand the thought horizon of the human experts and not to just provide an answer. Although the PrivateAIDELPHI is designed to operate using confidential data (system design and background information), for practical reasons it was demonstrated in this paper using public information on the NuScale Small Modular Reactor (SMR) design and a small set of relevant public documents giving background on nuclear system risks. Four AI models (three that can be considered private/local and ChatGPT) were used, this case study did not experiment on the optimization of the LLMs and the results are not to be seen as a comparison/benchmark of the different AI models (between them or against humans). The integration of human and AI experts in the limited NuScale case study showed that the AI can bring valuable input to the group of experts tasked with risk identification and prioritization, thus it was successful. While not being able to express risks in a systematic manner (the AI results can be seen more like talking points - food for thought) the integration of AI experts together with humans does enhance the risk assessment process. It is very important to highlight that humans are in control and finally responsible for the final results.","2577-0993","979-8-3503-6774-4","10.1109/RAMS48127.2025.10935226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10935226","Risk assessment;Private AI;Delphi;Large Language Model;Safety;Security;Resilience","Training;Systematics;Large language models;Safety;Risk management;Security;Reliability;Artificial intelligence;System analysis and design;Resilience","","","","30","IEEE","27 Mar 2025","","","IEEE","IEEE Conferences"
"An LLM-Based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks","Q. Qin; X. Cao; G. Nan; S. Chen; R. Li; L. Su; H. Du; Q. Cui; P. Mao; X. Tao; T. Q. S. Quek",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,IEEE Communications Magazine,"","2025","PP","99","1","7","Recently emerged 6G space-air-ground integrated networks (SAGINs), which integrate satellites, aerial networks, and terrestrial communications, offer ubiquitous coverage for various mobile applications. However, the highly dynamic, open, and heterogeneous nature of SAGINs poses severe security issues. Forming a defense line of SAGINs suffers from two preliminary challenges: accurately understanding massive unstructured multi-dimensional threat information to generate defense strategies against various malicious attacks, and rapidly adapting to potential unknown threats to yield more effective security strategies. To tackle the above two challenges, we propose a novel security framework for SAGINs based on large language models (LLMs), which consists of two key ingredients: LLM-6GNG and 6G-INST. Our proposed LLM-6GNG leverages refined chain-of-thought (CoT) reasoning and dynamic multi-agent mechanisms to analyze massive unstructured multi-dimensional threat data and generate comprehensive security strategies, thus addressing the first challenge. Our proposed 6G-INST relies on a novel self-evolving method to automatically update LLM-6GNG, enabling it to accommodate unknown threats under dynamic communication environments, thereby addressing the second challenge. Additionally, we prototype the proposed framework with ns-3, OpenAirInterface (OAI), and software-defined radio (SDR). Experiments on three benchmarks demonstrate the effectiveness of our framework. The results show that our framework produces highly accurate security strategies that remain robust against a variety of unknown attacks. We will release our code to contribute to the community.","1558-1896","","10.1109/MCOM.003.2400695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049854","","6G mobile communication;Security;Monitoring;Information processing;Feature extraction;Semantics;Real-time systems;Communication channels;Satellite broadcasting;Reconfigurable intelligent surfaces","","","","","IEEE","24 Jun 2025","","","IEEE","IEEE Early Access Articles"
"LLM for Question Generation and Validation to Enhance School Level Student Assessment","A. D. Varma; S. Anand; A. K. Thekkedath; K. P; N. Prasanth; S. N. Rao","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India; Center for Wireless Networks & Applications (WNA), Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India; Center for Wireless Networks & Applications (WNA), Amrita Vishwa Vidyapeetham, Amritapuri, India",2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN),"19 Jun 2025","2025","","","1609","1615","Recent advancements in large language models (LLMs) have accelerated the growth of several AI-based solutions in the daily lives of people, including in the field of education. Using LLM in education can potentially automate various aspects of the teaching-learning process. This work explores how LLMs can assist educators in generating questions for student assessment. Using sophisticated prompt engineering, a system has been developed to generate multiple levels of questions from a single topic, enabling teachers to evaluate and curate a variety of questions attuned to the diverse needs of learners. This innovative approach diverges from conventional ICT-based techniques that primarily rely on keyword matching and superficial metrics. The system generates questions, taking into account the semantic meaning and contextual relevance. Furthermore, LLM evaluation metrics have been applied to assess the methods used for the generation of questions, and the results are presented accordingly.","","979-8-3315-3519-3","10.1109/ICPCSN65854.2025.11035415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035415","LLM;Student Assessment;Generative AI;Question Generation;Bloom’s Taxonomy;Gemini;School","Measurement;Pervasive computing;Social networking (online);Large language models;Semantics;Education;Taxonomy;Computer architecture;Question generation;Prompt engineering","","","","25","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Natural Language Processing for Conversational AI: Chatbots and Virtual Assistants","N. Shrivastava; P. Tewari; S. Sujatha; S. R. Bogireddy; N. Varshney; V. Sharma","Dept. of Engineering, Medicaps University, Indore, India; Dept. of Vocational Studies, Guru Nanak College, Dhanbad, India; Dept. of Civil Engineering, K. Ramakrishnan College of Technology, Trichy, India; Dept. of Software Engineer, Horizon Systems Inc, Phoenix, Arizona; Dept. of CSE, GLA University, Mathura, India; Dept. of Computer Science, Jiwaji University, Gwalior, India",2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI),"9 May 2025","2025","3","","1","6","The frontline in developing the capabilities of chatbots and virtual assistants involves the use of NLP, enabling these machines to evolve into truly advanced, interactive machines that are able to comprehend and respond to human language with an almost unimaginable degree of accuracy. The paper will analyze some of the major NLP techniques and methodologies used for such systems: machine learning algorithms, neural networks, and semantic analysis. This would also mean that, with the help of big data and continuous learning, the work of chatbots and virtual assistants will range from answering queries to personalized recommendations. Language understanding, generation, and context management are discussed in detail, underlining how NLP improves user experience by making interactions more natural and intuitive. The challenges of ambiguous language processing, conversational context, and ensuring data privacy and security are discussed as well. Case studies and applications in real life show the impact of NLP on different sectors: customer service, healthcare, and e-commerce. The findings bring out the potential of NLP to change human-computer interaction and allow for more responsive and intelligent digital assistants.","","979-8-3315-2169-1","10.1109/IATMSI64286.2025.10984818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984818","Natural Language Processing;NLP;Chatbots;Virtual Assistants;Voice Recognition;Sentiment Analysis;User Experience;Artificial Intelligence","Ethics;Technological innovation;Sentiment analysis;Virtual assistants;Semantics;Speech recognition;Chatbots;Natural language processing;User experience;Text processing","","5","","20","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
"C3 – Code Commit Collab - A Collaborative Code Editor using Repository Level LLM","A. Aher; R. S. Waghode; M. Jamsutkar; A. J. Patil; U. Padelkar; D. S. Gat","CSE (Data Science), A. P. Shah Institute of Technology, Thane, India; CSE (Data Science), A. P. Shah Institute of Technology, Thane, India; CSE (Data Science), A. P. Shah Institute of Technology, Thane, India; CSE (Data Science), A. P. Shah Institute of Technology, Thane, India; CSE (Data Science), A. P. Shah Institute of Technology, Thane, India; CSE (Data Science), A. P. Shah Institute of Technology, Thane, India","2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)","14 Jul 2025","2025","3","","2071","2076","Collaborative Code editors are essential tools in modern software development. It plays a critical role in enhancing productivity and collaboration among distributed teams. However, traditional code editors often lack advanced features which needed to be addressed. Challenges such as seamless collaboration, intelligent automation, and efficient repository-level management. To address these limitations, we introduce a new collaborative code editor that utilizes WebSocket for real-time synchronization based on operational transformations(OT) and conflict-free replicated datatypes(CRDTs) ensuring conflict-free code merging. The platform advances automation with the use of short language models (SLMs) and traversal bots for smart code validation and repository level automation. In addition, The platform integrates large language Models (LLMs) to dynamically generate documentation, such as README files, accurately reflecting code changes. Smart Commits automate version control by analyzing modi- fications and generating meaningful commit messages. Semantic search streamlines navigation within complex codebases, enabling faster project initialization with uniform folder structures and code generation. Built on scalable technologies like ElectronJS and django rest framework (DRF), the system supports seamless API interactions and precise code completion. This unified platform reduces errors, optimizes resources, and fosters maintainable, efficient, and collaborative software development for distributed teams.","","979-8-3315-3607-7","10.1109/ICCSAI64074.2025.11064134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064134","Collaborative Code Editor;Large Language Model;Repository Level Code Generation;Smart Commits;Reflection AI","Codes;Semantic search;Large language models;Collaboration;Reflection;Real-time systems;Systems support;Synchronization;Security;Software development management","","","","18","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Extracting and Analyzing Factors to Identify the Malicious Conversational AI Bots on Twitter","G. Vyas; P. Muzumdar; A. Chennamaneni; A. Rajavat; R. Rawat","Computer Information Systems, Texas A&M University&#x2010;Central Texas, Killeen, Texas, USA; University of South Florida, Florida, USA; Computer Information Systems, Texas A&M University&#x2010;Central Texas, Killeen, Texas, USA; Department of Computer Science Engineering, Director, Shri Vaishnav Institute of Information Technology, Shri Vaishnav Vidyapeeth Vishwavidyalaya, Indore, India; Department of Computer Science, Shri Vaishnav Vidyapeeth Vishwavidyalaya, Indore, India",Conversational Artificial Intelligence,"","2024","","","71","83","Summary <p>On social media, many third‐party vendors utilize Conversational Artificial Intelligence (CAI) to use social bots to spread marketing campaigns and to increase followers, thereby opening the door for malicious bots to compromise the security on social media, especially on Twitter where the posts are concise, making it hard to distinguish between human written posts and bot‐generated tweets. Thus, such malicious bots on Twitter can break into user accounts, spread misinformation, breach account data, and market advertising spam. Hence, this chapter aims to conduct a detailed exploratory study to identify the crucial Twitter account features that help to detect malicious bots. Machine learning‐based techniques such as information gain, correlation, and chi‐square feature selections are used in this chapter to select the top feature set by comparing all three techniques. Twitter account data provided by Kaggle.com, which are publicly available, have been used. The finding suggests that Twitter account age, tweet replies, number of user mentions, friends count, favorites counts, listed count, account verification status, followers count, number of users who liked a tweet, default profile, bot description, and retweet count are the factors that can help to identify and detect the malicious bots on social media.</p>","","9781394200795","10.1002/9781394200801.ch5","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10952888.pdf&bkn=10950236&pdfType=chapter","","Chatbots;Social networking (online);Blogs;Feature extraction;Artificial intelligence;Training;Oral communication;Data models;Crawlers;Systematic literature review","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Control of Multilayer Mobile Autonomous Systems in Adversarial Environments: A Games-in-Games Approach","J. Chen; Q. Zhu","Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, USA; Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, USA",IEEE Transactions on Control of Network Systems,"10 Sep 2020","2020","7","3","1056","1068","A mobile autonomous system (MAS) becomes pervasive especially in the vehicular and robotic networks. Multiple heterogeneous MAS networks can be integrated together as a multilayer MAS network to offer holistic services. The network connectivity of the multilayer MAS plays an important role in the information exchange between agents within and across different layers of the network. In this article, we establish a games-in-games framework to capture the uncoordinated nature of decision making under adversarial environment at different layers. Specifically, each network operator controls the mobile agents in his own subnetwork and designs a secure strategy to maximize the global network connectivity by considering the behavior of jamming attackers that aim to disconnect the network. The solution concept of metaequilibrium is proposed to characterize the system-of-systems behavior of the autonomous agents. For online implementation of the control, we design a resilient algorithm that improves the network algebraic connectivity iteratively. We show that the designed algorithm converges to a metaequilibrium asymptotically. Finally, we use case studies of a two-layer MAS network to corroborate the security and agile resilience of the network controlled by the proposed strategy.","2325-5870","","10.1109/TCNS.2019.2962316","National Science of Foundation(grant numbers:ECCS-1847056,CNS-1544782,SES-1541164); U.S. Department of Homeland Security(grant numbers:015-ST-061-CIRC01); Army Research Office(grant numbers:W911NF-19-1-0041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943277","Connectivity;cybersecurity;games-in-games;mobile autonomous system (MAS);multilayer networks","Robot kinematics;Resilience;Laplace equations;Control systems;Games;Autonomous systems","","20","","36","IEEE","25 Dec 2019","","","IEEE","IEEE Journals"
"SAMIHS: Adaptation of Segment Anything Model for Intracranial Hemorrhage Segmentation","Y. Wang; K. Chen; W. Yuan; Z. Tang; C. Meng; X. Bai","Image Processing Center, Beihang University; Image Processing Center, Beihang University; Image Processing Center, Beihang University; Department of Neurology, Tongji Hospital; Image Processing Center, Beihang University; Image Processing Center, Beihang University",2024 IEEE International Symposium on Biomedical Imaging (ISBI),"22 Aug 2024","2024","","","1","5","Segment Anything Model (SAM), a vision foundation model trained on large-scale annotations, has recently continued raising awareness within medical image segmentation. Despite the impressive capabilities of SAM on natural scenes, it struggles with performance decline when confronted with medical images, especially those involving blurry boundaries and highly irregular regions of low contrast. In this paper, a SAM-based parameter-efficient fine-tuning method, called SAMIHS, is proposed for intracranial hemorrhage segmentation, which is a crucial and challenging step in stroke diagnosis and surgical planning. Distinguished from previous SAM and SAM-based methods, SAMIHS incorporates parameter-refactoring adapters into SAM’s image encoder and considers the efficient and flexible utilization of adapters’ parameters. Additionally, we employ a combo loss that combines the binary cross-entropy loss and a boundary-sensitive loss to enhance SAMIHS’s ability to recognize the boundary regions. Our experimental results on two public datasets demonstrate the effectiveness of our proposed method. Code is available at https://github.com/mileswyn/SAMIHS.","1945-8452","979-8-3503-1333-8","10.1109/ISBI56570.2024.10635673","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10635673","Medical image segmentation;Foundation models;Intracranial hemorrhage segmentation;CT","Image segmentation;Solid modeling;Three-dimensional displays;Codes;Surgery;Transformers;Planning","","9","","23","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Integrating Generative AI and Federated Learning for Privacy Preserved Sequence-Based Stomach Adenocarcinoma Detection","M. Sikandar; I. U. Din; A. Almogren","Department of Information Technology, The University of Haripur, Haripur, Pakistan; Department of Information Technology, The University of Haripur, Haripur, Pakistan; Department of Computer Science, College of Computer and Information Sciences, Chair of Cyber Security, King Saud University, Riyadh, Saudi Arabia",IEEE Transactions on Consumer Electronics,"13 Dec 2024","2024","70","3","5278","5285","Stomach Adenocarcinoma (STAD) significantly impacts global cancer mortality rates. Recent strides in artificial intelligence (AI), machine learning (ML), and deep learning (DL) have primarily harnessed imaging techniques like CT, X-rays, PET, and MRI for cancer detection. Concurrently, the rapidly growing volume of genomic big data presents an untapped reservoir for identifying genetic mutations characteristic of STAD. Our research explores this avenue by examining gene amino acid sequences altered by STAD. We employ physical properties of amino acids, i.e., Electro-Ion Interaction Pseudopotential (EIIP) values and Kidera factors in feature extraction, a novel strategy in STAD diagnostics. To address the issue of class imbalance, we incorporate generative AI to produce additional data samples. Addressing the privacy and security challenges associated with data centralization in healthcare, we propose Fed_ANN11, an artificial neural network (ANN) model developed in a federated environment following an initial deployment as ANN11. Our model demonstrates remarkable accuracy in both simple and federated environments with extracted feature sets, namely, EIIP-based and Kidera factors-based. We found that EIIP-based features eclipse Kidera factors in performance. In a simple setting, the proposed model achieved a testing accuracy of 86% and a training accuracy of 88% for STAD detection using the EIIP-based feature set. In a federated environment, it achieved an accuracy of 0.94% in testing and 0.99% in training for STAD detection using the EIIP-based feature set. Moreover, our proposed model shows significant performance compared to existing state-of-the-art methods. Fed_ANN11 not only excels in diagnostic precision but also upholds stringent big data security and privacy protocols, heralding a paradigm shift in AI’s role in healthcare.","1558-4127","","10.1109/TCE.2024.3423786","Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia, through the Vice Deanship of Scientific Research Chairs: Chair of Cyber Security; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10587004","Stomach adenocarcinoma detection;genetic mutations;federated learning;amino acid sequences genomic data analysis","Amino acids;Medical services;Feature extraction;Cancer;Training;Data privacy;Artificial intelligence","","2","","27","IEEE","5 Jul 2024","","","IEEE","IEEE Journals"
"A contract among autonomous agents to deal with egalitarian social welfare","J. Carrero; I. Rodríguez; F. Rubio","Depatamento de Sistemas Informáticos y Computación, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain; Depatamento de Sistemas Informáticos y Computación, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain; Depatamento de Sistemas Informáticos y Computación, Facultad de Informática, Universidad Complutense de Madrid, Madrid, Spain",2021 IEEE 20th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),"4 Jul 2022","2021","","","131","138","Auction security has been a major challenge for researchers in this area. For example, one of the biggest problems has always been the trust in a third party, an intermediary, which is the one who usually conducts the auction and knows the bids made by the participants. Over time, traditional methods have been overtaken by new technologies that eliminate the problems that arise when using traditional methods. Blockchain technology allows us to use its inherent characteristics of privacy, traceability and decentralization to conduct auctions with a much higher level of security and to execute auctions while reducing transaction costs. In addition, the automation of operations provided by smart contracts allows us to eliminate the intermediary, leading to additional cost savings. Furthermore, in contrast to previous technologies, the pseudo-anonymity of blockchain allows us to verify the authenticity of data, mitigating malicious behavior on the part of agents. In this paper we address this challenge; we present a smart contract that allows us to run an auction within the Ethereum blockchain at a relatively low cost, eliminating the intermediary and guaranteeing the trust of the agents involved in the auction. In particular, we concentrate on dealing with egalitarian social welfare, where the goal is to maximize the utility of the agent whose utility turns out to be minimal.","","978-1-6654-2119-5","10.1109/ICCICC53683.2021.9811317","Comunidad de Madrid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811317","Social Welfare;Genetic Algorithms;Contracts;Auctions","Privacy;Costs;Automation;Smart contracts;Autonomous agents;Blockchains;Behavioral sciences","","1","","38","IEEE","4 Jul 2022","","","IEEE","IEEE Conferences"
"AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology","M. H. Nguyen; T. Phan Chau; P. X. Nguyen; N. D. Q. Bui","FPT Software AI Center, Vietnam; FPT Software AI Center, Vietnam; FPT Software AI Center, Canada; FPT Software AI Center, Vietnam",2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge),"2 Jul 2025","2025","","","156","167","Software agents are emerging as powerful tools for tackling complex software engineering tasks. However, existing approaches often oversimplify development workflows, assuming basic models that lack the nuances of real-world software processes. Moreover, they frequently include entire codebases in their instructions, leading to inefficiencies when working with large-scale projects. To overcome these challenges, we introduce AgileCoder, a multi-agent system that incorporates Agile Methodology (AM) principles, assigning specialized agents to roles such as Product Manager, Developer, and Tester for collaborative, iterative development. AgileCoder structures work into sprints, enabling incremental progress based on user input. A standout feature, the Dynamic Code Graph Generator, continuously builds a Code Dependency Graph as the codebase evolves, allowing agents to gain a deeper understanding of the structure for more precise code generation and efficient modifications. We evaluate AgileCoder on two fronts: (1) code generation benchmarks, including HumanEval and MBPP, and (2) real-world software development scenarios. The results show that AgileCoder outperforms existing systems like ChatDev and MetaGPT, setting a new standard for multi-agent systems in software engineering. The source code is available at https://github.com/FSoft-AI4Code/AgileCoder.","","979-8-3315-0211-9","10.1109/Forge66646.2025.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052788","agents;multi-agent;Agile;LLMs;software development","Codes;Collaboration;Static analysis;Benchmark testing;Generators;Iterative methods;Standards;Software development management;Software engineering;Multi-agent systems","","","","62","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Cultural Bias in Text-to-Image Models: A Systematic Review of Bias Identification, Evaluation, and Mitigation Strategies","W. Elsharif; M. Alzubaidi; M. Agus","ICT Division, College of Science and Engineering, Hamad Bin Khalifa University, Ar Rayyan, Qatar; ICT Division, College of Science and Engineering, Hamad Bin Khalifa University, Ar Rayyan, Qatar; ICT Division, College of Science and Engineering, Hamad Bin Khalifa University, Ar Rayyan, Qatar",IEEE Access,"22 Jul 2025","2025","13","","122636","122659","Despite their continuous advancements, text-to-image (TTI) models often reflect and reinforce cultural biases, perpetuating stereotypes often inherent in their training data. This systematic review critically examines cultural bias in text-to-image (TTI) models, addressing gaps in existing research by analyzing its manifestations, evaluation methods, and mitigation strategies—both directly and through the lens of intersectionality with other bias dimensions. A comprehensive literature review was conducted across multiple major databases, following a rigorously structured search strategy, resulting in the selection of 58 studies spanning bias analysis, evaluation frameworks, and mitigation techniques. Thematic findings highlight that gender bias was the most extensively studied, appearing in 53 studies (91%), followed by racial/ethnic bias (42 studies) and other social biases (41 studies). Furthermore, the review explores how these biases intersect and compound in AI-generated imagery, shaping and reinforcing cultural bias. Our findings reveal the following key aspects: 1) the lack of standardization and scalability in bias evaluation, 2) the lack of a fully effective mitigation strategy, 3) contributed TTI benchmarks favoring Western-centric perspectives. We finally propose future directions to improve fairness and representation in TTI models.","2169-3536","","10.1109/ACCESS.2025.3585745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071263","AI ethics;AI fairness;bias evaluation;bias mitigation;CLIP;cultural bias;generative AI;gender bias;prompt engineering;racial bias;responsible AI;text-to-image models","Cultural differences;Prevention and mitigation;Text to image;Systematic literature review;Solid modeling;Artificial intelligence;Computational modeling;Visualization;Natural language processing;Medical services","","","","115","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"Automated Classification and Identification of Non-Functional Requirements in Agile-Based Requirements Using Pre-Trained Language Models","A. Alhaizaey; M. Al-Mashari","Department of Information Systems, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Information Systems, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Access,"23 May 2025","2025","13","","87401","87417","Non-functional requirements (NFRs) are critical factors for software quality and success. A frequently reported challenge in agile requirements engineering is that NFRs are often neglected due to the focus on functional requirements (FRs) and the limited capability of agile requirements documented as user stories to represent NFRs. With the emergence of transfer learning and large pre-trained language models, various applications in requirements engineering have become feasible, alleviating several longstanding challenges. This study evaluates transformer-based models for the automated identification and classification of NFRs. We leveraged transfer learning with pre-trained transformer models to automate the identification and classification of NFRs in agile textual requirements documented as user stories. A dataset of over 10k user stories was collected and labeled, and pre-trained transformer models, including BERT, RoBERTa, XLNet, and DistilBERT, were fine-tuned to automate the identification of NFRs. We incorporated Focal Loss during training to mitigate the dominance of functionally driven requirements and class imbalances. In addition, thorough experiments on hyperparameter optimization were employed using Bayesian hyperparameter optimization to obtain the combination of hyperparameters that best correlated with the aim of enhancing each model’s performance. Our evaluation demonstrated that the finetuned pre-trained models significantly outperformed comparable prior approaches relying on rule-based techniques or traditional machine learning, with a fine-tuned BERT model achieving an F1 Score of 93.4 %. These findings highlight the potential of pre-trained language models in agile requirements engineering, enabling more efficient NFRs identification, reducing manual review burden, and facilitating a viable and efficient approach to address the neglect of NFRs in agile development processes.","2169-3536","","10.1109/ACCESS.2025.3570359","King Saud University (KSU); King Khalid University (KKU), Saudi Arabia; KKU through the Ph.D. Scholarship at KSU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005451","Nonfunctional requirements;agile software development;requirements engineering;user stories;transfer learning;transformers;pre-trained language models;BERT;XLNet","Transformers;Solid modeling;Requirements engineering;Artificial intelligence;Adaptation models;Transfer learning;Training;Software quality;Natural languages;Labeling","","","","66","CCBY","15 May 2025","","","IEEE","IEEE Journals"
"Learning To Code With Text-Bison-001:A Beginner-Friendly Explainer for Python, C, Java","K. S. Krishna; B. D. Kumar; M. D. Reddy; B. S. Varun; M. Belwal","Department of CSE, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of CSE, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of CSE, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of CSE, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of CSE, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","This work aims to develop a Code comprehensive interface for the three programming languages JAVA, C, and Python integrated with error detection and code optimization. Users can give input codes of these language codes in the system or any algorithm and it will explain to the user in detail, The working of the code via language-oriented parsers and tailored analysis techniques. The system breaks apart the code, line by line unveiling the code’s logic, flow of control, and major algorithms. By employing quick yet in-depth descriptions of the code users always get to see behind the scenes with easier debugging, reading, and learning. Talking of multi-language support, ‘CODE EXPLAINER’ becomes a good resource for developers, students, and teachers providing insight into programming concepts","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724566","Code Explainer;Generative AI;Prompt Engineering;Lexical Analysis;Syntax Analysis;Semantic Analysis","Java;Codes;Error analysis;Instruments;Debugging;Programming;Internet;Logic;Optimization;Python","","","","24","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"A Decentralized Smart Distribution Management System","P. T. SEENATH BEEVI; M. L. ARAVIND","Executive Engineer, IT Unit, KSEBL; Assistant Engineer, IT Unit, KSEBL, Trivandrum, Kerala, India",2018 1st International Conference on Advanced Research in Engineering Sciences (ARES),"27 May 2019","2018","","","1","6","This paper proposes load management in an is-landed distribution network using Decentralized Multi Agent System (MAS) during contingency. The major grid features Sustainability, Energy Security, Reliability etc. became the challenges of the 21st century grid management due to the rapid proliferation of Distributed Renewable Generation (DGs) and the increasing number of Electrical Vehicles in to the grid. To manage the grid during a contingency alternate options are explored for the management of critical loads by using a hybrid model on integrating the DGs and Electric Vehicles (EVS) in a decentralized operation. Most critical loads have been prioritized and accordingly formulated the restoration strategy. The power restoration is formulated as a multi objective optimization problem considering maximization of the prioritized critical loads for restoration and minimization of switching operation subject to the constraints as power quality parameters. Developed the Software used to achieve the distributed Intelligence in the Distribution Network. The advantages and disadvantages for the V2G integration were assessed.","","978-1-5386-4844-5","10.1109/ARESX.2018.8723272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723272","AA -Aggregator Agent;DG- Distributed Generator;LA -Load Agent;MAS-Multi Agent System;SA-Switch Agent;SoC-State-of-Charge;FIPA- Foundation for Intelligent Physical Agencies;OMS- Outage Management System;DA-Distribution Automation;ERP- Enterprise Resourse Planning","Switches;Vehicle-to-grid;Reliability;Software;Batteries;Load modeling;Optimization","","","","8","IEEE","27 May 2019","","","IEEE","IEEE Conferences"
"Understanding Code Changes Practically with Small-Scale Language Models","C. Li; Z. Xu; P. Di; D. Wang; Z. Li; Q. Zheng","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Ant Group, Hangzhou, China; Zhejiang University, Hangzhou, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","216","228","Recent studies indicate that traditional techniques for understanding code changes are not as effective as techniques that directly prompt language models (LMs). However, current LM-based techniques heavily rely on expensive, large LMs (LLMs) such as GPT-4 and Llama-13b, which are either commercial or prohibitively costly to deploy on a wide scale, thereby restricting their practical applicability. This paper explores the feasibility of deploying small LMs (SLMs) while maintaining comparable or superior performance to LLMs in code change understanding. To achieve this, we created a small yet high-quality dataset called HQCM which was meticulously reviewed, revised, and validated by five human experts. We fine-tuned state-of-the-art 7b and 220m SLMs using HQCM and compared them with traditional techniques and LLMs with 70b parameters. Our evaluation confirmed HQCM’s benefits and ≥demonstrated that SLMs, after finetuning by HQCM, can achieve superior performance in three change understanding tasks: change summarization, change classification, and code refinement. This study supports the use of SLMs in environments with security, computational, and financial constraints, such as in industry scenarios and on edge devices, distinguishing our work from the others.CCS CONCEPTS• Software and its engineering → Software maintenance tools.","2643-1572","979-8-4007-1248-7","","Ant Group; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764914","code change;code review;language model;LLM;SLM","Performance evaluation;Industries;Software maintenance;Codes;Computational modeling;Security;Software engineering","","1","","54","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Preface of RESET 2023: 2nd International Workshop on Requirement Engineering for Software Startups and Emerging Technologies","A. Nguyen-Duc; C. Arora; P. Abrahamsson","University of South Eastern Norway, Norway; Monash Univeristy; Tampere University, Finland",2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),"28 Sep 2023","2023","","","365","366","The Second International Workshop on Requirement Engineering for Software startups and Emerging Technologies (RESET) is a part of the 31st IEEE International Requirements Engineering Conference 2023, held on 4 September 2023. The workshop brought together requirements engineering researchers and practitioners to discuss the need for adapting conventional requirement engineering artifacts (i.e., requirement definition, metrics), processes and practices in developing and operating emerging technologies, including Software Startups, Artificial Intelligence (AI), Blockchain, and Quantum Computing. Participants gained insights into the RE practices, tools, techniques, and frameworks that can help them build scalable, robust, and innovative software-intensive systems. The workshop included a keynote presentation and four paper presentations.","2770-6834","979-8-3503-2691-8","10.1109/REW57809.2023.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260766","workshop summary;software startups;generative AI;blockhain;requirement engineering","Measurement;Quantum computing;Conferences;Software;Blockchains;Requirements engineering;Artificial intelligence","","1","","3","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"Bassa-Llama — Fine-Tuned Meta’s Llama LLM, Blockchain and NFT Enabled Real-Time Network Attack Detection Platform for Wind Energy Power Plants","E. Bandara; S. H. Bouk; S. Shetty; R. Gore; S. Kompella; R. Mukkamala; A. Rahman; P. Foytik; X. Liang; N. W. Keong; K. De Zoysa","Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; U.S. Naval Research Laboratory; Old Dominion University, Norfolk, VA, USA; Deloitte & Touche LLP; Old Dominion University, Norfolk, VA, USA; Florida International University, USA; Nanyang Technological University, Singapore; University of Colombo School of Computing, Sri Lanka",2025 International Wireless Communications and Mobile Computing (IWCMC),"2 Jul 2025","2025","","","330","336","Large Language Models (LLMs) are widely recognized for their applications in natural language processing tasks, but their potential extends far beyond traditional use cases. This paper introduces ""Bassa-Llama,"" a novel platform that harnesses LLMs for predictive tasks in the realm of network security. Specifically, we propose a platform for real-time network attack detection in Wind Power Plants, leveraging a fine-tuned version of Meta’s Llama-3 LLM alongside blockchain and NFT-based data storage. Using a network PCAP dataset containing both malicious and benign packets, we fine-tune the Llama-3 LLM, with Quantized Low-Rank Adapter (QLoRA), to detect anomalies in network traffic. This approach ensures optimal performance on consumer-grade hardware while significantly enhancing the model’s ability to accurately analyze PCAP data and identify attack patterns. The end-to-end orchestration of the real-time network attack detection flow for Wind Power Plants is fully automated through blockchain smart contracts, and NFTs for storing identified attack data from the PCAP. To the best of our knowledge, this research represents the first effort to utilize a fine-tuned LLM for real-time network attack detection tasks. The results highlight the transformative potential of combining fine-tuned LLMs with blockchain and NFTs to build robust and secure network defense systems for Wind Power Plants. A prototype of the proposed platform was developed in collaboration with the U.S. Department of Energy, utilizing a simulated Wind Power Plant as a testbed.","2376-6506","979-8-3315-0887-6","10.1109/IWCMC65282.2025.11059647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059647","Generative-AI;Llama-3;LLM;LLMOps;Blockchain;NFT;Wind-Energy","Wireless communication;Wind energy;Smart contracts;Prototypes;Telecommunication traffic;Wind power generation;Network security;Real-time systems;Natural language processing;Blockchains","","","","24","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications","A. Gheorghiu",NA,Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications,"","2024","","","","","Solve real-world problems easily with artificial intelligence (AI) using the LlamaIndex data framework to enhance your LLM-based Python applications Key FeaturesExamine text chunking effects on RAG workflows and understand security in RAG app developmentDiscover chatbots and agents and learn how to build complex conversation enginesBuild as you learn by applying the knowledge you gain to a hands-on projectBook DescriptionDiscover the immense potential of Generative AI and Large Language Models (LLMs) with this comprehensive guide. Learn to overcome LLM limitations, such as contextual memory constraints, prompt size issues, real-time data gaps, and occasional ‘hallucinations’. Follow practical examples to personalize and launch your LlamaIndex projects, mastering skills in ingesting, indexing, querying, and connecting dynamic knowledge bases. From fundamental LLM concepts to LlamaIndex deployment and customization, this book provides a holistic grasp of LlamaIndex's capabilities and applications. By the end, you'll be able to resolve LLM challenges and build interactive AI-driven applications using best practices in prompt engineering and troubleshooting Generative AI projects.What you will learnUnderstand the LlamaIndex ecosystem and common use casesMaster techniques to ingest and parse data from various sources into LlamaIndexDiscover how to create optimized indexes tailored to your use casesUnderstand how to query LlamaIndex effectively and interpret responsesBuild an end-to-end interactive web application with LlamaIndex, Python, and StreamlitCustomize a LlamaIndex configuration based on your project needsPredict costs and deal with potential privacy issuesDeploy LlamaIndex applications that others can useWho this book is forThis book is for Python developers with basic knowledge of natural language processing (NLP) and LLMs looking to build interactive LLM applications. Experienced developers and conversational AI developers will also benefit from the advanced techniques covered in the book to fully unleash the capabilities of the framework.","","9781805124405","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10540159.pdf&bkn=10540158&pdfType=book","","","","","","","","28 May 2024","","","Packt Publishing","Packt Publishing eBooks"
"AI-Driven Synthetic Fingerprint Generation: Enhancing Privacy and Biometric Accessibility Using T-SFG Based Framework","S. A; A. Lakkshmanan; I. P. C K; A. D; M. D.C; K. K.","Department of Computing Technologies, SRM Institute of science and technology, Chengalpattu District; Department of Computing Technologies, SRM Institute of science and technology, Chengalpattu District; Department of Computing Technologies, SRM Institute of science and technology, Chengalpattu District; Department of CSE, Sathyabama University, Chennai; Department of Computer Science and Engineering, SNS College of Technology, Coimbatore; Department of Mathematics, RVS College of Engineering and Technology, Coimbatore, India",2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA),"31 Jul 2025","2025","","","112","119","Biometric authentication is important for security and human device interaction, however, problems of fingerprint loss attributable to medical conditions, privacy issues and scarcity of data prevent widespread adoption. In this research, we present an AI based solution to the issue of generating synthetic fingerprint using T-SFG framework, where we solve the problem of biometric availability, privacy protection and ethical data handling. It differs from classic methods based on the presence of private biometric data and does not require storage or processing of such data, which is compliant with privacy regulations such as GDPR and HIPAA. Synthetic fingerprint generation also helps in data augmentation, which allows for generating diverse and representative datasets to make models robust and reduce bias in diverse demographics. The results of this technique are significantly cheaper and faster than in the real world, while being able to generate scaled dataset. Additionally, these factors enable the proposed framework to improve the modularity of authentication technologies in different conditions, give stress testing to biometric systems for security holes, and helps sync that AI model training by simulating uncommon and broad constraints. The experimental results show that T-SFG can produce high quality synthetic fingerprints for biometric applications, privacy focused authentication and for the development of artificial skin or prosthetic limbs with fingerprint ridges for improved touchscreen interaction. The results show that synthetic biometric data can also help the research, innovation and regulatory compliant solutions and more secure, accessible and ethical biometric technologies.","","979-8-3315-2142-4","10.1109/ICIRCA65293.2025.11089524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11089524","Data Augmentation;Privacy Preservation;Biometric Security;Transformer Models;Synthetic Fingerprints","Biometrics;Training;Data privacy;Privacy;Accuracy;Biological system modeling;Fingerprint recognition;Transformers;Data augmentation;Security","","","","15","IEEE","31 Jul 2025","","","IEEE","IEEE Conferences"
"Model-Driven Development Architectures to Solve Complex Autonomous Robotics Problems","A. Beaulieu; S. N. Givigi; D. Ouellet; J. T. Turner","Royal Military College of Canada, Kingston, ON, CA; Royal Military College of Canada, Kingston, ON, CA; Royal Military College of Canada, Kingston, ON, CA; Royal Military College of Canada, Kingston, ON, CA",IEEE Systems Journal,"2 May 2018","2018","12","2","1404","1413","In this paper, we discuss model-driven development (MDD) and real-time objected oriented software design paradigms to solve two uninhabited autonomous robotics problems. The first problem we analyze is that of a single robot that has strict timing requirements to perform simultaneous localization and mapping. The second problem we analyze is that of a swarming of flocks of various sizes. Both architectures are discussed and compared for the solution of complex robotics problems. The main contribution of this paper is the definition of an MDD methodology for solving robotics problems, its implementation and validation. Results show that the method can guarantee the real-time requirements for the applications.","1937-9234","","10.1109/JSYST.2016.2583403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7509640","Autonomous agents;real-time systems;robots;robot programming;simultaneous localization and mapping (SLAM);software architecture","Unified modeling language;Real-time systems;Computer architecture;Simultaneous localization and mapping;Object oriented modeling","","7","","39","Crown","12 Jul 2016","","","IEEE","IEEE Journals"
"Can an LLM Find Its Way Around a Spreadsheet?","C. -T. Lee; A. Neeser; S. Xu; J. Katyan; P. Cross; S. Pathakota; M. Norman; J. Simeone; J. Chandrasekaran; N. Ramakrishnan","Virginia Tech, Arlington, VA, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Arlington, VA, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA; World Forest ID, Washington DC, USA; Simeone Consulting, Littleton, NH, USA; Virginia Tech, Arlington, VA, USA; Virginia Tech, Arlington, VA, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","294","306","Spreadsheets are routinely used in business and scientific contexts, and one of the most vexing challenges is performing data cleaning prior to analysis and evaluation. The ad-hoc and arbitrary nature of data cleaning problems, such as typos, inconsistent formatting, missing values, and a lack of standardization, often creates the need for highly specialized pipelines. We ask whether an LLM can find its way around a spreadsheet and how to support end-users in taking their free-form data processing requests to fruition. Just like RAG retrieves context to answer users' queries, we demonstrate how we can retrieve elements from a code library to compose data preprocessing pipelines. Through comprehensive experiments, we demonstrate the quality of our system and how it is able to continuously augment its vocabulary by saving new codes and pipelines back to the code library for future retrieval.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00101","NSF(grant numbers:CMMI-2240402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029781","LLMs;code generation;data cleaning;end-user programming","Vocabulary;Codes;Pipelines;Data preprocessing;Standardization;Programming;Libraries;Cleaning;Software engineering;Business","","","","52","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Whispering Pixels: Exploiting Uninitialized Register Accesses in Modern GPUs","F. D. Pustelnik; X. M. Sass; J. -P. Seifert","Technische Universitat Berlin - SecT, Berlin, Germany; Technische Universitat Berlin - SecT, Berlin, Germany; Technische Universitat Berlin - SecT, Berlin, Germany",2024 IEEE 9th European Symposium on Security and Privacy (EuroS&P),"22 Aug 2024","2024","","","345","360","Graphic Processing Units (GPUs) have transcended their traditional use-case of rendering graphics and nowadays also serve as a powerful platform for accelerating ubiquitous, non-graphical rendering tasks. One prominent task is inference of neural networks, which process vast amounts of personal data, such as audio, text or images. Thus, GPUs became integral components for handling vast amounts of potentially confidential data, which has awakened the interest of security researchers. This lead to the discovery of various vulnerabilities in GPUs in recent years. In this paper, we uncover yet another vulnerability class in GPUs: We found that some GPU implementations lack proper register initialization routines before shader execution, leading to unintended register content leakage of previously executed shader kernels. We showcase the existence of the aforementioned vulnerability on products of 3 major vendors - Apple, NVIDIA and Qualcomm. The vulnerability poses unique challenges to an adversary due to opaque scheduling and register remapping algorithms present in the GPU firmware, complicating the reconstruction of leaked data. In order to illustrate the real-world impact of this flaw, we showcase how these challenges can be solved for attacking various workloads on the GPU. First, we showcase how uninitialized registers leak arbitrary pixel data processed by fragment shaders. We further implement information leakage attacks on intermediate data of Convolutional Neural Networks (CNNs) and present the attack's capability to leak and reconstruct the output of Large Language Models (LLMs).","2995-1356","979-8-3503-5425-6","10.1109/EuroSP60621.2024.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10629018","System Security;GPU;Machine Learning Security","Neural networks;Graphics processing units;Rendering (computer graphics);Vectors;Scheduling;Registers;Security","","","","48","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"A Deep Dive into Vector Stores: Classifying the Backbone of Retrieval-Augmented Generation","R. Shan","Department of Data Science, North Carolina School of Science and Mathematics, Durham, NC, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","8831","8833","Vector stores represent a crucial building block for Retrieval-Augmented Generation (RAG), efficiently storing and retrieving high-dimensional embeddings to ensure relevance and accuracy for generative AI applications. This paper introduces a classification scheme that categorizes vector stores into four main classes of systems: lightweight and local solutions, open-source and distributed platforms, cloud-native and commercial services, and semantic/contextual search-oriented systems. We discuss the architectures, capabilities, strengths, weaknesses, and use cases of one representative vector database in each category: FAISS, Milvus, Pinecone, and Weaviate. Practical guidelines on the implementation are presented, focused on optimization techniques, strategies for data management, and considerations on security. Comparative insights enable practitioners to align the selection of the vector store with the workflow of RAG solutions. Future trends are explored, such as hybrid search and explainability.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825992","Retrieval-Augmented Generation;vector store;landscape;FAISS;Chroma;Milvus;Pinecone;Weaviate;generative AI;implementation best practices;classification","Generative AI;Databases;Retrieval augmented generation;Big Data;Market research;Vectors;Security;Optimization;Best practices;Guidelines","","1","","4","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Towards a Smart Learning Environment : A Model for Smart Education using IoT and AI","A. Dehbi; A. Bakhouyi; R. Dehbi; M. Talea","Laboratory of Information Processing (LTI) Faculty of Sciences Ben M’Sick, Hassan II University, Casablanca, Morocco; Laboratory of Information Processing (LTI) Faculty of Sciences Ben M’Sick, Hassan II University, Casablanca, Morocco; Laboratory of Computer Science (LIS) Faculty of Sciences Aïn Chock, Hassan II University, Casablanca, Morocco; Laboratory of Information Processing (LTI) Faculty of Sciences Ben M’Sick, Hassan II University, Casablanca, Morocco",2024 6th International Symposium on Advanced Electrical and Communication Technologies (ISAECT),"19 Dec 2024","2024","","","1","5","Smart education has become a hallmark of information and communication technology in education (ICTE). The continuous introduction of new technologies into learning environments aims to enable learners to develop and enhance their skills, leading to improved learning outcomes. Technologies such as the Internet of Things (IoT), Generative AI, and mobile technology are among the latest to be integrated into educational infrastructures and systems. These smart technologies offer personalized content creation, automate administrative tasks, and enhance student engagement through adaptive interactions. However, despite the promising benefits, challenges such as security and privacy concerns, the need for robust infrastructure, and ongoing technical support must be addressed. This paper proposes a comprehensive model for implementing smart education technologies, addressing these challenges. The proposed model serves as a blueprint for educational institutions aiming to leverage modern technologies to create smarter, more efficient learning environments.","","979-8-3315-2998-7","10.1109/ISAECT64333.2024.10799743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10799743","Generative AI;Internet of Things (IoT);ICTE;Smart Education;e-learning","Training;Adaptation models;Technological innovation;Privacy;Generative AI;Data security;Educational technology;Information and communication technology;Internet of Things;Stakeholders","","1","","17","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"SecureGenAI: A Standardized Framework for Authentication and Provenance in AI-Generated Images using Blockchain-Enhanced Watermarking","D. Besiahgari",Amazon Web Services,2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS),"24 Jun 2025","2025","","","1","6","The escalating popularity of Generative AI (GenAI) for image creation has raised challenges surrounding authenticity, ownership, and misuse. This paper proposes SecureGenAI, a revolutionary framework designed to tackle those issues, which incorporates invisible watermarks into the genesis of the images produced by the AI model to allow for seamless verification that is tamper-proof. SecureGenAI contrasts with more traditional methods based on watermarking, which usually add a watermark to an image after it has been created. SecureGenAI implements Discrete Wavelet Transform (DWT) watermarking in the AI model itself, allowing for greater resistance to adversarial techniques used to remove watermarks after image generation. Moreover, the framework combines the advantages of DWT watermarking with blockchain to store and authenticate the watermark data, making sure that watermarks cannot be altered or their identifying information removed. One of the standout features of SecureGenAI is the real-time API designed for online image verification: it eliminates the need for verification metadata, which can be easily spoofed. This shift in paradigm increases the trustworthiness, accountability and security of AI generated content while lowering risks of being targeted by deepfakes or image manipulation. SecureGenAI’s combination of embedded invisible watermarking in the AI model and decentralized blockchain-enabled verification presents a new technological advantage for the field of AI-generated imagery.","","979-8-3315-3701-2","10.1109/ICKECS65700.2025.11035329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035329","Generative AI;image authentication;invisible watermarking;blockchain verification;deepfake prevention;real-time content authentication","Resistance;Deepfakes;Generative AI;Prevention and mitigation;Authentication;Watermarking;Transforms;Real-time systems;Discrete wavelet transforms;Blockchains","","","","19","IEEE","24 Jun 2025","","","IEEE","IEEE Conferences"
"Voice-Activated Personalized Assistant with Raspberry Pi and Google API Integration","P. Gokhale; S. Vadada; V. K. Daule; M. Belwal","Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, Amrita Vishwa Vidyapeetham, India",2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS),"24 Jun 2025","2025","","","1485","1489","As we enter a new age of a world of fast-paced living and a technology-driven lives, the need for personal assistants with can simplify everyday tasks and productivity is needed as a help for the humankind. There is a demanding need for a device which does not need to be operated by hands or with high-level coding but a simple English command which will do the task requested for. The proposed personal assistant aims to fulfill this requirement by providing a voice-interactive personal assistant powered by Raspberry Pi and generative AI that will listen to voice commands and respond intelligently by generated voice commands. The assistant will process voice inputs and offer auditory responses in real time using advanced AI models. With speech recognition, natural language processing, and audio synthesis in real time, this system provides a very seamless user experience. It has demonstrated a cost-effective and practical approach to building an intuitive virtual companion that can assist with simple daily tasks. This method proposes efficiency in the process with a cost-effective approach and a security concern.","","979-8-3315-0724-4","10.1109/ICAISS61471.2025.11041858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11041858","Natural Language Processing(NLP);Voice Assistant(VA);Voice Recognition;Generative AI(GAI);Text-to-Speech Synthesis;Raspberry Pi(RP)","Productivity;Hands;Generative AI;Speech recognition;Real-time systems;User experience;Natural language processing;Text to speech;Internet;Security","","","","24","IEEE","24 Jun 2025","","","IEEE","IEEE Conferences"
"AI-Powered Strategies for Cloud Infrastructure Management","K. A. Singh; A. Choudhry","Cloud Center of Execellence, Technology Software and Services, Tata Consultancy Services Ltd., Bangalore, India; Cloud Center of Execellence, Technology Software and Services, Tata Consultancy Services Ltd., Noida, India",2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0,"14 Jul 2025","2025","","","1","5","Cloud computing offering such as unparalleled flexibility, cost savings, and scalability has changed the way companies manage their IT resources and IT ecosystem. Conversely, with rapid adoption of hybrid and multi-cloud architecture, cloud ecosystems have become more complex. It has become extremely challenging to manage Cloud to keep up to date with the rapid pace of technological innovation and ever-changing business dynamics.Power of Generative AI (Gen AI) provides a much needed and new approach for cloud infrastructure management. Contrasting traditional rule-based automation, Gen AI enables systems to constantly learn from data and make independent decisions, providing a path towards self-optimizing, self-healing cloud environments. Leveraging Gen AI in cloud infrastructure management, companies can also reveal new levels of performance, security, and resilience, apart from improved operational efficiency. The purpose of this paper is to discover how Gen AI can be best harnessed to cloud infrastructure management, focusing on key scenarios and to recommend strategies for implementation.","","979-8-3315-3536-0","10.1109/OTCON65728.2025.11070393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11070393","cloud infrastructure management;generative ai;gen ai;implementation strategy;strategic recommendations","Cloud computing;Technological innovation;Costs;Generative AI;Scalability;Ecosystems;Companies;Security;Predictive analytics;Resilience","","","","5","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Leveraging Multimodal Retrieval-Augmented Generation for Cyber Attack Detection in Transit Systems","M. B. Munir; Y. Cai; L. Khan; B. Thuraisingham","The University of Texas, Dallas, USA; The University of Texas, Dallas, USA; The University of Texas, Dallas, USA; The University of Texas, Dallas, USA","2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)","16 Jan 2025","2024","","","341","350","Large Language Models (LLMs) often tend to hallucinate, one of the reasons is due to limitations in their training datasets. These datasets are vast, and the training process is resource-intensive, making LLMs unreliable for generating accurate responses for recent information. To address this issue, Retrieval-Augmented Generation (RAG) uses indexed text chunks from relevant, up-to-date knowledge databases to generate more accurate and current responses. Our project explores the use of RAG in the domain of transit security. Transit security systems include physical objects such as video and audio surveillance, alarms, threat sensors, and infrastructure monitoring sensors, which scan the environment for potential threats and relay this information to the Transit Management Center, Transit Vehicles, Emergency Management Center, etc. We aimed to predict potential cyber threats to these information flows that adversaries might exploit to infiltrate the systems. By utilizing the description of the information flow and other characteristics of the data, we leveraged LLMs with RAG to map possible cyber attack techniques from the MITRE ATT&CK knowledge-base. As the MITRE ATT&CK technique database is continuously updated to keep track of the new cyberattack techniques, using RAG enhances our ability to predict how adversaries might target transit security information flows. We analyzed information flows of transit systems from the USDOT public website, manually annotating possible attack techniques to establish a benchmark. Our multimodal RAG model achieved an F-1 score of 40.5% and a precision of 42.5%, representing a 73.65% improvement over the baseline approach. These results demonstrate the effectiveness of integrating LLMs with RAG and incorporating multimodality in predicting cyber threats in transit cybersecurity.","","979-8-3503-8674-5","10.1109/TPS-ISA62245.2024.00046","Clemson University; Morgan State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835420","Large Language Model;Retrieval Augmented Generation;Transportation Security;Transit System;MITRE ATT&CK;Multimodal RAG","Training;Accuracy;Target tracking;Databases;Retrieval augmented generation;Knowledge based systems;Sensor systems;Threat assessment;Sensors;Cyberattack","","","","26","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Research on Self-Evolving Deepfake Detection Technology Based on LLM","C. Yoon; J. Cho; K. Jang Mook","Korean National Police Univ, Asan, Korea; Institute of Police Studies, Cheong-ju, Korea; Far East Univ, Umsung, Korea",2025 1st International Conference on Consumer Technology (ICCT-Pacific),"30 May 2025","2025","","","1","4","Deepfake technology enables the manipulation of text, images, audio, and video, offering innovative applications in areas like virtual reality and entertainment. However, it also poses risks such as fake news, privacy breaches, and political misuse, challenging existing static detection models that struggle to adapt to evolving manipulation techniques. This study proposes a self-evolving deepfake detection system using generative AI (LLM) to learn and adapt in real time. The framework integrates real-time learning, multimodal data processing, and lightweight models, emphasizing ethical data practices to ensure fairness, transparency, and security. By addressing technical, social, and legal challenges, this research provides a robust solution for mitigating deepfake risks while fostering ethical and reliable AI deployment.","","979-8-3315-0412-0","10.1109/ICCT-Pacific63901.2025.11012805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012805","Deepfake Detection;Self-Evolving Models;formatting;Generative AI (LLM);Ethical Data Utilization;Real-Time Learning. s)","Deepfakes;Ethics;Solid modeling;Adaptation models;Law;Generative AI;Virtual reality;Real-time systems;Data models;Standards","","","","23","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Assessing the Resilience of BFT-Raft Consensus Against Insider DoS Attacks in Blockchain","A. Altarawneh; J. Owusu-Tweneboah","Department of Computer Science, Tennessee Technological University, Cookeville, USA; Department of Computer Science, Tennessee Technological University, Cookeville, USA",2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC),"5 Mar 2025","2025","","","00058","00065","A significant amount of research has put forward various consensus mechanisms for blockchain technology, but many have not been implemented due to security and performance concerns. Consensus mechanisms are essential for ensuring the continued operation (liveness) and security of blockchain systems. The Byzantine Fault Tolerant-Raft (BFT-Raft) consensus algorithm combines the simplicity of Raft, developed by the Stanford group, with the resilience of Byzantine Fault Tolerance (BFT) mechanisms. However, the liveness and security of BFT-Raft as a consensus mechanism have not been thoroughly validated. This study addresses this gap by analyzing the availability of BFT-Raft, particularly focusing on the behavior of malicious miners who manipulate their timeout to influence the leader election process within the consensus mechanism. Using both simulation and theoretical models, the research assesses the vulnerability of BFT-Raft to insider denial of service (DoS) attacks. Additionally, the study evaluates BFT-Rafts' ability to maintain availability and effectively terminate the consensus and miner selection processes in the presence of malicious miners and clients. Using binomial distribution, queuing theory, and Markov chains, the resilience of BFT-Raft is systematically examined. The findings indicate that BFT-Raft has specific security vulnerabilities making it susceptible to insider DoS attacks. The paper also proposes potential approaches to mitigate these vulnerabilities, such as a game theory approach with incentives and penalties, a hardware-based approach, and an attack detection approach using AI and explainable AI to help make decisions for these complex attacks.","","979-8-3315-0769-5","10.1109/CCWC62904.2025.10903681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903681","Distributed Ledger Technology (DLT);Blockchain;Byzantine Fault Tolerant (BFT);BFT-Raft;Security analysis;Tangaroa;Generative AI;LLM;Game Theory","Fault tolerance;Explainable AI;Voting;Fault tolerant systems;Focusing;Consensus protocol;Security;Game theory;Queueing analysis;Resilience","","1","","42","IEEE","5 Mar 2025","","","IEEE","IEEE Conferences"
"Multi-Agent Deep Reinforcement Learning Applications in Cybersecurity: Challenges and Perspectives","Z. Tolba; N. E. H. Dehimi; S. Galland; S. Boukelloul; D. Guassmi","Department of Mathematics and Computer Science, LIAOA Laboratory, University of Oum El Bouaghi, Algeria; Department of Mathematics and Computer Science, LIAOA Laboratory, University of Oum El Bouaghi, Algeria; UTBM, CIAD, CEDEX, Belfort, France; Department of Mathematics and Computer Science, LIAOA Laboratory, University of Oum El Bouaghi, Algeria; Department of Mathematics and Computer Science, LIAOA Laboratory, University of Oum El Bouaghi, Algeria","2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)","28 Jan 2025","2024","","","1","6","This paper explores the perspectives and challenges associated with the application of Multi-Agent Deep Reinforcement Learning (MADRL) in the field of cybersecurity. As cyber threats continue to evolve in complexity, the integration of MADRL techniques offers promising solutions for enhancing security measures. The paper delves into various perspectives surrounding the implementation of MADRL in cybersecurity applications, highlighting its potential benefits. Additionally, it addresses the challenges and obstacles faced in the deployment of such advanced techniques, emphasizing the need for further research and development to overcome these hurdles. The findings contribute to a comprehensive understanding of the landscape, paving the way for the effective integration of MADRL in cybersecurity frameworks. The paper outlines the growing significance of MAS and DRL, examines their current applications in cybersecurity, discusses the associated challenges, and provides insights into future directions. By investigating decentralized threat intelligence sharing, privacy-preserving collaboration, robustness against adversarial attacks, and crossdomain collaboration, this research aims to illuminate the path toward a more secure and resilient cyber future.","","979-8-3503-8848-0","10.1109/ECTE-Tech62477.2024.10851146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851146","Multi agent systems;Deep reinforcement learning;Cybersecurity;Threats;Attacks","Adaptive systems;Digital systems;Ecosystems;Collaboration;Deep reinforcement learning;Robustness;Computer security;Protection;Computer crime;Research and development","","","","24","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"Enhanced Environmental Awareness and Security for Smart Devices using WiFi-Sensing","G. Gad; I. Batool; M. M. Fouda; M. I. Ibrahem; Z. M. Fadlullah","Department of Computer Science, Western University, London, ON, Canada; Department of Computer Science, Western University, London, ON, Canada; Department of Electrical and Computer Engineering, Idaho State University, Pocatello, ID, USA; School of Computer and Cyber Sciences, Augusta University, Augusta, GA, USA; Department of Computer Science, Western University, London, ON, Canada","2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)","2 Jun 2025","2025","","","1","6","With the current advancements generative AI. Applications across many fields are being integrated with AI agents to provide a better experience to the users. One of these applications is personal assistants which can be integrated with AI to support Natural Language Understanding (NLU). In this work we introduce the architecture and evaluation of an AI-powered smart home device. The role of the role of the presenteddeviceevice is to be a personal assistant which is accessible across different platforms (web, desktop, mobile, and wearable devices), using multiple communication methods (text, voice, notification). The device will be able to collect and process multi-modal data from different platforms including sensory data which is analyzed to predict human activity, bridging the digital and the physical worlds.We assess the performance for three key tasks: Human identification and activity tracking using wifi sensing, storytelling using large language models, and text-to-speech synthesis. We evaluate the three tasks using a combination of objective performance metrics and user studies. Statistical analysis was conducted to evaluate different state-of-the-art Large Language Models (LLM) and Text-To-Speech (TTS) models. We performed deep learning across different data learning paradigms including local, central, and federated learning ensuring privacy and high accuracy.","2996-4393","979-8-3315-1088-6","10.1109/ICHORA65333.2025.11017226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017226","user study;Machine Learning;Federated Learning;wifi sensing;Edge devices;IoT","Privacy;Accuracy;Federated learning;Large language models;Smart homes;Robot sensing systems;Sensors;Text to speech;Internet;Wireless fidelity","","","","12","IEEE","2 Jun 2025","","","IEEE","IEEE Conferences"
"Program Synthesis with Generative Pre-trained Transformers and Grammar-Guided Genetic Programming Grammar","N. Tao; A. Ventresque; T. Saber","School of Computer Science, University College Dublin, Ireland; Lero – the Irish Software Research Centre; Lero – the Irish Software Research Centre",2023 IEEE Latin American Conference on Computational Intelligence (LA-CCI),"26 Jan 2024","2023","","","1","6","Grammar-Guided Genetic Programming (G3P) is widely recognised as one of the most successful approaches to program synthesis. Using a set of input/output tests, G3P evolves programs that fit a defined BNF grammar and that are capable of solving a wide range of program synthesis problems. However, G3P’s inability to scale to more complex problems has limited its applicability. Recently, Generative Pre-trained Transformers (GPTs) have shown promise in revolutionizing program synthesis by generating code based on natural language prompts. However, challenges such as ensuring correctness and safety still need to be addressed as some GPT-generated programs might not work while others might include security vulnerabilities or blacklisted library calls. In this work, we proposed to combine GPT (in our case ChatGPT) with a G3P system, forcing any synthesised program to fit the BNF grammar-thus offering an opportunity to evolve/fix incorrect programs and reducing security threats. In our work, we leverage GPT-generated programs in G3P’s initial population. However, since GPT-generated programs have an arbitrary structure, the initial work that we undertake is to devise a technique that maps such programs to a predefined BNF grammar before seeding the code into G3P’s initial population. By seeding the grammar-mapped code into the population of our G3P system, we were able to successfully improve some of the desired programs using a well-known program synthesis benchmark. However, in its default configuration, G3P is not successful in fixing some incorrect GPT-generated programs–even when they are close to a correct program. We analysed the performance of our approach in depth and discussed its limitations and possible future improvements.","2769-7622","979-8-3503-4807-1","10.1109/LA-CCI58595.2023.10409384","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10409384","Program Synthesis;Grammar Guided Genetic Programming;Generative Pre-trained Transformers;Large Language Models;Grammar","Codes;Sociology;Genetic programming;Transformers;Grammar;Security;Statistics","","5","","29","EU","26 Jan 2024","","","IEEE","IEEE Conferences"
"Bridging the Theory-Practice Gap in a Maintenance Programming Course: An Experience Report","S. Ouhbi","Dept. Information Technology, Uppsala University, Uppsala, Sweden",2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET),"19 Jun 2024","2024","","","359","367","This paper presents our experience in teaching a maintenance programming course with the aim of bridging the gap between theory and practice, a recurring issue in previous course offerings. To achieve this goal, we implemented active learning strategies within an active learning classroom setting and redesigned the project work. Our approach involves peer learning and teamwork activities to cover various aspects of legacy code maintenance. For the project work, we adopted an open-ended approach that allowed students to choose their legacy code projects, which could be open-source software or a previous software project they had worked on. Analysis of students' feedback and project reports highlighted the effectiveness of our approach in bridging the gap between theory and practice. We believe that our approach had the potential to enhance students' engagement and critical thinking abilities, as well as improve practical maintenance skills relevant to their future careers.","2832-7578","979-8-4007-0498-7","10.1145/3639474.3640062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554707","Software Maintenance;Software Engineering Education;Open-ended Project;Group Work;Active Learning;Students Engagement;Generative AI","Training;Software maintenance;Codes;Engineering profession;Maintenance;Teamwork;Programming profession","","1","","40","CCBY","19 Jun 2024","","","IEEE","IEEE Conferences"
"Enhancing Exploratory Testing by Large Language Model and Knowledge Graph","Y. Su; D. Liao; Z. Xing; Q. Huang; M. Xie; Q. Lu; X. Xu","Australian National University, Australia; Jiangxi Normal University, China; Data61, CSIRO, Australia; Jiangxi Normal University, China; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1197","1208","Exploratory testing leverages the tester's knowledge and creativity to design test cases for effectively uncovering system-level bugs from the end user's perspective. Researchers have worked on test scenario generation to support exploratory testing based on a system knowledge graph, enriched with scenario and oracle knowledge from bug reports. Nevertheless, the adoption of this approach is hindered by difficulties in handling bug reports of inconsistent quality and varied expression styles, along with the infeasibility of the generated test scenarios. To overcome these limitations, we utilize the superior natural language understanding (NLU) capabilities of Large Language Models (LLMs) to construct a System KG of User Tasks and Failures (SysKG-UTF). Leveraging the system and bug knowledge from the KG, along with the logical reasoning capabilities of LLMs, we generate test scenarios with high feasibility and coherence. Particularly, we design chain-of-thought (CoT) reasoning to extract human-like knowledge and logical reasoning from LLMs, simulating a developer's process of validating test scenario feasibility. Our evaluation shows that our approach significantly enhances the KG construction, particularly for bug reports with low quality. Furthermore, our approach generates test scenarios with high feasibility and coherence. The user study further proves the effectiveness of our generated test scenarios in supporting exploratory testing. Specifically, 8 participants find 36 bugs from 8 seed bugs in two hours using our test scenarios, a significant improvement over the 21 bugs found by the state-of-the-art baseline.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548271","Exploratory testing;Knowledge graph;AI chain;Prompt engineering","Computer bugs;Knowledge graphs;Coherence;Cognition;Natural language processing;Scenario generation;Task analysis","","","","38","","14 Jun 2024","","","IEEE","IEEE Conferences"
"DURA-CPS: A Multi-Role Orchestrator for Dependability Assurance in LLM-Enabled Cyber-Physical Systems","T. Srinivasan; S. Patapati; H. Musku; I. Gode; A. Arora; S. Bhattacharya; A. Nazriev; S. Hirave; Z. Kanjiani; S. Ghose","Department of AI Deployment and Safety, Cyrion Labs, Dallas, USA; Department of AI Deployment and Safety, Cyrion Labs, Dallas, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; College of Engineering, Cornell University, Ithaca, USA; ACM AI, University of California San Diego, San Diego, USA; Department of R&D, Cyrion Labs, San Roman, USA; Sentinel DE, University of Montana, Missoula, USA; Dept. of Computer Science & Engineering, Oakland University, Rochester, USA; School of Applied Economics and Management, Cornell University, Ithaca, USA; School of Science, University of North Texas, Denton, USA",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),"14 Jul 2025","2025","","","63","70","Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to operate in critical applications. However, traditional verification and validation methods often struggle to handle the unpredictable and dynamic nature of AI components. In this paper, we introduce DURA-CPS, a novel framework that employs multi-role orchestration to automate the iterative assurance process for AI-powered CPS. By assigning specialized roles (e.g., safety monitoring, security assessment, fault injection, and recovery planning) to dedicated agents within a simulated environment, DURA-CPS continuously evaluates and refines AI behavior against a range of dependability requirements. We demonstrate the framework through a case study involving an autonomous vehicle navigating an intersection with an AI-based planner. Our results show that DURA-CPS effectively detects vulnerabilities, manages performance impacts, and supports adaptive recovery strategies, thereby offering a structured and extensible solution for rigorous V&V in safety-and security-critical systems.","2325-6664","979-8-3315-1205-7","10.1109/DSN-W65791.2025.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071569","Cyber-Physical Systems (CPS);Verification and Validation (V&V);Artificial Intelligence (AI);Safety-Critical Systems;Large Language Models (LLM);Autonomous Driving","Runtime;Navigation;Cyber-physical systems;Safety;Planning;Security;Iterative methods;Artificial intelligence;Vehicle dynamics;Autonomous vehicles","","","","35","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Modeling Methods Complex Computer Systems","N. Domukhovsky; D. Leichuk; E. Ponomareva","Ural Security System Center, Ekaterinburg, Russia; Ural Federal Unversity, Ekaterinburg, Russia; Ural Federal Unversity, Ekaterinburg, Russia","2020 Ural Symposium on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT)","16 Jun 2020","2020","","","0600","0601","The paper discusses the methods of modeling computer systems that are applicable for developing an algorithm that allows to evaluate the current state of the observed object in terms of information security, to identify unsafe states of a real system by interpreting the values of the observed parameters. The authors describe the existing problems of modern automated information security systems, indicate the shortcomings and limitations that lead to low efficiency and high cost of ownership of such systems. The paper provides an overview of the methods that can be used to develop an algorithm for analyzing the parameters of an information system that recognizes whether the current state of a real system belongs to one of the classes (“safe” or “unsafe”). In particular, the following systems modeling methods are given – the reduction method, based on multi-agent systems, and modeling based on agents. The reduction method is considered on the example of cluster analysis. For multidimensional data, the use of Kohonen self-organizing maps is most appropriate. For complex modeling methods (based on multi-agent systems and agent-based), their basic concepts (agents and their properties, types), a brief description of the methods are introduced.","","978-1-7281-3165-8","10.1109/USBEREIT48449.2020.9117786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9117786","Information security;computer systems modeling;artificial intelligence;multi-agent models;agent-based models","Self-organizing feature maps;Analytical models;Computational modeling;Biological system modeling;Information security;Systems modeling;Object recognition","","","","5","IEEE","16 Jun 2020","","","IEEE","IEEE Conferences"
"SentimentGPT: Leveraging GPT for Advancing Sentiment Analysis","K. Kheiri; H. Karimi","Utah State University, Logan, UT, USA; Utah State University, Logan, UT, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","7051","7060","This study thoroughly examines various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other current, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, with more than 22% in the F1-score compared to the state-of-the-art. Further, the paper sheds light on common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores the enhanced capabilities of the GPT models to handle these complexities effectively. These findings highlight the promising potential of GPT models in sentiment analysis, setting the stage for future research in this field. The code can be found at https://github.com/DSAatUSU/SentimentGPT","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825350","Sentiment Analysis;Social Media Mining;Chat-GPT;Large Language Models;Machine Learning","Sentiment analysis;Analytical models;Codes;Media;Big Data;Transformers;Data models;Complexity theory;Prompt engineering","","9","","45","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"RAG Beyond Text: Enhancing Image Retrieval in RAG Systems","S. Bag; A. Gupta; R. Kaushik; C. Jain","Data Science and Insights, Genpact India Private Limited, Bengaluru, India; Data Science and Insights, Genpact India Private Limited, Bengaluru, India; Data Science and Insights, Genpact India Private Limited, Bengaluru, India; Data Science and Insights, Genpact India Private Limited, Bengaluru, India","2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","8 Oct 2024","2024","","","1","6","This paper presents a novel methodology for the extraction and retrieval of images in RAG (Retrieval Augmented Generation) powered Question Answering Conversational Systems that circumvents the limitations of Optical Character Recognition and Large Language Model (OCR-LLM) powered traditional image retrieval approaches. We are leveraging the positional information of images in a vast array of multi-modal (text/image) documents for ingesting image information alongside text, followed by advanced retrieval and prompt engineering techniques to develop an RAG system that maintains the integrity of textual and visual data correlation in responses to queries pertaining to both text and images in QnA solutions and is adept at retrieving both OCR-compatible and OCR-incompatible images. We have successfully incorporated this approach over a variety of multimodal documents ranging from research papers, application documentations, surveys to guides and manuals containing text, images and even tables with images and managed to achieve SoTA (State of The Art) performance over simple to complex queries asked on the mentioned documents. Furthermore, our approach performed explicitly better in cases where Vision Models like GPT-4 Vision fails to accurately retrieve images which are OCR incompatible and pertains to highly customized scientific devices or diagrams and in cases where the image's visual representation is not semantically aligned with textual information but is important to be retrieved for completeness in the response.","","979-8-3503-9591-4","10.1109/ICECET61485.2024.10698598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698598","Document Question Answering;GPT4;Large Language Models;Langchain;Mu-RAG (Multi-modal Retrieval Augmented Generation);RAG (Retrieval Augmented Generation)","Performance evaluation;Surveys;Visualization;Correlation;Image retrieval;Optical character recognition;Metadata;Question answering (information retrieval);Prompt engineering;Testing","","4","","10","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Building Bridges of Knowledge: Innovating Education with Automated Crossword Generation","K. Zeinalipour; T. Iaquinta; G. Angelini; L. Rigutini; M. Maggini; M. Gori","DIISM, University of Siena, Siena, Italy; DIISM, University of Siena, Siena, Italy; R&D, expert.ai, Modena, Italy; R&D, expert.ai, Modena, Italy; DIISM, University of Siena, Siena, Italy; DIISM, University of Siena, Siena, Italy",2023 International Conference on Machine Learning and Applications (ICMLA),"19 Mar 2024","2023","","","1228","1236","Educational crossword puzzles enhance critical thinking, vocabulary development, and concept reinforcement. They encourage independent learning, improve memorization, and foster problem-solving skills. With their multisensory approach, crossword puzzles offer a valuable educational experience. With the help of AI technology, creating high-quality, diverse crosswords is now easier, promoting enjoyable and effective learning experiences. In this endeavor, we harnessed the power of multiple language models, including GPT3, GPT2-XL, and BERT, to construct a comprehensive system that generates and verifies crossword clues. Our ultimate aim is to employ this system in the creation of educational crosswords. To achieve this, we compiled an extensive dataset consisting of over seven million clue-answer pairs spanning the years 1913 to mid-2021. By leveraging this dataset, we aimed to generate original yet challenging clues that engage solvers. Our generator underwent fine-tuning using this large collection of clues and corresponding answers, covering a wide range of themes. Additionally, we implemented a few/zero-shot learning techniques, such as prompt engineering, to generate clues based on given texts. To guarantee the quality of the generated clue-answer pairs, we utilized diverse classifiers, by fine-tuning pre-existing language models on a labeled dataset and additionally, we harnessed the power of the zero-shot learning approach to validate the generated clue-answer pairs effectively. This classifier effectively filters out nonsensical or subpar pairings. The evaluation results are highly encouraging, reinforcing the efficacy of the proposed approach.","1946-0759","979-8-3503-4534-6","10.1109/ICMLA58977.2023.00185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459980","Natural Language Processing;Educational Crossword;Large Language Models;Zero-shot shot Learning;Few-Shot Learning","Vocabulary;Zero-shot learning;Education;Layout;Generators;Natural language processing;Classification algorithms","","1","","27","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"LLM-CDM: A Large Language Model Enhanced Cognitive Diagnosis for Intelligent Education","X. Chen; J. Zhang; T. Zhou; F. Zhang","College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; College of Civil Engineering and Architecture, Shandong University of Science and Technology, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China",IEEE Access,"19 Mar 2025","2025","13","","47165","47180","Cognitive diagnosis is a key component of intelligent education to assess students’ comprehension of specific knowledge concepts. Current methodologies predominantly rely on students’ historical performance records and manually annotated knowledge concepts for analysis. However, the extensive semantic information embedded in exercises, including latent knowledge concepts, has not been fully utilized. This paper presents a novel cognitive diagnosis model based on the LLAMA3-70B framework (referred to as LLM-CDM), which integrates prompt engineering with the rich semantic information inherent in exercise texts to uncover latent knowledge concepts and improve diagnostic accuracy. Specifically, this study first inputs exercise texts into a large language model and develops an innovative prompting method to facilitate deep mining of implicit knowledge concepts within these texts by the model. Following the integration of these newly extracted knowledge concepts into the existing Q matrix, this paper employs a neural network to diagnose students’ understanding of knowledge concepts while applying the monotonicity assumption to ensure the interpretability of model factors. Experimental results from an examination data set for course completion assessments demonstrate that LLM-CDM exhibits superior performance in both accuracy and explainability.","2169-3536","","10.1109/ACCESS.2025.3549309","Distinguished Teachers Training Plan Program of Shandong University of Science and Technology(grant numbers:MS20211105); National Higher Education Research Project of the Coal Industry of China(grant numbers:2021MXJG105); Education Ministry Humanities and Social Science Research Planning Fund Project of China “Personalized Learning Path Recommendation Driven by Multi-Source Educational Data and Its Quantitative Evaluation”(grant numbers:23YJAZH192); General Project of the 14th Five-Year Plan for Educational Science of Shandong Province “Research on the Generation Method of Test Resource Based on Large Language Models”(grant numbers:2023YB162); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916617","Cognitive diagnosis;large language models;exercise texts;higher education and intelligent education","Education;Large language models;Annotations;Accuracy;Semantics;Prompt engineering;Printers;Optimization;Manuals;Long short term memory","","1","","52","CCBY","7 Mar 2025","","","IEEE","IEEE Journals"
"Utilizing an Agent Based Negotiation Mechanism to Defend Against Jamming Attack in Smart Grid Power Market","Z. Alavikia; N. Mozayani; J. Shahbazi; F. Alavikia","Department of Computer Engineering, Iran University of Science and Technology, Tehran, Iran; Department of Computer Engineering, Iran University of Science and Technology, Tehran, Iran; Department of Computer Engineering, Iran University of Science and Technology, Tehran, Iran; Department of Computer Engineering, Iran University of Science and Technology, Tehran, Iran",2018 9th International Symposium on Telecommunications (IST),"7 Mar 2019","2018","","","45","52","The upcoming generation of electric grid is smart grid through which distribution and management of the grid are enhanced by fusion of advanced capabilities of both digital technology and digital communication. Nevertheless, as grid network evolves to smart grid, vulnerability to jamming attack as one of security threats is increased. Jamming is a kind of denial of service attack in communication layer of the electric grid. With regard to electricity market, Jamming means preventing remote sensors from transmitting measured data to the center of monitoring and control in order to gain illegal profit. In this paper, we consider smart grid as a multi agent system (MAS) for the purpose of securing smart grid network. To overcome jamming attack in the physical layer of communication network in electricity market, we propose utilizing a modified version of contract network protocol (CNP) as a kind of negotiation protocol among agents. Simulated results indicate that with regard to possible presence of non-trusted users in the market, applying the proposed protocol during jamming attack can lower the jammer's illegal profit and decrease his motive toward attacking the market.","","978-1-5386-8274-6","10.1109/ISTEL.2018.8660977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660977","Contract Net Protocol (CNP);Power Market;Multi Agent System (MAS);Security;Smart Grid;Trust","Jamming;Smart grids;Transmission line measurements;Electricity supply industry;Power measurement;Real-time systems","","1","","24","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"Ice-kun: A Virtual Pet on a Low Energy Display Controlled by a Large Language Model","F. Abdullah; A. Roussely; B. Dayres; T. Riehs; X. Li; R. Makino; K. Matsumura; H. Noma; H. Takada; R. Thawonmas","Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Graduate School of Engineering, ENSEIRB-MATMECA, Bordeaux, France; Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan",2025 IEEE International Conference on Consumer Electronics (ICCE),"26 Mar 2025","2025","","","1","6","This paper presents “Ice-kun,” a virtual pet controlled by a large language model (LLM) and displayed on addressable light-emitting diode (LED) boards. Unlike virtual pets with limited interactions, Ice-kun leverages an LLM to interpret natural language input and generate countless playful animations. Ice-kun is configured into several parts to generate the animations. The LLM is tasked with generating animations for these parts. Ideally, as a real-time control agent for virtual pets, an LLM is expected to perform quickly and respond in the correct format. To achieve this, two prompting strategies and six prompt engineering techniques are compared. Fast response time is achieved through a prompting strategy that uses multiple shorter prompts, each corresponding to a different part and executed asynchronously in parallel. To ensure the LLM responds with high accuracy in the correct format, few-shot prompting and zero-shot CoT prompting are incorporated into the prompts. Code, experiment results, and demo videos are available in our repository https://github.com/anonymouspenguin27/icekun","2158-4001","979-8-3315-2116-5","10.1109/ICCE63647.2025.10930195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930195","large language models;procedural animation;virtual pet","Codes;Large language models;Natural languages;Animation;Light emitting diodes;Real-time systems;Time factors;Prompt engineering;Consumer electronics;Videos","","","","22","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Natural Language Explanation for Autonomous Navigation","L. Trigg; B. Morgan; A. Stringer; L. Schley; D. F. Hougen","School of Computer Science, University of Oklahoma, Norman, Oklahoma, USA; School of Computer Science, University of Oklahoma, Norman, Oklahoma, USA; 76 Software Engineering Group, United States Air Force, Oklahoma City, Oklahoma, USA; Oklahoma Aerospace Defense Innovation Institute, University of Oklahoma, Norman, Oklahoma, USA; School of Computer Science, University of Oklahoma, Norman, Oklahoma, USA",2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC),"15 Nov 2024","2024","","","1","9","Navigating an aircraft is a complicated problem as it requires analyzing extensive operational data to identify an optimal and safe path. Recently, many studies have employed deep reinforcement learning (DRL) to address the navigation problem, and it has been demonstrated to be a powerful tool for addressing these kinds of problems. Despite being a promising tool, the opaque nature of the reasoning mechanisms of DRL methods make them difficult to troubleshoot performance issues and fosters mistrust, thereby constraining their application in critical scenarios. This deficiency necessitates the need for the development of explanation methods aimed at clarifying the reasoning processes of DRL models for users. Additionally, governments around the world are beginning to require the inclusion of such explanation methods in autonomous systems used for safety critical applications. In this paper, we propose NavChat, an explanation framework designed to justify the trajectory suggested by a trained DRL model for an efficient and safe path in an unknown environment. NavChat is a post-hoc approach that leverages SHapley Additive exPlanations (SHAP), a Large Language Model (LLM), and prompt engineering to generate natural language explanations. Using SHAP, we identify the most important features that affect the agent's decision. The LLM provides natural language explanations which facilitate faster comprehension and more lucidity for non-expert users in comparison with visual explanations. We compare the explanations provided by NavChat for various prompts and then evaluate the accuracy and consistency of its explanations via a user study. This method facilitates understanding of the decisions made by the automated navigation model and communicates the reasoning process.","2155-7209","979-8-3503-4961-0","10.1109/DASC62030.2024.10749360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749360","Explainable AI;Deep Reinforcement Learning;UAV;SHAP;Large Language Models","Visualization;Large language models;Natural languages;Government;Deep reinforcement learning;Cognition;Aircraft navigation;Trajectory;Safety;Prompt engineering","","","","18","IEEE","15 Nov 2024","","","IEEE","IEEE Conferences"
"Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?","T. Zhang; B. Xu; F. Thung; S. A. Haryono; D. Lo; L. Jiang","School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University",2020 IEEE International Conference on Software Maintenance and Evolution (ICSME),"2 Nov 2020","2020","","","70","80","Extensive research has been conducted on sentiment analysis for software engineering (SA4SE). Researchers have invested much effort in developing customized tools (e.g., SentiStrength-SE, SentiCR) to classify the sentiment polarity for Software Engineering (SE) specific contents (e.g., discussions in Stack Overflow and code review comments). Even so, there is still much room for improvement. Recently, pre-trained Transformer-based models (e.g., BERT, XLNet) have brought considerable breakthroughs in the field of natural language processing (NLP). In this work, we conducted a systematic evaluation of five existing SA4SE tools and variants of four state-of-the-art pre-trained Transformer-based models on six SE datasets. Our work is the first to fine-tune pre-trained Transformer-based models for the SA4SE task. Empirically, across all six datasets, our fine-tuned pre-trained Transformer-based models outperform the existing SA4SE tools by 6.5-35.6% in terms of macro/micro-averaged F1 scores.","2576-3148","978-1-7281-5619-4","10.1109/ICSME46990.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240704","Sentiment Analysis;Software Mining;Natural Language Processing;Pre-trained Models","Sentiment analysis;Analytical models;Software maintenance;Systematics;Tools;Task analysis;Software engineering","","86","","44","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
