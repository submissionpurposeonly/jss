"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"SMART: Serverless Module Analysis and Recognition Technique for Managed Applications","A. Ashkenazi; E. Grolman; A. Elyashar; D. Mimran; O. Brodt; Y. Elovici; A. Shabtai","Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; Cyber Labs@BGU, Ben-Gurion University of the Negev, Israel; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel","2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing (CCGrid)","8 Oct 2024","2024","","","442","452","Serverless Function-as-a-Service (FaaS) environments enable developers to build and run cloud applications without the need to manage the underlying servers and computing infrastructure, allowing them to focus on implementing the application logic. Such environments contain numerous functions and dynamic resources, e.g., APIs and databases, making it challenging to gain insight and context of internal events i.e., recognize modules. Module in a serverless application is a set of functions and resources, that represents a functional unit that shares logical context. This paper presents SMART, a method for automatic analysis and recognition of modules for managed serverless applications. The proposed method creates an event-based graph by analyzing the standard serverless logs that document events involving the application’s functions and resources and utilizes well-known community detection algorithms (such as Louvain), with graph centrality metrics (such as degree centrality) to recognize the modules. SMART enables high-level visibility of the application’s structure and logical context which can facilitate security analysis and contribute to improved decision-making of incident response handlers, who typically do not have direct access to the application’s design and code, which can lead to challenges in fully understanding the system’s intricacies. We focused on the popular Amazon Web Services (AWS) Lambda serverless computing platform and evaluated the proposed method on three different demo applications (Airline Booking, VOD, and E-commerce). We compared SMART’s performance to four overlapping community detection algorithms and showed that it outperformed them in the task of module recognition, with a maximum improvement of 61% on the omega index metric compared to the Speaker-Listener Label Propagation algorithm. In addition, we demonstrate that the use of large language models (LLMs) with the knowledge gained by SMART can enrich security analysis insights.","2993-2114","979-8-3503-9566-2","10.1109/CCGrid59990.2024.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10701367","Serverless computing;Function-as-a-Service;Security analysis;Incident response;Serverless activity logs;Serverless application architecture","Measurement;Web services;Serverless computing;Computer architecture;Security;Indexes;Electronic commerce;Detection algorithms;Standards;Airline industry","","2","","30","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Dark Watchdog: A Novel RAG-Driven System for Real-Time Detection and Analysis of Data Leaks on Dark Web Forums","S. -L. Hung; C. -K. Chen; K. Furumoto; T. Takahashi; H. -M. Sun","Institue of Information Security, National Tsing Hua University, Hsinchu, Taiwan; CyCraft Technology CyCraft Technology, Taiwan; Cybersecurity Research Institute, National Institute of Information and Communications Technology, Tokyo, Japan; Cybersecurity Research Institute, National Institute of Information and Communications Technology, Tokyo, Japan; Departmant of Computer Science, National Tsing Hua University, Hsinchu, Taiwan",2024 Annual Computer Security Applications Conference Workshops (ACSAC Workshops),"18 Mar 2025","2024","","","11","19","Personal data breaches have become increasingly common, making the dark web a key marketplace for trading stolen information, often without the immediate awareness of affected organizations. To address this challenge, we introduce Dark Watchdog, a novel system that actively monitors dark web forums and employs a specially fine-tuned BERT classification model to categorize transaction posts into five distinct types of breaches with high accuracy. Dark Watchdog uniquely integrates retrieval-augmented generation (RAG) to efficiently vectorize and analyze dark web data, allowing cyber security analysts to access the latest intelligence on data leaks while preserving privacy by minimizing data exposure to large language models (LLMs). This approach not only improves detection precision but also optimizes computational resources by reducing token usage. Dark Watchdog offers an innovative and practical solution for real-time dark web monitoring, enabling timely insights into ongoing data leak incidents and enhancing the overall effectiveness of cyber security efforts.","","979-8-3315-3281-9","10.1109/ACSACW65225.2024.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917873","Dark web;cyber security;Tor;BERT;Classification;Retrieval-augmented generation;RAG;Large language model;LLM;Privacy","Data privacy;Privacy;Dark Web;Large language models;Conferences;Retrieval augmented generation;Organizations;Real-time systems;Computer crime;Monitoring","","","","19","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"LLMGraph: Label-Free Detection Against APTs in Edge Networks Via LLM and GCN","T. Yu; G. Liu; C. Wang; Y. Yang","Key Laboratory of Intelligent Sensing System and Security (Ministry of Education), School of Artificial Intelligence, Hubei University, Wuhan, China; Hubei Key Laboratory of Internet of Intelligence, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Internet of Intelligence, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Intelligent Sensing System and Security (Ministry of Education), School of Artificial Intelligence, Hubei University, Wuhan, China",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","16","In the growing trend of remote working, millions of edge networks (e.g., homes or branch offices) are increasingly threatened by Advanced Persistent Threats (APTs), because of the weakened segmentation between business and non-business devices in remote working environment. Despite the fact that numerous APT detection mechanisms have been proposed, all of them are struggling to handle the complex structure, the massive scale and the diverse topology of edge networks. Can recent machine-learning advances tackle these APT detection pain points in edge networks? The GNNs (Graph Neural Networks) seems to be suited to capture the complex structure, but its adjacency matrix fails to capture key network flow context. Additionally, GNNs require extensive manual labeling, which is not scalable. LLMs (Large Language Models) have the potential to provide automatic labeling for the GNNs, but they lack the supplementary security context needed for effective labeling. To address these gaps, we present LLMGraph, which incorporates extended GCNs (Graph Convolutional Networks) and domain-specific RAG (Retrieval-Augmented Generation) pipeline to achieve label-free detection against APTs in edge networks. LLMGraph's extended GCNs model can capture network flow context and direction. LLMGraph's domain-specific RAG pipeline can supplement key security contexts, including device vulnerability and network flow, for effective labeling. Additionally, LLMGraph provides an LLM aggregator to augment and merge the diverse topology of the edge networks. Compared to the state-of-the-art mechanisms, LLMGraph proves effective and scalable, improving the F1-score by at least 46.9%, and the training time for 1 million edge networks is within 1000 s.","1941-0018","","10.1109/TDSC.2025.3596092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113355","APT Detection;GCN;LLM;network security","Image edge detection;Labeling;Training;Security;Business;Topology;Retrieval augmented generation;Network topology;Cameras;Pain","","","","","IEEE","5 Aug 2025","","","IEEE","IEEE Early Access Articles"
"LLM-Based Automated Mitigation and Assurance Case Generation Against Threats to AI Systems","Y. Fujiwara; T. Tuchida; R. Miyata; H. Washizaki; N. Ubayashi","Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","906","911","Artificial intelligence (AI)-integrated systems face unique threats, vulnerabilities, and risks compared to conventional systems. Consequently, implementing security measures for AI systems in organizations is paramount. However, the security database, Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS) has deficiencies in addressing and mitigating these concerns. Furthermore, while the application of large language models (LLMs) presents promising prospects in this field, thorough evaluations of their effectiveness have yet to be performed. In this study, we propose an LLM-based fully automated method for generating mitigations against AI systems threats and validating these mitigations using assurance cases. Furthermore, it presents innovative automated techniques for generating assurance cases, encompassing the dynamic collection of evidence, validation of effectiveness through these data, and solution nodes structured based on Toulmin's theory. We validated it using the method on 46 entries in ATLAS, producing mitigations and their corresponding assurance cases. To explore the potential superiority of the proposed method, we evaluated the mitigations based on information theory and assessed the assurance cases based on their completeness. The results indicate that the proposed method has the potential to generate more risk-specific mitigations, while the completeness of the produced assurance cases improved by up to 88.4% through each step of the proposed method.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050665","AI;LLM;assurance case;security","Databases;Prevention and mitigation;Large language models;Organizations;Security;Reliability;Artificial intelligence;Faces;Information theory","","","","15","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Toward Trustworthy Governance of AI-Generated Content (AIGC): A Blockchain-Driven Regulatory Framework for Secure Digital Ecosystems","F. Yang; M. Z. Abedin; Y. Qiao; L. Ye","School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; Department of Accounting and Finance, School of Management, Swansea University, Swansea, U.K.; School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; Xi'an Institute of Electromechanical Information Technology, Xi'an, China",IEEE Transactions on Engineering Management,"17 Oct 2024","2024","71","","14945","14962","Digital platforms are experiencing a growing presence of generative artificial intelligence (AI) content, raising concerns due to the prevalence of misinformation that disrupts market integrity. Consequently, the development of effective regulatory measures for overseeing generative AI content becomes imperative. This necessitates the establishment of mechanisms to detect and filter out inaccuracies, ensuring compliance with regulatory requirements. In addition, collaboration among experts, regulators, and AI developers is essential to encourage responsible AI deployment on digital platforms. Successful governance hinges on principles of transparency, accountability, and proactive risk management to navigate the evolving generative AI on digital platforms. Therefore, in order to address the security issues currently faced by artificial intelligence generated content (AIGC), this article first proposes a method of efficient cache mechanism for AIGC content. The secure method of determining the identity of AIGC content owners is proposed based on blockchain technology. Subsequently, it suggests mechanisms for access control and data encryption for generated content within a blockchain environment. Finally, it presents an efficient data supervision mechanism tailored to the AIGC environment. The methods outlined in this article aim to enhance security from three perspectives: protection of content creators' identities, safeguarding data security, and ensuring effective data supervision within the AIGC framework. The experimental results further confirm that our proposed method not only ensures the security of the AIGC framework but also provides an efficient data analysis and supervision solution for digital platforms.","1558-0040","","10.1109/TEM.2024.3472292","Natural Science Basic Research Program of Shaanxi(grant numbers:2023-JC-YB-490); Research Fund of Guangxi Key Lab of Multisource Information Mining & Security(grant numbers:MIMS24-06); Fundamental Research Funds for the Central Universities, JLU(grant numbers:93K172024K12); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703091","Artificial intelligence generated content (AIGC) regulation;blockchain governance;consensus mechanism;data security;data traceability","Security;Generative AI;Artificial intelligence;Regulation;Data privacy;Blockchains;Engineering management;Data security;Data models;Reliability","","8","","38","IEEE","3 Oct 2024","","","IEEE","IEEE Journals"
"Advancing Reversible Data Hiding using GAN-Enhanced Steganography and Cryptography Synergy","M. K. S; V. K. D; M. G; A. M. C; A. M; V. T","Biomedical Engineering, Vinayaka Mission's Kirupananda Variyar Engineering College, Vinayaka Mission's Research Foundation (Deemed to be University), Salem, Tamil Nadu, India; Biomedical Engineering, Vinayaka Mission's Kirupananda Variyar Engineering College, Vinayaka Mission's Research Foundation (Deemed to be University), Salem, Tamil Nadu, India; Biomedical Engineering, Vinayaka Mission's Kirupananda Variyar Engineering College, Vinayaka Mission's Research Foundation (Deemed to be University), Salem, Tamil Nadu, India; Biomedical Engineering, Vinayaka Mission's Kirupananda Variyar Engineering College, Vinayaka Mission's Research Foundation (Deemed to be University), Salem, Tamil Nadu, India; Computer Science and Engineering, SRM Institute of Science and Technology Ramapuram, Chennai, Tamil Nadu, India; Biomedical Engineering, Vinayaka Mission's Kirupananda Variyar Engineering College, Vinayaka Mission's Research Foundation (Deemed to be University), Salem, Tamil Nadu, India",2024 4th International Conference on Sustainable Expert Systems (ICSES),"3 Dec 2024","2024","","","371","375","In today's world, data security and privacy remain as significant challenges. Reversible data hiding (RDH) is a technique used to embed data into cover media in a manner that allows both the embedded data and the original media to be recovered. Unlike traditional data hiding techniques, which permanently alter the cover media, RDH ensures that the original content can be restored exactly as it was before embedding. The concept of RDH relies on the fact that the embedded data does not cause irreversible distortion or permanent damage to the cover media. In addition to this feature, it is crucial to enhance the data security of hidden information. This paper introduces a methodology that combines Generative Adversarial Networks (GANs) with steganography and cryptography techniques to advance reversible data hiding and enhance data security. By integrating Generative AI -enhanced steganography, the paper aims to embed data within cover images in a reversible manner, ensuring that the original media can be recovered with improved image quality compared to the original image. Furthermore, the integration of cryptography techniques ensures the integrity and confidentiality of the concealed data, making it resistant to unauthorized access and detection. The synergy between Generative AI -driven steganography and cryptography in RDH helps sustain key elements of reversible data hiding, including reversibility, embedding capacity, and data security. Enhancing performance can be applied in various fields such as medical imaging, forensics, intellectual property protection, secure communications, and military applications.","","979-8-3315-4036-4","10.1109/ICSES63445.2024.10763116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763116","Reversible Data Hiding (RDH);Generative Artificial Intelligence;Generative Adversarial Networks (GAN);Steganography;Data Security","Military communication;Steganography;Visualization;Generative AI;Intellectual property;Media;Generative adversarial networks;Image restoration;Protection;Immune system","","","","20","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"A New Intrusion Detection Model Transformer_KAN","Y. Ji; L. Guo; T. Hu; J. Wei","School of Communication and Artificial Intelligence, School of Integrated Circuits, Nanjing Institute of Technology, Nanjing, China; School of Communication and Artificial Intelligence, School of Integrated Circuits, Nanjing Institute of Technology, Nanjing, China; School of Communication and Artificial Intelligence, School of Integrated Circuits, Nanjing Institute of Technology, Nanjing, China; School of Communication and Artificial Intelligence, School of Integrated Circuits, Nanjing Institute of Technology, Nanjing, China",2024 7th International Conference on Data Science and Information Technology (DSIT),"18 Feb 2025","2024","","","1","5","With the rapid development of network technology, the type and scale of network cyberattacks are also evolving, and the network security problem is becoming increasingly serious. In this paper, we propose a new intrusion detection model, Transformer_KAN, which combines the advantages of the KAN and Transformer models to efficiently handle large-scale and multi-dimensional network traffic data. In this model, the univariate spline function of the KAN model is used instead of the linear weights in the traditional MLP, which fully uses of the nonlinear correlation between features and improves the feature representation capability. In addition, with the powerful sequence modeling capability of the Transformer model, the potential dependencies in the time series are effectively captured to improve the system’s ability to identify complex attack patterns. To verify the performance of the new model, we tested it on the CIC-IDS2017 dataset. Results show that the Transformer_KAN model achieves significant improvement in the accuracy rate, loss value, and other metrics compared with the traditional machine learning and a single deep learning model, and especially performs excellently in detecting a few classes of attack samples. The proposed model provides an efficient and widely applicable solution for the development of IDS.","","979-8-3503-8409-3","10.1109/DSIT61374.2024.10881441","Nanjing Institute of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881441","intrusion detection model;deep learning;KAN;Transformer;network security","Deep learning;Adaptation models;Accuracy;Time series analysis;Telecommunication traffic;Network security;Transformers;Data models;Reliability;Splines (mathematics)","","","","12","IEEE","18 Feb 2025","","","IEEE","IEEE Conferences"
"A Mask Optimization Method for Automated Vulnerability Repair","J. Li; Y. Lei; F. Qin","University of Electronic Science and Technology of China, Chengdu, China; Chengdu Development Center of Science and Technology, China Academy of Engineering Physics, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China",2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT),"3 Jun 2025","2025","","","1784","1787","In recent years, automated vulnerability repair methods, particularly those based on Transformer models, have been increasingly applied to address software security challenges. These methods often employ masking techniques to focus on attack-prone code areas. Inspired by Vision Transformers in object detection, this paper introduces a mask optimization solution. It integrates masks into the decoder’s cross-attention mechanism, allowing the model to focus on key vulnerability segments. Additionally, the mask is applied to the encoder’s self-attention, enhancing feature representation. The proposed method demonstrates improvements over approaches such as VulRepair and VQM.","","979-8-3315-4285-6","10.1109/ISCAIT64916.2025.11010430","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11010430","automated vulnerability repair;software security;transformer","Codes;Optimization methods;Object detection;Maintenance engineering;Transformers;Software;Graph neural networks;Decoding;Security;Information technology","","","","12","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Advancing Deep-Learning in NLP: From Network Logs to Text Classification","L. R. Ónozó; B. Gyires-Tóth","Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary",NOMS 2025-2025 IEEE Network Operations and Management Symposium,"15 Jul 2025","2025","","","1","4","This PhD Symposium Paper explores deep-learning based sequential modeling methods for textual data by investigating two applications: network security log analysis and financial forecasting. The network log analysis was performed using a hybrid approach that combines traditional pattern matching and transformer architectures. This method successfully identified common log patterns and achieved high accuracy in classifying new log types. For economic forecasting, economic news articles and retail data are used; transformer models demonstrated superior performance in sentiment analysis and item classification. Sentiment indices showed predictive power during economic downturns. These findings suggest that the integration of novel methods with traditional approaches can lead to improved models and robust applications that bridge qualitative and quantitative data.","2374-9709","979-8-3315-3163-8","10.1109/NOMS57970.2025.11073620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073620","NLP;Deep Learning;Machine learning;Artifi-cial Intelligence;Network Security;Log Analysis;Macroeconomic Forecasting;LLM","Analytical models;Sentiment analysis;Biological system modeling;Text categorization;Predictive models;Network security;Transformers;Data models;Macroeconomics;Pattern matching","","","","17","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"A Survey of Human-Object Interaction Detection With Deep Learning","G. Han; J. Zhao; L. Zhang; F. Deng","Department of Automation, Beijing Institute of Technology, Beijing, China; National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Beijing Institute of Technology, Beijing, China; Department of Automation, Beijing Institute of Technology, Beijing, China",IEEE Transactions on Emerging Topics in Computational Intelligence,"23 Jan 2025","2025","9","1","3","26","Human-object interaction (HOI) detection has attracted significant attention due to its wide applications, including human-robot interactions, security monitoring, automatic sports commentary, etc. HOI detection aims to detect humans, objects, and their interactions in a given image or video, so it needs a higher-level semantic understanding of the image than regular object recognition or detection tasks. It is also more challenging technically because of some unique difficulties, such as multi-object interactions, long-tail distribution of interaction categories, etc. Currently, deep learning methods have achieved great performance in HOI detection, but there are few reviews describing the recent advance of deep learning-based HOI detection. Moreover, the current stage-based category of HOI detection methods is causing confusion in community discussion and beginner learning. To fill this gap, this paper summarizes, categorizes, and compares methods using deep learning for HOI detection over the last nine years. Firstly, we summarize the pipeline of HOI detection methods. Then, we divide existing methods into three categories (two-stage, one-stage, and transformer-based), distinguish them in formulas and schematics, and qualitatively compare their advantages and disadvantages. After that, we review each category of methods in detail, focusing on HOI detection methods for images. Moreover, we explore the development process of using foundation models for HOI detection. We also quantitatively compare the performance of existing methods on public HOI datasets. At last, we point out the future research direction of HOI detection.","2471-285X","","10.1109/TETCI.2024.3518613","Key Program of National Natural Science Foundation of China(grant numbers:61933002); National Science Fund for Distinguished Young Scholars of China(grant numbers:62025301); National Natural Science Foundation of China Basic Science Center Program(grant numbers:62088101); China Postdoctoral Science Foundation(grant numbers:BX20220186,2023M741965); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816567","Deep learning;visual relationship detection;human-object interaction;foundation models;attention mechanism;GNN;transformer","Transformers;Feature extraction;Reviews;Foundation models;Visualization;Object recognition;Pipelines;Surveys;Semantics;Heavily-tailed distribution","","","","210","IEEE","26 Dec 2024","","","IEEE","IEEE Journals"
"Trustworthy AI-Generative Content for Intelligent Network Service: Robustness, Security, and Fairness","S. Li; X. Lin; Y. Liu; X. Chen; J. Li",NA; NA; NA; NA; NA,IEEE Communications Magazine,"","2025","PP","99","1","7","AI-generated content (AIGC) models, represented by large language models (LLM), have revolutionized content creation. High-speed next-generation communication technology is an ideal platform for providing powerful AIGC network services. At the same time, advanced AIGC techniques can also make future network services more intelligent, especially various online content generation services. However, the significant untrustworthiness concerns of current AIGC models, such as robustness, security, and fairness, greatly affect the credibility of intelligent network services, especially in ensuring secure AIGC services. This article proposes TrustGAIN, a trustworthy AIGC framework that incorporates robust, secure, and fair network services. We first discuss the robustness to adversarial attacks faced by AIGC models in network systems and the corresponding protection issues. Subsequently, we emphasize the importance of avoiding unsafe and illegal services and ensuring the fairness of the AIGC network services. Then, as a case study, we propose a novel sentiment analysis-based detection method to guide the robust detection of unsafe content in network services. We conduct our experiments on fake news, malicious code, and unsafe review datasets to represent LLM application scenarios. Our results indicate that TrustGAIN is an exploration of future networks that can support trustworthy AIGC network services.","1558-1896","","10.1109/MCOM.004.2400646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11020580","","Security;Robustness;Intelligent networks;Data models;Solid modeling;Artificial intelligence;Metaverse;Biological system modeling;Training;Reliability","","1","","","IEEE","2 Jun 2025","","","IEEE","IEEE Early Access Articles"
"4 Security, Trust, and Integrity","C. Vulkán; P. Szilágyi; N. Sprecher",NA; NA; NA,Revolutionizing Network Management: The Journey to AI-native Autonomy,"","2025","","","73","94","End-to-end automation in telecommunications is a challenging yet critical industry objective, representing collective vision for technology evolution in the coming years. Key enablers for achieving this include the expression and the translation of high-level business goals (e.g. intents) into actionable and impactful operations, the deployment and interaction between closed loops, real-time data management, the extraction of meaningful insights from data, ML-driven analytics and intelligence, and seamless orchestration and resource control. Automation processes must be transparent, reliable and robust. This book provides a comprehensive insight into the automation journey. It explores the vision of zero-touch, AI-native network and service autonomy, examining the key trends, catalysts, and technological advancements shaping this paradigm shift. It provides a comprehensive analysis of critical aspects such as data and knowledge management, security and trust, native AI/ML management, intent-based automation, and human-to-machine as well as machine-to-machine interfaces. By delving into advanced concepts such as data-driven, AI-powered analytics, semantic and decision models, network digital twins, and the role of natural language processing and large language models, the book bridges theory and practical application. It highlights how these innovations leverage and maximize intent-driven and closed-loop automation, enabling seamless, intelligent, and autonomous networks. Additionally, it identifies key areas where further research is needed to address existing gaps and unlock the full potential of these technologies. Ultimately, this book provides valuable insights, outlining the transformative potential of zero-touch, AI-native networks and paving the way for seamless, intelligent, and autonomous management of networks and services, driving innovation, efficiency, and new opportunities in the evolving digital landscape.","","9788770228985","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11123667.pdf&bkn=11123653&pdfType=chapter","","","","","","","","12 Aug 2025","","","River Publishers","River eBook Chapters"
"Re(gEx|DoS)Eval: Evaluating Generated Regular Expressions and their Proneness to DoS Attacks","M. L. Siddiq; J. Zhang; L. Roney; J. C. S. Santos","University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA",2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),"29 Oct 2024","2024","","","52","56","With the recent advances of code generation techniques based on Large Language Models (LLMs), developers are using them for a vast range of tasks, including regex generation. Despite the efforts to generate regexes from natural language, there is no benchmark for LLMs with real-world data and robust test sets. Moreover, a regex can be prone to Denial of Service (DoS) attacks due to catastrophic backtracking. Hence, we need a systematic evaluation process to evaluate the correctness and security of the regexes generated by the language models. In this paper, we describe RE(GEx|DoS)EvAL, a framework that includes a dataset of 762 regex descriptions (prompts) from real users, refined prompts with examples, and a robust set of tests. We introduce the pass@k and vulnerable@k metrics to evaluate the generated regexes based on the functional correctness and proneness of ReDoS attacks. Moreover, we demonstrate the RE(GEx|DoS)EvAL with three LLMs (T5, Phi, and GPT-3), and describe the future plans to extend this framework.","2832-7632","979-8-4007-0500-7","10.1145/3639476.3639757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10727146","Regex Generation;ReDoS;DoS Attack;Evaluation;Dataset","Measurement;Backtracking;Systematics;Codes;Large language models;Natural languages;Benchmark testing;Security;Software engineering","","1","","38","","29 Oct 2024","","","IEEE","IEEE Conferences"
"LLM for Test Script Generation and Migration: Challenges, Capabilities, and Opportunities","S. Yu; C. Fang; Y. Ling; C. Wu; Z. Chen","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","25 Dec 2023","2023","","","206","217","This paper investigates the application of large language models (LLM) in the domain of mobile application test script generation. Test script generation is a vital component of software testing, enabling efficient and reliable automation of repetitive test tasks. However, existing generation approaches often encounter limitations, such as difficulties in accurately capturing and reproducing test scripts across diverse devices, platforms, and applications. These challenges arise due to differences in screen sizes, input modalities, platform behaviors, API inconsistencies, and application architectures. Overcoming these limitations is crucial for achieving robust and comprehensive test automation.By leveraging the capabilities of LLMs, we aim to address these challenges and explore its potential as a versatile tool for test automation. We investigate how well LLMs can adapt to diverse devices and systems while accurately capturing and generating test scripts. Additionally, we evaluate its cross-platform generation capabilities by assessing its ability to handle operating system variations and platform-specific behaviors. Furthermore, we explore the application of LLMs in cross-app migration, where it generates test scripts across different applications and software environments based on existing scripts.Throughout the investigation, we analyze its adaptability to various user interfaces, app architectures, and interaction patterns, ensuring accurate script generation and compatibility. The findings of this research contribute to the understanding of LLMs’ capabilities in test automation. Ultimately, this research aims to enhance software testing practices, empowering app developers to achieve higher levels of software quality and development efficiency.","2693-9177","979-8-3503-1958-3","10.1109/QRS60937.2023.00029","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366647","Large Language Model;ChatGPT;Mobile App Testing;Test Generation;Test Migration","Software testing;Automation;Software quality;User interfaces;Mobile applications;Software reliability;Behavioral sciences","","25","","67","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Efficient Agent Based Trust Threshold Model for Healthcare Cloud Applications","S. Rajasingham; U. S. Premarathne","Department of Electrical and Computer Department, Open University of Sri Lanka, Nawala, Sri Lanka; Department of Electrical and Computer Department, Open University of Sri Lanka, Nawala, Sri Lanka",2018 IEEE International Conference on Information and Automation for Sustainability (ICIAfS),"28 Nov 2019","2018","","","1","6","The field of agent technology and cloud computing have procured a new discipline called the agent-based cloud computing which provides the application of agent based techniques to cloud computing for further development of resource management, service management, service discovery and security. The emergence and exponential rise in the cloud computing opens up an array of trust and security concerns with regard to this pervasive technology. MAS technology is a different way of approaching the distributed system paradigm where multiple agents contribute to resolving tasks of interest cooperating with each other in a decentralized approach. This paper proposes an agent based trust threshold model that is efficient and secure in integrating and distributing Electronic Health Records (EHR) to the respective user. In addition, we introduce a novel trust model which is dynamically adaptable over time such that the agents can accurately classify users into maximum trust, average trust, minimum trust and malicious/quarantined. The results give a pronounced indication of the importance of considering both the parameters such as the action, Oa and frequency of the transactions of the user, Υ, in order to accurately classify the respective users to establish a secure foundation for the system to run smoothly.","2151-1810","978-1-5386-9418-3","10.1109/ICIAFS.2018.8913357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913357","MAS;cloud;agents;Electronic Health Records;trust","Cloud computing;Security;Computational modeling;Monitoring;Resource management;Task analysis;Medical services","","1","","21","IEEE","28 Nov 2019","","","IEEE","IEEE Conferences"
"A 2-stage optimisation approach to ensure security of supply in rural cellular energy structures with solid biomass-based (hybrid) systems","L. Richter; V. Lenz; M. Dotzauer; J. Seifert",NA; NA; NA; NA,ETG Congress 2023,"4 Jul 2023","2023","","","1","7","The aspect of resilience and security of supply of the energy system is increasingly becoming the focus of societal interest. The decentralised use of solid biomass in combination with heat pumps and heat storage in hybrid systems could therefore play an important role. This can be particularly relevant in rural areas where the possibility of a district heating network is not available. Accordingly, it is even more crucial to manage this growing number of decentralised energy assets in order to avoid problematic grid conditions. Cellular energy systems are discussed as a method to organise the high com-plexity of numerous within itself complex systems in the grid from the bottom up. The modelling and mathematical optimisation of such cellular structured systems requires a detailed knowledge of the internal processes and thus a highly sophisticated implementation. A direct feedback between optimal operation and optimal planning is particularly important here, as the optima are interdependent. For this, the concept of a 2-stage optimisation approach of the local aspect is presented in this paper, which additionally considers the autonomous and subsidiary properties of the cellular approach within multi-agent systems. This leads to a value-optimised combination of the cellular approach and solid biomass-based (hybrid) systems with the goal of maximising the impact of the limited potential of biogenic residues.","","978-3-8007-6108-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172994","","","","","","","","4 Jul 2023","","","VDE","VDE Conferences"
"An Evolutionary Large Language Model for Hallucination Mitigation","A. Boulesnane; A. Souilah","BIOSTIM Laboratory, Faculty of Medicine, Salah Boubnider University, Constantine, Algeria; Department of IFA, Faculty of NTIC, Abdelhamid Mehri University, Constantine, Algeria","2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)","28 Jan 2025","2024","","","1","8","The emergence of LLMs, like ChatGPT and Gemini, has marked the modern era of artificial intelligence applications characterized by high-impact applications generating text, images, and videos. However, these models usually ensue with one critical challenge called hallucination: confident presentation of inaccurate or fabricated information. This problem attracts serious concern when these models are applied to specialized domains, including healthcare and law, where the accuracy and preciseness of information are absolute conditions. In this paper, we propose EvoLLMs, an innovative framework inspired by Evolutionary Computation, which automates the generation of high-quality Question-answering (QA) datasets while minimizing hallucinations. EvoLLMs employs genetic algorithms, mimicking evolutionary processes like selection, variation, and mutation, to guide LLMs in generating accurate, contextually relevant question-answer pairs. Comparative analysis shows that EvoLLMs consistently outperforms human-generated datasets in key metrics such as Depth, Relevance, and Coverage, while nearly matching human performance in mitigating hallucinations. These results highlight EvoLLMs as a robust and efficient solution for QA dataset generation, significantly reducing the time and resources required for manual curation.","","979-8-3503-8848-0","10.1109/ECTE-Tech62477.2024.10851107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851107","Large Language Model (LLM);Evolutionary Computation;Optimization Problem;Genetic Algorithm;Prompt Engineering;Hallucination","Measurement;Accuracy;Large language models;Prevention and mitigation;Computational modeling;Medical services;Manuals;Evolutionary computation;Videos;Genetic algorithms","","","","35","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation","B. Steenhoek; M. Tufano; N. Sundaresan; A. Svyatkovskiy",Microsoft Data & AI; Google; Microsoft Data & AI; Google DeepMind,2025 IEEE/ACM International Workshop on Deep Learning for Testing and Testing for Deep Learning (DeepTest),"11 Jun 2025","2025","","","37","44","Software testing is a crucial but time-consuming aspect of software development, and recently, Large Language Models (LLMs) have gained popularity for automated test case generation. However, because LLMs are trained on vast amounts of open-source code, they often generate test cases that do not adhere to best practices and may even contain test smells (anti-patterns). To address this issue, we propose Reinforcement Learning from Static Quality Metrics (RLSQM), wherein we utilize Reinforcement Learning to generate high-quality unit tests based on static analysis-based quality metrics. First, we analyzed LLM-generated tests and show that LLMs frequently do generate undesirable test smells — up to 37% of the time. Then, we implemented lightweight static analysis-based reward model and trained LLMs using this reward model to optimize for five code quality metrics. Our experimental results demonstrate that the RL-optimized Codex model consistently generated higher-quality test cases than the base LLM, improving quality metrics by up to 23%, and generated nearly 100% syntactically-correct code. RLSQM also outperformed GPT-4 on all code quality metrics, in spite of training a substantially cheaper Codex model. We provide insights into how reliably utilize RL to improve test generation quality and show that RLSQM is a significant step towards enhancing the overall efficiency and reliability of automated software testing. Our data are available at this link: https://doi.org/10.6084/m9.figshare.25983166.","","979-8-3315-0190-7","10.1109/DeepTest66595.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11026897","deep learning;test generation;test smells;code smells;reinforcement learning;codex;gpt-4","Measurement;Training;Software testing;Deep learning;Analytical models;Codes;Large language models;Reinforcement learning;Software reliability;Test pattern generators","","","","52","IEEE","11 Jun 2025","","","IEEE","IEEE Conferences"
"BRETAGNE: Building a Reproducible and Efficient Training AI Gym for Network Environments","Y. Gourlet; T. Lefeuvre; J. F. Loevenich; T. Hürten; F. Spelter; E. Adler; J. Braun; L. Moxon; R. R. F. Lopes","Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany",MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM),"6 Dec 2024","2024","","","164","169","This paper introduces BRETAGNE, a network simulation environment designed to serve as a training ground for autonomous defense agents using hybrid AI models in simulations. The platform integrates docker, a lightweight virtualization technology orchestrated by Kathara with widely used network protocols such as BGP, OSPF, HTTP, SSH and others to simulate production-like environments, thereby addressing the limitations of existing simulators that often lack applicability in real-world networks. We present a multi-agent architecture involving blue, red, green, and white agents, designed to create dynamic, communicative environments for training purposes. Furthermore, our work includes a comparative analysis of large language models (LLMs) for detecting cyber attacks, which highlights the benefits and constraints of using AI for autonomous decision-making in cybersecurity. Overall, the BRETAGNE framework offers a realistic and scalable solution for the training and deployment of autonomous agents in operational networks.","2155-7586","979-8-3503-7423-0","10.1109/MILCOM61039.2024.10773848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773848","Autonomous Cyber Defence;Multi-Agent Reinforcement Learning;Cyber Security;Network Virtualization","Training;Military communication;Large language models;Decision making;Telecommunication traffic;Reinforcement learning;Autonomous agents;Mirrors;Virtualization;Testing","","3","","12","IEEE","6 Dec 2024","","","IEEE","IEEE Conferences"
"LEMMAS: a secured and trusted Local Energy Market simulation system","R. Andrade; J. Vitorino; S. Wannous; E. Maia; I. Praça","GECAD—Knowledge Engineering and Decision Support Research Centre, School of Engineering, Polytechnic of Porto (ISEP/IPP); GECAD—Knowledge Engineering and Decision Support Research Centre, School of Engineering, Polytechnic of Porto (ISEP/IPP); GECAD—Knowledge Engineering and Decision Support Research Centre, School of Engineering, Polytechnic of Porto (ISEP/IPP); GECAD—Knowledge Engineering and Decision Support Research Centre, School of Engineering, Polytechnic of Porto (ISEP/IPP); GECAD—Knowledge Engineering and Decision Support Research Centre, School of Engineering, Polytechnic of Porto (ISEP/IPP)",2022 18th International Conference on the European Energy Market (EEM),"20 Oct 2022","2022","","","1","5","The ever changing nature of the energy grid and the addition of novel systems such as the Local Energy Market (LEM) drastically increase its complexity, thus making the management harder and with increased importance at local level. Providing innovative and advanced management solutions is fundamental for the success of this new distributed energy grid paradigm. In this paper we extend Multi-Agent System (MAS) based simulation tool for LEMs called LEMMAS. A cyberattack detection model is developed and integrated in LEMMAS with the objective of preventing cyber-attacks from affecting the negotiations. This model is compared with the previous version which only analysed the trustworthiness of participants. The results show that the cyber-attack detection model drastically increases the security capabilities of LEMMAS.","2165-4093","978-1-6654-0896-7","10.1109/EEM54602.2022.9921159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9921159","Local Energy Market;Multi-Agent System;Trust;Cyber-Security","Analytical models;Limiting;Buildings;Europe;Critical infrastructure;Complexity theory;Communication networks","","2","","19","IEEE","20 Oct 2022","","","IEEE","IEEE Conferences"
"RTLCoder: Outperforming GPT-3.5 in Design RTL Generation with Our Open-Source Dataset and Lightweight Solution","S. Liu; W. Fang; Y. Lu; Q. Zhang; H. Zhang; Z. Xie",HKUST; HKUST; HKUST; HKUST; HKUST (GZ) & HKUST; HKUST,2024 IEEE LLM Aided Design Workshop (LAD),"1 Oct 2024","2024","","","1","5","The automatic generation of RTL code (e.g., Verilog) using natural language instructions and large language models (LLMs) has attracted significant research interest recently. However, most existing approaches heavily rely on commercial LLMs such as ChatGPT, while open-source LLMs tailored for this specific design generation task exhibit notably inferior performance. The absence of high-quality open-source solutions restricts the flexibility and data privacy of this emerging technique. In this study, we present a new customized LLM solution with a modest parameter count of only 7B, achieving better performance than GPT-3.5 on all representative benchmarks for RTL code generation. Especially, it outperforms GPT-4 in VerilogEval Machine benchmark. This remarkable balance between accuracy and efficiency is made possible by leveraging our new RTL code dataset and a customized LLM algorithm, both of which have been made fully open-source1.","","979-8-3503-7608-1","10.1109/LAD62341.2024.10691788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691788","","Data privacy;Codes;Accuracy;Large language models;Conferences;Natural languages;Benchmark testing;Chatbots;Hardware design languages","","35","","28","IEEE","1 Oct 2024","","","IEEE","IEEE Conferences"
"Natural Language Coding (NLC) for Autonomous Stock Trading: A New Dimension in No-Code/Low-Code (NCLC) AI","Y. Kumar; W. Li; K. Huang; M. Thompson; B. Hannon","Kean University, Union, NJ, USA; Kean University, Wenzhou, Zhejiang, China; Kean University, Union, NJ, USA; Kean University, Union, NJ, USA; Kean University, Union, NJ, USA","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","19 Feb 2024","2023","","","873","874","In the evolving field of AI, the advent of Large Language Models (LLMs) and Natural Language Coding (NLC) represents a revolutionary step in programming and computational linguistics. This research, conducted by early-career scholars and their mentors, constructs a self-reliant stock trading bot using Transformer Neural Networks, AutoGPT, and the Alpaca API, exploring the potentials of a No-Code/Code-Free AI framework rooted in NLC. This investigation assesses the effectiveness of this approach in stock trading influenced by social media dynamics and compares it with traditional trading mechanisms. Initially focused on the financial analysis of the platform “X”, formerly Twitter, the study has adapted to the continuous transformations in social media landscapes and advancements in AI. The results highlight the extensive capabilities of LLMs in tasks such as code generation, data analytics, and app development, suggesting NLC as an emerging frontier in AI.","2693-9371","979-8-3503-5939-8","10.1109/QRS-C60940.2023.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430057","Natural Language Coding (NLC);ChatGPT;Social Media Stock Prediction;Autonomous Trading Bot","Data analysis;Social networking (online);Natural languages;Chatbots;Transformers;Encoding;Artificial intelligence","","3","","6","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"SA-DS: A Dataset for Large Language Model-Driven AI Accelerator Design Generation","D. Vungarala; M. Nazzal; M. Morsali; C. Zhang; A. Ghosh; A. Khreishah; S. Angizi","Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA",2025 IEEE International Symposium on Circuits and Systems (ISCAS),"27 Jun 2025","2025","","","1","4","In the ever-evolving landscape of Deep Neural Networks (DNN) hardware acceleration, unlocking the true potential of systolic array accelerators has long been hindered by the daunting challenges of expertise and time investment. Large Language Models (LLMs) offer a promising solution for automating code generation, which is key to unlocking unprecedented efficiency and performance in various domains, including hardware descriptive code. The generative power of LLMs can enable the effective utilization of preexisting designs and dedicated hardware generators. However, the successful application of LLMs to hardware accelerator design is contingent upon the availability of specialized datasets tailored for this purpose. To bridge this gap, we introduce the Systolic Array-based Accelerator DataSet (SA-DS). SA-DS comprises a diverse collection of spatial array designs following the standardized Berkeley’s Gemmini accelerator generator template, enabling design reuse, adaptation, and customization. SA-DS is intended to spark LLM-centered research on DNN hardware accelerator architecture. We envision that SA-DS provides a framework that will shape the course of DNN hardware acceleration research for generations to come. SA-DS is open-sourced under the permissive MIT license at https://github.com/ACADLab/SA-DS.","2158-1525","979-8-3503-5683-0","10.1109/ISCAS56072.2025.11044008","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044008","Systolic array design;LLM-powered hardware synthesis;accelerator architecture","Codes;Power demand;Shape;Artificial neural networks;Licenses;Systolic arrays;Generators;Sparks;Prompt engineering;Hardware acceleration","","","","30","IEEE","27 Jun 2025","","","IEEE","IEEE Conferences"
"GUIDE: LLM-Driven GUI Generation Decomposition for Automated Prototyping","K. Kolthoff; F. Kretzer; C. Bartelt; A. Maedche; S. P. Ponzetto","Institute for Software and Systems Engineering, Clausthal University of Technology, Clausthal, Germany; Human-Centered Systems Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Software and Systems Engineering, Clausthal University of Technology, Clausthal, Germany; Human-Centered Systems Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany; Data and Web Science Group, University of Mannheim, Mannheim, Germany",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","1","4","Graphical user interface (GUI) prototyping serves as one of the most valuable techniques for enhancing the elicitation of requirements, facilitating the visualization and refinement of customer needs and closely integrating the customer into the development activities. While GUI prototyping has a positive impact on the software development process, it simultaneously demands significant effort and resources. The emergence of Large Language Models (LLMs) with their impressive code generation capabilities offers a promising approach for automating GUI prototyping. Despite their potential, there is a gap between current LLM-based prototyping solutions and traditional user-based GUI prototyping approaches which provide visual representations of the GUI prototypes and direct editing functionality. In contrast, LLMs and related generative approaches merely produce text sequences or non-editable image output, which lacks both mentioned aspects and therefore impede supporting GUI prototyping. Moreover, minor changes requested by the user typically lead to an inefficient regeneration of the entire GUI prototype when using LLMs directly. In this work, we propose GUIDE, a novel LLM-driven GUI generation decomposition approach seamlessly integrated into the popular prototyping framework Figma. Our approach initially decomposes high-level GUI descriptions into fine-granular GUI requirements, which are subsequently translated into Material Design GUI prototypes, enabling higher controllability and more efficient adaption of changes. To efficiently conduct prompting-based generation of Material Design GUI prototypes, we propose a retrieval-augmented generation (RAG) approach to integrate the component library. Our preliminary evaluation demonstrates the effectiveness of GUIDE in bridging the gap between LLM generation capabilities and traditional GUI prototyping workflows, offering a more effective and controlled user-based approach to LLM-driven GUI prototyping. Video presentation of GUIDE is available at: https://youtu.be/C9RbhMxqpTU","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024434","Automated GUI Prototyping;Retrieval-Augmented Generation (RAG);Prompt Decomposition;LLM","Visualization;Translation;Large language models;Retrieval augmented generation;Prototypes;Controllability;Libraries;Graphical user interfaces;Software engineering;Software development management","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Performance Review on LLM for solving leetcode problems","L. Wang; C. Shi; S. Du; Y. Tao; Y. Shen; H. Zheng; X. Qiu","Duke University, North Carolina, USA; University of California San Diego, California, USA; University of Amsterdam, Amsterdam, Netherlands; Johns Hopkins University, Maryland, USA; University of Amsterdam, Amsterdam, Netherlands; University of California San Diego, California, USA; Northeastern University, Boston, USA",2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM),"26 Mar 2025","2024","","","1050","1054","This paper presents a comprehensive performance evaluation of Large Language Models (LLMs) in solving programming challenges from Leetcode, a widely used platform for algorithm practice and technical interviews. We began by crawling the Leetcode website to collect a diverse set of problems encompassing various difficulty levels and topics. Using this dataset, we generated solutions with multiple LLMs, including GPT-4 and GPT-3.5-turbo (ChatGPT-turbo). The generated solutions were systematically evaluated for correctness and efficiency. We employed the pass@k metric to assess the success rates within a given number of attempts and analyzed the runtime performance of the solutions. Our results highlight the strengths and limitations of current LLMs [1] in code generation and problem-solving tasks, providing insights into their potential applications and areas for improvement in automated programming assistance.","","979-8-3315-4172-9","10.1109/AIIM64537.2024.10934280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10934280","LLM;LLM performance evaluation;ChatGPT review","Performance evaluation;Runtime;Codes;Reviews;Large language models;Programming;Chatbots;Manufacturing;Problem-solving;Interviews","","","","17","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Wireless Security Enhancement Framework Based on AI and RIS in Industrial IoT Networks","R. Zhao; H. Song; H. Wen; Z. Chen; W. Hou; X. Feng","School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, and the Sichuan Provincial Engineering Research Center of Communication Technology for Intelligent IoT, University of Electronic Science and Technology of China, Chengdu, China",IEEE Network,"14 Jul 2025","2025","39","4","29","36","Reconfigurable Intelligent Surface (RIS) technology, closely integrated with Artificial Intelligence (AI) as one of the Physical Layer (PL) technology approaches, is considered an effective solution for enhancing security in industrial Internet of Things (IIoT) networks. Integrating RIS, AI, and heterogeneous IIoT networks presents a promising approach to improving the security of wireless communications in IIoT. This paper discusses new AI-based Physical Layer Authentication (PLA) approaches and how they can be integrated with RIS to enable identity authentication and malicious node detection, aiming to provide light-weight isolation in IIoT terminals. An anti-jamming and secure communication framework for IIoT is proposed, which leverages Deep Reinforcement Learning (DRL) and RIS to defend against malicious jamming and eavesdropping targeting legitimate users’ channels. Additionally, a foundational framework that employs Quantum Reinforcement Learning (QRL) is presented to improve RIS-assisted secure communication. Furthermore, the threats posed by Generative AI (GAI) to RIS-assisted IIoT communication networks and possible defense schemes are provided. Finally, the paper concludes by discussing research opportunities and future challenges.","1558-156X","","10.1109/MNET.2025.3543829","National Natural Science Foundation of China(grant numbers:62201132,U23B2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10896740","Physical layer authentication;Industrial internet of things (IIoT);Reconfigurable intelligent surface;Artificial intelligence","Industrial Internet of Things;Artificial intelligence;Wireless communication;Security;Authentication;Physical layer;Feature extraction;Communication system security;Fingerprint recognition;Jamming;Reconfigurable intelligent surfaces","","1","","15","IEEE","20 Feb 2025","","","IEEE","IEEE Magazines"
"ChatPRCS: A Personalized Support System for English Reading Comprehension Based on ChatGPT","X. Wang; Y. Zhong; C. Huang; X. Huang","Zhejiang Key Laboratory of Intelligent Education Technology and Application, Zhejiang Normal University, Jinhua, China; Zhejiang Key Laboratory of Intelligent Education Technology and Application, Zhejiang Normal University, Jinhua, China; Zhejiang Key Laboratory of Intelligent Education Technology and Application, Zhejiang Normal University, Jinhua, China; School of Computing, Mathematics, and Engineering, Charles Sturt University, Albury, NSW, Australia",IEEE Transactions on Learning Technologies,"14 Jun 2024","2024","17","","1722","1736","Reading comprehension is a widely adopted method for learning English, involving reading articles and answering related questions. However, the reading comprehension training typically focuses on the skill level required for a standardized learning stage, without considering the impact of individual differences in linguistic competence. This article presents a personalized support system for reading comprehension, named chat generative pretrained transformer (ChatGPT)-based personalized reading comprehension support (ChatPRCS), based on the zone of proximal development (ZPD) theory. It leverages the advanced capabilities of large language models, exemplified by ChatGPT. ChatPRCS employs methods, including skill prediction, question generation and automatic evaluation, to enhance reading comprehension instruction. First, a ZPD-based algorithm is developed to predict students' reading comprehension skills. This algorithm analyzes historical data to generate questions with appropriate difficulty. Second, a series of ChatGPT prompt patterns is proposed to address two key aspects of reading comprehension objectives: question generation, and automated evaluation. These patterns further improve the quality of generated questions. Finally, by integrating personalized skill prediction and reading comprehension prompt patterns, ChatPRCS is validated through a series of experiments. Empirical results demonstrate that it provides learners with high-quality reading comprehension questions that are broadly aligned with expert-crafted questions at a statistical level. Furthermore, this study investigates the effect of the system on learning achievement, learning motivation, and cognitive load, providing further evidence of its effectiveness in instructing English reading comprehension.","1939-1382","","10.1109/TLT.2024.3405747","National Science and Technology Major(grant numbers:2022ZD0117105); National Natural Science Foundation of China(grant numbers:62007031,62337001); Pioneer; Leading Goose(grant numbers:2022C03106); Zhejiang Provincial Philosophy and Social Sciences Planning Project(grant numbers:24ZJQN083Y); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539340","Chat generative pretrained transformer (ChatGPT);personalized question generation (QG);prompt engineering;reading comprehension","Chatbots;Artificial intelligence;Linguistics;Prediction algorithms;Vocabulary;Task analysis;Learning systems","","10","","58","IEEE","27 May 2024","","","IEEE","IEEE Journals"
"Boosting the automated Information Processing for Reconnaissance","R. Duro; M. Andresel; C. Singewald; V. Siska; A. Weißenfeld; D. Ignjatović","Center for Digital Safety & Security, AIT Austrian Institute of Technology Gmbh, Vienna, Austria; Center for Digital Safety & Security, AIT Austrian Institute of Technology Gmbh, Vienna, Austria; Syncpoint GmbH, Vienna, Austria; Center for Digital Safety & Security, AIT Austrian Institute of Technology Gmbh, Vienna, Austria; Center for Digital Safety & Security, AIT Austrian Institute of Technology Gmbh, Vienna, Austria; Center for Digital Safety & Security, AIT Austrian Institute of Technology Gmbh, Vienna, Austria",2023 IEEE International Workshop on Technologies for Defense and Security (TechDefense),"8 Jan 2024","2023","","","214","219","The emerging complexities due to an increasing availability of data sources and advanced technologies for data and information processing in the defense sector require careful considerations. In this study, we looked at the different aspects related to the exploitation of the advancing technologies for the reconnaissance operations. Specifically, system architecture, data fusion, human in the loop and knowledge modeling are explored, with an exemplary case of Large Language Models (LLM) on reconnaissance data is shown.","","979-8-3503-1939-2","10.1109/TechDefense59795.2023.10380937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380937","reconnaissance;data fusion;LLM;prompt engineering;knowledge modelling","Uncertainty;Transfer learning;Data integration;Systems architecture;Information processing;Reconnaissance;Data models","","1","","20","IEEE","8 Jan 2024","","","IEEE","IEEE Conferences"
"Performance Comparison of the LLM Models on LLM-Based Seed Generation Method for IoT Device Fuzzing","H. Nakanishi; K. Hasegawa; S. Hidano; K. Fukushima; K. Hashimoto; N. Togawa","Department of Computer Science and Communications Engineering, Waseda University; KDDI Research, Inc.; KDDI Research, Inc.; KDDI Research, Inc.; Department of Computer Science and Communications Engineering, Waseda University; Department of Computer Science and Communications Engineering, Waseda University",2025 IEEE International Conference on Consumer Electronics (ICCE),"26 Mar 2025","2025","","","1","5","The proliferation of IoT devices has increased the need for device security measures. Recently, an method of initial seeds generation utilizing an LLM (Large Language Model) for IoT device fuzzing (LLM-based seed generation method, in short) has been proposed to reduce the cost and improve the efficiency of vulnerability detection. However, various LLMs have been released in recent years, and existing studies have not adequately evaluated their adaptability to various LLM models. In this paper, we compare the seeds generation and the associated fuzzing results by the LLM-based seed generation method among the various LLM models of Vicuna v1.5, Mistral, Phi-3, and Llama 3. Comparison experiment results show that Mistral, Phi-3, and Llama 3 detected many vulnerabilities with high conformance rates of the seed format.","2158-4001","979-8-3315-2116-5","10.1109/ICCE63647.2025.10929957","National Institute of Information and Communications Technology(grant numbers:JPJ012368C08101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929957","IoT device;fuzzing;LLM;security","Performance evaluation;Adaptation models;Costs;Large language models;Fuzzing;Computer crashes;Internet of Things;Security;Consumer electronics","","","","9","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Research on Knowledge Graph Extraction Methods for Chinese STEM Curriculum","C. Wang; X. Sang; X. Wang; Y. Gao; Y. Liu","College of Computer Science and Engineering, Northwest Normal University, LanZhou, China; College of Computer Science and Engineering, Northwest Normal University, LanZhou, China; College of Computer Science and Engineering, Northwest Normal University, LanZhou, China; College of Computer Science and Engineering, Northwest Normal University, LanZhou, China; College of Computer Science and Engineering, Northwest Normal University, LanZhou, China",2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP),"20 Dec 2024","2024","","","1","8","STEM education, as an innovative teaching model, has gained widespread attention in recent years. However, the lack of relevant textbooks and learning resources has made its implementation challenging. Developing interdisciplinary knowledge graphs tailored for STEM education has become an urgent issue. To address this, a knowledge extraction framework named Llms4edu is proposed, which utilizes a series of effective prompts to guide large language models in knowledge extraction. Specifically, the knowledge extraction task is transformed into multiple rounds of question-and-answer interactions with the LLM, gradually identifying entity-relation triplets from subject data. Through experiments, an F1-score of 89.4% was achieved on the named entity recognition task in the chemistry subject, and an F1-score of 66.7% on the relation extraction task. Finally, a subject ontology model was built for subject text, and a subject data set was constructed using Llms4edu, which includes three subjects of junior high school mathematics, physics, and chemistry, a total of 2,511 entities, 2,010 relationship triples, and cross-disciplinary knowledge is linked to construct a cross-disciplinary knowledge graph.","","979-8-3503-5497-3","10.1109/MLNLP63328.2024.10800180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10800180","interdisciplinary knowledge graph;large language model;prompt engineering","Knowledge engineering;Training;Chemistry;Annotations;Large language models;Knowledge graphs;Named entity recognition;Ontologies;Data mining;Physics","","","","27","IEEE","20 Dec 2024","","","IEEE","IEEE Conferences"
"SSE: A Speaking Style Extractor Based on Fine-Grained Contrastive Learning between Speech and Descriptive Text","Z. Zhang; Y. Wu; Z. Dong; W. Xiang; S. Shen; B. W. Schuller","College of Computer Science and Electronic Engineering, Hunan University, China; College of Computer Science and Electronic Engineering, Hunan University, China; College of Computer Science and Electronic Engineering, Hunan University, China; College of Computer Science and Electronic Engineering, Hunan University, China; College of Computer Science and Electronic Engineering, Hunan University, China; Department of Computing, GLAM, Imperial College London, UK","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Effective extraction of paralinguistic features from speech, such as emotion, accent, and age, remains a challenging task in speech processing. Traditional methods typically address each type of paralinguistic information with separate classification or regression tasks—e. g., emotion recognition, accent detection, and age estimation. These approaches can result in fragmented and incomplete descriptions of speech style, failing to capture the full range of paralinguistic attributes in an integrated way. To address these limitations, we propose the Speech Style Extractor (SSE), a novel approach that aims to provide a more comprehensive extraction of speech style features. SSE leverages an optimized fine-grained contrastive learning scheme, enhancing the extraction of diverse paralinguistic features. The optimization approach outperforms the baseline on 11 out of 13 datasets, with an average improvement of 2.1% in terms of the R@1 evaluation metric. We also propose a complete data generation framework using large language models to create 199k text samples across 9 paralinguistic categories, such as emotion, deception, stuttering, and accent, to fill the gap in speaking style descriptions in public datasets. This extensive dataset not only facilitates our research but also serves as a valuable resource for the speech processing community.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10888883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888883","Speaking Styles;Contrastive Learning;Prompt Engineering;Fine-Grained Loss","Large language models;Noise reduction;Contrastive learning;Data collection;Signal processing;Feature extraction;Speech;Data mining;Speech processing;Optimization","","","","34","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Automatic Mapping of Upper-Level Ontology Classes (DOLCE) and Domain-Specific Ontology ITSMO","A. Khalov; O. Ataeva","Moscow Institute of Physics and Technology (National Research University) Center “Pusk”, Moscow, Russia; FRC Computer Sciences and Control Russian Academy Of Sciences, Moscow, Russia",2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD),"21 Jul 2025","2025","","","795","802","This paper proposes a method for extending the top-level ontology DOLCE (DOLCE-lite version, referred to as TLO) to the domain of IT services without expert involvement. The main challenge addressed is the automatic mapping of classes in conditions of a small number of objects (<100) and the absence of annotated data. A review of existing approaches is conducted, their limitations are identified, and novel mapping methods are proposed, integrating embeddings and large language models. The suggested method achieved an 82.35% mapping accuracy when integrating DOLCE and ITSMO ontologies. As a result, the ITO-seed ontology was developed, containing linked classes from DOLCE and ITSMO, which can be utilized in further research and in building knowledge graphs for IT Service Management (ITSM) systems.","2769-3554","979-8-3315-1936-0","10.1109/ICAIBD64986.2025.11082040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082040","Ontology;RDF;OWL;mapping;rdf2vec;owl2vec;BERT;GPT;prompt engineering;clustering;ITIL;DOLCE","Reviews;Large language models;OWL;Knowledge graphs;Ontologies;Transformers;Resource description framework;Knowledge management;Graph neural networks;Prompt engineering","","","","33","IEEE","21 Jul 2025","","","IEEE","IEEE Conferences"
"Strategies to Map Education 5.0 and Industry 5.0 in the Context of a Modernized Undergraduate Program in Chemical Engineering","D. Galatro; S. Chakraborty","Department of Chemical Engineering & Applied Chemistry, University of Toronto, Toronto, Canada; Department of Chemical and Biomolecular Engineering, Johns Hopkins University, Baltimore, United States",2025 IEEE Global Engineering Education Conference (EDUCON),"3 Jun 2025","2025","","","1","9","Education 5.0 is the direct application of novel technologies to consciously create a humanized, holistic teaching experience, to directly target the requirements of Industry 5.0. This work describes the design and implementation of a set of pedagogical strategies systematically employed to comprehensively map Education 5.0 and Industry 5.0, within the context of modernization of the undergraduate Chemical Engineering & Applied Chemistry program, clustered by (i) core courses such as Heat & Mass Transfer, (ii) electives such as Petroleum Processing, and (iii) 500level (undergraduate/graduate) advanced courses, such as Data Based Modelling for Prediction and Control. Implementation strategies include consciously integrating sustainability and engineering safety practices for chemical process design, using Generative Artificial Intelligence (Generative AI) in class to augment student self-learning, data-driven causation and machine learning versus first-principle-based phenomena analysis by employing dynamic process simulation and computational fluid dynamics tools, industry standards, codes and recommended practices, to instill active learning among students, and circularity indicators for process design and description. Examples of active learning initiatives embedded within our strategies include (i) the Petroleum Processing Lab, where students combine chatbots use and Machine Learning (ML) and/or simulation tools to analyze oil price market trends, mass balances crude distillation units, and risk assessments in oil refineries; and (ii) the Heat and Mass Transfer Lab, where students combine data analysis, machine learning and first-principles to describe and analyze heat convection relationships during the lectures. Chatbots assisted activities are qualitatively assessed for accuracy via a novel APC-EPE approach (Assumptions, Process description, and Calculations, with Effective Prompt Engineering); and we have successfully employed the APC-EPE framework to enhance the chances of chatbots providing accurate and reliable results aligned with students' expectations. Vertical integration of such strategies, right from sophomore to final years of our undergraduate program is implemented in tandem with standalone 'practices' in courses; and dedicated process design / capstone courses which combine several of these practices are offered. Our strategies are currently being assessed via anonymized student surveys, thereby attesting towards their effectiveness and high receptivity, as the department gradually transitions to a more modernized curriculum in upcoming years. Student and faculty feedback is identified as critical towards iteratively improving the course/curriculum design process in future, to ensure that the department's teaching approach towards realizing Education 5.0 is perceived as valuable to Industry 5.0 requirements and demands that employers seek from undergraduates. Our efforts are thus impactful towards creating future generations of the industry workforce trained in Education 5.0 to match Industry 5.0's requirements.","2165-9567","979-8-3315-3949-8","10.1109/EDUCON62633.2025.11016293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016293","Mapping Education 5.0 and Industry 5.0;curriculum modernization;Generative AI;simulation","Process design;Industries;Accuracy;Computational fluid dynamics;Chemical engineering;Active learning;Machine learning;Chatbots;Fifth Industrial Revolution;Petroleum","","","","17","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Implementing Machine Learning for AI-Powered Solutions in Robotics, Computer Vision, and Natural Language Processing","V. R. Kasu; B. K. Malamuthu; B. S. Kumar; V. S. Pandi; E. Sivajothi; D. S. Deepika","Sr Functional Architect, Celina, Texas; Financial Crimes Technology, Morgan Stanley Services Inc, New York City, New York; Department of Electronics and Communication, JB Institute of Engineering & Technology, Telangana; Centre for Advanced Wireless Integrated Technology, Chennai Institute of Technology, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, Vel Tech Rangarajan, Dr. Sagunthala R&D Institute of Science and Technology; Department of Information Technology, R.M.D. Engineering College, Kavaraipettai, Tamil Nadu",2025 Global Conference in Emerging Technology (GINOTECH),"17 Jul 2025","2025","","","1","6","Machine Learning (ML) is a relatively recent development that has had a profound impact on Robotics, Computer Vision (CV) and Natural Language Processing (NLP) by allowing automation of intelligent processing, perception and human-computer interaction. ML-driven AI solutions are crucial in these areas for real-time decision-making, pattern recognition, and autonomous operations; traditional rule-based methods tend to lack the adaptability and scalability to meet the demands of these fields. RL and deep learning have increasingly contributed to the improvement of robotic perception, motion planning, and manipulation in robotics, enabling better and more adaptive autonomous systems. Convolutional neural networks (CNNs) and transformer-based architectures have revolutionized computer vision, with applications ranging from object detection and image segmentation to facial recognition, allowing for advanced visual analysis across sectors such as healthcare, security, and self-driving cars. In NLP, the introduction of transformers like BERT and GPT has transformed the space by enabling more context-aware and human-like AI-driven language models, leading to drastic improvements in areas like speech recognition, sentiment analysis, and machine translation. This study delves into the application of ML techniques across these domains, evaluating the implications on efficiency, accuracy, and scalability along with challenges like data quality, model interpretability, and computational constraints. DQN has made advances for robotics, ViT in the domain of computer vision, and LLMs in the subject of NLU. A comparative study to analyse the progress and limitations of such state-of-the-art ML models. The results highlight the promise of multi-modal AI systems, where machine learning algorithms work in conjunction to improve robotic navigation, as well as visual perception and natural language understanding. Extending prior studies of intelligent automation, this research points the way to the development of new adaptive, human-centric, and autonomous AI innovations in diverse sectors.","","979-8-3315-0775-6","10.1109/GINOTECH63460.2025.11077035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077035","Natural Language Processing (NLP);Computer Vision;Convolutional Neural Networks (CNNs);Reinforcement Learning (RL);Transformer Models;Human-Robot Interaction (HRI);Autonomous Systems;Vision Transformers (ViTs)","Computer vision;Sentiment analysis;Service robots;Computational modeling;Scalability;Computer architecture;Reinforcement learning;Transformers;Real-time systems;Data models","","","","18","IEEE","17 Jul 2025","","","IEEE","IEEE Conferences"
"Movable Antenna-Aided Secure Full-Duplex Multi-User Communications","J. Ding; Z. Zhou; B. Jiao","School of Electronics, Peking University, Beijing, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; School of Electronics, Peking University, Beijing, China",IEEE Transactions on Wireless Communications,"11 Mar 2025","2025","24","3","2389","2403","In this paper, we investigate physical layer security (PLS) for full-duplex (FD) multi-user systems. We consider a base station (BS) that operates in FD mode and transmits artificial noise (AN) to simultaneously protect uplink (UL) and downlink (DL) transmissions. Conventional fixed-position antennas (FPAs) at the FD BS struggle to fully exploit spatial degrees of freedom (DoFs) to improve signal reception and suppress interference. To overcome this limitation, we propose a novel FD BS architecture equipped with multiple transmit and receive movable antennas (MAs). The MAs introduce the DoFs in antenna position optimization, which can improve the performance of secure communication systems. To serve users and counter the cooperative interception of multiple eavesdroppers (Eves), we formulate a sum of secrecy rates (SSR) maximization problem to jointly optimize the MA positions, the transmit, receive, and AN beamformers at the BS, and the UL powers. We propose an alternating optimization (AO) algorithm, which decomposes the original problem into three sub-problems, to solve the challenging non-convex optimization problem with highly coupled variables. Specifically, we propose the multi-velocity particle swarm optimization (MVPSO), which is an improved version of the standard particle swarm optimization (PSO), to simultaneously optimize all MA positions. The transmit/AN beamformers and the UL powers are solved by successive convex approximation (SCA). The optimal receive beamformer is derived as a closed-form solution. Simulation results demonstrate the effectiveness of the proposed algorithms and the advantages of MAs over conventional FPAs in enhancing the security of FD multi-user systems.","1558-2248","","10.1109/TWC.2024.3520806","National Natural Science Foundation of China(grant numbers:62171006); High-Performance Computing Platform of Peking University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818453","Movable antenna (MA);physical layer security (PLS);full-duplex (FD);alternating optimization (AO);particle swarm optimization (PSO)","Antennas;Optimization;Array signal processing;Particle swarm optimization;Full-duplex system;Vectors;Standards;Physical layer security;MISO;Cryptography","","6","","35","IEEE","30 Dec 2024","","","IEEE","IEEE Journals"
"Software Vulnerability Detection Using LLM: Does Additional Information Help?","S. Shimmi; Y. Saini; M. Schaefer; H. Okhravi; M. Rahimi","Department of Computer Science, Northern Illinois University, IL, USA; Department of Computer Science, Northern Illinois University, IL, USA; Department of Computer Science, Northern Illinois University, IL, USA; MIT Lincoln Laboratory, MA, USA; Department of Computer Science, Northern Illinois University, IL, USA",2024 Annual Computer Security Applications Conference Workshops (ACSAC Workshops),"18 Mar 2025","2024","","","216","223","Unlike conventional machine learning (ML) or deep learning (DL) methods, Large Language Models (LLM) possess the ability to tackle complex tasks through intricate chains of reasoning, a facet often overlooked in existing work on vulnerability detection. Nevertheless, these models have demonstrated variable performance when presented with different prompts (inputs), motivating a surge of research into prompt engineering – the process of optimizing prompts to enhance their performance. This paper studies different prompt settings (zero-shot and few-shot) when using LLMs for software vulnerability detection. Our exploration involves harnessing the power of both natural language (NL) unimodal and NL-PL (programming language) bimodal models within the prompt engineering process. Experimental results indicate that LLM, when provided only with source code or zero-shot prompts, tends to classify most code snippets as vulnerable, resulting in unacceptably high recall. These findings suggest that, despite their advanced capabilities, LLMs may not inherently possess the knowledge for vulnerability detection tasks. However, few-shot learning benefits from additional domain-specific knowledge, offering a promising direction for future research in optimizing LLMs for vulnerability detection.","","979-8-3315-3281-9","10.1109/ACSACW65225.2024.00031","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917361","Software vulnerability detection;software vulnerability detection using LLM","Computer languages;Conferences;Source coding;Large language models;Natural languages;Software;Prompt engineering;Surges;Few shot learning;Computer security","","1","","37","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"Don’t Stop Believin’: A Unified Evaluation Approach for LLM Honeypots","S. B. Weber; M. Feger; M. Pilgermann","Department of Computer Science, Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany; Department of Computer Science, Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany; Department of Computer Science and Media, Brandenburg University of Applied Sciences, Brandenburg an der Havel, Germany",IEEE Access,"10 Oct 2024","2024","12","","144579","144587","The research area of honeypots is gaining new momentum, driven by advancements in large language models (LLMs). The chat-based applications of generative pretrained transformer (GPT) models seem ideal for the use as honeypot backends, especially in request-response protocols like Secure Shell (SSH). By leveraging LLMs, many challenges associated with traditional honeypots – such as high development costs, ease of exposure, and breakout risks – appear to be solved. While early studies have primarily focused on the potential of these models, our research investigates the current limitations of GPT-3.5 by analyzing three datasets of varying complexity. We conducted an expert annotation of over 1,400 request-response pairs, encompassing 230 different base commands. Our findings reveal that while GPT-3.5 struggles to maintain context, incorporating session context into response generation improves the quality of SSH responses. Additionally, we explored whether distinguishing between convincing and non-convincing responses is a metrics issue. We propose a paraphrase-mining approach to address this challenge, which achieved a macro F1 score of 77.85% using cosine distance in our evaluation. This method has the potential to reduce annotation efforts, converge LLM-based honeypot performance evaluation, and facilitate comparisons between new and previous approaches in future research.","2169-3536","","10.1109/ACCESS.2024.3472460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703029","IT security;honeypot;large language model;GPT;cosine distance;evaluation","Annotations;Protocols;Measurement;Complexity theory;Large language models;History;Data models;Accuracy;Usability;Information security;Risk management;Performance evaluation","","","","24","CCBYNCND","2 Oct 2024","","","IEEE","IEEE Journals"
"Federated Learning and Resource-Aware Graph Neural Network for Intrusion Detection in 6G-IoT Driven Healthcare System","X. Ma; J. Hu; S. Liang; Y. Wu","Department of Emergency Medicine, Shengjing Hospital of China Medical University, Shenyang, China; Department of Anesthesiology, The First Hospital of China Medical University, Shenyang, China; Department of Emergency Medicine, Shengjing Hospital of China Medical University, Shenyang, China; Department of Emergency Medicine, Shengjing Hospital of China Medical University, Shenyang, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Large Language Models (LLMs), enabled by advancements in Transformer architectures, have revolutionized natural language understanding and multimodal processing, finding transformative applications in sectors such as healthcare, intelligent manufacturing, and smart transportation. In healthcare, LLMs facilitate tasks like semantic analysis of medical records, real-time monitoring, and intelligent diagnostics. The emergence of 6G, with its integration of AI, IoT, and edge computing, offers unprecedented opportunities for deploying large models in real-time, privacy-sensitive, and resource-constrained environments. This paper proposes FLARE (Federated Learning and Resource-aware Embedding), a novel framework tailored for IoT-driven healthcare systems. FLARE introduces three technical innovations: dynamic graph modeling with optimal temporal window selection, edge-aware aggregation mechanisms that enhance local feature representation, and adaptive multi-hop embedding strategies that address computational constraints. By adopting federated learning instead of centralized approaches, FLARE enables privacy-preserving collaborative modeling across distributed IoT nodes, while effectively addressing data heterogeneity and reducing privacy risks in network traffic analysis and intrusion detection. Experimental results on CICIDS2017 and UNSW-NB15 datasets demonstrate FLAREs superior performance, achieving F1-scores of 0.935 and 0.927, and AUC-ROC values of 0.947 and 0.938 respectively, outperforming state-of-theart methods while maintaining competitive training efficiency","2327-4662","","10.1109/JIOT.2025.3564722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10977998","Federated Learning;Resource-aware Embedding;IoT Security;6G;Intrusion Detection","Internet of Things;Medical services;Federated learning;Data privacy;Collaboration;Symbiosis;Security;Intrusion detection;Adaptation models;6G mobile communication","","","","","IEEE","28 Apr 2025","","","IEEE","IEEE Early Access Articles"
"Anaphoric Ambiguity Resolution in Software Requirement Texts","S. M. Jafari; S. Yildirim; M. Cevik; A. Basar","Data Science Lab, Toronto Metropolitan University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada",2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","4722","4730","In requirements engineering (RE), anaphoric ambiguity is a frequent cause of misunderstandings. It can have a detrimental effect on the quality of requirements and jeopardize the success of a project. If stakeholders of the system, such as testers, developers, or customers, have different understandings or interpretations of software requirements, the system may not be accepted during customer validation. Despite its significance, there has been limited investigation into anaphoric ambiguity in RE. However, focusing on both recognizing and solving uncertainty can be more advantageous than just identifying it. Therefore we investigated the effectiveness of various QA learning techniques including encoder-based and text generation-based NLP models for two goals. We conduct detailed numerical experiments using various transformer models on two public requirements datasets and one generic dataset. Our results indicated that our QA architecture exhibits superior performance compared to baseline models in detecting ambiguity as well as resolving anaphora in contrast to other baseline approaches. We showed that our developed architecture can automatically support requirement development to minimize interpretation risk between stakeholders.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386192","Requirements Engineering;Ambiguity;Anaphora resolution;Transformers","Uncertainty;Focusing;Computer architecture;Big Data;Transformers;Software;Numerical models","","2","","24","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"LLM-based Vulnerability Detection","H. Li; L. Shan","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China",2023 International Conference on Human-Centered Cognitive Systems (HCCS),"1 Mar 2024","2023","","","1","4","The emerging Large language models (LLMs) are increasingly used as a revolutionised tools in many industry. In cyber security, the LLMs can offer innovative ways to detect, identify, and mitigate vulnerability through their natural language processing capability. This work aims to fine tune pre-trained LLMs to detect anomalies and vulnerability by analysing vast amounts of data. A ChatGPT 3.5 model based vulnerability detector were developed that can conduct common vulnerability analysis. Experimental results demonstrate the effectiveness of proposed solution.","","979-8-3503-5918-3","10.1109/HCCS59561.2023.10452613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452613","Cyber attack;Detection;LLM;GPT","Industries;Analytical models;Detectors;Chatbots;Cognitive systems;Cyberattack","","5","","16","IEEE","1 Mar 2024","","","IEEE","IEEE Conferences"
"Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement","J. Pan; S. L. Wong; X. W. Chia; Y. Yuan","Home Team Science and Technology Agency, Singapore; Home Team Science and Technology Agency, Singapore; Home Team Science and Technology Agency, Singapore; Home Team Science and Technology Agency, Singapore",2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),"19 Mar 2025","2025","","","0366","0371","Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics. However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations. Accountability ensures models have the means to provide explainable reasonings and outcomes. This information can be extracted through explicit prompt requests. For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well. One approach to deal with this consideration is to have the data processed locally using a local instance of the model. Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used. These SLMs have significantly fewer parameters compared to the LLMs. However, such size reductions have notable performance reduction, especially when tasked to provide reasoning explanations. In this paper, we aim to mitigate performance reduction through the integration of cognitive strategies that humans use for problem-solving. We term this as cognitive enhancement through prompts. Our experiments showed significant improvement gains of the SLMs' performances when such enhancements were applied. We believe that our exploration study paves the way for further investigation into the use of cognitive enhancement to optimize SLM for cyber security applications.","2831-6983","979-8-3315-0702-2","10.1109/ICAIIC64266.2025.10920811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10920811","Smaller Large Language Model;Cognitive Enhancement;Digital Forensics","Data privacy;Large language models;Digital forensics;Graphics processing units;Data processing;Cognition;Data models;Security;Problem-solving;Computer crime","","","","35","IEEE","19 Mar 2025","","","IEEE","IEEE Conferences"
"IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic","H. Wasswa; T. Lynar; A. Nanyonga; H. Abbass","School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia",2023 Global Conference on Information Technologies and Communications (GCITC),"18 Apr 2024","2023","","","1","6","Despite the demonstrated effectiveness of transformer models in NLP, and image and video classification, the available tools for extracting features from captured IoT network flow packets fail to capture sequential patterns in addition to the absence of spatial patterns consequently limiting transformer model application. This work introduces a novel preprocessing method to adapt transformer models, the vision transformer (ViT) in particular, for IoT botnet attack detection using network flow packets. The approach involves feature extraction from .pcap files and transforming each instance into a 1-channel 2D image shape, enabling ViT-based classification. Also, the ViT model was enhanced to allow use any classifier besides Multilayer Perceptron (MLP) that was deployed in the initial ViT paper. Models including the conventional feed forward Deep Neural Network (DNN), LSTM and Bidirectional-LSTM (BLSTM) demonstrated competitive performance in terms of precision, recall, and F1-score for multiclass-based attack detection when evaluated on two IoT attack datasets.","","979-8-3503-0816-7","10.1109/GCITC60406.2023.10426522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426522","IoT botnet;IoT security;attack detection;transformer;vision transformer","Adaptation models;Botnet;Stacking;Artificial neural networks;Transforms;Transformers;Feature extraction","","1","","26","IEEE","18 Apr 2024","","","IEEE","IEEE Conferences"
"Movable-Antenna Position Optimization for Physical-Layer Security via Discrete Sampling","W. Mei; X. Wei; Y. Liu; B. Ning; Z. Chen","National Key Laboratory of Wireless Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Wireless Communications, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Wireless Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Wireless Communications, University of Electronic Science and Technology of China, Chengdu, China",GLOBECOM 2024 - 2024 IEEE Global Communications Conference,"11 Mar 2025","2024","","","4750","4755","Fluid antennas (FAs) and mobile antennas (MAs) are innovative technologies in wireless communications that are able to proactively improve channel conditions by dynamically adjusting the transmit/receive antenna positions within a given spatial region. In this paper, we investigate an MA-enhanced multiple-input single-output (MISO) secure communication system, aiming to maximize the secrecy rate by jointly optimizing the positions of multiple MAs. Instead of continuously searching for the optimal MA positions as in prior works, we propose to discretize the transmit region into multiple sampling points, thereby converting the continuous antenna position optimization into a discrete sampling point selection problem. However, this point selection problem is combinatory and thus difficult to be optimally solved. To tackle this challenge, we ingeniously transform this combinatory problem into a recursive path selection problem in graph theory and propose a partial enumeration algorithm to obtain its optimal solution without the need for high-complexity exhaustive search. To further reduce the complexity, a linear-time sequential update algorithm is also proposed to obtain a high-quality suboptimal solution. Numerical results show that our proposed algorithms yield much higher secrecy rates as compared to the conventional FPA and other baseline schemes.","2576-6813","979-8-3503-5125-5","10.1109/GLOBECOM52923.2024.10901621","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901621","","Fluids;Transmitting antennas;Transforms;Mobile antennas;Search problems;Graph theory;MISO;Security;Global communication;Optimization","","1","","21","IEEE","11 Mar 2025","","","IEEE","IEEE Conferences"
"Textual Differential Privacy for Context-Aware Reasoning with Large Language Model","J. Yu; J. Zhou; Y. Ding; L. Zhang; Y. Guo; H. Sato","The University of Tokyo, Tokyo, Japan; Independent Researcher, Tokyo, Japan; Hiroshima University, Hiroshima, Japan; The University of Tokyo, Tokyo, Japan; The University of Tokyo, Tokyo, Japan; National Institute of Informatics / The University of Tokyo, Tokyo, Japan","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","988","997","Large language models (LLMs) have demonstrated proficiency in various language tasks but encounter difficulties in specific domain or scenario. These challenges are mitigated through prompt engineering techniques such as retrieval-augmented generation, which improves performance by integrating contextual information. However, concerns regarding the privacy implications of context-aware reasoning architectures persist, particularly regarding the transmission of sensitive data to LLMs service providers, potentially compromising personal privacy. To mitigate these challenges, this paper introduces Tex-tual Differential Privacy, a novel paradigm aimed at safeguarding user privacy in LLMs-based context-aware reasoning. The proposed Differential Embedding Hash algorithm anonymizes sensitive information while maintaining the reasoning capability of LLMs. Additionally, a quantification scheme for privacy loss is proposed to better understand the trade-off between privacy protection and loss. Through rigorous analysis and experimentation, the effectiveness and robustness of the proposed paradigm in mitigating privacy risks associated with context-aware reasoning tasks are demonstrated. This paradigm addresses privacy concerns in context-aware reasoning architectures, enhancing the trust and utility of LLMs in various applications.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633584","Large Language Model;Differential Privacy;Context-Aware Reasoning;Named -Entity Recognition;Retrieval-Augmented Generation","Privacy;Differential privacy;Systematics;Large language models;Computer architecture;Cognition;Robustness","","","","32","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"LLM-Based AI Agent for VNF Deployment in OpenStack Environment","S. Nam; N. Van Tu; J. W. -K. Hong","Department of Computer Science and Engineering, POSTECH, Pohang, Korea; Department of Computer Science and Engineering, POSTECH, Pohang, Korea; Department of Computer Science and Engineering, POSTECH, Pohang, Korea",NOMS 2025-2025 IEEE Network Operations and Management Symposium,"15 Jul 2025","2025","","","1","7","This paper presents a novel approach to automating the deployment of Virtual Network Functions (VNFs) in an OpenStack environment using Large Language Models (LLMs). Building on the concept of Intent-Driven Networking (IDN), which allows network administrators to manage complex networks via natural language commands, we explore the feasibility of using LLMs to automate VNF deployment tasks. A dataset of Method of Procedure (MOP) documents was created and utilized to prompt LLMs to generate Python code for deploying and configuring VNFs. Our LLM-based AI agent framework tests the generated code within an OpenStack environment, comparing the performance of various LLMs. Our findings highlight both the potential and current challenges of using LLMs in network automation, suggesting pathways for future research, including advanced prompt engineering and real-time error correction.","2374-9709","979-8-3315-3163-8","10.1109/NOMS57970.2025.11073607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073607","IDN;LLM;NFV;Automated Network Manage-ment","Codes;Automation;Large language models;Natural languages;Buildings;Complex networks;Real-time systems;Error correction;Prompt engineering","","","","20","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Teach me : AI-Powered Voice Chat Robot Using Internet of Things","K. B. B. R; R. A; S. R; K. S. T; R. Meena","Easwari Engineering College, Chennai, India; Easwari Engineering College, Chennai, India; Easwari Engineering College, Chennai, India; Easwari Engineering College, Chennai, India; Easwari Engineering College, Chennai, India",2025 International Conference on Emerging Systems and Intelligent Computing (ESIC),"16 Apr 2025","2025","","","333","337","This paper presents TEACH ME: An Artificial Intelligence-Powered Voice Chat Robot Integrated with the Internet of Things (IoT), designed to facilitate flexible, voice-powered communication with connected devices Leveraging Large Language Models (LLMs). TEACH ME Natural Language Processing Increases (NLP) Powerful, robust robotic voice translation enables them to create, engage in active conversations, and respond in human-like ways that integrate LLMs with the IoT extend beyond traditional systems for experiencing it is highly personalized and contextual, and allows users to interact with smart devices This system design seamlessly combines the capabilities of LLMs with IoT devices, 1999—creating new opportunities for applications in areas such as smart home automation, education, customer support, etc. TEACH ME’s key components include real-time voice recognition, advanced response generation, and IoT-powered task performance. Examines applicability and future directions.","","979-8-3315-2210-0","10.1109/ESIC64052.2025.10962703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962703","Artificial Intelligence;IoT;Voice Chat Robot;Personalized Learning;NLP;Educational Technology;TeachMe;Student Engagement;Intelligent Tutoring Systems","Performance evaluation;Large language models;Oral communication;Speech recognition;Smart homes;Natural language processing;Real-time systems;Internet of Things;Smart devices;Robots","","","","10","IEEE","16 Apr 2025","","","IEEE","IEEE Conferences"
"iRisk: A Scalable Microservice for Classifying Issue Risks Based on Crowdsourced App Reviews","V. M. A. De Lima; J. R. Barbosa; R. M. Marcacini","Três Lagoas Campus (CPTL), Federal University of Mato Grosso do Sul (UFMS), Três Lagoas, Brazil; Institute of Informatics (INF), Federal University of Goiás (UFG), Goiânia, Brazil; Institute of Mathematics and Computer Sciences (ICMC), University of são Paulo (USP), São Carlos, Brazil",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","858","862","Analyzing mobile app reviews is essential for identifying trends and issue patterns that affect user experience and app reputation in app stores. A risk matrix provides a straightforward, intuitive method to prioritize software maintenance actions to mitigate negative ratings. However, manually constructing a risk matrix is time-consuming, and stakeholders often struggle to understand the context of risks due to varied descriptions and the sheer volume of reviews. Therefore, machine learning-based methods are needed to extract risks and classify their priority effectively. While existing studies have automated risk matrix generation in software development, they have not explored app reviews or utilized Large Language Models (LLMs) in a scalable architecture. To address this gap, we present iRisk (scalable microservice for classifying issue Risks), a tool for generating a risk matrix based on crowdsourced app reviews using LLM. We present i-LLAMA, a fine-tuned version of LLaMA 3, optimized to detect and prioritize app-related issues using a risk analysis dataset of reviews categorized by severity and likelihood of occurrence. This dataset is also publicly available. Our contributions include the open-source resources to support the software maintenance and evolution industry, fine-tuning of LLaMA 3, and a scalable microservice architecture to handle large volumes of data. The iRisk can manage app issues and risks and provide an automated dashboard and visualizations for decision-making, monitoring, and risk mitigation. The tool is available on GitHub11https://github.com/vitormesaque/iRisk, and a presentation about the tool can be found in this video22https://irisk.mappidea.com.","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794993","Opinion Mining;Large language model;App Reviews;Risk Matrix;Issue Prioritization","Software maintenance;Reviews;Microservice architectures;Computer architecture;User experience;Stakeholders;Risk analysis;Monitoring;Software development management;Risk mitigation","","","","20","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Fairness Testing Through Extreme Value Theory","V. Monjezi; A. Trivedi; V. Kreinovich; S. Tizpaz-Niari",University of Illinois Chicago; University of Colorado Boulder; University of Texas at El Paso; University of Illinois Chicago,2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1501","1513","Data-driven software is increasingly being used as a critical component of automated decision-support systems. Since this class of software learns its logic from historical data, it can encode or amplify discriminatory practices. Previous research on algorithmic fairness has focused on improving “average-case” fairness. On the other hand, fairness at the extreme ends of the spectrum, which often signifies lasting and impactful shifts in societal attitudes, has received significantly less emphasis. Leveraging the statistics of extreme value theory (EVT), we propose a novel fairness criterion called extreme counterfactual discrimination (ECD). This criterion estimates the worst-case amounts of disadvantage in outcomes for individuals solely based on their memberships in a protected group. Utilizing tools from search-based software engineering and generative AI, we present a randomized algorithm that samples a statistically significant set of points from the tail of ML outcome distributions even if the input dataset lacks a sufficient number of relevant samples. We conducted several experiments on four ML models (deep neural networks, logistic regression, and random forests) over 10 socially relevant tasks from the literature on algorithmic fairness. First, we evaluate the generative AI methods and find that they generate sufficient samples to infer valid EVT distribution in 95% of cases. Remarkably, we found that the prevalent bias mitigators reduce the average-case discrimination but increase the worst-case discrimination significantly in 35% of cases. We also observed that even the tail-aware mitigation algorithm-MiniMax-Fairness-increased the worst-case discrimination in 30% of cases. We propose a novel ECD-based mitigator that improves fairness in the tail in 90% of cases with no degradation of the average-case discrimination. We hope that the EVT framework serves as a robust tool for evaluating fairness in both average-case and worst-case discrimination.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00070","NSF(grant numbers:CCF-2317206,CCF-2317207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029970","software testing;fairness;extreme value theory","Hands;Logistic regression;Generative AI;Prevention and mitigation;Software algorithms;Software;Logic;Random forests;Software engineering;Testing","","1","","74","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Connectivity Based Multi-Agent System Communication Network in Polymorphic Network","Y. Lu; X. Jing; H. Liu; S. Li; Q. Shan","School of Navigation, Dalian Maritime University, Dalian, China; School of Transportation Engineering, Dalian Maritime University, Dalian, China; School of Navigation, Dalian Maritime University, Dalian, China; School of Marine Electrical Engineering, Dalian Maritime University, Dalian, China; School of Navigation, Dalian Maritime University, Dalian, China",2023 International Conference on Ubiquitous Communication (Ucom),"27 Sep 2023","2023","","","455","459","With the development of artificial intelligence and network technology, the mission of multi-agent systems(MAS) has become more complex. The cooperative behavior between agents depends on the transmission of data information, i.e. the connected communication network. Therefore, combining the ideas of high security, high robustness, high efficiency and high availability of polymorphic network, a method for maintaining the connectivity of multi-agent system communication network is proposed. Firstly, an efficient and low complexity algorithm for determining the connectivity of multi-agent system communication network is proposed. Then, based on the above method, the method for maintaining the connectivity of multi-agent system communication network is designed. Finally, a simulation example is given to verify the feasibility of the proposed method.","","979-8-3503-4043-3","10.1109/Ucom59132.2023.10257615","Fundamental Research Funds for the Central Universities(grant numbers:3132023147); National Natural Science Foundation of China(grant numbers:52201407,51939001,61976033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257615","Multi-Agent System;Polymorphic Network;Connectivity Maintenance","Security management;Maintenance engineering;Reliability theory;Data processing;Robustness;Internet;Communication networks","","1","","16","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"Improving Accuracy of LLM-based Code Clone Detection U sing Functionally Equivalent Methods","R. Inoue; Y. Higo","Osaka University, Japan; Osaka University, Japan","2024 IEEE/ACIS 22nd International Conference on Software Engineering Research, Management and Applications (SERA)","26 Sep 2024","2024","","","24","27","Avstract-A code clone is a code snippet identical or similar to another in the source code. The presence of code clones causes the spread of bugs, which means that efficient code clone detection and appropriate refactoring are necessary. Code clone detection using large language models (in short, LLMs) is more accurate than conventional tools that do not use LLMs for code clones with low syntactic similarity. However, even for LLM-based clone detection tools, detecting such code clones is still difficult, and there is room for improvement. In this study, we improved the accuracy of LLM-based code clone detection through fine-tuning using FEMPDataset. The results showed that our fine-tuning improved the accuracy of code clone detection.","2770-8209","979-8-3503-9134-3","10.1109/SERA61261.2024.10685589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685589","code clone;large language model;fine tuning;functionally equivalent methods","Codes;Accuracy;Source coding;Large language models;Computer bugs;Cloning;Syntactics","","5","","18","IEEE","26 Sep 2024","","","IEEE","IEEE Conferences"
"Exploring the Capability of ChatGPT in Test Generation","G. Yi; Z. Chen; Z. Chen; W. E. Wong; N. Chau","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; University of Texas at Dallas, Richardson, Texas, USA; University of Texas at Dallas, Richardson, Texas, USA","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","19 Feb 2024","2023","","","72","80","The design of test is a crucial step in the field of software testing. The quality of test significantly impacts the effectiveness of software testing, with well-designed test cases improving the efficiency of bug detection. However, manual test case design and writing are often considered time-consuming and labor-intensive. With the emergence of large language models (LLMs), especially ChatGPT, the potential of LLMs in the field of test generation has become evident. Pretrained LLMs can learn and understand code in various programming languages and design test cases using multiple testing frameworks. In this paper, we used ChatGPT to generate tests for some tested projects. Through experiments, we found that ChatGPT has some gaps compared to traditional test generation tools, but its performance is closer to manual testing. However, the tests generated by ChatGPT exhibit higher readability. We believe that ChatGPT is better suited to serve as a manual testing assistant, helping understand the tested code and providing testing ideas.","2693-9371","979-8-3503-5939-8","10.1109/QRS-C60940.2023.00013","National Natural Science Foundation of China(grant numbers:61932012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429996","Test Generation;LLM;ChatGPT","Software testing;Codes;Manuals;Writing;Chatbots;Software reliability;Test pattern generators","","9","","32","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"BSoNet: Deep Learning Solution for Optimizing Image Quality of Portable Backscatter Imaging Systems","L. Li; W. Wei; Y. Lu; W. Zhang; Y. Zhang; W. Zhao","School of Physics, Beihang University, Beijing, China; School of Physics, Beihang University, Beijing, China; Beijing Love Wisdom Fashion Technology Company, Ltd., Beijing, China; School of Physics, Beihang University, Beijing, China; Beijing Love Wisdom Fashion Technology Company, Ltd., Beijing, China; Tianmushan Laboratory and Hangzhou International Innovation Institute, Beihang University, Hangzhou, China",IEEE Transactions on Computational Imaging,"20 May 2025","2025","11","","650","662","Portable backscatter imaging systems (PBI) integrate an X-ray source and detector in a single unit, utilizing Compton scattering photons to rapidly acquire superficial or shallow structural information of an inspected object through single-sided imaging. The application of this technology overcomes the limitations of traditional transmission X-ray detection, offering greater flexibility and portability, making it the preferred tool for the rapid and accurate identification of potential threats in scenarios such as borders, ports, and industrial nondestructive security inspections. However, the image quality is significantly compromised due to the limited number of Compton-backscattered photons. The insufficient photon counts result primarily from photon absorption in materials, the pencil-beam scanning design, and short signal sampling times. It therefore yields severe image noise and an extremely low signal-to-noise ratio, greatly reducing the accuracy and reliability of PBI systems. To address these challenges, this paper introduces BSoNet, a novel deep learning-based approach specifically designed to optimize the image quality of PBI systems. The approach significantly enhances image clarity, recognition, and contrast while meeting practical application requirements. It transforms PBI systems into more effective and reliable inspection tools, contributing significantly to strengthening security protection.","2333-9403","","10.1109/TCI.2025.3567817","Natural Science Foundation of Zhejiang Province(grant numbers:LZ23A050002); National Natural Science Foundation of China(grant numbers:12175012); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990033","Portable backscatter imaging systems (PBI);deep learning;image optimization;convolutional neural network;transformer models","Imaging;Backscatter;Photonics;X-ray imaging;Security;Detectors;Scattering;Image quality;Optimization;Inspection","","1","","49","IEEE","7 May 2025","","","IEEE","IEEE Journals"
"Intelligent Flagged Content Detection with Transformer-Based Models for Secure Online Environments","R. S. Lakshmi Balaji; G. Abirami; S. Suwannakhun; T. C S; T. Yingthawornsuk","Department of Advanced Computing Sciences, Academy of Maritime Education and Training University (AMET), Chennai, India; Department of Computer Science and Engineering, Academy of Maritime Education and Training University (AMET), Chennai, India; Faculty of Industrial Education and Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand; National Cadet Corps Govt of India, Tamil Nadu, India; Department of Media Technology, King Mongkut's University of Technology Thonbur, Bangkok, Thailand",2025 13th International Electrical Engineering Congress (iEECON),"9 May 2025","2025","","","1","6","The increasing volume of user-generated content on global online platforms has made it very crucial to detect and moderate harmful content like criminal activities, illegal substances, extremist codewords, and other prohibited materials across multiple languages. In this study, we present an intelligent system for detecting flagged content using advanced transformer-based models such as BERT, RoBERTa, XLNet, and T5. These models have been further trained to very accurately and effectively detect from illegal activities to extreme language and drug related content. Our method surpasses previous methods of content moderation achieving great improvements in classification accuracy, precision, recall and F1-score. Furthermore, the implemented system enables offline or online real-time process and therefore large-scale throughput. It also gives a detailed overview of the architectural designs of the model, training processes and other problems faced during the model development stage. The results illustrate the power of transformer-based models in offering a robust strategy for automated detection of flagged content across languages to help in cultivating better online safety. This research also contributes to SDG 16 by enhancing online security and SDG 10 by promoting fairer digital spaces. The study concludes with a discussion on potential applications in social media moderation, law enforcement, and global security agencies and future research aimed at improving detection capabilities.","","979-8-3315-4395-2","10.1109/iEECON64081.2025.10987682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987682","flagged content detection;transformer models;BERT;content moderation;extremist words;multilingual detection;illegal activities;real-time processing","Training;Accuracy;Law enforcement;Social networking (online);User-generated content;Transformers;Throughput;Real-time systems;Multilingual;Security","","","","14","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
"Diff-GO: Diffusion Goal-Oriented Communications with Ultra-High Spectrum Efficiency","A. Wijesinghe; S. Zhang; S. Wanninayaka; W. Wang; Z. Ding","University of California, Davis, CA, USA; University of Louisiana at Lafayette, LA, USA; University of California, Davis, CA, USA; University of California, Davis, CA, USA; University of California, Davis, CA, USA",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","1079","1084","Recent advances in artificial intelligence (AI) present many unprecedented opportunities to achieve much improved bandwidth savings in communications. Unlike conventional communication systems focusing on packet transport, rich datasets and AI makes it possible to efficiently transfer only the information most critical to the goals of message recipients. This work presents an ultra-efficient communication design by utilizing generative AI-based diffusion models as a specific example of the general goal-oriented communication framework. To better control the regenerated message at the receiver output, our diffusion system design includes a local regeneration module with finite-dimensional noise latent. The critical significance of noise latent control and sharing residing on our Diff-GO is the ability to introduce the concept of “local generative feedback” (Local-GF), which enables the transmitter to monitor the quality and gauge the quality or accuracy of the message recovery at the semantic system receiver. To this end, we propose a new low-dimensional noise space for the training of diffusion models, which significantly reduces the communication overhead and achieves satisfactory message recovery performance. Our experimental results demonstrate that the proposed noise space and the diffusion-based generative model achieve ultra-high spectrum efficiency and accurate recovery of transmitted image signals. By trading off computation for bandwidth efficiency (C4BE), this new framework provides an important avenue to achieve exceptional computation-bandwidth tradeoff.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615283","National Science Foundation(grant numbers:2029027,2009001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615283","Goal-oriented;diffusion model;generative AI;local generative feedback;computation for bandwidth efficiency","Accuracy;Spectral efficiency;Transmitters;Conferences;Computational modeling;Noise;Receivers","","","","25","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"QUASAR: QUality and Aesthetics Scoring With Advanced Representations","S. Kastryulin; D. Prokopenko; A. Babenko; D. V. Dylov","Skolkovo Institute of Science and Technology, Moscow, Russia; Department of Biomedical Computing, King’s College London, London, U.K.; Yandex, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia",IEEE Access,"6 Nov 2024","2024","12","","160946","160956","This paper introduces a new data-driven, non-parametric method for image quality and aesthetics assessment, surpassing existing approaches and requiring no prompt engineering or fine-tuning. We eliminate the need for expressive textual embeddings by proposing efficient image anchors in the data. Through extensive evaluations of seven state-of-the-art self-supervised models, our method demonstrates superior performance and robustness across various datasets and benchmarks. Notably, it achieves high agreement with human assessments even with limited data and shows high robustness to the nature of data and their pre-processing pipeline. Our contributions offer a streamlined solution for assessment of images while providing insights into the perception of visual information. The source code of our method can be found at https://github.com/photosynthesis-team/QUASAR.","2169-3536","","10.1109/ACCESS.2024.3487010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736587","Foundation models;image quality assessment;metrics and benchmarks;multi-modal representations;self-supervised learning","Image quality;Measurement;Benchmark testing;Robustness;Solid modeling;Text to image;Pipelines;Distortion;Data models;Data mining","","","","46","CCBYNCND","28 Oct 2024","","","IEEE","IEEE Journals"
"SSFuzz: State-Guided Fuzzing With Shared Feedback for Black-Box IoT Devices","L. Hou; P. Liu; J. Ding; J. Sheng; H. Le; Y. Chen; W. Wang","College of Control Science and Engineering, Zhejiang University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; China Tobacco Zhejiang Industrial CO, LTD, Hangzhou, China; China Tobacco Zhejiang Industrial CO, LTD, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","The rapid growth of Internet of Things (IoT) devices has enhanced convenience but introduced significant security risks. Due to limited visibility into device internals, black-box fuzzing has become the primary method for IoT vulnerability detection. However, it is often difficult to recognize the triggered states, which limits the ability to explore different regions of the state space and, as a result, hinders the discovery of vulnerabilities. Additionally, it lacks feedback, preventing the fuzzer from refining its test inputs based on the results and reducing its effectiveness in discovering vulnerabilities. To address these challenges, we propose SSFuzz, an automated black-box fuzzing framework leveraging large language models (LLMs) to extract state nodes from interaction messages, enabling a state-guided approach. Additionally, we design a cross-device feedback-sharing mechanism based on source code similarities, aiming to make more effective use of the limited feedback available. Evaluated against five leading tools on 18 IoT devices, SSFuzz identified 38 previously undisclosed vulnerabilities, significantly outperforming existing methods. SSFuzz discovered 38 previously unknown vulnerabilities, significantly outperforming Snipuzz (5 vulnerabilities) and IoTHunter (1 vulnerability).","2327-4662","","10.1109/JIOT.2025.3587299","Fellowship of China National Postdoctoral Program for Innovative Talents(grant numbers:BX20230307); National Natural Science Foundation of China(grant numbers:62302443); Fundamental Research Funds for the Central Universities(grant numbers:Zhejiang University NGICS Platform+226-2024-00048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11075858","IoT communication;Large language model;Fuzzing;IoT security;IoT devices","Fuzzing;Internet of Things;Protocols;Closed box;Codes;Static analysis;Source coding;Security;Microprogramming;Space exploration","","","","","IEEE","10 Jul 2025","","","IEEE","IEEE Early Access Articles"
"3D Part Segmentation via Geometric Aggregation of 2D Visual Features","M. Garosi; R. Tedoldi; D. Boscaini; M. Mancini; N. Sebe; F. Poiesi",University of Trento; University of Trento; Fondazione Bruno Kessler; University of Trento; University of Trento; Fondazione Bruno Kessler,2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),"8 Apr 2025","2025","","","3257","3267","Supervised 3D part segmentation models are tailored for a fixed set of objects and parts, limiting their transferability to open-set, real-world scenarios. Recent works have explored vision-language models (VLMs) as a promising alternative, using multi-view rendering and textual prompting to identify object parts. However, naively applying VLMs in this context introduces several drawbacks, such as the need for meticulous prompt engineering, and fails to leverage the 3D geometric structure of objects. To address these limitations, we propose COPS, a COmprehensive model for Parts Segmentation that blends the semantics extracted from visual concepts and 3D geometry to effectively identify object parts. COPS renders a point cloud from multiple viewpoints, extracts 2D features, projects them back to 3D, and uses a novel geometric-aware feature aggregation procedure to ensure spatial and semantic consistency. Finally, it clusters points into parts and labels them. We demonstrate that COPS is efficient, scalable, and achieves zero-shot state-of-the-art performance across five datasets, covering synthetic and real-world data, texture-less and coloured objects, as well as rigid and non-rigid shapes. The code is available at https://3d-cops.github.io.","2642-9381","979-8-3315-1083-1","10.1109/WACV61041.2025.00322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943567","3d part segmentation;vision foundation models;zero-shot;training-free","Point cloud compression;Solid modeling;Visualization;Three-dimensional displays;Foundation models;Shape;Semantics;Feature extraction;Rendering (computer graphics);Object recognition","","","","59","IEEE","8 Apr 2025","","","IEEE","IEEE Conferences"
"An Intrusion Detection System Dataset for a Multi-Agent Cyber-Physical Conveyor System","G. Funchal; F. Zahid; V. Melo; M. M. Y. Kuo; T. Pedrosa; R. Sinha; F. de la Prieta; P. Leitao","Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politecnico de Braganca, Braganca, Portugal; Computer Science and Software Engineering Department, Auckland University of Technology, Auckland, New Zealand; Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politecnico de Braganca, Braganca, Portugal; Computer Science and Software Engineering Department, Auckland University of Technology, Auckland, New Zealand; Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politecnico de Braganca, Braganca, Portugal; Computer Science and Software Engineering Department, Auckland University of Technology, Auckland, New Zealand; BISITE Digital Innovation hub, University of Salamanca, Salamanca, Spain; Research Centre in Digitalization and Intelligent Robotics (CeDRI), Instituto Politecnico de Braganca, Braganca, Portugal",2023 IEEE International Conference on Industrial Technology (ICIT),"9 Jun 2023","2023","","","1","6","Industry 4.0 is built upon the foundation of connecting devices and systems via Internet of Things (IoT) technologies, with Cyber- Physical Systems (CPS) serving as the backbone infrastructure. Although this approach brings numerous benefits like improved performance, responsiveness and reconfigurability, it also introduces security concerns, making devices and systems vulnerable to cyber attacks. There is a need for effective techniques to protect these systems, and the availability of datasets becomes essential to support the development of such techniques. This paper presents a dataset based on the collection of traffic information exchanged in a self-organizing conveyor system using the multi-agent systems (MAS) architecture and containing various intelligent conveyor modules. The dataset comprises data collected at the network and agent levels under normal system operation, denial of service (DoS) attacks, and malicious agent attacks. An intrusion detection system that integrates Fast Fourier Transform (FFT) and Machine Learning (ML) analysis is developed to demonstrate the utility of this dataset.","2643-2978","979-8-3503-3650-4","10.1109/ICIT58465.2023.10143037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10143037","Cyber-security;Cyber-Physical System;Denial of Service (DoS);Dataset;Machine Learning","Performance evaluation;Fast Fourier transforms;Systems operation;Intrusion detection;Machine learning;Fourth Industrial Revolution;Internet of Things","","","","16","IEEE","9 Jun 2023","","","IEEE","IEEE Conferences"
"Evaluating Multimodal Vision-Language Model Prompting Strategies for Visual Question Answering in Road Scene Understanding","A. Keskar; S. Perisetla; R. Greer","University of California, Merced; University of California, Merced; University of California, Merced",2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW),"29 Apr 2025","2025","","","937","946","Understanding complex traffic scenes is a crucial challenge in advancing autonomous driving systems. Visual Question Answering (VQA) tasks have emerged as a promising approach to extracting actionable insights from multimodal traffic data, enabling vehicles to make accurate, real-time decisions. The MAPLM-QA dataset, introduced as part of the 2025 WACV Large Language Vision Models Challenge for Autonomous Driving (LLVM-AD), offers a robust benchmark for this task, comprising 14,000 multi-modal frames combining high-resolution panoramic images and rendered Bird's Eye View (BEV) depictions of LiDAR 3D point clouds. In this work, we explore the application of NVIDIA's Vision-Language Model (ViLA) to address VQAs in MAPLM-QA. By employing detailed prompt engineering tailored to the dataset, we systematically evaluate ViLA's performance, identifying strengths in certain metrics such as quality assessment while highlighting challenges in lane counting, intersection recognition, and nuanced scene understanding. Our findings illustrate the potential of Vision-Language Models (VLMs) in enhancing traffic scene analysis and autonomous driving, establishing a strong foundation and analysis of limitations for future research in leveraging VLMs and multimodal datasets toward scalable, robust traffic scene understanding.","2690-621X","979-8-3315-3662-6","10.1109/WACVW65960.2025.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972502","vision-language models;autonomous driving;safety;multimodal machine learning;foundation models","Point cloud compression;Visualization;Solid modeling;Three-dimensional displays;Roads;Question answering (information retrieval);Real-time systems;Quality assessment;Prompt engineering;Autonomous vehicles","","","","30","IEEE","29 Apr 2025","","","IEEE","IEEE Conferences"
"Towards Early Warning and Migration of High-Risk Dormant Open-Source Software Dependencies","Z. Huang; L. Cai; X. Mao; K. Yang","Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai Development Center of Computer Software Technology, Shanghai, China; Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai Development Center of Computer Software Technology, Shanghai, China; Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai, China; Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai Development Center of Computer Software Technology, Shanghai, China",2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),"10 Jun 2025","2025","","","121","125","Dormant open-source software (OSS) dependencies are no longer maintained or actively developed, their related code components are more vulnerable and error-prone since they can hardly keep up with evolving software dependents. Presently, their migration remains costly and challenging for practitioners. To tackle such a challenge, we intend to characterize, predict, and automatically migrate high-risk dormant OSS dependencies. Our pilot study of 4,945 Maven dependencies reveals over half of them are dormant, and 12.15% pose a high security risk. These high-risk dependencies can be predicted early based on their version release and usage characteristics. They are rarely migrated by developers, and simple one-to-one API migrations can be achieved with little context using Large Language Models (LLMs). Future research will be conducted on a more complete dataset, incorporate socio-technical features for improved high-risk prediction, and fine-tune a migration code generator.","2832-7632","979-8-3315-3711-1","10.1109/ICSE-NIER66352.2025.00030","China Postdoctoral Science Foundation; State Grid Hebei Energy Technology Service; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023967","dependency migration;open source sustainability;supply chain security;empirical software engineering","Analytical models;Codes;Large language models;Supply chains;Predictive models;Security;Sustainable development;Open source software;Software engineering;Context modeling","","","","30","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"Revisiting SWE-Bench: On the Importance of Data Quality for LLM-Based Code Models","R. Aleithan","Lassonde School of Engineering York University, Toronto, Canada",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","235","236","The use of Large Language Models (LLMs) for code generation has emerged as a rapidly growing field, gaining substantial traction within software engineering. However, ensuring the reliability and accuracy of generated code requires robust evaluation frameworks. To address this gap, Carlos et al. introduced the SWE-bench dataset, which consists of 2,294 GitHub issues paired with their corresponding pull requests, collected from 12 prominent Python repositories. This dataset has become a key benchmark for evaluating code generation models, with resolution rates prominently featured on the SWE-bench leaderboard. Despite its widespread adoption, the dataset has yet to undergo a systematic reliability assessment. Motivated by this gap, we conducted the first empirical study aimed at evaluating the reliability of the SWE-Bench dataset to ensure it provides meaningful and realistic model evaluations. We centered our analysis on the highest-performing model reported on the leaderboard at the time of the study: SWE-Agent + GPT-4. A thorough investigation was conducted by comparing the model-generated patches with the corresponding pull requests from the dataset. Our findings revealed two key issues: (1) 32.67% of successful cases were influenced by solution leakage, and (2) 31.08% succeeded due to weak test cases. When these problematic instances were excluded, the resolution rate of SWE-Agent + GPT-4 dropped from 12.47% to 3.97%.","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024333","","Codes;Accuracy;Systematics;Large language models;Robustness;Data models;Software reliability;Software engineering;Software development management;Python","","","","11","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Analysis of Cybersecurity Measures for Detection, Prevention, and Misbehaviour of Social Systems","A. Imtiaz; D. Shehzad; F. Nasim; M. Afzaal; M. Rehman; A. Imran","Department of Computer Science, Riphah International University, Lahore, Pakistan; Department of Computer Science, Superior University, Lahore, Pakistan; Department of Computer Science, Superior University, Lahore, Pakistan; College of Engineering, Al Ain University, Al Ain, UAE; Department of Computer Science, Superior University, Lahore, Pakistan; Department of Computer Science, Superior University, Lahore, Pakistan","2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)","2 Jan 2024","2023","","","1","7","The rapid proliferation of digital financial products has given rise to profound challenges in safeguarding consumer interests, notably concerning fraud and scams. These issues, which carry the potential to erode trust in digital services, are especially pronounced in developing nations. Consequently, preventing victimization has emerged as a paramount policy imperative. Notably, recent revelations have illustrated the misuse of Large Language Models (LLMs) for fraudulent activities, impersonation, and the generation of malicious software. Concurrently, other researchers have delved into the broader issue of AI alignment. This underscores the imperative for both developers and practitioners to remain cognizant of the security-related challenges posed by such models. The detection of online sexual predatory behaviors and the combatting of abusive language on social media platforms have assumed paramount importance in contemporary research. This concern is driven by mounting apprehensions surrounding online safety, particularly for vulnerable segments of the population, including children and adolescents. Researchers have been diligently exploring diverse techniques and approaches to devise effective detection systems capable of identifying and mitigating these inherent risks. This paper conducts a comprehensive analysis of prevalent challenges spanning various global sectors and assesses their far-reaching consequences. Additionally, it undertakes an evaluation of the associated hurdles while identifying optimal strategies to address these multifaceted challenges.","2831-7343","979-8-3503-1890-6","10.1109/SNAMS60348.2023.10375405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375405","Large Scale Models;Online Safety;social media;Security Solutions","Social networking (online);Law enforcement;Sociology;Organizations;Message services;Fraud;Information and communication technology","","","","24","IEEE","2 Jan 2024","","","IEEE","IEEE Conferences"
"Index","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","315","322","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310597.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"A Review of Recent Advances, Challenges, and Opportunities in Malicious Insider Threat Detection Using Machine Learning Methods","F. R. Alzaabi; A. Mehmood","College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates",IEEE Access,"1 Mar 2024","2024","12","","30907","30927","Insider threat detection has become a paramount concern in modern times where organizations strive to safeguard their sensitive information and critical assets from malicious actions by individuals with privileged access. This survey paper provides a comprehensive overview of insider threat detection, highlighting its significance in the current landscape of cybersecurity. The review encompasses a broad spectrum of methodologies and techniques, with a particular focus on classical machine-learning approaches and their limitations in effectively addressing the intricacies of insider threats. Furthermore, the survey explores the utilization of modern deep learning and natural language processing (NLP) based methods as promising alternatives, shedding light on their advantages over traditional methods. The comprehensive analysis of results from experiments utilizing NLP and large language models to detect malicious insider threats on the CMU CERT dataset reveals promising insights. Studies surveyed in this paper indicate that these advanced techniques demonstrate notable efficacy in identifying suspicious activities and anomalous behaviors associated with insider threats within organizational systems. Additionally, the survey underscores the potential of NLP and large language model-based approaches, which can enhance threat detection by deciphering textual and contextual information. In the conclusion section, the paper offers valuable insights into the future directions of insider threat detection. It advocates for the integration of more sophisticated time-series-based techniques, recognizing the importance of temporal patterns in insider threat behaviors. These recommendations reflect the evolving nature of insider threats and emphasize the need for proactive, data-driven strategies to safeguard organizations against internal security breaches. In conclusion, this survey not only underscores the urgency of addressing insider threats but also provides a roadmap for the adoption of advanced methodologies to enhance detection and mitigation capabilities in contemporary cybersecurity paradigms.","2169-3536","","10.1109/ACCESS.2024.3369906","Abu Dhabi University’s Office of Research and Grant Programs; Abu Dhabi University’s office of sponsored programs in the United Emirates funded this endeavor(grant numbers:19300752); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445123","Insider threat detection;privilege escalation;anomaly detection;user action graph;cyber security;user behavior;temporal information;pre-trained language models;word embedding;CERT dataset","Threat assessment;Behavioral sciences;Security;Surveys;Data breach;Telecommunication traffic;Reviews;Malware;Classification algorithms;Natural language processing;Time series analysis","","57","","93","CCBYNCND","26 Feb 2024","","","IEEE","IEEE Journals"
"Exploring Zero-Shot Prompting for Generating Data Format Descriptions","P. Anantharaman; V. Varadharaju",Narf Industries; Narf Industries,2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","1","15","Parsers validate and process untrusted user input and transform it into data structures that provide easier access. Software engineers either build these parsers for data formats from scratch or leverage libraries targeting specific formats. The recent surge in data description languages (DDLs) and parser combinator libraries for parsing data formats has aided developers in producing parsers using standardized tools. However, producing a parser for an unfamiliar data format in an unfamiliar DDL can be daunting, given the learning curve of understanding two specifications or manuals well. As more researchers adopt tools such as GitHub Copilot [39] to simplify their programming tasks, we ask whether LLMs already hold sufficient knowledge to produce valid DDL specifications for popular data formats. To explore this, we systematically prompt LLMs to provide specifications in valid DDL syntax and evaluate whether these specifications are syntactically valid and correct. We found that while some LLMs, such as GPT 4 Turbo, Claude 3.5 Sonnet, and Deepseek V3, can produce valid Kaitai Struct YAML files, Hammer C files, and Rust Nom files, they struggle to produce valid specifications in complex DDLs, such as DaeDaLus, Spicy, and DFDL. In general, all LLMs fare much better at producing syntactically valid C code using the Hammer library and Rust code using the Nom library, given the large corpora of valid C and Rust code available. None of the LLMs in our test were able to produce a valid DFDL file or DaeDaLus file. We also found that while providing the specification manuals for the DDLs did not help in producing more syntactically valid specifications, providing sample specification files modestly increased the number of successful compilations.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050832","data description languages;language-theoretic security;data formats;parser generation","Codes;Manuals;Transforms;Syntactics;Programming;Libraries;Software;Security;Surges;Software development management","","","","53","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"JavaLLM: A Fine-Tuned LLM for Java Programming Education","J. Zhang; K. Liu","School of Information Science and Engineering, Hunan Urban Professional College, Changsha, China; School of Information Science and Engineering, Hunan Urban Professional College, Changsha, China",2024 8th International Symposium on Computer Science and Intelligent Control (ISCSIC),"14 Mar 2025","2024","","","276","280","The integration of Large Language Models (LLMs) into education marks a significant advancement toward personalized and adaptive learning environments, particularly in programming education. Addressing the limitations of existing LLMs in specialized domains like Java programming, this paper introduces JavaLLM — a model specifically tailored for Java programming education. Built upon a robust codeLLM and fine-tuned using extensive, high-quality Java-focused datasets, JavaLLM demonstrates superior performance in code generation and Java-specific question answering. Through rigorous evaluation and iterative refinement, JavaLLM facilitates a transformative classroom experience, enhancing the quality of teaching and enabling a personalized learning journey for students in Java programming courses. This innovation paves the way for smarter, more tailored educational approaches, leveraging AI’s generative capabilities to meet the evolving demands of modern education.","","979-8-3503-8028-6","10.1109/ISCSIC64297.2024.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10914617","Large Language Model;Java Education;Fine-tuning","Java;Adaptation models;Technological innovation;Codes;Large language models;Education;Question answering (information retrieval);Iterative methods;Programming profession;Intelligent control","","","","32","IEEE","14 Mar 2025","","","IEEE","IEEE Conferences"
"Language Models at the Edge: A Survey on Techniques, Challenges, and Applications","S. Hadish; V. Bojković; M. Aloqaily; M. Guizani","Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE",2024 2nd International Conference on Foundation and Large Language Models (FLLM),"28 Jan 2025","2024","","","262","271","The invention of the transformer architectures has spurred Large Language Models (LLMs) to the forefront of artificial intelligence, driving state-of-the-art advancements across various domains. However, the huge scale of these models, often comprising hundreds of billions of parameters, presents significant challenges in terms of computational resources for both training and deployment. Consequently, the development and implementation of LLMs have largely been confined to major technology corporations. Recent research has focused on addressing these limitations by developing compact LLMs capable of operating on edge devices, rather than relying on centralized server infrastructure. This approach offers numerous benefits, including reduced computational costs, lower latency, enhanced security, and the potential for task-specific, specialized models. This paper examines the latest research trends and developments in the field of compact LLMs, exploring their applications and discussing the challenges associated with their implementation. Our investigation aims to provide insights into the future landscape of accessible and efficient language models.","","979-8-3503-5479-9","10.1109/FLLM63129.2024.10852473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852473","AI;ML;LLM;Edge Computing;Edge AI;EdgeLLM;Model Compression","Training;Surveys;Technological innovation;Computational modeling;Large language models;Computer architecture;Transformers;Market research;Servers;Security","","","","70","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"CoUpJava: A Dataset of Code Upgrade Histories in Open-Source Java Repositories","K. Jiang; B. Jin; P. Nie","University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","441","445","Modern programming languages are constantly evolving, introducing new language features and APIs to enhance software development practices. Software developers often face the tedious task of upgrading their codebase to new programming language versions. Recently, large language models (LLMs) have demonstrated potential in automating various code generation and editing tasks, suggesting their applicability in automating code upgrade. However, there exists no benchmark for evaluating the code upgrade ability of LLMs, as distilling code changes related to programming language evolution from real-world software repositories’ commit histories is a complex challenge. In this work, we introduce CoUpJava, the first large-scale dataset for code upgrade, focusing on the code changes related to the evolution of Java. CoUpJava comprises 10,697 code upgrade samples, distilled from the commit histories of 1,379 open-source Java repositories and covering Java versions 7–23. The dataset is divided into two subsets: CoUpJava-FINE, which captures fine-grained method-level refactorings towards new language features; and CoUpJava-COARSE, which includes coarse-grained repository-level changes encompassing new language features, standard library APIs, and build configurations. Our proposed dataset provides high-quality samples by filtering irrelevant and noisy changes and verifying the compilability of upgraded code. Moreover, CoUpJava reveals diversity in code upgrade scenarios, ranging from small, fine-grained refactorings to large-scale repository modifications.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00075","Natural Sciences and Engineering Research Council of Canada; University of Waterloo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025747","Code upgrade;software evolution;Java;dataset;benchmark","Java;Computer languages;Codes;Benchmark testing;Software;Libraries;History;Noise measurement;Standards;Software development management","","","","32","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Poster: gptCombFuzz: Combinatorial Oriented LLM Seed Generation for effective Fuzzing","D. Lohiya; M. R. Golla; S. Godboley; P. R. Krishna","Department of Computer Science and Engineering, NITMiner Technologies, NATIONAL INSTITUTE OF TECHNOLOGY, WARANGAL, WARANGAL, TELANGANA, INDIA; Department of Computer Science and Engineering, NITMiner Technologies, NATIONAL INSTITUTE OF TECHNOLOGY, WARANGAL, WARANGAL, TELANGANA, INDIA; Department of Computer Science and Engineering, NITMiner Technologies, NATIONAL INSTITUTE OF TECHNOLOGY, WARANGAL, WARANGAL, TELANGANA, INDIA; Department of Computer Science and Engineering, NITMiner Technologies, NATIONAL INSTITUTE OF TECHNOLOGY, WARANGAL, WARANGAL, TELANGANA, INDIA","2024 IEEE Conference on Software Testing, Verification and Validation (ICST)","27 Aug 2024","2024","","","438","441","The important contribution that large language models (LLMs) have made to the development of a new software testing era is the main objective of this proposed approach. It emphasizes the role that LLMs play in producing complex and diverse input seeds, which opens the way for efficient bug discovery. In the study we also introduce a systematic approach for combining various input values, employing the principles of Combinatorial testing using the PICT (Pairwise independent Combinatorial testing). By promoting a more varied set of inputs for thorough testing, PICT enhances the seed production process. Then we show how these different seeds may be easily included in the American Fuzzy Lop (AFL) tool, demonstrating how AFL can effectively use them to find and detect software flaws. This integrated technique offers a powerful yet straightforward approach to software Quality.","2159-4848","979-8-3503-0818-1","10.1109/ICST60714.2024.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638604","Large Language Model;AFL;Pairwise independent combinatorial testing","Codes;Systematics;Combinatorial testing;Large language models;Computer bugs;Software quality;Production","","","","10","IEEE","27 Aug 2024","","","IEEE","IEEE Conferences"
"Observer-Based Adaptive Synchronization of Multiagent Systems With Unknown Parameters Under Attacks","S. Wen; X. Ni; H. Wang; S. Zhu; K. Shi; T. Huang","Australian AI Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; College of Artificial Intelligence, Southwest University, Chongqing, China; School of Mathematics, China University of Mining and Technology, Xuzhou, China; School of Information Science and Engineering, Chengdu University, Chengdu, China; Science Program, Texas A&M University at Qatar, Doha, Qatar",IEEE Transactions on Neural Networks and Learning Systems,"6 Jul 2022","2022","33","7","3109","3119","This article studies the observer-based adaptive synchronization of multiagent systems (MASs) with unknown parameters under attacks. First, to estimate the state of agents, the observer for MAS is introduced. When disturbance, nonlinear function, and system model uncertainty are not considered, the nominal controller is proposed to achieve synchronization and state estimation. Then, in order to eliminate the effect of unknown parameters in the disturbance, nonlinear function, and system model uncertainty, the adaptive controller with switching term is introduced. However, the attack will lead to the destruction of the network topology so as the destruction of the nominal controller. By constructing an appropriate Lyapunov function, we analyze the effect caused by attacks, and the security control law is given to make sure the synchronization of the MASs under attacks. Finally, a numerical simulation is given to verify the validness of the obtained theorem.","2162-2388","","10.1109/TNNLS.2021.3051017","Qatar National Research Fund under NPRP(grant numbers:NPRP12C-0814-190012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340575","Adaptive control;cyberattack;multiagent system (MAS);synchronization;unknown parameter","Synchronization;Uncertainty;Observers;Network topology;Communication networks;Topology;Symmetric matrices","","20","","43","IEEE","29 Jan 2021","","","IEEE","IEEE Journals"
"Fault-Tolerant Consensus Control With Privacy-Preserving Virtual Layer for Heterogeneous Multi-Agent System","J. Liu; J. Dong","College of Information Science and Engineering, Liaoning Province Key Laboratory of Safe Operation Technique for Autonomous Unmanned Systems, and the State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; College of Information Science and Engineering, Liaoning Province Key Laboratory of Safe Operation Technique for Autonomous Unmanned Systems, and the State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China",IEEE Transactions on Automation Science and Engineering,"7 Mar 2025","2025","22","","5687","5699","The paper investigates the privacy-preserving cooperative tracking problem under actuator faults, system uncertainties and unmatched disturbances for the heterogeneous multi-agent system (MAS). The virtual system is constructed to preserve the initial states and transient processes with the dynamic perturbation method against internal and external eavesdroppers. The real system achieves tracking to the virtual system and heterogeneous consensus by the adaptive fault-tolerant (FT) controller. It is demonstrated that for groups of agents with different initial states, the designed privacy-preserving algorithm can achieve consistent output to the eavesdropper while ensuring ultimate consensus. Compared with the existing results in the privacy-preserving problem, the requirements for an accurate fault-free model are avoided by the hierarchical design approach. Simulation examples validate the effectiveness of the suggested control scheme. Note to Practitioners—The study is motivated by the privacy-preserving problem of communication between MASs, and it applies to groups like UAVs, vehicles and robots that need to exchange information to achieve common goals. There are hostile parties who eavesdrop on messages sent between agents via network interception in order to get sensitive private information. To prevent eavesdroppers from obtaining privacy of the sent information and achieve the agent group’s common objective, communication information with perturbation and corresponding control mechanisms are established. The information protected by the paper is the agent’s initial states and transient process, and the genuine states will be wrapped with dynamic perturbation signals. However, due to the interference of the real measuring mechanism and the actuator faults, precisely measuring and controlling the genuine state is challenging. As a result, this research proposes a virtual system with privacy-preserving performance. The disguised signals of virtual system are communicated between agents, while the real system is designed to track the virtual system while suppressing disturbances and faults. Future studies will concentrate on privacy preservation with security constraints.","1558-3783","","10.1109/TASE.2024.3428408","National Natural Science Foundation of China(grant numbers:62273079,61420106016); Fundamental Research Funds for the Central Universities in China(grant numbers:N2004002,N2104005,N182608004); Research Fund of the State Key Laboratory of Synthetical Automation for Process Industries in China(grant numbers:2013ZCX01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10601615","Multi-agent system (MAS);privacy preservation;virtual system;heterogeneous system;fault-tolerant control","Actuators;Privacy;Consensus control;Process control;Perturbation methods;Uncertainty;Transient analysis","","3","","40","IEEE","17 Jul 2024","","","IEEE","IEEE Journals"
"Inferring Questions from Programming Screenshots","F. Ahmed; X. Tan; F. Adewole; S. Datta; M. Nayebi","York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; York University, Toronto, ON, Canada",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","750","755","The integration of generative AI into developer forums like Stack Overflow presents an opportunity to enhance problem-solving by allowing users to post screenshots of code or Integrated Development Environments (IDEs) instead of traditional text-based queries. This study evaluates the effectiveness of various large language models (LLMs)—specifically LLAMA, GEMINI, and GPT-4o in interpreting such visual inputs. We employ prompt engineering techniques, including in-context learning, chain-of-thought prompting, and few-shot learning, to assess each model’s responsiveness and accuracy. Our findings show that while GPT-4o shows promising capabilities, achieving over $60 \%$ similarity to baseline questions for $51.75 \%$ of the tested images, challenges remain in obtaining consistent and accurate interpretations for more complex images. This research advances our understanding of the feasibility of using generative AI for image-centric problem-solving in developer communities, highlighting both the potential benefits and current limitations of this approach while envisioning a future where visual-based debugging copilot tools become a reality.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025629","Large language model;stack overflow","Visualization;Accuracy;Large language models;Debugging;Programming;Software;Problem-solving;Prompt engineering;Data mining;Few shot learning","","","","47","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"An Improved Defender–Attacker–Defender Model for Transmission Line Defense Considering Offensive Resource Uncertainties","Y. Xiang; L. Wang","GEIRI North America, San Jose, CA, USA; GEIRI North America, San Jose, CA, USA",IEEE Transactions on Smart Grid,"22 Apr 2019","2019","10","3","2534","2546","Developing efficient strategies for defending electric power systems against attacks is a major concern for contemporary power grids, especially when uncertainties are involved. This paper addresses the allocation of the defensive resource to minimize the damage when there are uncertainties regarding the resource that the attacker has. A multiple-attack-scenario (MAS) defender-attacker-defender (DAD) model is proposed by extending the conventional trilevel DAD model. The proposed model considers the uncertainties related to the offensive resource and the interactions involving the security personnel at the top-level, the attacker at the middle-level, and the power system operator at the bottom-level. The column-and-constraint generation algorithm is implemented by decomposing the MAS DAD model into an upper-level problem for the security personnel, and a lower-level problem for the attacker involving the optimal power flow analysis-based corrective power redispatch implemented by the power system operator. Case studies are performed based on the IEEE RTS79 and 57-bus systems, and the results validate that the proposed method is able to minimize the damage when uncertainties are involved in the offensive resource. This paper can offer meaningful insights into power system protection involving uncertainties.","1949-3061","","10.1109/TSG.2018.2803783","National Science Foundation(grant numbers:ECCS1711617,ECCS1739485); Research Growth Initiative Program of the University of Wisconsin–Milwaukee(grant numbers:101X360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286941","Robust optimization;power system security;trilevel programming;power system uncertainty","Uncertainty;Optimization;Power grids;Security;Robustness;Programming","","72","","34","IEEE","8 Feb 2018","","","IEEE","IEEE Journals"
"Designing for Emergent Security in Heterogeneous Human-Machine teams","P. N. Brown","Department of Computer Science, University of Colorado, Colorado Springs",2019 IEEE 58th Conference on Decision and Control (CDC),"12 Mar 2020","2019","","","2175","2180","This work seeks to design decisionmaking rules for autonomous agents to jointly influence and optimize the behavior of teamed human decisionmakers in the presence of an adversary. We study a situation in which computational jobs are scheduled on servers by a collection of autonomous machines in concert with self-interested human decisionmakers, and the human and machine schedulers must react to an adversary's attack on one of the servers. We show a simple machine scheduling policy such that if all schedulers have permission to schedule jobs on all servers, increasing the penetration of machine schedulers always increases the level of security in the system, even when the machine schedulers have no explicit coordination or communication amongst themselves. However, we show a companion result in which simple constraints on server availability can nullify the machine schedulers' ability to effectively influence human schedulers; here, even if machine schedulers control an overwhelming majority of jobs, are socially-aware, and fully coordinated amongst themselves, they are incapable of influencing human decisionmakers to mitigate the harm of an attack.","2576-2370","978-1-7281-1398-2","10.1109/CDC40024.2019.9030174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9030174","","Servers;Security;Delays;Optimal scheduling;Aggregates;Man-machine systems;Autonomous agents","","","","22","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"The Zero-trust Paradigm: Concepts, Architectures and Applications","C. Katsis; E. Bertino",NA; NA,"The Zero-trust Paradigm: Concepts, Architectures and Applications","","2025","","","","","Existing measures aimed at securing network perimeters have demonstrated insufficiency in preventing breaches within an organization’s infrastructure. This inadequacy stems from the escalating resource capabilities of adversaries and the increasing sophistication of multi-step attack strategies, rendering breaches feasible. Zero Trust Architecture (ZTA), also known as perimeter-less security, is a recent paradigm that challenges the conventional notion of network security by considering both internal and external networks as potentially compromised and that threats exist at all times in the network. The notion of ZTA has been introduced as a fine-grained defense approach. It assumes that no entities outside and inside the protected system can be trusted and, therefore, requires articulated and high coverage deployment of security controls. However, ZTA is a complex notion that does not have a single design solution, rather, it consists of numerous interconnected concepts and processes that need to be assessed prior to deciding on a solution. In this monograph, the authors cover the principles and architectural foundations of ZTA following the guidelines by NIST, and provide a detailed analysis of ZTA proposed by research and industry. The monograph also describes an approach for the automatic generation of Zero Trust (ZT) policies based on application communication requirements, network topology, and organizational information. This approach was designed to meet a critical need of ZTA, that is, the generation and implementation of a large number of fine-grained policies. Finally, the monograph discusses several research directions, including the incorporation of threat intelligence into ZT networks and the use of large language models.","","9781638285731","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11031166.pdf&bkn=11031165&pdfType=book","","","","","","","","12 Jun 2025","","","now","Now Foundations and Trends Books"
"Anomaly Detection in Security Logs using Sequence Modeling","S. Gökstorp; J. Nyberg; Y. Kim; P. Johnson; G. Dán","Division of Network and Systems Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Network and Systems Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Network and Systems Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Network and Systems Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Network and Systems Engineering, KTH Royal Institute of Technology, Stockholm, Sweden",NOMS 2024-2024 IEEE Network Operations and Management Symposium,"2 Jul 2024","2024","","","1","9","As cyberattacks are becoming more sophisticated, automated activity logging and anomaly detection are becoming important tools for defending computer systems. Recent deep learning-based approaches have demonstrated promising results in cybersecurity contexts, typically using supervised learning combined with large amounts of labeled data. Self-supervised learning has seen growing interest as a method of training models because it does not require labeled training data, which can be difficult and expensive to collect. However, existing self-supervised approaches to anomaly detection in user authentication logs either suffer from low precision or rely on large pre-trained natural language models. This makes them slow and expensive both during training and inference. Building on previous works, we therefore propose an end-to-end trained self-supervised transformer-based sequence model for anomaly detection in user authentication events. Thanks in part to an adapted masked-language modeling (MLM) learning task and domain knowledge-based improvements to the anomaly detection method, our proposed model outperforms previous long short-term memory (LSTM)-based approaches at detecting red-team activity in the ""Comprehensive, Multi-Source Cyber-Security Events"" authentication event dataset, improving the area under the receiver operating characteristic curve (AUC) from 0.9760 to 0.9989 and achieving an average precision of 0.0410. Our work presents the first application of end-to-end trained self-supervised transformer models to user authentication data in a cybersecurity context, and demonstrates the potential of transformer-based approaches for anomaly detection.","2374-9709","979-8-3503-2793-9","10.1109/NOMS59830.2024.10575561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575561","cybersecurity;misuse detection;anomaly detection;sequence modeling;machine learning;transformer;LSTM","Training;Adaptation models;Computational modeling;Authentication;Training data;Self-supervised learning;Transformers","","2","","25","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"From Deepfakes to Digital Truths: The Role of Watermarking in AI-Generated Image Verification","J. J. Thakkar; A. Kaur","Dept of Computer Science, New Jersey Institute of Technology, New Jersey, USA; Dept of Computer Science, New Jersey Institute of Technology, New Jersey, USA",2024 47th International Conference on Telecommunications and Signal Processing (TSP),"30 Jul 2024","2024","","","216","222","The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.","2768-3311","979-8-3503-6559-7","10.1109/TSP63128.2024.10605975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605975","Artificial Intelligence;Content Authentication;Deepfake Detection;Digital Media Integrity;Digital Watermarking;Generative AI;Machine Learning","Deepfakes;Ethics;Reviews;Watermarking;Pressing;Learning (artificial intelligence);Media","","1","","29","IEEE","30 Jul 2024","","","IEEE","IEEE Conferences"
"Evidences of AI powered Use Cases and Challenges in E-tailing from leading Indian E-tailers","G. Ranjit; S. Subramoniam; K. Jnaneswar","APJAKTU and CETSOM College of Engineering Trivandrum, Trivandrum, India; CET School of Management College of Engineering Trivandrum, Trivandrum, India; CET School of Management College of Engineering Trivandrum, Trivandrum, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","The paper highlights the usage and challenges of artificial intelligence in etailing, citing use cases from leading Indian etailers like Amazon and Flipkart. Both organizations have embraced artificial intelligence in a number of ways to improve its operations and enhance customer experience. AI has emerged as a powerful tool that has significantly impacted etailers throughout the globe and especially in India. The results of the study show that both etailers have harnessed the transformative capabilities of AI to secure a strong market position. While Amazon employs machine learning, chatbot assistants, product recommendations, and generative AI, Flipkart applies AI for customized search, issue detection, Microsoft partnership, project Mira to name a few. This article is a reflection of how these leading Indian e-tailers has devoted resources to developing AI capabilities and also exposes the challenges involved like security risks, perception regarding ethics, technology integration, culture wars and quality of data.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10725605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725605","artificial intelligence;e-tailing;machine learning;chatbot;generative AI;Mira","Technological innovation;Companies;Machine learning;Reflection;Product design;Quality assessment;Electronic commerce;Security;Artificial intelligence;Guidelines","","1","","21","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Securing Next-Generation Wireless Networks Against Native GenAI Attacks: An Evidence-Theoretic Approach","M. S. Munir; S. Proddatoori; M. Muralidhara; M. Gamarra; W. Saad; Z. Han; S. Shetty","School of Computing, Analytics, and Modeling, University of West Georgia, Carrollton, GA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA; Electrical and Computer Engineering, University of Houston, Houston, TX, USA; AFRL, Rome, NY, USA; Old Dominion University, Norfolk, VA, USA",2025 International Wireless Communications and Mobile Computing (IWCMC),"2 Jul 2025","2025","","","805","811","Intelligent poisoning attacks will pose fundamental challenges for sixth-generation (6G) wireless network security due to the massive deployment of native AI in radio units as well as in core networks. Network metrics and parameters, which are inherently uncertain, can become susceptible to intelligent poisoning through native generative AI (GenAI) mechanisms. In this paper, GenAI-driven intelligent attacks in wireless networks are investigated in order to understand their impact and severity by using uncertainty-informed root cause analysis. Then, a new approach for mitigating GenAI-driven attacks is proposed through the use of trustworthy service aggregation. First, a joint decision problem is formulated for generating intelligent adversarial attacks, understanding uncertain attack severity, and mitigating them in wireless networks. Second, a novel evidencetheoretic trustworthy AI (ET-TAI) framework is developed to address the formulated problem by understanding the root-cause of the native GenAI-driven intelligent attack and establishing defense in wireless networks. In particular, the proposed ET-TAI framework enables a narrow GenAI scheme that is designed to penetrate intelligent adversarial attacks in wireless networks’ metrics and parameters. Then a Dempster–Shafer-based mechanism that is deployed to capture the uncertain behavior of those intelligent attacks through prior evidence to quantify the trust for further mitigation. Extensive experimental analysis shows the proposed ET-TAI framework’s efficacy in understanding the trust in GenAI-driven intelligent poisoning attacks on network parameters and metrics by quantifying root causes and mitigating rates. Results show that the GenAI can penetrate intelligent poisoning attacks with high reconstruction capabilities of 95% for downlink services.","2376-6506","979-8-3315-0887-6","10.1109/IWCMC65282.2025.11059708","National Science Foundation; Air Force Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059708","Native Generative AI;Intelligent Attacks;Evidence Theory;Trustworthy AI","Measurement;Root cause analysis;Accuracy;Generative AI;Wireless networks;Prevention and mitigation;Autoencoders;Vectors;Security;Mutual information","","1","","12","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"AI Powered Plant Disease Detection and Diagnosis","A. Sasane; V. Yerkar; A. Wanjare; K. Zende; G. Yadav; Y. Ingle","Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence & Data Science, Vishwakarma Institute of Information Technology, Pune, India",2025 International Conference on Emerging Smart Computing and Informatics (ESCI),"9 May 2025","2025","","","1","6","Certain plant diseases cause extensive damage in agriculture; this leads results in a huge loss, and poses a major risk to food security. In general, conventional techniques of diagnosing these diseases are time- consuming, expensive and depend solely on human operator’s experience. As part of this study, we suggest an entirely new architecture for disease detection, diagnostics, and remedies using Ensemble Learning, Generative AI, and, Explainable AI (XAI). It combines deep learning method Convolutional Neural Networks (CNNs), Random Forest classifiers and transformer-based generative models to give diagnosis and suggest treatment processes. LIME and heat plots of attention make the behavior of the system clear to users and contribute to the perfect implementation of artificial intelligence technology in agriculture. This framework is also both timely and suitable for the development and practice of sustainable agriculture especially in the developing world where professional input on agriculture is hard to come by.","2996-1815","979-8-3315-1568-3","10.1109/ESCI63694.2025.10988070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988070","Plant Disease Detection;Convolutional Neural Networks (CNN);Ensemble Learning;Generative AI (GenAI);Explainable AI (XAI)","Plant diseases;Accuracy;Explainable AI;Generative AI;Soil;Transformers;Agriculture;Convolutional neural networks;Ensemble learning;Random forests","","","","19","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
"Machine Learning in Ambient Assisted Living for Enhanced Elderly Healthcare: A Systematic Literature Review","A. A. Mir; A. S. Khalid; S. Musa; M. Faizal Ahmad Fauzi; N. Norfiza Abdul Razak; T. Boon Tang","Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; Faculty of Engineering, Multimedia University, Cyberjaya, Selangor, Malaysia; Department of Electrical and Electronic Engineering, Jalan IKRAM-UNITEN, Kajang, Selangor, Malaysia; Centre for Intelligent Signal and Imaging Research, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia",IEEE Access,"2 Jul 2025","2025","13","","110508","110527","As the global population ages, Ambient Assisted Living (AAL) systems have become essential in supporting the elderly to maintain independence and quality of life. Such systems integrate advanced technologies such as machine learning (ML), internet of things (IoT), and sensors to enhance safety and healthcare delivery. However, deploying such technologies raises significant challenges, especially in managing privacy, ensuring ethical compliance, and gaining user acceptance. This systematic literature review (SLR) explores the current state and advancements in AAL technologies, with a specific focus on their applications in elderly care. It synthesizes current methodologies, including predictive analytics, Explainable AI (XAI), and Generative AI (GenAI), while also evaluating the role of vision-based systems and multi-modal data fusion. It examines how such technologies are implemented to improve lives while also highlighting critical areas requiring attention, particularly privacy and ethical considerations. The review methodically analyzes articles and papers from the year 2020, selected based on their relevance to AAL technologies, their use of ML algorithms, and their focus on elderly care. The findings reveal the need for interpretability in AI-driven decisions and the role of GenAI in synthetic data generation and personalized conversational assistants. While ML and IoT significantly enhance AAL systems through predictive healthcare and personalized interventions, they also pose substantial privacy risks. The review identifies privacy as a critical concern due to the sensitive nature of the data collected and the vulnerabilities inherent in digital systems. Issues around data privacy, security breaches, and the need for robust privacy-preserving mechanisms are recurrent themes. This SLR illustrates the potential of AAL systems in elderly care and emphasizes the crucial requirement of addressing privacy and ethical issues to ensure such technologies are both beneficial and secure. The findings serve as a foundation for understanding the current state of AAL technologies and guide future advancements in elderly healthcare.","2169-3536","","10.1109/ACCESS.2025.3580961","Government Linked University (GLU) Research Collaborative Fund (GRCF) 2023, managed by the Center for Research and Innovation (CoRI), Universiti Kuala Lumpur(grant numbers:CoRI/GRCF2023_01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039768","Ambient assisted living;elderly;explainable AI;generative AI;healthcare;Internet of Things;machine learning;predictive analytics;privacy","Older adults;Medical services;Data privacy;Sensors;Prediction algorithms;Monitoring;Ambient assisted living;Internet of Things;Ethics;Real-time systems","","","","59","CCBY","18 Jun 2025","","","IEEE","IEEE Journals"
"Llama-Recipe — Fine-Tuned Meta's Llama LLM, PBOM and NFT Enabled 5G Network-Slice Orchestration and End-to-End Supply-Chain Verification Platform","E. Bandara; S. H. Bouk; S. Shetty; S. Roy; R. Mukkamala; A. Rahman; P. Foytik; X. Liang; N. W. Keong; K. De Zoysa","Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Deloitte & Touche LLP; Old Dominion University, Norfolk, VA, USA; Florida International University, USA; Nanyang Technological University, Singapore; University of Colombo School of Computing, Sri Lanka",2025 IEEE 22nd Consumer Communications & Networking Conference (CCNC),"5 May 2025","2025","","","1","6","Modern 5G networks offer a network-sliced infrastructure where each network slice contains a dedicated 5G core software service layer. The 5G core software services in each slice shares common core network resources to meet specific customer needs. A primary challenge in 5G network slicing involves resource sharing and efficient network slice orchestration. Container-based methodologies, including tools like Docker and Kubernetes, have become popular for orchestrating 5G network slice services and managing configurations in microservices-based cloud-native service deployment. However, despite their utility, these tools present significant challenges. Their complexity often necessitates dedicated DevOps teams for effective management, while configuration management can prove arduous, and end-to-end supply chain oversight is lacking. To address these challenges, this paper introduces “Llama-Recipe,” a cloud-native 5G-core service deployment and orchestration platform integrating Generative AI, SBOM, PBOM and NFT. 5G-core service configurations across different network slices are represented as “HOCON (Human-Optimized Config Object Notation)” config objects adhering to the GitOps paradigm. Leveraging custom-trained Meta's Llama2 LLM, Llama-Recipe generates the Kubernetes manifests for network-sliced 5G-core services based on the defined HOCON configurations. The generated Kubernetes manifests of the 5G-core services are deployed in designated Kubernetes clusters utilizing GitOps tools (e.g., ArgoCD), ensuring seamless and automated deployment processes. Additionally, Llama-Recipe introduced a novel mechanism to handle end-to-end supply chain verification of 5G-core software services using Software-Bill of Materials (SBOM) and Pipeline-Bill of Materials (PBOM). SBOMs track all the dependencies and PBOMs facilitate the comprehensive tracking of end-to-end supply chain data for 5G-core software services, enhancing transparency and security. These PBOMs are also generated using the fine-tuned Meta's Llama-2 LLM and are encoded as NFT tokens with a novel NFT token schema. This schema enables easy verification and validation of supply-chain data during deployments, thus helping to prevent various supply-chain attacks. To fine-tune the Meta's Llama2 LLM, we've undertaken a meticulous training process, collaborating with Qlora to transform a 4-bit quantized pre-trained language model into Low-Rank Adapters(LoRA). The effectiveness of the Llama-Recipe is demonstrated through a real-world test-bed deployment in a sliced network scenario, utilizing multiple 5G cores (i.e., Open5GS) across Ericsson's new Radio Access Network (RAN).","2331-9860","979-8-3315-0805-0","10.1109/CCNC54725.2025.10976116","U.S. Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976116","5G;6G;Generative-AI;LLM;Llama2;DevSec-Ops;NFT;PBOM","Training;5G mobile communication;Network slicing;Supply chains;Transforms;Software;Nonfungible tokens;Security;Resource management;Radio access networks","","","","22","IEEE","5 May 2025","","","IEEE","IEEE Conferences"
"Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop","M. Hamza; D. Siemon; M. A. Akbar; T. Rahman","Software Engineering, LUT University, Lahti, Finland; Software Engineering, LUT University, Lahti, Finland; Software Engineering, LUT University, Lahti, Finland; Software Engineering, LUT University, Lahti, Finland",2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB),"3 Sep 2024","2024","","","7","14","This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.","","979-8-4007-0571-7","10.1145/3643690.3648236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10653701","Generative AI;ChatGPT;Software Engineering;Workshop;Empirical Investigation","Conferences;Collaboration;Chatbots;Software;Security;Resource management;Problem-solving","","2","","32","CCBY","3 Sep 2024","","","IEEE","IEEE Conferences"
"Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents","J. Yoon; R. Feldt; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; Dept. of Computer Science & Engineering, Chalmers University, Gothenburg, Sweden; School of Computing, KAIST, Daejeon, Republic of Korea","2024 IEEE Conference on Software Testing, Verification and Validation (ICST)","27 Aug 2024","2024","","","129","139","GUI testing checks if a software system behaves as expected when users interact with its graphical interface, e.g., testing specific functionality or validating relevant use case scenarios. Currently, deciding what to test at this high level is a manual task since automated GUI testing tools target lower level adequacy metrics such as structural code coverage or activity coverage. We propose DroidAgent, an autonomous GUI testing agent for Android, for semantic, intent-driven automation of GUI testing. It is based on Large Language Models and support mechanisms such as long- and short-term memory. Given an Android app, DroidAgent sets relevant task goals and subsequently tries to achieve them by interacting with the app. Our empirical evaluation of DroidAgent using 15 apps from the Themis benchmark shows that it can set up and perform realistic tasks, with a higher level of autonomy. For example, when testing a messaging app, DroidAgent created a second account and added a first account as a friend, testing a realistic use case, without human intervention. On average, DroidAgent achieved 61% activity coverage, compared to 51 % for current state-of-the-art GUI testing techniques. Further, manual analysis shows that 317 out of the 547 autonomously created tasks are realistic and relevant to app functionalities, and also that DroidAgent interacts deeply with the apps and covers more features.","2159-4848","979-8-3503-0818-1","10.1109/ICST60714.2024.00020","National Research Foundation of Korea (NRF); Korean Government MSIT(grant numbers:RS-2023-00208998,2022-0-00995); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638557","software testing;GUI testing;test automation;artificial intelligence;large language model","Software testing;Measurement;Automation;Large language models;Semantics;Manuals;Software systems","","12","","36","IEEE","27 Aug 2024","","","IEEE","IEEE Conferences"
"One Mutation Fits All: Exploring Universal Library Fuzzing based on Exogenous Mutation","R. Dong; F. Tong; H. Huang; X. Zhu; X. Xiao; S. Wang; S. Wen; Y. Xiang","Department of Computing Technologies, Swinburne University of Technology, Hawthorn, Australia; International Graduate School, Tsinghua University, Shenzhen, China; Department of Computing Technologies, Swinburne University of Technology, Hawthorn, Australia; School of Computer and Mathematical Sciences, The University of Adelaide, Adelaide, SA, Australia; International Graduate School, Tsinghua University, Shenzhen, China; Central University of Finance and Economics; Department of Computing Technologies, Swinburne University of Technology, Hawthorn, Australia; Department of Computing Technologies, Swinburne University of Technology, Hawthorn, Australia",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","12","Fuzzing is a critical technique for uncovering vulnerabilities in software libraries. However, current approaches often struggle with cross-language compatibility and integration with diverse fuzzing tools. We propose EXo-Muta, a novel universal library fuzzing framework based on exogenous mutation. We use the term ‘exogenous’ to describe this new mutation process because it operates externally to the fuzzer's core engine, executing within the fuzz driver as an independent component, unlike traditional endogenous mutations tightly integrated within the fuzzer itself. By decoupling the mutation process from specific fuzzers, EXo-Muta achieves unprecedented adaptability across diverse programming languages and fuzzing tools. It leverages static analysis to extract structured data representations and applies language-independent mutation operators at the code level. This design enables seamless integration with various existing fuzzers, enhancing their performance regardless of the target language. We further utilize large language models (LLM) for efficient cross-language data conversion. In experiments, we evaluated EXo-Muta on 20 real-world libraries across C++, Python, Java, and JavaScript, integrating it with multiple stateof- the-art fuzzers, such as AFL++ and libFuzzer, and languagespecific tools, such as Atheris and Jazzer. Results show significant improvements in code coverage across different fuzzers and languages, with up to 58% more edges discovered in C++ projects when integrated with libFuzzer, and consistent outperformance in other scenarios (27% on Python, 9% on Java, 6% on JavaScript). EXo-Muta represents a significant advancement in fuzzing technology, offering a universal, language-agnostic approach that substantially improves code coverage across diverse programming languages and fuzzing tools, thereby expanding the reach and effectiveness of library API testing.","1941-0018","","10.1109/TDSC.2025.3588878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11079961","Software testing;API fuzzing;cross-language compatibility;universal fuzzing framework;language-agnostic design","Fuzzing;Libraries;C++ languages;Engines;Codes;Python;Data structures;Java;Data mining;Testing","","1","","","IEEE","14 Jul 2025","","","IEEE","IEEE Early Access Articles"
"Leveraging Machine Learning for Enhanced Software Defect Prediction and Quality Assurance: A Comparative Analysis","P. Mohandas; A. Duraipandian; V. Chaitanya; A. N. Tharun; D. B. Vishnuvardhan; D. N. V. Kumar","Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA; Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA; Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA; Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA; Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA; Computer Science and Engineering Department, Sasi Institute of Technology and Engineeering, Tadepalligudem, INDIA",2024 International Conference on Computing and Intelligent Reality Technologies (ICCIRT),"18 Mar 2025","2024","","","198","202","The evolution of software engineering practices has heightened the emphasis on quality assurance, particularly in defect prediction and testing methodologies. Traditional approaches often fall short in addressing the complexities of modern software systems, prompting the integration of advanced technologies such as deep learning and machine learning. Recent research highlights the development of robust models for predicting defect density, which effectively tackle issues of data sparsity, alongside the introduction of specialized validation frameworks for AI-driven software that utilize innovative testing methods. Additionally, advancements in automated testing practices, including the use of large language models for test case generation and ensemble machine learning for bug classification, underscore the critical role of efficient maintenance in ensuring software quality. Furthermore, novel frameworks for validating unsupervised learning systems bridge user expectations with system performance evaluations. Collectively, these contributions reveal a trend towards leveraging cutting-edge methodologies to address the multifaceted challenges of software quality, emphasizing the need for adaptive and innovative strategies as software systems continue to evolve.","","979-8-3315-1029-9","10.1109/ICCIRT59484.2024.10921974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921974","Machine Learning;Software Testing;Artificial Intelligence;Cross-Project Defect Detection;Bug Classification;Automated Testing","Deep learning;Quality assurance;Computer bugs;Software quality;Software systems;Market research;Software reliability;Maintenance;Testing;Software engineering","","","","15","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"IIIM-SAM: Zero-Shot Texture Anomaly Detection Without External Prompts","Z. Zhang; Y. Zhou; J. Yue; R. Zhang; J. Ma","National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Automation Science and Engineering,"2 May 2025","2025","22","","14610","14622","Anomaly detection is a crucial aspect in ensuring the reliability of industrial products in smart manufacturing. Despite employing unsupervised anomaly detection methods to mitigate the challenges associated with obtaining defect data, there remains the challenge of adapting anomaly detectors to drift within normal data distributions, especially when there are significant intra-class variations in normal samples. Consequently, zero-shot anomaly detection techniques, which do not require training data and thus avoid interference from training data, have emerged as a new research direction. Meanwhile, the zero-shot segmentation capability demonstrated by the Segment Anything Mode (SAM) visual foundation model has further fueled our research enthusiasm. In this paper, we focus on texture images and propose a no-external prompt SAM-based method for zero-shot texture anomaly detection, called Image Internal Information Mining SAM (IIIM-SAM). We utilize the Image Internal Information Mining Prompter to mine relationships between internal regions of the image, identifying specific background and potential defect points. The two types of prompt points are fed into the SAM model in different stages, imparting the SAM with incorporating category information segmentation capability. Unlike current methods, our zero-shot texture anomaly detection method requires no external prompts or expert knowledge, and also avoids the uncertainty introduced by text prompts necessary for CLIP-based approaches. Our experimental results demonstrate the superiority of our zero-shot texture anomaly detection method compared to other approaches. Specifically, in the texture subset of MVTecAD/KolektorSDD2, our IIIM-SAM achieves 99.2%/93.6% image-level AUROC and 98.6%/92.3% pixel-level AUROC. Note to Practitioners—The motivation of this paper arises from a practical challenge in anomaly detection in smart flexible manufacturing—customized customer demands lead to significant intra-class variations and even entirely different types of products. Currently, most anomaly detection methods struggle to adapt quickly to this challenge, severely impeding production efficiency. This paper proposes a zero-shot texture anomaly detection method based on SAM, which automatically generates background and potential defect points through an image internal information mining prompter. Compared to existing zero-shot anomaly detection algorithms based on foundation models, our method’s most significant uniqueness is without any expert knowledge and the absence of any external text prompts. Through comparisons with four advanced methods on six instances using two evaluation metrics, the results demonstrate the outstanding anomaly detection capability of our approach.","1558-3783","","10.1109/TASE.2025.3561776","National Natural Science Foundation of China(grant numbers:U1913602,61991412); Foundation of Equipment Pre-Research Area(grant numbers:50911020603); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967541","Smart manufacturing;texture anomaly detection;prompt engineering;foundation model;SAM","Anomaly detection;Image segmentation;Training;Foundation models;Adaptation models;Training data;Interference;Decoding;Accuracy;Visualization","","","","40","IEEE","17 Apr 2025","","","IEEE","IEEE Journals"
"GeminiDE: A Novel Parameter Adaptation Scheme in Differential Evolution","R. Zhong; S. Zhang; J. Yu; M. Munetomo","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Science and Technology, Niigata University, Niigata, Japan; Institute of Science and Technology, Niigata University, Niigata, Japan; Information Initiative Center, Hokkaido University, Sapporo, Japan",2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS),"10 Oct 2024","2024","","","33","38","Parameter adaptation in differential evolution (DE) has been a well-known research topic for decades. However, the increasing complexity of expert-designed parameter adaptation schemes can be inconvenient for users. Motivated by the rapid development of large language models (LLMs), this paper proposes a novel and simple parameter adaptation scheme. Specifically, we treat the internal mechanism of parameter adaptation as a black-box problem and employ the LLM Gemini with the standard CRISPE prompt engineering framework to automatically design the parameter adaptation scheme during optimization. The proposed scheme is integrated into DE to form our proposal Gem-iniDE. To evaluate the performance of our proposed GeminiDE, we conduct comprehensive numerical experiments on IEEE-CEC2017 and CEC2022, using constant and random parameter settings in DE as competitor adaptation schemes. Experimental results and statistical analyses demonstrate that our proposed scheme significantly accelerates the optimization convergence of DE and has great potential for extending to various metaheuristic approaches. The source code of this research can be downloaded from https://github.com/RuiZhong961230/GeminiDE.","","979-8-3503-7784-2","10.1109/DOCS63458.2024.10704309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10704309","Evolutionary Computation (EC);Differential Evolution (DE);Parameter Adaptation Scheme;Large Language Model","Statistical analysis;Source coding;Large language models;Metaheuristics;Closed box;Evolutionary computation;Prompt engineering;Proposals;Standards;Convergence","","1","","19","IEEE","10 Oct 2024","","","IEEE","IEEE Conferences"
"Multi-Agentic Plan-and-Solve Engine for Managing System of Systems via Natural Language","C. Hegedűs; Á. Tóth; M. Bancsics; P. Varga","Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary",NOMS 2025-2025 IEEE Network Operations and Management Symposium,"15 Jul 2025","2025","","","1","6","The management of complex Systems of Systems (SoS) often requires interacting with a variety of heterogeneous user interfaces and APIs across different components. This task becomes especially challenging when trying to dynamically manage resources real-time. In this paper, we propose a novel multi-agent architecture for an intent based solver engine, which leverages Large Language Models (LLMs) to facilitate system management via natural language interactions. Our engine utilizes multiple LLM agents to autonomously plan and execute user-intended tasks across various RESTful microservices, such as querying data or modifying system resources. The architecture is designed to support multimodal user input, offering transparency and explainability by allowing users to review and modify plans and workflow steps during execution. This approach combines LLM reasoning capabilities, prompt engineering, and multi-agentic patterns to automate decision-making while ensuring a high level of control for the user. The paper details the architecture and reference implementation of the proposed engine and showcases its capabilities through a practical use case.","2374-9709","979-8-3315-3163-8","10.1109/NOMS57970.2025.11073647","National Research, Development and Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073647","","Reviews;Large language models;Natural languages;Decision making;Microservice architectures;User interfaces;Real-time systems;Prompt engineering;Engines;System of systems","","","","22","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion","L. S. S. Ray; B. Zhou; S. Suh; P. Lukowicz","DFKI, Germany; RPTU & DFKI, Germany; RPTU & DFKI, Germany; RPTU & DFKI, Germany",2025 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),"19 Jun 2025","2025","","","685","688","Conventional human activity recognition (HAR) relies on classifiers trained to predict discrete activity classes, inherently limiting recognition to activities explicitly present in the training set. Such classifiers would invariably fail, putting zero likelihood, when encountering unseen activities. We propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this limitation by first converting each activity into natural language and breaking it into a sequence of elementary motions. This descriptive text is then encoded into a fixed-size embedding. The model is trained to regress this embedding, which is subsequently decoded back into natural language using a pre-trained embedding inversion model. Unlike other works that rely on auto-regressive large language models (LLMs) at their core, OV-HAR achieves open vocabulary recognition without the computational overhead of such models. The generated text can be transformed into a single activity class using LLM prompt engineering. We have evaluated our approach on different modalities, including vision (pose), IMU, and pressure sensors, demonstrating robust generalization across unseen activities and modalities, offering a fundamentally different paradigm from contemporary classifiers.","2766-8576","979-8-3315-3553-7","10.1109/PerComWorkshops65533.2025.00163","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11038591","HAR;NLP;IMU;Pressure Sensor;Pose","Pressure sensors;Training;Vocabulary;Computational modeling;Conferences;Natural languages;Semantics;Human activity recognition;Prompt engineering;Unsupervised learning","","","","12","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Abbreviation Identification and Disambiguation in Real-World Clinical Narratives","J. P. Joaquim; I. Fontes de Araújo; C. Moro","NA; Graduate Program of Health Technology, Pontifícia Universidade Católica do Paraná, Curitiba, Brazil; Graduate Program of Health Technology, Pontifícia Universidade Católica do Paraná, Curitiba, Brazil",2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS),"4 Jul 2025","2025","","","21","24","The use of non-standardized and context-dependent abbreviations in clinical narratives introduces critical challenges for natural language processing models, limiting the accuracy of information extraction, affecting semantic interpretation, and posing risks to clinical decision-making and patient safety. This paper presents a solution to identify and expand abbreviations in Brazilian Portuguese clinical narratives, dealing with a critical challenge in the interpretation of medical texts. The method, which uses the SemClinBr dataset of 1,000 anonymous real-world clinical texts and a low-resource approach that combines the GPT model, prompt engineering and few-shot learning techniques, achieved a success rate of 83.2 % in identification and 93.04 % in correct expansion. Despite the inherent challenges of real-world data and manual evaluation, the results, which are comparable to established international benchmarks, highlight the potential of large language models (LLMs) to provide efficient comprehension of medical documents, especially for languages with limited data.","2372-9198","979-8-3315-2610-8","10.1109/CBMS65348.2025.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058584","clinical narratives;Large Language Model (LLM);Natural Language Processing (NLP);Abbreviations","Accuracy;Large language models;Semantics;Symbols;Medical services;Natural language processing;Data models;Safety;Prompt engineering;Context modeling","","","","24","IEEE","4 Jul 2025","","","IEEE","IEEE Conferences"
"Essay Scoring with LLM Agent","F. P. Espino; A. Y. Dolganov","Ural Federal University - CTI, Ekaterinburg, Russia; Ural Federal University - RTF, Ekaterinburg, Russia","2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT)","2 Jul 2025","2025","","","191","194","This study presents an AI-based agent designed to automate the grading of student essays in the Ecology course at Ural Federal University. The agent leverages the capabilities of Large Language Models (LLMs), particularly from the Llama family, to evaluate various aspects of student writing, including grammar, structure, and content relevance. The system integrates advanced natural language processing techniques, Python libraries for data handling and analysis, and prompt engineering strategies to ensure accurate interpretation of student input. In addition to scoring, the model generates detailed feedback aimed at helping students understand their strengths and areas for improvement.Preliminary results from experiments using different versions of Llama models show a tendency to assign mid-range scores across most submissions. This indicates a challenge in clearly distinguishing between low- and high-quality responses, particularly for essays lacking strong arguments or cohesive structure. Despite occasional inconsistencies in scoring, the implementation of AI in the grading process has the potential to significantly streamline assessment workflows, reduce instructor workload, and enhance the consistency and depth of feedback. These findings suggest promising directions for improving both the accuracy and transparency of automated grading systems in educational contexts.","2769-3635","979-8-3503-9270-8","10.1109/USBEREIT65494.2025.11054195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11054195","LLM;Agent;Essay scoring","Accuracy;Biological system modeling;Large language models;Refining;Ecology;Natural language processing;Libraries;Grammar;Prompt engineering;Testing","","","","13","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"FATPaSE: Proposing a Computationally Intelligent Framework for Automated Target Profiling and Social Engineering","M. Bischof; E. Portmann","Human-IST Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Institute, University of Fribourg, Fribourg, Switzerland","2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","29 Jan 2024","2023","","","4022","4027","Social engineering is recurrently listed as a prime threat according to major cyber security agencies. Over the course of the last decades, various sources expressed serious concerns about the potential impact of artificial intelligence on automating criminal cyber activities. With the recent developments and skyrocketing popularity of large language models, this threat forecast drastically worsened within an overwhelmingly short time period. In this paper, we propose the framework FATPaSE which pursues the goal of maximizing automation of digital profiling and social engineering aided by computational intelligence techniques. We discuss the design of the framework in detail, argue for possible technological choices to realize specific parts and elaborate on already existing proof of concept work. The interconnection of all components should enable a working, fully automated kill chain. During the subsequent design science oriented implementation, the achievable degree of automation will be intensely studied, resulting in novel, innovative research artifacts. Our progress shall be directly validated in the field based on a realistic, industrial test setup. We will continuously publish our results during the development process and expect to gain deepened insights on the potentials of the idea to contribute to the toolbox of cyber security experts.","2577-1655","979-8-3503-3702-0","10.1109/SMC53992.2023.10394207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10394207","social engineering;profiling;automation;computational intelligence;open source intelligence;offensive security","Automation;Computational modeling;Predictive models;Security;Computer crime;Cybernetics;Computational intelligence","","2","","16","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Developing Design Features to Facilitate AI-Assisted User Interactions","S. Meng; R. Dollahite; A. Kaur; P. Schell; A. Sharma; G. Ventre; I. Kranz; G. Nudelman; G. J. Gerling",University of Virginia; University of Virginia; University of Virginia; University of Virginia; University of Virginia; University of Virginia; Sumo Logic; Sumo Logic; University of Virginia,2024 Systems and Information Engineering Design Symposium (SIEDS),"21 May 2024","2024","","","437","442","Interactive software tools employing generative artificial intelligence (AI) that help users formulate custom system queries are increasingly needed with growth in data quantities, relationships, and complexity. The need to afford such interactions is not new. Indeed, chatbots have long sought to bridge gaps between an individual’s intent and the system’s response. However, generative AI chatbots – in contrast to traditional chatbots that navigate pre-defined, rules-based decision trees – are unique in their promise to accept and respond to highly customized queries. At present though, most still rely upon the precise articulation of a structured prompt. The work herein develops and evaluates design features to facilitate AI-assistive user interactions in query formulation. The design features attempt to balance functional needs of users to make specific, goal-oriented, customized queries, with minimal constraints on exactly articulating pre-defined prompts. In a case study, we wireframe user interface prototypes in the domain of data log management, for evaluation with expert and novice users. Key elements of the design features revolve around the 1) refinement of search categories, 2) context-aware prompt recommendations, and 3) customization of query input per a user’s technical ability.","2994-3531","979-8-3503-8514-4","10.1109/SIEDS61124.2024.10534665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534665","User Experience Design;Interaction Design;Prompt Engineering;AI-Assistive Technologies","Bridges;Generative AI;Navigation;Prototypes;User interfaces;Chatbots;User experience","","1","","8","IEEE","21 May 2024","","","IEEE","IEEE Conferences"
"Integrating Cloud-Based AI in Software Engineers' Professional Training and Development","P. Wolfschwenger; B. Sabitzer; Z. Lavicza","Johannes Kepler University, Linz, Austria; Johannes Kepler University, Linz, Austria; Johannes Kepler University, Linz, Austria",2023 IEEE Frontiers in Education Conference (FIE),"5 Jan 2024","2023","","","1","5","Artificial Intelligence (AI) has recently gained immense popularity. With impressive capabilities and versatility, large language models have quickly become a valuable tool for a wide range of applications, from chatbots and language translation to content creation and research. Generative AI can aid in the creation of computer code and provide information on a wide range of technical topics. This work-in-progress brings AI to vocational training by incorporating Cloud Computing (CC) services into a professional training and development program for software engineers, concentrating on practical skills development, hands-on experience and job-specific competencies. The approach is evaluated in the context of action research, with an emphasis on the potential benefits and challenges of code generation.","2377-634X","979-8-3503-3642-9","10.1109/FIE58773.2023.10343391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343391","Artificial Intelligence;Cloud Computing;Professional Training and Development;Lifelong Learning","Cloud computing;Codes;Computational modeling;Learning (artificial intelligence);Vocational training;Chatbots;Software","","5","","33","IEEE","5 Jan 2024","","","IEEE","IEEE Conferences"
"Investigating ChatGPT’s Potential to Assist in Requirements Elicitation Processes","K. Ronanki; C. Berger; J. Horkoff","Dept. of Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden",2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA),"1 Jan 2024","2023","","","354","361","Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE) seeks to apply NLP tools, techniques, and resources to the RE process to increase the quality of the requirements. There is little research involving the utilization of Generative AI-based NLP tools and techniques for requirements elicitation. In recent times, Large Language Models (LLM) like ChatGPT have gained significant recognition due to their notably improved performance in NLP tasks. To explore the potential of ChatGPT to assist in requirements elicitation processes, we formulated six questions to elicit requirements using ChatGPT. Using the same six questions, we conducted interview-based surveys with five RE experts from academia and industry and collected 30 responses containing requirements. The quality of these 36 responses (human-formulated + ChatGPT-generated) was evaluated over seven different requirements quality attributes by another five RE experts through a second round of interview-based surveys. In comparing the quality of requirements generated by ChatGPT with those formulated by human experts, we found that ChatGPT-generated requirements are highly Abstract, Atomic, Consistent, Correct, and Understandable. Based on these results, we present the most pressing issues related to LLMs and what future research should focus on to leverage the emergent behaviour of LLMs more effectively in natural language-based RE activities.","2376-9521","979-8-3503-4235-2","10.1109/SEAA60479.2023.00061","Vinnova; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371698","ChatGP;Large Language Model;NLP4R;Requirements Elicitatio","Surveys;Industries;Pressing;Chatbots;Requirements engineering;Task analysis;Software engineering","","27","","33","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Multi-objective Gray Wolf Optimization Algorithm for Multi-agent Pathfinding Problem","L. Wei; Z. Cai; K. Zhou","School of Artificial Intelligence, Jilin University, Changchun, China; School of Artificial Intelligence, Jilin University, Changchun, China; School of Artificial Intelligence, Jilin University, Changchun, China",2022 IEEE 5th International Conference on Electronics Technology (ICET),"14 Jul 2022","2022","","","1241","1249","As a core problem of multi-agent systems, multiagent pathfinding has an important impact on the efficiency of multi-agent systems. Because of this, many novel multi-agent pathfinding methods have been proposed over the years. However, these methods have focused on different agents with different goals for research, and less research has been done on scenarios where different agents have the same goal. We propose a multiagent pathfinding method incorporating a multi-objective gray wolf optimization algorithm to solve the multi-agent pathfinding problem with the same objective. First, constrained optimization modeling is performed to obtain objective functions about agent wholeness and security. Then, the multi-objective gray wolf optimization algorithm is improved for solving the constrained optimization problem and further optimized for scenarios with insufficient computational resources. To verify the effectiveness of the multi-objective gray wolf optimization algorithm, we conduct experiments in a series of simulation environments and compare the improved multi-objective grey wolf optimization algorithm with some classical swarm intelligence optimization algorithms. The results show that the multi-agent pathfinding method incorporating the multi-objective gray wolf optimization algorithm is more efficient in handling multi-agent pathfinding problems with the same objective.","2768-6515","978-1-6654-8508-1","10.1109/ICET55676.2022.9824428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824428","multi-agent pathfinding;multi-objective gray wolf optimization;swarm intelligence","Heuristic algorithms;Computational modeling;Sociology;Linear programming;Security;Statistics;Particle swarm optimization","","2","","37","IEEE","14 Jul 2022","","","IEEE","IEEE Conferences"
"Adversarial AI Attacks, Mitigations, and Defense Strategies: A cybersecurity professional's guide to AI attacks, threat modeling, and securing AI with MLSecOps","J. Sotiropoulos",NA,"Adversarial AI Attacks, Mitigations, and Defense Strategies: A cybersecurity professional's guide to AI attacks, threat modeling, and securing AI with MLSecOps","","2024","","","","","Understand how adversarial attacks work against predictive and generative AI, and learn how to safeguard AI and LLM projects with practical examples leveraging OWASP, MITRE, and NISTKey FeaturesUnderstand the connection between AI and security by learning about adversarial AI attacksDiscover the latest security challenges in adversarial AI by examining GenAI, deepfakes, and LLMsImplement secure-by-design methods and threat modeling, using standards and MLSecOps to safeguard AI systemsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAdversarial attacks trick AI systems with malicious data, creating new security risks by exploiting how AI learns. This challenges cybersecurity as it forces us to defend against a whole new kind of threat. This book demystifies adversarial attacks and equips cybersecurity professionals with the skills to secure AI technologies, moving beyond research hype or business-as-usual strategies. The strategy-based book is a comprehensive guide to AI security, presenting a structured approach with practical examples to identify and counter adversarial attacks. This book goes beyond a random selection of threats and consolidates recent research and industry standards, incorporating taxonomies from MITRE, NIST, and OWASP. Next, a dedicated section introduces a secure-by-design AI strategy with threat modeling to demonstrate risk-based defenses and strategies, focusing on integrating MLSecOps and LLMOps into security systems. To gain deeper insights, you’ll cover examples of incorporating CI, MLOps, and security controls, including open-access LLMs and ML SBOMs. Based on the classic NIST pillars, the book provides a blueprint for maturing enterprise AI security, discussing the role of AI security in safety and ethics as part of Trustworthy AI. By the end of this book, you’ll be able to develop, deploy, and secure AI systems effectively.What you will learnUnderstand poisoning, evasion, and privacy attacks and how to mitigate themDiscover how GANs can be used for attacks and deepfakesExplore how LLMs change security, prompt injections, and data exposureMaster techniques to poison LLMs with RAG, embeddings, and fine-tuningExplore supply-chain threats and the challenges of open-access LLMsImplement MLSecOps with CIs, MLOps, and SBOMsWho this book is forThis book tackles AI security from both angles - offense and defense. AI builders (developers and engineers) will learn how to create secure systems, while cybersecurity professionals, such as security architects, analysts, engineers, ethical hackers, penetration testers, and incident responders will discover methods to combat threats and mitigate risks posed by attackers. The book also provides a secure-by-design approach for leaders to build AI with security in mind. To get the most out of this book, you’ll need a basic understanding of security, ML concepts, and Python. ","","9781835088678","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769347.pdf&bkn=10769346&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Toward Neurosymbolic Program Comprehension","A. Velasco; A. Garryyeva; D. N. Palacio; A. Mastropaolo; D. Poshyvanyk","Department of Computer Science, William & Mary, USA; Department of Computer Science, William & Mary, USA; Department of Computer Science, William & Mary, USA; Department of Computer Science, William & Mary, USA; Department of Computer Science, William & Mary, USA",2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC),"17 Jun 2025","2025","","","377","381","Recent advancements in Large Language Models (LLMs) have paved the way for Large Code Models (LCMs), enabling automation in complex software engineering tasks, such as code generation, software testing, and program comprehension, among others. Tools like GitHub Copilot and ChatGPT have shown substantial benefits in supporting developers across various practices. However, the ambition to scale these models to trillion-parameter sizes, exemplified by GPT-4, poses significant challenges that limit the usage of Artificial Intelligence (AI)-based systems powered by large Deep Learning (DL) models. These include rising computational demands for training and deployment and issues related to trustworthiness, bias, and interpretability. Such factors can make managing these models impractical for many organizations, while their “black-box” nature undermines key aspects, including transparency and accountability. In this paper, we question the prevailing assumption that increasing model parameters is always the optimal path forward, provided there is sufficient new data to learn additional patterns. In particular, we advocate for a Neurosymbolic research direction that combines the strengths of existing DL techniques (e.g., LLMs) with traditional symbolic methods-renowned for their reliability, speed, and determinism. To this end, we outline the core features and present preliminary results for our envisioned approach, aimed at establishing the first Neurosymbolic Program Comprehension (NsPC) framework to aid in identifying defective code components.","2643-7171","979-8-3315-0223-2","10.1109/ICPC66645.2025.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025925","Neuro-Symbolic AI;Vulnerability Detection;Program Comprehension;Interpretability","Training;Software testing;Deep learning;Codes;Computational modeling;Large language models;Organizations;Reliability;Software engineering;Software development management","","","","47","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Tailored Resume Generation Using RAG with LLM as per Job Specifications","K. P. Patra; M. Diwakar; C. Arya","National College of Ireland, Dublin, Ireland; Department of CSE, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; Graphic Era Hill University, Dehradun, India","2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC)","9 May 2025","2024","","","848","853","The traditional resume being common for each specific job applications which result to rejection for job seekers. These research tailors the resume based on different domain of job applications using Retrieved Augmented Generation (RAG) and LLMs. The automated system starts from resume parsing for information retrieval as per the sections using LLM model like Mixtral, Google Gemma and LLAMA-3. The resume has been further stored into vector databases such as Pinecone and MongoDB with JSON resume further retrieved using re-ranking methods such as BM25 and Cross encoder. The prompt techniques used to construct the model to make them understand better. For providing the memory to the LLM models and refining the tailored resume, the conversational buffer memory is implemented. The efficiency and the performance of the methodology is showcase through the performance evaluation metrics such as BERTscore, RAGAs Metrics and Custom metrics such as Content preservation and Job Alignment. By comparing the cosine similarity for content preservation between LLM and RAG with LLM are 72% and 89% respectively. Compared to LLM models using RAG with LLM models generates consistent and relevant tailored resumes. For a better user friendly and seamless UI, the chatbot is developed.","2573-3079","979-8-3315-2134-9","10.1109/PDGC64653.2024.10984036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984036","Retrieval Augmented Generation (RAG);Large Language Model (LLM);Resume Generation;Conversational Memory;Prompt Engineering;Memory;LLAMA;Mixtral;BERTscore;RAGAS","Performance evaluation;Computational modeling;Large language models;Resumes;Retrieval augmented generation;Refining;Vectors;Job specification;Internet;Prompt engineering","","","","13","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
