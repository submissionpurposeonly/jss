"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Automatic Commit Message Generation: A Critical Review and Directions for Future Work","Y. Zhang; Z. Qiu; K. -J. Stol; W. Zhu; J. Zhu; Y. Tian; H. Liu","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Lero, the Science Foundation Ireland Research Centre for Software and the School of Computer Science and IT, University College Cork, Cork, Ireland; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China; Tmall Technology Co., Zhejiang, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",IEEE Transactions on Software Engineering,"17 Apr 2024","2024","50","4","816","835","Commit messages are critical for code comprehension and software maintenance. Writing a high-quality message requires skill and effort. To support developers and reduce their effort on this task, several approaches have been proposed to automatically generate commit messages. Despite the promising performance reported, we have identified three significant and prevalent threats in these automated approaches: 1) the datasets used to train and evaluate these approaches contain a considerable amount of ‘noise’; 2) current approaches only consider commits of a limited diff size; and 3) current approaches can only generate the subject of a commit message, not the message body. The first limitation may let the models ‘learn’ inappropriate messages in the training stage, and also lead to inflated performance results in their evaluation. The other two threats can considerably weaken the practical usability of these approaches. Further, with the rapid emergence of large language models (LLMs) that show superior performance in many software engineering tasks, it is worth asking: can LLMs address the challenge of long diffs and whole message generation? This article first reports the results of an empirical study to assess the impact of these three threats on the performance of the state-of-the-art auto generators of commit messages. We collected commit data of the Top 1,000 most-starred Java projects in GitHub and systematically removed noisy commits with bot-submitted and meaningless messages. We then compared the performance of four approaches representative of the state-of-the-art before and after the removal of noisy messages, or with different lengths of commit diffs. We also conducted a qualitative survey with developers to investigate their perspectives on simply generating message subjects. Finally, we evaluate the performance of two representative LLMs, namely UniXcoder and ChatGPT, in generating more practical commit messages. The results demonstrate that generating commit messages is of great practical value, considerable work is needed to mature the current state-of-the-art, and LLMs can be an avenue worth trying to address the current limitations. Our analyses provide insights for future work to achieve better performance in practice.","1939-3520","","10.1109/TSE.2024.3364675","National Natural Science Foundation of China(grant numbers:62141209,62202048,62232003); Science Foundation Ireland(grant numbers:13/RC/2094-P2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433002","Commit-based software development;open collaboration;commit message generation;benchmark","Codes;Chatbots;Task analysis;Noise measurement;Machine translation;Information retrieval;Software maintenance","","20","","79","CCBYNCND","12 Feb 2024","","","IEEE","IEEE Journals"
"BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target","G. Shen; S. Cheng; Z. Zhang; G. Tao; K. Zhang; H. Guo; L. Yan; X. Jin; S. An; S. Ma; X. Zhang","Purdue University, USA; Purdue University, USA; Purdue University, USA; University of Utah, USA; Purdue University, USA; Purdue University, USA; Purdue University, USA; Purdue University, USA; Purdue University, USA; University of Massachusetts at Amherst, USA; Purdue University, USA",2025 IEEE Symposium on Security and Privacy (SP),"16 Jun 2025","2025","","","1676","1694","Recent literature has shown that LLMs are vulnerable to backdoor attacks, where malicious attackers inject a secret token sequence (i.e., trigger) into training prompts and enforce their responses to include a specific target sequence. Unlike discriminative NLP models, which have a finite output space (e.g., those in sentiment analysis), LLMs are generative models, and their output space grows exponentially with the length of response, thereby posing significant challenges to existing backdoor detection techniques, such as trigger inversion. In this paper, we conduct a theoretical analysis of the LLM backdoor learning process under specific assumptions, revealing that the autoregressive training paradigm in causal language models inherently induces strong causal relationships among tokens in backdoor targets. We hence develop a novel LLM backdoor scanning technique, BAIT (Large Language Model Backdoor ScAnning by Inverting Attack Target). Instead of inverting back-door triggers like in existing scanning techniques for non-LLMs, BAIT determines if a model is backdoored by inverting back-door targets, leveraging the exceptionally strong causal relations among target tokens. BAIT substantially reduces the search space and effectively identifies backdoors without requiring any prior knowledge about triggers or targets. The search-based nature also enables BAIT to scan LLMs with only the black-box access. Evaluations on 153 LLMs with 8 architectures across 6 distinct attack types demonstrate that our method outperforms 5 baselines. Its superior performance allows us to rank at the top of the leaderboard in the LLM round of the TrojAI competition (a multi-year, multi-round backdoor scanning competition).","2375-1207","979-8-3315-2236-0","10.1109/SP61157.2025.00103","National Science Foundation(grant numbers:SHF-1901242,SHF-1910300,Proto-OKN 2333736,IIS-2416835); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023440","ai security;backdoor scanning;large language model","Training;Analytical models;Sentiment analysis;Privacy;Large language models;Closed box;Security","","1","","73","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"FVEval: Understanding Language Model Capabilities in Formal Verification of Digital Hardware","M. Kang; M. Liu; G. B. Hamad; S. M. Suhaib; H. Ren","University of California, Berkeley, CA; NVIDIA, Santa Clara, CA; NVIDIA, Santa Clara, CA; NVIDIA, Santa Clara, CA; NVIDIA, Santa Clara, CA","2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","6","The remarkable reasoning and code generation capabilities of large language models (LLMs) have spurred significant interest in applying LLMs to enable task automation in digital chip design. In particular, recent work has investigated early ideas of applying these models to formal verification (FV), an approach to verifying hardware implementations that can provide strong guarantees of confidence but demands significant amounts of human effort. While the value of LLM-driven automation is evident, our understanding of model performance, however, has been hindered by the lack of holistic evaluation. In response, we present FVEval, the first comprehensive benchmark and evaluation framework for characterizing LLM performance in tasks pertaining to FV. The benchmark consists of three sub-tasks that measure LLM capabilities at different levels-from the generation of SystemVerilog assertions (SVA) given natural language descriptions to reasoning about the design RTL and suggesting assertions directly without additional human input. As test instances, we present both collections of expert-written verification collateral and methodologies to scalably generate synthetic examples aligned with industrial FV workflows. A wide range of existing LLMs, both proprietary and open-source, are evaluated against FVEval, based on which we investigate where today's LLMs stand and how we might further enable their application toward improving productivity in digital FV. Our benchmark and evaluation code is available at https://github.com/NVlabs/FVEval.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10992720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992720","","Measurement;Productivity;Codes;Automation;Benchmark testing;Syntactics;Hardware;Cognition;Formal verification;Context modeling","","1","","27","","21 May 2025","","","IEEE","IEEE Conferences"
"Can ChatGPT Serve as a Multi-Criteria Decision Maker? A Novel Approach to Supplier Evaluation","X. Wang; X. Wu","Beihang University, Beijing, China; Peking University, Beijing, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","10281","10285","Multi-Criteria Decision Making (MCDM) has found extensive applications across various domains such as business, engineering, education, and academia, with supplier evaluation being a quintessential task among them. Traditional MCDM models typically gather quantitative and qualitative data through methods like questionnaire surveys administered to industry experts. Subsequently, experts proficient in MCDM techniques employ methods like the Analytic Hierarchy Process (AHP) and Fuzzy Comprehensive Evaluation (FCE) to conduct objective and scientific evaluations of suppliers. However, with the advent of large language models (LLMs) like ChatGPT, these models are now capable of assisting or even replacing human experts in tasks such as writing, consulting, and code generation. Bridging these two paradigms, this paper introduces a novel expert-level supplier evaluation method based on ChatGPT. Initially, a supplier dataset was collected and organized, followed by evaluations using traditional MCDM models to obtain expert assessment results. Thereafter, the ChatGPT model was employed to generate evaluations for this supplier dataset, which were then compared with the expert evaluations from the previous step. The final results indicate that the supplier evaluations based on the ChatGPT model closely align with those of human experts, underscoring the capability of ChatGPT to serve as a Multi-Criteria Decision Maker. Furthermore, this method proves to be faster and more cost-effective.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447204","ChatGPT;LLM;Multi-Criteria Decision Making;Supplier Evaluation","Surveys;Industries;Writing;Signal processing;Chatbots;Data models;MCDM","","4","","28","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"Designing Silicon Brains Using LLM: Leveraging ChatGPT for Automated Description of a Spiking Neuron Array","M. Tomlinson; J. Li; A. Andreou","Department of ECE, Johns Hopkins University, Baltimore, MD; Department of ECE, Johns Hopkins University, Baltimore, MD; Department of ECE, Johns Hopkins University, Baltimore, MD",2024 Argentine Conference on Electronics (CAE),"5 Apr 2024","2024","","","154","159","Large language models (LLMs) have made head-lines for synthesizing correct-sounding responses to a variety of prompts, including code generation. In this paper, we present the prompts used to guide ChatGPT4 to produce a synthesizable and functional verilog description for the entirety of a programmable Spiking Neuron Array ASIC. This design flow showcases the current state of using ChatGPT4 for natural language driven hardware design. The AI-generated design was verified in simu-lation using handcrafted testbenches and has been submitted for fabrication in Skywater 130nm through Tiny Tapeout 5 using an open-source EDA flow.","2836-1024","979-8-3503-0508-1","10.1109/CAE59785.2024.10487167","NSF(grant numbers:2020624); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487167","","Fabrication;Electric potential;Codes;Natural languages;Neurons;Computer bugs;Chatbots","","4","","11","IEEE","5 Apr 2024","","","IEEE","IEEE Conferences"
"On the Taxonomy of Developers’ Discussion Topics with ChatGPT","E. Sagdic; A. Bayram; M. R. Islam","Lamar University, Beaumont, Texas, USA; Lamar University, Beaumont, Texas, USA; Lamar University, Beaumont, Texas, USA",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","197","201","Large language models (LLMs) like ChatGPT can generate text for various prompts. With exceptional reasoning capabilities, ChatGPT (particularly the GPT-4 model) has achieved widespread adoption across many tasks - from creative writing to domain-specific inquiries, code generation, and more. This research analyzed the DevGPT dataset to determine common topics posed by developers interacting with ChatGPT. The DevGPT dataset comprises ChatGPT interactions from GitHub issues, pull requests and discussions. By employing a mixed-methods approach combining unsupervised semantic modeling and expert qualitative analysis we categorize the topics developers discuss when interacting with ChatGPT.Our approach reveals 17 topics within seven categories, with over 25% of prompts focused on advanced programming guidance. Additional areas of significant query volume include DevOps workflows, SQL, databases, and specialized domains, such as localization, streaming media, and image processing. This research effectively illuminates core topics and dependencies that motivate developers to leverage ChatGPT. The taxonomy classification further clarifies critical areas to better customize AI tools for aligning with workflows and needs within software engineering contexts.CCS CONCEPTS• Software and its engineering → Programming teams.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555669","DevGPT;ChatGPT;Software Engineering;Topic Taxonomy","Analytical models;DevOps;Taxonomy;Semantics;Programming;Chatbots;Software","","","","32","","18 Jun 2024","","","IEEE","IEEE Conferences"
"An LLM-assisted Analog IC Design Tool with Automatic Topology Selection and Circuit Sizing","A. Nguyen; C. -N. J. Liu","EECS International Graduate Program, Institute of Electronics, National Yang-Ming Chiao Tung University, Hsinchu City, Taiwan, R.O.C.; EECS International Graduate Program, Institute of Electronics, National Yang-Ming Chiao Tung University, Hsinchu City, Taiwan, R.O.C.","2025 21st International Conference on Synthesis, Modeling, Analysis and Simulation Methods, and Applications to Circuits Design (SMACD)","29 Jul 2025","2025","","","1","4","Recently, Large Language Models (LLMs) have gained a rising interest in different domains, including code generation for digital IC design. However, building an effective LLM for analog IC design is challenging because a valid analog circuit cannot be constructed by just randomly combining some codes. In this paper, an LLM-assisted analog IC design tool is presented to support from automatic topology selection to circuit sizing in a conversational manner. This tool allows designers to express their requirements through natural language rather than being restricted by a fixed template, which decreases the learning curve of using such an automation tool. In order to meet users’ intentions, a subsequent ANN-based sizing process is invoked to further refine the ""nearest"" circuit obtained from the LLM without tedious iterations. Compared with previous works, the proposed LLM-assisted tool is more efficient and convenient while generating reliable analog designs to meet users’ requirements. Our experiments show that the tool can generate workable circuits with short execution time.","2575-4890","979-8-3315-2395-4","10.1109/SMACD65553.2025.11091899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091899","LLM;Zero-shot-CoT prompting;kNN search;automatic circuit sizing;ANN;circuit topology selection","Circuit topology;Codes;Large language models;Natural languages;Reliability engineering;Design tools;Topology;Circuit synthesis;Integrated circuit modeling;Engines","","","","15","IEEE","29 Jul 2025","","","IEEE","IEEE Conferences"
"LLM4GV: An LLM-Based Flexible Performance-Aware Framework for GEMM Verilog Generation","D. Zou; G. Zhang; K. Sun; Z. Wen; M. Wang; Z. Wang","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Sun Yat-sen University, Shenzhen, China; Sun Yat-sen University, Shenzhen, China; Sun Yat-sen University, Shenzhen, China; Nanjing University, Nanjing, China","2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","2","Advancements in AI have increased the demand for specialized AI accelerators, with design for general matrix multiplication (GEMM) module being crucial but time-consuming. While large language models (LLMs) show promise for automating GEMM design, challenges arise from GEMM's vast design space and performance requirements. Existing LLM-based frameworks for RTL code generation often lack flexibility and performance awareness. To overcome the challenges, we propose LLM4GV, a multi-agent LLM-based framework that integrates hardware optimization techniques (HOTs) and performance modeling, improving correctness and performance of the generated code over prior works.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10992751","National Key R&D Program of China(grant numbers:2022YFB4400600); National Natural Science Foundation of China(grant numbers:62404256); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992751","","Codes;Automation;Large language models;Europe;AI accelerators;Benchmark testing;Hardware;Hardware design languages;Optimization","","","","6","","21 May 2025","","","IEEE","IEEE Conferences"
"Neuro-Symbolic Program Synthesis for Multi-Hop Natural Language Navigation","W. English; D. Simon; R. Ahmed; S. Jha; R. Ewetz","ECE, University of Florida, Gainesville, Florida, USA; ECE, University of Florida, Gainesville, Florida, USA; ECE, University of Central Florida, Orlando, Florida, USA; CEC, Florida International University, Miami, Florida, USA; ECE, University of Florida, Gainesville, Florida, USA",2024 International Conference on Assured Autonomy (ICAA),"27 Nov 2024","2024","","","114","117","Solving navigation problems from natural language descriptions is essential for advancing humanrobot interaction and enhancing the usability of autonomous systems. Symbolic approaches to path planning excel in well defined environments but cannot cope with the ambiguity of natural language inputs. On the other hand, neural solutions centered on large language models (LLMs) can parse free-form natural language but lack the reasoning capabilities for solving complex multihop path planning problems. In this paper, we propose a neuro-symbolic framework based on program synthesis for multi-hop natural language navigation called NSPS. The framework uses an LLM to parse the problem definition in natural language, a graph of the environment, and an API of a graph library. Next, the code generation capabilities of the LLM are used to synthesize a program for path planning and verification. The path planning program is executed to generate a solution path that is checked by the verification program. A selfcorrection loop is used to fix both syntax and value errors. The framework is evaluated using 600 multihop navigation tasks with 1 to 10 hops. Compared with neural approaches, the NSPS framework improves the success rate and path efficiency by an average of 64.3% and 19.4% across all tasks, respectively.","","979-8-3315-2101-1","10.1109/ICAA64256.2024.00027","U.S. Department of Energy; Office of Science; Office of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765960","Neuro-Symbolic AI;Navigation;LLM;Spatial Reasoning;Path Planning","Navigation;Large language models;Natural languages;Human-robot interaction;Syntactics;Path planning;Libraries;Cognition;Planning;Usability","","","","19","IEEE","27 Nov 2024","","","IEEE","IEEE Conferences"
"DSML4JaCaMo: A Modelling tool for Multi-agent Programming with JaCaMo","B. Karaduman; B. T. Tezel; G. Kardas; M. Challenger","Department of Computer Science, University of Antwerp and Flanders Make, Antwerp, Belgium; Department of Computer Science, University of Antwerp and Flanders Make, Antwerp, Belgium; International Computer Institute, Ege University, Izmir, Türkiye; Department of Computer Science, University of Antwerp and Flanders Make, Antwerp, Belgium",2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS),"4 Nov 2024","2024","","","637","642","This paper introduces a domain-specific modelling language (DSML) called DSML4JaCaMo to develop belief-desire-intention (BDI) agents. The DSML’s design covers aspects of Jason, Cartago, and Moise from viewpoints that follow the meta-modelling approach. In this way, the DSML4JaCaMo enables graphical modelling of JaCaMo’s multi-agent systems (MASs), providing comprehensive support for defining agents’ beliefs, desires, and intentions (BDI) using Jason, specifying artifacts and their operations with Cartago, and outlining organizational structures and norms via Moise. The DSML’s operational semantics ensure seamless integration of these components, facilitating automatic code generation and artifact construction for creating a JaCaMo-based system. The graphical syntax contributes to ease of use, making it accessible for novice and experienced developers. This work aims to enhance the JaCaMo ecosystem by offering a model-driven approach to provide abstraction on MAS development as well as facilitating design and implementation.","","978-83-969601-6-0","10.15439/2024F6157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736036","","Codes;Systematics;Biological system modeling;Semantics;Ecosystems;Syntactics;Programming;Complexity theory;Usability;Multi-agent systems","","","","28","","4 Nov 2024","","","IEEE","IEEE Conferences"
"ChatGPT Chats Decoded: Uncovering Prompt Patterns for Superior Solutions in Software Development Lifecycle","L. Wu; Y. Zhao; X. Hou; T. Liu; H. Wang","Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Monash University, Melbourne, Australia; Huazhong University of Science and Technology, China",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","142","146","The advent of Large Language Models (LLMs) like ChatGPT has markedly transformed software development, aiding tasks from code generation to issue resolution with their human-like text generation. Nevertheless, the effectiveness of these models greatly depends on the nature of the prompts given by developers. Therefore, this study delves into the DevGPT dataset, a rich collection of developer-ChatGPT dialogues, to unearth the patterns in prompts that lead to effective problem resolutions. The underlying motivation for this research is to enhance the collaboration between human developers and AI tools, thereby improving productivity and problem-solving efficacy in software development. Utilizing a combination of textual analysis and data-driven approaches, this paper seeks to identify the attributes of prompts that are associated with successful interactions, providing crucial insights for the strategic employment of ChatGPT in software engineering environments.CCS CONCEPTS•Information systems → Data mining.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555800","Data mining;Large language model;LLM;ChatGPT","Productivity;Oral communication;Chatbots;Frequency conversion;Software;Data mining;Problem-solving","","","","14","","18 Jun 2024","","","IEEE","IEEE Conferences"
"IEEE AI Standards for Agentic Systems","R. J. Tong; H. Li; S. Raghavan; Q. Wen; S. Gray; A. Paul; J. Liang; J. Zalewski; Y. Yang; G. Tambouratzis; B. C. Ang","IEEE Artificial Intelligence Standards Committee, Macao University of Science and Technology; IEEE P3428, China; IEEE P3394, United States; IEEE P3428, United States; Gray Sky AI, Australia; IEEE P3394, United States; IEEE P3428, China; State University of Applied Sciences, Poland; Tsinghua University, China; Athena Research Center, Greece; Intel, United States",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","1603","1609","This paper synthesizes key insights from emerging IEEE Artificial Intelligence Standards Committee (AISC) standards - P3394 and P3428 - that are shaping agent-based software engineering for intelligent systems. IEEE P3394 (LLM Agent Interface) defines a Universal Message Format (UMF) and communication protocols for Large Language Model (LLM) agents, establishing standard message envelopes, semantic payload, agent roles, session management, and interaction patterns. IEEE P3428 (LLM Agents for Education) specifies a modular agent architecture and lifecycle tailored to adaptive learning environments. It standardizes agent components, lifecycle states, and orchestration mechanisms to enable plug-and-play integration of multiple AI-driven agents in an adaptive instructional system. Together, P3394 and P3428 promote modular, interoperable, and scalable design of intelligent agent ecosystems. We highlight how P3394's universal message protocols and P3428's standardized agent lifecycle complement each other in supporting LLM-based agents and agent-based intelligent systems. We also briefly discuss IEEE P3427, an initiative on semantic information agents, which underscores the broader context of evaluation and continuous improvement of agent-based systems. By unifying communication interfaces and architectural frameworks, these standards lay a foundation for next-generation agentic systems that can seamlessly interoperate across platforms and domains.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050630","Agentic Systems;IEEE Standards;LLM Agent Interface;Adaptive Instructional System;AISC","Technological innovation;Adaptive systems;Protocols;Semantics;Intelligent agents;Artificial intelligence;Intelligent systems;Standards;Interoperability;Software engineering","","","","5","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"ContractTinker: LLM-Empowered Vulnerability Repair for Real-World Smart Contracts","C. Wang; J. Zhang; J. Gao; L. Xia; Z. Guan; Z. Chen","School of Computer Science, Peking University, Beijing, China; School of Computer Science, Peking University, Beijing, China; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; School of Computer Science, Peking University, Beijing, China; National Engineering Research Center For Software Engineering, Peking University, Beijing, China; School of Computer Science, Peking University, Beijing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","2350","2353","Smart contracts are susceptible to being exploited by attackers, especially when facing real-world vulnerabilities. To mitigate this risk, developers often rely on third-party audit services to identify potential vulnerabilities before project deployment. Nevertheless, repairing the identified vulnerabilities is still complex and labor-intensive, particularly for developers lacking security expertise. Moreover, existing pattern-based repair tools mostly fail to address real-world vulnerabilities due to their lack of high-level semantic understanding. To fill this gap, we propose ContractTinker, a Large Language Models (LLMs)-empowered tool for real-world vulnerability repair. The key insight is our adoption of the Chain-of-Thought approach to break down the entire generation task into sub-tasks. Additionally, to reduce hallucination, we integrate program static analysis to guide the LLM. We evaluate ContractTinker on 48 high-risk vulnerabilities. The experimental results show that among the patches generated by ContractTinker, 23 (48%) are valid patches that fix the vulnerabilities, while 10 (21%) require only minor modifications. A video of ContractTinker is available at https://youtu.be/HWFVi-YHcPE.CCS Concepts• Software and its engineering → Software development techniques; • Security and privacy → Software security engineering.","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764925","Program Repair;Smart Contract;Large Language Model","Privacy;Large language models;Smart contracts;Semantics;Static analysis;Maintenance engineering;Software;Security;Software engineering;Software development management","","1","","12","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Adversarial Attacks On Multi-Agent Communication","J. Tu; T. Wang; J. Wang; S. Manivasagam; M. Ren; R. Urtasun",Waabi; MIT; Waabi; Waabi; Waabi; Waabi,2021 IEEE/CVF International Conference on Computer Vision (ICCV),"28 Feb 2022","2021","","","7748","7757","Growing at a fast pace, modern autonomous systems will soon be deployed at scale, opening up the possibility for cooperative multi-agent systems. Sharing information and distributing workloads allow autonomous agents to better perform tasks and increase computation efficiency. However, shared information can be modified to execute adversarial attacks on deep learning models that are widely employed in modern systems. Thus, we aim to study the robustness of such systems and focus on exploring adversarial at-tacks in a novel multi-agent setting where communication is done through sharing learned intermediate representations of neural networks. We observe that an indistinguishable adversarial message can severely degrade performance, but becomes weaker as the number of benign agents increases. Furthermore, we show that black-box transfer attacks are more difficult in this setting when compared to directly perturbing the inputs, as it is necessary to align the distribution of learned representations with domain adaptation. Our work studies robustness at the neural network level to con-tribute an additional layer of fault tolerance to modern security protocols for more secure multi-agent systems.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.00767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711249","Adversarial learning;Detection and localization in 2D and 3D;Vision applications and systems;Vision for robotics and autonomous vehicles","Deep learning;Fault tolerance;Protocols;Computational modeling;Neural networks;Fault tolerant systems;Robustness","","35","","61","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"LTM: Scalable and Black-Box Similarity-Based Test Suite Minimization Based on Language Models","R. Pan; T. A. Ghaleb; L. C. Briand","School of EECS, University of Ottawa, Ottawa, ON, Canada; Computer Science Department, Trent University, Peterborough, ON, Canada; Lero SFI Centre for Software Research, University of Limerick, Limerick, Ireland",IEEE Transactions on Software Engineering,"13 Nov 2024","2024","50","11","3053","3070","Test suites tend to grow when software evolves, making it often infeasible to execute all test cases with the allocated testing budgets, especially for large software systems. Test suite minimization (TSM) is employed to improve the efficiency of software testing by removing redundant test cases, thus reducing testing time and resources while maintaining the fault detection capability of the test suite. Most existing TSM approaches rely on code coverage (white-box) or model-based features, which are not always available to test engineers. Recent TSM approaches that rely only on test code (black-box) have been proposed, such as ATM and FAST-R. The former yields higher fault detection rates (FDR) while the latter is faster. To address scalability while retaining a high FDR, we propose LTM (Language model-based Test suite Minimization), a novel, scalable, and black-box similarity-based TSM approach based on large language models (LLMs), which is the first application of LLMs in the context of TSM. To support similarity measurement using test method embeddings, we investigate five different pre-trained language models: CodeBERT, GraphCodeBERT, UniXcoder, StarEncoder, and CodeLlama, on which we compute two similarity measures: Cosine Similarity and Euclidean Distance. Our goal is to find similarity measures that are not only computationally more efficient but can also better guide a Genetic Algorithm (GA), which is used to search for optimal minimized test suites, thus reducing the overall search time. Experimental results show that the best configuration of LTM (UniXcoder/Cosine) outperforms ATM in three aspects: (a) achieving a slightly greater saving rate of testing time ($41.72\%$41.72% versus $41.02\%$41.02%, on average); (b) attaining a significantly higher fault detection rate ($0.84$0.84 versus $0.81$0.81, on average); and, most importantly, (c) minimizing test suites nearly five times faster on average, with higher gains for larger test suites and systems, thus achieving much higher scalability.","1939-3520","","10.1109/TSE.2024.3469582","Huawei Technologies Canada Company, Ltd.; Mitacs Accelerate Program; Science Foundation Ireland(grant numbers:13/RC/2094-2); Natural Sciences and Engineering Research Council of Canada (NSERC); Alliance de recherche numérique du Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10697930","Test suite minimization;test suite reduction;pre-trained language models;genetic algorithm;black-box testing","Minimization;Codes;Fault detection;Closed box;Scalability;Time measurement;Genetic algorithms;Source coding;Vectors;Unified modeling language","","1","","50","CCBYNCND","30 Sep 2024","","","IEEE","IEEE Journals"
"Enhanced Anomaly Detection in IoT: A Transformer Based Approach for Multivariate Time Series data","S. Zia; N. Bibi","Department Of Computer Science, Fatima Jinnah Women University, Rawalpindi, Pakistan; Department Of Computer Science, Fatima Jinnah Women University, Rawalpindi, Pakistan",2024 International Conference on Engineering & Computing Technologies (ICECT),"8 Jul 2024","2024","","","1","6","In IoT (Internet of Things) systems, the identification of anomalies plays a crucial role in ensuring the security and reliability of data. The rapid progression of digitization has led to the widespread deployment of sensor networks across various domains, supplying vital information for organizations to achieve complete autonomy. These sensor networks generate copious amounts of data, often in the form of multivariate time series, capturing both typical operational patterns and unusual occurrences. In the realm of anomaly detection for multivariate time series within IoT networks, our research introduces a transformer-based approach. The chosen model employs a transformer encoder-decoder architecture, leveraging its robust capabilities to analyze and identify aberrant patterns within intricately connected and complex data streams. To enhance the accuracy of anomaly detection, the study addresses the challenges posed by multivariate time series data and proposes a distinctive transformer-based methodology. Through experimentation and evaluation of authentic IoT dataset, this research illustrates the potential of the proposed model in delivering improved anomaly detection performance, consequently contributing to the development of more resilient and efficient IoT systems.","","979-8-3503-4971-9","10.1109/ICECT61618.2024.10581104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581104","Anomaly Detection;Transformer Models;Multivariate Time Series Analysis;Internet of Things (IoT);Deep Learning;Sequence Modeling","Analytical models;Computational modeling;Time series analysis;Organizations;Transformers;Internet of Things;Security","","3","","20","IEEE","8 Jul 2024","","","IEEE","IEEE Conferences"
"Dynamic Temporal Positional Encodings for Early Intrusion Detection in IoT","I. Panopoulos; M. -L. A. Bartsioka; S. Nikolaidis; S. I. Venieris; D. I. Kaklamani; I. S. Venieris","School of Electrical and Computer Engineering, NTUA, Athens, Greece; School of Electrical and Computer Engineering, NTUA, Athens, Greece; School of Electrical and Computer Engineering, NTUA, Athens, Greece; Samsung AI Center, Cambridge, UK; School of Electrical and Computer Engineering, NTUA, Athens, Greece; School of Electrical and Computer Engineering, NTUA, Athens, Greece",2025 10th International Conference on Smart and Sustainable Technologies (SpliTech),"30 Jul 2025","2025","","","1","6","The rapid expansion of the Internet of Things (IoT) has introduced significant security challenges, necessitating efficient and adaptive Intrusion Detection Systems (IDS). Traditional IDS models often overlook the temporal characteristics of network traffic, limiting their effectiveness in early threat detection. We propose a Transformer-based Early Intrusion Detection System (EIDS) that incorporates dynamic temporal positional encodings to enhance detection accuracy while maintaining computational efficiency. By leveraging network flow timestamps, our approach captures both sequence structure and timing irregularities indicative of malicious behaviour. Additionally, we introduce a data augmentation pipeline to improve model robustness. Evaluated on the CICIoT2023 dataset, our method outperforms existing models in both accuracy and earliness. We further demonstrate its real-time feasibility on resource-constrained IoT devices, achieving low-latency inference and minimal memory footprint.","","978-953-290-142-9","10.23919/SpliTech65624.2025.11091651","Hellenic Foundation for Research and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091651","Early intrusion detection;Internet of Things (IoT);Transformer models;Temporal positional encodings","Accuracy;Computational modeling;Intrusion detection;Telecommunication traffic;Transformers;Encoding;Threat assessment;Timing;Internet of Things;Low latency communication","","","","25","","30 Jul 2025","","","IEEE","IEEE Conferences"
"FAVbot: An Autonomous Target Tracking Micro-Robot with Frequency Actuation Control","Z. Hao; A. Lele; Y. Fang; A. Raychowdhury; A. Ansari","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Kennesaw State University, Marietta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",IEEE Transactions on Circuits and Systems for Artificial Intelligence,"","2025","PP","99","1","13","Robotic autonomy at centimeter scale requires compact and miniaturization-friendly actuation integrated with sensing and neural network processing assembly within a tiny form factor. Applications of such systems have witnessed significant advancements in recent years in fields such as healthcare, manufacturing, and post-disaster rescue. The system design at this scale puts stringent constraints on power consumption for both the sensory front-end and actuation back-end and the weight of the electronic assembly for robust operation. In this paper, we introduce FAVbot, the first autonomous mobile micro-robotic system integrated with a novel actuation mechanism and convolutional neural network (CNN) based computer vision - all integrated within a compact 3-cm form factor. The novel actuation mechanism utilizes the mechanical resonance phenomenon to achieve frequency-controlled steering with a single piezoelectric actuator. Experimental results demonstrate the effectiveness of FAVbot’s frequency-controlled actuation, which offers a diverse selection of resonance modes with different motion characteristics. The actuation system is complemented with the vision frontend where a camera along with a microcontroller supports object detection for closed-loop control and autonomous target tracking. This enables adaptive navigation in dynamic environments. This work contributes to the evolving landscape of neural network-enabled micro-robotic systems showing the smallest autonomous robot built using controllable multi-directional single-actuator mechanism.","2996-6647","","10.1109/TCASAI.2025.3596217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119216","Robotic autonomy;Motion Control;Autonomous Agents;CNN;Computer Vision","Robots;Motors;Cameras;Resonant frequency;Vibrations;Convolutional neural networks;Computer vision;Robot vision systems;Resonance;Imaging","","","","","IEEE","6 Aug 2025","","","IEEE","IEEE Early Access Articles"
"A Context-Aware, AI-Driven Load Balancing Framework for Incident Escalation in SOCs","A. Abuaziz; B. Celiktas","Computer Engineering Department, Isik University, Istanbul, Turkey; Computer Engineering Department, Isik University, Istanbul, Turkey",2025 9th International Symposium on Innovative Approaches in Smart Technologies (ISAS),"12 Aug 2025","2025","","","1","10","SOCs face growing challenges in incident management due to increasing alert volumes and the complexity of cyberattacks. Traditional rule-based escalation models often fail to account for the workload of the analyst, the severity of the incident, and the organizational context. This paper proposes a context-aware, AI-driven load balancing framework for intelligent analyst assignment and incident escalation. Our framework leverages large language models (LLMs) with retrievalaugmented generation (RAG) to evaluate incident relevance and historical assignments. A reinforcement learning (RL)-based scheduler continuously optimizes incident-to-analyst assignments based on operational outcomes, enabling the system to adapt to evolving threat landscapes and organizational structures. Planned simulations in realistic SOC environments will compare the model with traditional rule-based models using metrics such as Mean Time to Resolution (MTTR), workload distribution, and escalation accuracy. This work highlights the potential of AIdriven approaches to improve SOC performance and enhance incident response effectiveness.","","979-8-3315-1482-2","10.1109/ISAS66241.2025.11101733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101733","AI-driven incident escalation;load balancing;security operation center;escalation;context-aware assignment","Measurement;Adaptation models;Large language models;Reinforcement learning;Load management;Security;Computer crime;Faces;Load modeling;Context modeling","","","","22","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"SHTree: A Structural Encrypted Traffic Fingerprint Generation Method for Multiple Classification Tasks","M. Ma; Z. Shi; Q. Yin; Y. Zong","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Zhongguancun Laboratory, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2024 IEEE Symposium on Computers and Communications (ISCC),"31 Oct 2024","2024","","","1","7","In recent years, encrypted traffic classification has been found widespread applications in the field of cybersecurity. Its main challenge lies in accurately represent traffic when features are obscured due to encryption. To address this, researchers utilize fingerprint construction methods based on statistical information or employ Deep Learning (DL) for traffic representation. However, in previous methods of feature selection, flat key-value pair features, or raw packet bytes are often used, ignoring the structured information embedded in packets and flows. Therefore, We propose a novel structured encrypted traffic fingerprint generation method called SHTree. It constructs traffic fingerprints using a set of tree-based structures to represent traffic, encapsulating structural features from the traffic, enhancing the representation of traffic. This enables it to adapt to various classification tasks through general feature selection. The experiments demonstrate that our method achieves comparable accuracy to state-of-the-art Large Language Models (LLMs), with an F1 score higher by 0.5% on specific tasks. Meanwhile, it outperforms by three orders of magnitude in classification speed. In unsupervised abnormal detection tasks, the True Positive Rate (TPR) exceeds 99%, while maintaining a False Positive Rate (FPR) of 0.5%.","2642-7389","979-8-3503-5423-2","10.1109/ISCC61673.2024.10733622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10733622","Network Traffic Classification;Network Security;Traffic Fingerprint","Deep learning;Computers;Accuracy;Large language models;Decision making;Telecommunication traffic;Fingerprint recognition;Feature extraction;Encryption;Computer security","","","","22","IEEE","31 Oct 2024","","","IEEE","IEEE Conferences"
"Advanced Reinforcement Learning Based Penetration Testing","A. U. H; B. S. Anavi; B. Goyal; S. P. Kasturi; P. Agarwal","Computer Science and Engineering Department, PES University, Bengaluru, India; Computer Science and Engineering Department, PES University, Bengaluru, India; Computer Science and Engineering Department, PES University, Bengaluru, India; Computer Science and Engineering Department, PES University, Bengaluru, India; Computer Science and Engineering Department, PES University, Bengaluru, India","2024 International Conference on Electronics, Computing, Communication and Control Technology (ICECCC)","23 Jul 2024","2024","","","1","6","Penetration testing is a technique that involves the identification and exploitation of security flaws by simulating real world attacks to find security loopholes. Manual pentesting is a tedious and time consuming process. With applications being developed within weeks and the rapid growth of cybercrime, automated pentesting is the need of the hour. This research focuses on training the pentesting agent using three different reinforcement learning algorithms - Proximal Policy Optimization(PPO), Deep Q-Network (DQN) and Ad-vantageous Actor-Critic (A2C) to discover the suitable technique to perform penetration testing. The goal is to create an agent which is capable of exploiting the vulnerabilities in a host system in an effective manner. The training occurs against various vulnerable machines to identify the optimal exploit path with each algorithm and their convergence is compared. The study finds that Advantageous Actor-Critic has the best convergence rate compared to the performance of Deep Q-Network and Proximal Policy Optimization. The time duration and resource consumption is minimal proving that manual penetration testing is old and outdated and automating the process is tedious but worthy and effective.","","979-8-3503-7180-2","10.1109/ICECCC61767.2024.10593902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593902","Reinforcement Learning;Proximal Policy Opti-mization;Deep Q Learning;Generative AI;Advantageous Actor Critic;Penetration Testing;Ethical Hacking;Automation","Training;Fault diagnosis;Reinforcement learning;Manuals;Security;Computer crime;Optimization","","2","","17","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"An AI-aware Orchestration Framework for Cloud-based LLM Workloads","Z. Ye; R. Ying","UM-SJTU Joint Intitute Shanghai Jiao Tong University, Shanghai, China; Dept of Cloud Software Engineering, Software and Advanced Technology Group, Intel, Shanghai, China",2024 IEEE 10th International Conference on Edge Computing and Scalable Cloud (EdgeCom),"14 Aug 2024","2024","","","22","24","Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized the entire industry with their extraordinary power, and gained traction in the cloud community. Deploying LLM workloads in cloud has become increasingly common nowadays, as cloud easily fulfills their requirement on extensive computing resources. There are already tools (such as Kubernetes) that help simplify the management of Artificial Intelligence (AI) workloads, yet LLMs often require the balancing of multi-dimensional demands, which can be hard to handle by basic tools. This paper introduces an AI-aware orchestration framework that optimizes LLM performance from aspects including scheduling, scaling, and advanced data management. It can improve the cost-efficiency of the LLM workloads while ensuring its performance, while ensuring the absence of common security risks, supported by Intel hardware.","","979-8-3503-7713-2","10.1109/EdgeCom62867.2024.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10629097","Artificial Intelligence;Machine Learning;Large Language Model;Kubernetes;Cloud Computing","Industries;Job shop scheduling;Processor scheduling;Large language models;Computational modeling;Chatbots;Hardware","","1","","6","IEEE","14 Aug 2024","","","IEEE","IEEE Conferences"
"S-Health: LLM-driven and Lightweight Blockchain-based Secure Framework for Healthcare 5.0","A. Kumari; M. H. Shah; P. V. Sheth","Department of Computer Science and Engineering, Institute of Technology, Nirma University, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Gujarat, India",2024 IEEE Globecom Workshops (GC Wkshps),"12 Aug 2025","2024","","","1","6","In Healthcare 5.0, the integration of Large Language Models (LLMs) and blockchain in healthcare is a transformative solution for safe and unaltered medical data analysis. In this paper, a framework is proposed, i.e., S-Health to perform the prediction analysis and medical report analysis based on the Internet of Things (IoT) healthcare data using the LLMs, which is integrated with lightweight blockchain technology for data security and integrity. Further, S-Health comprises an Interplanetary File System (IPFS), which is a decentralized file storage system that allows all stakeholders of S-Health to share analytical reports securely. Next, performance evaluation criteria like the Mean Absolute Error (MAE), Mean Squared Error (MSE), Accuracy, and the confusion matrix are adopted to measure the effectiveness of the developed framework. Thus, the results prove the efficiency of the suggested integration and show that it is more accurate and secure in the context of medical data analysis and storage than other available approaches. S-Health addresses key challenges in healthcare data management, presenting a robust solution for the modern healthcare industry.","2166-0077","979-8-3315-0567-7","10.1109/GCWkshp64532.2024.11100794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100794","Healthcare 5.0;LLM;Blockchain;IoT;Predictive Analytics","Data analysis;Accuracy;Data security;Scalability;Medical services;Blockchains;Internet of Things;InterPlanetary File System;Stakeholders;Predictive analytics","","","","15","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"CRALA: A Chinese-centric Risk Simulation and Assessment Framework for LLM Agents","W. Ye; Z. Zhang; W. Li; Y. Qin; P. Zhang","Chongqing No.8 Secondary School, Chongqing, China; Chongqing No.8 Secondary School, Chongqing, China; Chongqing No.8 Secondary School, Chongqing, China; Chongqing No.8 Secondary School, Chongqing, China; Tsinghua University, Beijing, China",2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM),"26 Mar 2025","2024","","","561","566","In recent years, large language models (LLMs) become more and more powerful. They can do many interesting tasks, like connecting to different external tools—sometimes we call them “plugins”—to help handle real things in the world. But at the same time, giving LLM agents more real-world power also creates a lot of risks we must be careful about. Checking these risks is not easy at all. It can cost lots of time and energy because we have to make special plugins and do complicated tests just to see if the model might do something unsafe. Most of the “serious” security checks, like the ones done on GPT-4, focus mostly on English. In Chinese, we know very little about the dangers with existing research. Many research pays attention to English, but not so much to Chinese cases, even though it’s super important. To fix this problem, we made a new framework called CRALA (Chinese-centric Risk Assessment for LLM Agents). It can simulate many situations in Chinese and then carefully check if there are any safety issues hiding inside these LLM agent tasks. CRALA includes two main parts: a Chinese Interaction Simulator, which creates and records pretend conversations, and an Evaluator, which looks at all these interactions and decides if interaction might be unsafe. We tested CRALA with human reviewers on 55 different Chinese scenarios. The results show that about $\mathbf{8 1. 5 \%}$ collected test cases are realistic. When the CRALA flags a case as dangerous, about 63.5% really were problems. We even tested 100 risky cases in Chinese apps with popular LLMs like GPT-4. GPT-4 only handled around 35% of them safely. This shows that we still have a long way to go before we can trust these agents completely, at least in Chinese contexts. In conclusion, CRALA makes checking these risks much less painful and gives us a better understanding of how safe Chinese LLM agents really are.","","979-8-3315-4172-9","10.1109/AIIM64537.2024.10934441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10934441","component;Risk Simulation and Assessment;Chinese LLM Agents","Heavily-tailed distribution;Costs;Annotations;Large language models;Oral communication;Manuals;Safety;Manufacturing;Security;Risk management","","","","18","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Initial Attempt at Automated Vulnerability Fixing of Obfuscated Smart Contracts Using a Large Language Model","C. Kado; T. Tsuchiya","Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",2024 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),"10 Dec 2024","2024","","","1","3","Countermeasures against vulnerabilities are essential for the security of smart contracts. Some recent studies have focused on automated vulnerability repair using large language models (LLMs). However, the ability of LLMs to fix unknown contracts is still unclear. To address this problem, we applied Code Llama LLM to a real-world smart contract with a vulnerability and its obfuscated version, assuming that the obfuscated version could be considered an unknown contract. We obtained three fixes generated by the LLM for each contract. Of these three, one fix was successful for each contract. While some fixes removed the vulnerability, they also altered the functionality of the contract. No clear difference was observed between the original and obfuscated contracts in terms of the LLM's repairing capability.","","979-8-3315-3083-9","10.1109/ICCE-Asia63397.2024.10773661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773661","Large language model;automated fix;Ethereum smart contract;vulnerability;obfuscation","Solid modeling;Codes;Large language models;Smart contracts;Maintenance engineering;Solids;Security","","","","14","IEEE","10 Dec 2024","","","IEEE","IEEE Conferences"
"Phishing Website Detection Method Based on Multimodal Large Language Model","C. Fang; X. Yin; P. Han","College of Electronic Information and Automation, Civil Aviation University of China, Tianjin, China; College of Electronic Information and Automation, Civil Aviation University of China, Tianjin, China; College of Electronic Information and Automation, Civil Aviation University of China, Tianjin, China","2025 8th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","24 Jun 2025","2025","","","264","268","In recent years, phishing attack methods have demonstrated characteristics of strong anti-detection abilities, resulting in significant economic losses. Traditional phishing website detection methods suffer from limited features and insufficient information, no longer meeting the practical requirements for effective security protection. To address complex and variable network phishing attacks, we propose a phishing website detection method based on multimodal large language models (LLMs). The different modalities of website features are transformed into text features by LLMs. The problem of detecting phishing websites is transformed into a text classification problem. The method we propose improves phishing website detection performance through the multimodal fusion of website information. Experimental evaluation on a public dataset demonstrates the method’s effectiveness, achieving an F1 score of 96.1%.","","979-8-3315-1091-6","10.1109/AEMCSE65292.2025.11042373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042373","Phishing Website;Multimodal;Large Language Model;Information Fusion;Text Classification","Economics;Social networking (online);Phishing;Large language models;Text categorization;Transforms;Feature extraction;Electronic mail;Protection;Software engineering","","","","14","IEEE","24 Jun 2025","","","IEEE","IEEE Conferences"
"Context-Aware AI for Real-Time Content and Quiz Recommendations in Student Learning Environments","A. Memeti; I. Neziri; N. Ajruli; K. Huseini; A. Nuhi; A. Iljazi","University of Tetova, Tetova, North Macedonia; University of Tetova, Tetova, North Macedonia; University of Tetova, Tetova, North Macedonia; University of Tetova, Tetova, North Macedonia; University of Tetova, Tetova, North Macedonia; University of Tetova, Tetova, North Macedonia",2025 3rd Cognitive Models and Artificial Intelligence Conference (AICCONF),"10 Jul 2025","2025","","","1","4","The paper presents a context-aware AI system designed to dynamically recommend course material and generate quizzes in real-time, based on the individual student interaction and performance. The proposed model integrates generative AI capability with a previously developed Learning Management System (LMS), using Blazor components for seamless user interface presentation and real-time system updates. Through the processing of contextual data such as enrolled courses, student activity, history, and participation patterns, the system acquires insight to generate intelligent content blocks and short quizzes tailored to the immediate needs of the learner. The artificial intelligence engine, which is built on large language models, is infused through guided questions that solicit recommended topics and related quiz items. Upon login by students, the dashboard includes an interactive ""Subject explanation"" panel, allowing real-time provision of AI-generated resources and quizzes, visually integrated using Blazor’s conditional rendering feature. This article describes the system design, implementation sequence, and deployment at the University of Tetova, illustrating how cognitive-aware AI can engage learners more and facilitate adaptive learning routes through autonomous, scalable learning augmentation.","","979-8-3315-0969-9","10.1109/AICCONF64766.2025.11063980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11063980","Artificial Intelligence;Context-Aware Learning;Generative Models;Blazor components;Adaptive Assessment;Real-Time Recommendation;Personalized Education","Learning management systems;Adaptive learning;Adaptation models;Adaptive systems;System dynamics;Large language models;User interfaces;Real-time systems;Artificial intelligence;Context modeling","","","","12","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"Optimizing Malware Detection with Random Forest, XGBoost, LightGBM, and LLM-Reporting","A. Charoenthanakitkul; P. Viboonsang; S. Kosolsombat","Data Science and Innovation Program, College of Interdisciplinary Studies, Thammasat University, Pathum Thani, Thailand; Data Science and Innovation Program, College of Interdisciplinary Studies, Thammasat University, Pathum Thani, Thailand; Data Science and Innovation Program, College of Interdisciplinary Studies, Thammasat University, Pathum Thani, Thailand",2025 IEEE International Conference on Cybernetics and Innovations (ICCI),"12 May 2025","2025","","","1","5","This study presents a comprehensive framework for malware detection that integrates traditional machine learning algorithms with advanced large language models (LLMs) to enhance both classification accuracy and automated report generation. The proposed approach leverages three widely used machine learning models-Random Forest, XGBoost, and LightGBM-to classify different types of malwares based on extracted features from the EMBER dataset, a well-known benchmark dataset for malware analysis. Each of these models was trained and evaluated to determine their effectiveness in identifying malicious software with high accuracy. Among the tested algorithms, LightGBM exhibited the best performance, achieving an impressive classification accuracy of 83%. XGBoost followed closely with 81%, while Random Forest achieved an accuracy of 79%. To further enhance the usability of the system for cybersecurity analysts, the study incorporates a large language model, specifically LLaMA, which is accessed via an API. This model is employed to generate detailed, human-readable reports that provide insights into detected malware threats. By automating the reporting process, the framework aims to reduce the manual effort required for malware analysis, allowing security professionals to focus on high-priority threats. Future research will focus on improving classification performance through advanced feature engineering techniques and exploring deep learning-based neural network architectures to further enhance the accuracy and efficiency of malware detection and analysis.","","979-8-3315-3326-7","10.1109/ICCI64209.2025.10987272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987272","Malware Detection;Random Forest;XGBoost;LightGBM;LLM;Cybersecurity","Training;Analytical models;Accuracy;Machine learning algorithms;Computational modeling;Large language models;Feature extraction;Malware;Computer security;Random forests","","","","19","IEEE","12 May 2025","","","IEEE","IEEE Conferences"
"Distributed Generative Model: A Data Synthesizing Framework for Multi-Source Heterogeneous Data","Z. Xiong; W. Li; Y. Li; Z. Cai","Department of Computer Science, University of Nevada Las Vegas, Las Vegas, NV, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","13","Recent advancement in generative AI influenced a broad area with successful applications across multiple domains, including computer vision, natural language processing, and the Internet of Things (IoT). However, many existing implementations rely on centralized architectures, which introduce security and privacy concerns while also increasing communication overhead. Limited research has explored the development of distributed generative models, particularly in scenarios where training data originates from various heterogeneous sources. To fill the gap, this paper introduces a distributed generative model framework aimed at enhancing data generation in hierarchical IoT systems. The proposed framework supports distributed data generation across three distinct scenarios: feature-related data, label-related data, and feature-label non-related data. Furthermore, both synchronous and asynchronous update mechanisms are incorporated to accommodate diverse application requirements within IoT environments. Comprehensive experiments using simulated, image, and tabular datasets are conducted to assess the performance of the proposed framework in comparison with state-of-the-art methods. The results indicate that the framework effectively produces high-quality synthetic data while preserving the integrity of downstream tasks. Beyond large language models (LLMs), these findings suggest that generative AI have the potential to transform data generation in distributed IoT systems and be extended to a broader range of applications.","2691-4581","","10.1109/TAI.2025.3575548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022721","Distributed Learning;Generative Adversarial Networks;Multi-source Heterogeneous Data;Federated Learning","Distributed databases;Data models;Training;Internet of Things;Generators;Data collection;Servers;Artificial intelligence;Computational modeling;Soft sensors","","","","","IEEE","3 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Verifying Computation Tree Logic of Knowledge via the Similar Reachability Graphs of Knowledge-oriented Petri Nets","L. He; G. Liu","Department of Computer Science, Tongji University, Shanghai, P. R. China; Department of Computer Science, Tongji University, Shanghai, P. R. China",2020 39th Chinese Control Conference (CCC),"9 Sep 2020","2020","","","5026","5031","Computation Tree Logic of Knowledge (CTLK) can specify many requirements of privacy or security of multi-agent systems (MAS). In our previous paper, we defined Knowledge-oriented Petri Nets (KPN) to model MAS. A KPN is a special Petri net in which some places are used to represent knowledge. Consequently, KPN can formally represent not only the interaction/collaboration process of multiple agents but also their epistemic evolutions. These epistemic evolutions are closely related to privacy and security of MAS. Then we defined the similar reachability graphs of KPN and constructed the equivalence classes of knowledge for each agent. We considered an epistemic operator K and designed its model checking algorithm based on similar reachability graph and equivalence class. In this paper, we design the model checking algorithm for another epistemic operator C. Additionally, we develop a related tool. Examples of privacy protocols illustrate the usefulness of our model and method.","1934-1768","978-9-8815-6390-3","10.23919/CCC50068.2020.9188719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188719","Epistemic Logic;Equivalence Class;Model Checking;Petri Nets","Petri nets;Protocols;Model checking;Privacy;Receivers;Security;Tools","","5","","22","","9 Sep 2020","","","IEEE","IEEE Conferences"
"The Ultimate Battle Against Zero-Day Exploits: Toward Fully Autonomous Cyber-Physical Defense","T. Halabi; M. Zulkernine","Université Laval, Québec, QC, Canada; Queen's University, Kingston, ON, Canada",2023 IEEE International Conference on Software Services Engineering (SSE),"4 Sep 2023","2023","","","256","261","The last decade has shown that networked cyber-physical systems (NCPS) are the future of critical infrastructure such as transportation systems and energy production. However, they have introduced an uncharted territory of security vulnerabilities and a wider attack surface, mainly due to network openness and the deeply integrated physical and cyber spaces. On the other hand, relying on manual analysis of intrusion detection alarms might be effective in stopping run-of-the-mill automated probes but remain useless against the growing number of targeted, persistent, and often AI-enabled attacks on large-scale NCPS. Hence, there is a pressing need for new research directions to provide advanced protection. This paper introduces a novel security paradigm for emerging NCPS, namely Autonomous Cyber-Physical Defense (ACPD). We lay out the theoretical foundations and describe the methods for building autonomous and stealthy cyber-physical defense agents that are able to dynamically hunt, detect, and respond to intelligent and sophisticated adversaries in real time without human intervention. By leveraging the power of game theory and multi-agent reinforcement learning, these self-learning agents will be able to deploy complex cyber-physical deception scenarios on the fly, generate optimal and adaptive security policies without prior knowledge of potential threats, and defend themselves against adversarial learning. Nonetheless, serious challenges including trustworthiness, scalability, and transfer learning are yet to be addressed for these autonomous agents to become the next-generation tools of cyber-physical defense.","","979-8-3503-4075-4","10.1109/SSE60056.2023.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234329","Cyber-physical security;reinforcement learning;autonomous and adaptive defense;advanced persistent threats","Scalability;Transfer learning;Transportation;Reinforcement learning;Production;Pressing;Software","","3","","26","IEEE","4 Sep 2023","","","IEEE","IEEE Conferences"
"A Vision for Operationalising Diversity and Inclusion in AI","M. Bano; D. Zowghi; V. Gervasi","CSIRO’s Data61, Clayton, VIC, Australia; CSIRO’s Data61, Eveleigh, NSW, Australia; Department of Computer Science, Pisa University, Italy",2024 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE),"11 Sep 2024","2024","","","36","43","The growing presence of Artificial Intelligence (AI] in various sectors necessitates systems that accurately reflect societal diversity. This study seeks to envision the operationalization of the ethical imperatives of diversity and inclusion (D&I] within AI ecosystems, addressing the current disconnect between ethical guidelines and their practical implementation. A significant challenge in AI development is the effective operationalization of D&I principles, which is critical to prevent the reinforcement of existing biases and ensure equity across AI applications. This paper proposes a vision of a framework for developing a tool utilizing persona-based simulation by Generative AI (GenAI]. The approach aims to facilitate the representation of the needs of diverse users in the requirements analysis process for AI software. The proposed framework is expected to lead to a comprehensive persona repository with diverse attributes that inform the development process with detailed user narratives. This research contributes to the development of an inclusive AI paradigm that ensures future technological advances are designed with a commitment to the diverse fabric of humanity.CCS CONCEPTS• Social and professional topics ~ User characteristics • Software and its engineering ~ Software creation and management ~ Designing software ~ Requirements analysis • Computing methodologies ~ Artificial intelligence ~ Natural language processing ~ Natural language generation","","979-8-4007-0572-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669894","Artificial Intelligence;Diversity and Inclusion;Requirements Engineering;Persona","Ethics;Generative AI;Ecosystems;Natural language generation;Software;Cultural differences;Artificial intelligence","","1","","34","CCBY","11 Sep 2024","","","IEEE","IEEE Conferences"
"Multi-Agent Resilient Control Based on False Data Injection Attacks","W. Yu; Z. Guo; P. Suo; N. Li; Z. Song; L. Deng","Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China; Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China; Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China; Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China; Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China; Yingkou Power Supply Company State Grid Liaoning Electric Power Co., Ltd., Yingkou, China",2024 Second International Conference on Cyber-Energy Systems and Intelligent Energy (ICCSIE),"7 Oct 2024","2024","","","1","5","The paper introduces a resilient control method for nonlinear multi-agent systems (MAS). The attack type considered in this paper is FDI (False Data Injection) attacks targeting the controller. The consequence of the attack is the occurrence of controller malfunction. In industrial control systems, FDI attacks pose a significant security threat. Instead of relying on global information about the communication network, this method allows agents to exchange information locally with their neighboring agents. Each agent has its own control mechanism, which helps avoid the need for centralized communication. Furthermore, this approach addresses the issue of elastic control in the presence of FDI attacks. It ensures that the system can continue to operate smoothly even when encountering unknown abnormal parameters. By carefully selecting Lyapunov functions, the paper demonstrates that the system achieves stable consensus between leaders and followers in a multi-agent setting.","","979-8-3503-7331-8","10.1109/ICCSIE61360.2024.10698075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698075","Cooperated control;nonlinear system","Industrial control;Control systems;Security;Communication networks;Information exchange;Multi-agent systems;Matlab;Lyapunov methods","","","","19","IEEE","7 Oct 2024","","","IEEE","IEEE Conferences"
"Reliable and Efficient Data Collection in UAV based IoT Networks","J. Poorvi; A. Kalita; M. Gurusamy","Department of Electrical and Computer Engineering, Communications and Networks Lab, National University of Singapore, Singapore; Mathematics and Computing Department, Indian Institute of Technology (ISM) Dhanbad, India; Department of Electrical and Computer Engineering, Communications and Networks Lab, National University of Singapore, Singapore",IEEE Communications Surveys & Tutorials,"","2025","PP","99","1","1","IoT involves sensors for monitoring and wireless networks for efficient communication. However, resource-constrained IoT devices and limitations in existing wireless technologies hinder its full potential. Integrating UAVs into IoT networks can address some challenges by expanding its coverage, providing security, and bringing computing closer to IoT devices. Nevertheless, effective data collection in UAV-assisted IoT networks is hampered by factors, including dynamic UAV behaviour, environmental variables, connectivity instability, and security considerations. In this survey, we first explore various communication technologies for UAV-IoT networks, performance metrics, and simulation tools, followed by a categorization of the UAV-IoT system based on the service model of UAV, mode of operation of UAV and UE during data collection, and network topology. As this article primarily emphasizes reliable and efficient data collection in UAV-assisted IoT networks, we briefly discuss existing research on data accuracy and consistency, network connectivity, and data security and privacy to provide insights into reliable data collection. Additionally, we discuss efficient data collection strategies in UAV-based IoT networks, covering trajectory planning and constraint management, sensor network clustering, data aggregation, and UAV swarm formations. Further, advanced AI techniques are discussed, which enable efficient and reliable data transfer in UAV-IoT systems. Finally, we discuss future challenges and their possible solutions using different approaches such as Decentralized Reinforcement and Federated Learning, Generative AI, and hybrid optical-RF communication links with integration of blockchain for reliable, efficient, and secure data collection in UAV-assisted IoT networks.","1553-877X","","10.1109/COMST.2025.3550274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922390","Internet of Things (IoT);Unmanned Aerial Vehicle (UAV);data collection;reliable;efficient;communication;security;network connectivity","Internet of Things;Autonomous aerial vehicles;Data collection;Security;Reliability;Sensors;Surveys;Wireless sensor networks;Wireless communication;Energy efficiency","","5","","","IEEE","11 Mar 2025","","","IEEE","IEEE Early Access Articles"
"Secure Full-Duplex Communication via Movable Antennas","J. Ding; Z. Zhou; C. Wang; W. Li; L. Lin; B. Jiao","School of Electronics, Peking University, Beijing, China; School of Electronics, Peking University, Beijing, China; School of Electronics, Peking University, Beijing, China; School of Electronics, Peking University, Beijing, China; School of Electronics, Peking University, Beijing, China; School of Electronics, Peking University, Beijing, China",GLOBECOM 2024 - 2024 IEEE Global Communications Conference,"11 Mar 2025","2024","","","885","890","This paper investigates physical layer security (PLS) in a movable antenna (MA)-assisted full-duplex (FD) system. In this system, an FD base station (BS) with multiple MAs for transmission and reception provides services for an uplink (UL) user and a downlink (DL) user. Each user operates in half-duplex (HD) mode and is equipped with a single fixed-position antenna (FPA), in the presence of a single-FPA eavesdropper (Eve). To ensure secure communication, artificial noise (AN) is transmitted to obstruct the interception of Eve. The objective of this paper is to maximize the sum secrecy rate (SSR) of the UL and DL users by jointly optimizing the beamformers of the BS and the positions of MAs. This paper also proposes an alternating optimization (AO) method to address the non-convex problem, which decomposes the optimization problem into three subproblems and solves them iteratively. Simulation results demonstrate a significant performance gain in the SSR achieved by the proposed scheme compared to the benchmark schemes.","2576-6813","979-8-3503-5125-5","10.1109/GLOBECOM52923.2024.10901646","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901646","Movable antenna (MA);physical layer security (PLS);full-duplex (FD);alternating optimization (AO)","Simulation;Noise;Half-duplex system;Full-duplex system;Physical layer security;Performance gain;Global communication;Uplink;Optimization;Antennas","","5","","17","IEEE","11 Mar 2025","","","IEEE","IEEE Conferences"
"Enhancing Security: Infused Hybrid Vision Transformer for Signature Verification","M. Ishfaq; A. Saadia; F. M. Alserhani; A. Gul","Department of Cyber Security, Air University, Islamabad, Pakistan; Department of Computer Science, Air University, Islamabad, Pakistan; Department of Computer Engineering and Networks, College of Computer and Information Sciences, Jouf University, Sakaka, Al-Jouf, Saudi Arabia; Faculty of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, U.K.",IEEE Access,"1 Oct 2024","2024","12","","137504","137521","Handwritten signature verification is challenging because there is a huge variation between the orientation thickness and appearance of handwritten signatures. A strong signature verification system is essential to refine the accuracy of confirming user authentication. This investigation introduces an inclusive framework for training and evaluating hybrid vision transformer models on diverse signature datasets, aiming to refine the accuracy in confirming user authentication. In previous studies, transformer & MobileNet were used for computer vision classification and signature verification separately. Drawing inspiration from the Convolutional Neural Network (CNN), the hybrid model is proposed as a deep-learning model (ResNet-18 & MobileNetV2) with the Vision Transformer model (proposed method 1 & proposed method 2).To bring originality to this study, we excluded the final layer of the feature extractor and smoothly integrated it with the initial layer of the vision transformer. In the scope of this research, we introduced a unique hybrid vision transformer model. Furthermore, we incorporated swish and tangent hyperbolic (tanh) activation functions into the validation model to enhance its performance. Experimental results showcase the effectiveness of the proposed hybrid model, achieving notable accuracies on various datasets, including 92.33% accuracy on Bhsig-Bengali, 99.89% accuracy on Bhsig-Hindi, 99.96% accuracy on Cedar, and 74.09% accuracy on UTsig-Persian datasets, respectively. The practical implications of this research extend to real-time signature verification for secure and efficient user authentication, particularly in mobile applications. This advancement in signature verification technology presents new possibilities for practical use in diverse scenarios beyond academia.","2169-3536","","10.1109/ACCESS.2024.3447083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654737","Vision transformer ResNet-18;MobileNetV2;handwritten character verification;signature verification;hybrid vision transformer;handwritten signature verification;UTsig-Persian","Transformers;Computer vision;Accuracy;Feature extraction;Authentication;Forgery;Computational modeling;Handwriting recognition","","1","","51","CCBYNCND","28 Aug 2024","","","IEEE","IEEE Journals"
"A Trusted Agent Strategy in Decentralized Network Environments","Karishma; S. Rao","International Institute of Information Technology Bangalore, Bangalore, India; International Institute of Information Technology Bangalore, Bangalore, India","2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","14 May 2020","2020","","","433","440","A problem currently faced by autonomous systems, learning agents, multi-agent systems and other cognitive systems is the extreme susceptibility to bad information and malicious misdirection. In this paper, we propose a strategy to identify trusted agents in a multi-agent system, so that a system can eliminate the knowledge provided by malicious or unknown agents. The strategy is covered in three phases by each agent; firstly sharing information with other agents in the system, secondly calculating the conclusion based on the majority of information received from others and lastly identifying the trusted, malicious and unknown agents in the system. The theoretical analysis shows that the trusted agent strategy (TAS) is capable of identifying malicious or compromised agents if a system has less than 25% of malicious agents. This is further improved in the advanced-TAS which can handle up to 40% malicious agents. The experimental results show that trusted and malicious agents can be identified with high accuracy.","2377-5750","978-1-7281-6582-0","10.1109/PDP50117.2020.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092389","network security;multi-agent system;parallel computing","Multi-agent systems;Arrays;Communication channels;Decision making;Fault tolerance","","1","","21","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Interactive Framework for Cybersecurity Education and Future Workforce Development","S. Ghimire; M. A. Chowdhury; R. Tsang; R. Yarnell; E. Heckert; J. Carpenter; Y. -Z. Lin; M. Mamun; R. F. DeMara; S. Rafatirad; P. Satam; S. Salehi","Department of Systems and Industrial Engineering, University of Arizona, Tucson, AZ; Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ; Department of Electrical and Computer Engineering, University of California Davis, Davis, CA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL; Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ; Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ; Department of Systems and Industrial Engineering, University of Arizona, Tucson, AZ; Department of Systems and Industrial Engineering, University of Arizona, Tucson, AZ; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL; Department of Computer Science, University of California Davis, Davis, CA; Department of Systems and Industrial Engineering, University of Arizona, Tucson, AZ; Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","7","This research-to-practice paper presents a novel pedagogical tool for hardware cybersecurity education and workforce development. The growing importance of hardware security has made it essential for individuals and organizations to understand hardware security principles and best practices. However, the current educational curriculum falls short of fulfilling these emerging demands due to the rapidly changing hardware security landscape and limited opportunities for hands-on training. To address these challenges, we propose and have developed the Interactive Hardware and Cybersecurity (I-HaC) Educational Framework, a pedagogical educational framework that supplements existing courses by leveraging generative AI for individualized instruction related to hardware and cybersecurity, data mining, and applied Machine Learning (ML), as well as data visualization to enhance cybersecurity education and workforce development. The framework is designed to be utilized by graduate and undergraduate Electrical and Computer Engineering (ECE) and Computer Science (CS) students for a comprehensive introduction to cybersecurity exploits and countermeasures in an interactive manner with hands-on components. Using I-HaC, we have developed tailored lab components for a diverse range of students and intend to release I-HaC as open-source for the benefit of the ECE and CS education community.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10892909","National Science Foundation(grant numbers:2335046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892909","National Vulnerability Database (NVD);Com-mon Vulnerability and Exposure (CVE);Common Weakness Enumeration (CWE);Hardware Security;Cybersecurity Education;Future Workforce Development","Training;Generative AI;Databases;Hardware security;Data visualization;Organizations;Machine learning;Ontologies;Computer security;Protection","","","","39","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Steganography With Generated Images: Leveraging Volatility to Enhance Security","J. Zhang; K. Chen; W. Li; W. Zhang; N. Yu","CAS Key Laboratory of Electro-Magnetic Space Information, University of Science and Technology of China, Hefei, China; CAS Key Laboratory of Electro-Magnetic Space Information, University of Science and Technology of China, Hefei, China; Guangdong Key Laboratory of Intelligent Information Processing and the Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China; CAS Key Laboratory of Electro-Magnetic Space Information, University of Science and Technology of China, Hefei, China; CAS Key Laboratory of Electro-Magnetic Space Information, University of Science and Technology of China, Hefei, China",IEEE Transactions on Dependable and Secure Computing,"11 Jul 2024","2024","21","4","3994","4005","The development of generative AI applications has revolutionized the data environment for steganography, providing a new source of steganographic cover. However, existing generative data-based steganography methods typically require white-box access, rendering them unsuitable for black-box generative models. To overcome this limitation, we propose a novel steganography method for generated images, which leverages the volatility of generative models and is applicable in black-box scenarios. The volatility of generative models refers to the ability to generate a series of images with slight variations by fine-tuning the input parameters of the model. These generated images exhibit varying degrees of volatility in different areas. To resist steganalysis, we mask steganographic modifications by confusing them with the inherent volatility of the model. Specifically, by modeling distributions of generated pixels and estimating the parameters of the distributions, the occurrence probabilities of generated pixels can be obtained, which serve as an effective measure for steganographic modification probabilities to render stego images as indistinguishable as possible from the images producible by the model. Moreover, we further combine it with existing costs to develop a more comprehensive steganographic algorithm. Experimental results show that the proposed method significantly outperforms baseline and comparative methods in resisting both feature-based and CNN-based steganalyzers.","1941-0018","","10.1109/TDSC.2023.3341427","National Natural Science Foundation of China(grant numbers:62102386,U2336206,62202310,62002334,62121002); China Postdoctoral Science Foundation(grant numbers:2022M722192); Open Fund of Anhui Province Key Laboratory of Cyberspace Security Situation Awareness and Evaluation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10354433","Black-box;generative model;steganography;volatility","Costs;Steganography;Security;Distortion;Closed box;Mathematical models;Minimization","","7","","43","IEEE","12 Dec 2023","","","IEEE","IEEE Journals"
"A First Look at LLM-powered Smartphones","L. Wu; Y. Zhao; C. Wang; T. Liu; H. Wang","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW),"28 Nov 2024","2024","","","208","217","The integration of Large Language Models (LLMs) into edge devices such as smartphones represents a significant leap in mobile technology, promising enhanced user experiences and novel functionalities. This paper presents a first look at LLM-powered smartphones, addressing four key aspects: the current market landscape, core functions enabled by integrated LLMs, potential security risks, and user perceptions. The findings reveal a rapidly evolving market with major manufacturers competing to integrate LLMs, innovative features that improve user interaction, significant security challenges, and mixed user perceptions that balance enthusiasm for new capabilities with privacy concerns. This study contributes to understanding LLM integration in mobile devices and its implications for users, manufacturers, and the broader technological landscape.","2151-0849","979-8-4007-1249-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765104","","Industries;Privacy;Technological innovation;Ethics;Large language models;Conferences;User experience;Security;Smart phones;Software engineering","","","","50","","28 Nov 2024","","","IEEE","IEEE Conferences"
"Experimental demonstration of local AI-Agents for lifecycle management and control automation of optical networks","C. Sun; X. Yang; N. Di Cicco; R. Ayassi; V. Virajit Garbhapu; P. A. Stavrou; M. Tornatore; G. Charlet; Y. Pointurier","Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France; Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France; Politecnico di Milano, Milan, Italy; Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France; Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France; Communication Systems Department, EURECOM, Sophia Antipolis, France; Politecnico di Milano, Milan, Italy; Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France; Optical Communication Technology Lab, Paris Research Center, Huawei Technologies France SASU, Boulogne-Billancourt, France",Journal of Optical Communications and Networking,"25 Apr 2025","2025","17","8","C82","C92","This paper presents an innovative approach to automating the full lifecycle management of optical networks using locally fine-tuned large language models (LLMs) and digital twin technologies. We experimentally demonstrate the integration of generative AI and digital twins to create powerful AI-Agents capable of handling the design, deployment, maintenance, and upgrade phases in the lifecycle of optical networks. By deploying and fine-tuning LLMs locally, our framework eliminates the need for public cloud services, thereby ensuring data privacy and security. The experimental setup includes a commercial-product-based testbed with eight optical multiplex sections in the C-band, showcasing the effectiveness of the AI-Agents in various automation tasks, such as API-calling for service establishment and periodic power equalization, as well as log analysis for troubleshooting. The results highlight significant improvements in operational accuracy and efficiency, underscoring the feasibility of this approach in real-world scenarios. This work represents a significant advancement toward intent-based networking, showcasing the transformative potential of AI in automating and optimizing optical network operations.","1943-0639","","10.1364/JOCN.550286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10977747","","Optical fiber networks;Transformers;Artificial intelligence;Optical fiber amplifiers;Optical amplifiers;Accuracy;Signal to noise ratio;Physical layer;Optical fiber testing;Digital twins","","","","","","25 Apr 2025","","","IEEE","IEEE Journals"
"Saudi Arabia's Vision 2030: Leveraging Generative Artificial Intelligence to Enhance Software Engineering","E. Albaroudi; T. Mansouri; M. Hatamleh; A. Alameer","School of Science, Engineering and Environment University of Salford University Road, Manchester, UK; Lecturer in Artificial Intelligence School of Science, Engineering and Environment University of Salford, Salford, Manchester, GB; Master in Business Administraion School of Business, Business Administration Edinburgh Napier University, Edinburgh, Scotland; Lecturer in Artificial Intelligence School of Science, Engineering and Environment University of Salford, Salford, Manchester, GB",2025 Eighth International Women in Data Science Conference at Prince Sultan University (WiDS PSU),"29 May 2025","2025","","","1","6","This research explores the transformative role of Generative Artificial Intelligence (GenAl) for the Kingdom of Saudi Arabia (KSA) software developers. KSA is transforming from an oil-dependent economy to a diversified one to achieve Vision 2030. Technological advancement is among the strategic objectives of the Kingdom, facilitating the achievement of the ambitious vision. GenAl's ability to undertake tasks like code generation, debugging, and documentation may threaten developers whose jobs could be replaced. However, instead of replacing software engineers, GenAl will create more opportunities for programmers, increase the demand for more experienced developers, and evolve the role of software engineers. While the benefits of GenAl in software engineering are immense, the Kingdom should address the ethical challenges, inadequate transparency, accountability problems, and data privacy issues. This paper recommends the establishment of a National AI Ethics Board, the government to mandate explainable AI (XAI), investments in more localised models like the Arabic Large Language Model (ALLaM), extensive training for GenAl engineers, cross-sector collaboration, and continuous monitoring.","","979-8-3315-2092-2","10.1109/WiDS-PSU64963.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014920","Artificial intelligence (AI);Generative AI;Soft-ware engineering;Vision 2030;Diversification;Technology","Training;Ethics;Data privacy;Generative AI;Explainable AI;Software;Software measurement;Artificial intelligence;Software engineering;Software development management","","","","49","IEEE","29 May 2025","","","IEEE","IEEE Conferences"
"Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence","T. R. McIntosh; T. Susnjak; N. Arachchilage; T. Liu; D. Xu; P. Watters; M. N. Halgamuge","Cyberoo Pty Ltd, Surrey Hills, NSW, Australia; Massey University, Auckland, New Zealand; RMIT University, Melbourne, VIC, Australia; Massey University, Auckland, New Zealand; RMIT University, Melbourne, VIC, Australia; Cyberstronomy Pty Ltd, Ballarat, VIC, Australia; RMIT University, Melbourne, VIC, Australia",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","18","The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.","2691-4581","","10.1109/TAI.2025.3569516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11002710","Artificial Intelligence (AI);AI Evaluation;Benchmark;Evaluation Frameworks;Large Language Model (LLM)","Benchmark testing;Cultural differences;Generative AI;Computer science;Large language models;Ethics;Cognition;Hardware;Adaptation models;Training","","6","","","IEEE","13 May 2025","","","IEEE","IEEE Early Access Articles"
"ClauseBench: Enhancing Software License Analysis with Clause-Level Benchmarking","Q. Ke; X. Hou; Y. Zhao; H. Wang","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","255","266","Open-source software (OSS) has revolutionized modern software development by fostering collaboration across diverse teams. However, as OSS projects grow in size and complexity, managing license compliance has become increasingly challenging. A critical issue lies in accurately recognizing and interpreting the varied clauses within OSS licenses, particularly when multiple licenses coexist, each with distinct permissions, obligations, and restrictions. Traditional license analysis tools, often rule-based, struggle to identify nuanced conflicts between license clauses, leading to potential compliance risks. In response to these challenges, this paper presents a fine-grained, high- quality dataset of 634 SPDX-certified licenses, annotated with 3,396 individual clauses across 14 categories. Each clause has been meticulously reviewed and validated using model-assisted checks to ensure accuracy, providing a solid foundation for detailed clause-level analysis. To improve clause recognition and conflict detection, we introduce Clausebench,a benchmarking framework that leverages large language models (LLMs) to detect and interpret license clauses with high precision. Clausebenchimproves detection accuracy by 50% compared to traditional document-level methods and significantly reduces hallucination rates by focusing on individual clauses, where precise distinctions in legal language are crucial. We also implemented a contextual prompt engineering strategy to optimize model performance, achieving 90% accuracy in clause identification. Our work sets a new standard for automated license conflict detection in OSS, demonstrating the potential of LLMs to manage the complexities of legal text interpretation. This work advances the license analysis field and opens the door to future research on integrating LLMs with OSS compliance tools.","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024443","","Solid modeling;Accuracy;Law;Licenses;Benchmark testing;Solids;Complexity theory;Software reliability;Prompt engineering;Standards","","","","44","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach","S. M. Hasan; A. M. Alotaibi; S. Talukder; A. R. Shahid","School of Computing, Southern Illinois University, Carbondale, IL, USA; School of Computing, Southern Illinois University, Carbondale, IL, USA; School of Computing, Southern Illinois University, Carbondale, IL, USA; School of Computing, Southern Illinois University, Carbondale, IL, USA","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","1496","1497","With the proliferation of edge devices, there is a significant increase in attack surface on these devices. The decen-tralized deployment of threat intelligence on edge devices, coupled with adaptive machine learning techniques such as the in-context learning feature of Large Language Models (LLMs), represents a promising paradigm for enhancing cybersecurity on resource-constrained edge devices. This approach involves the deployment of lightweight machine learning models directly onto edge devices to analyze local data streams, such as network traffic and system logs, in real-time. Additionally, distributing computational tasks to an edge server reduces latency and improves responsiveness while also enhancing privacy by processing sensitive data locally. LLM servers can enable these edge servers to autonomously adapt to evolving threats and attack patterns, continuously updating their models to improve detection accuracy and reduce false positives. Furthermore, collaborative learning mechanisms facilitate peer-to-peer secure and trustworthy knowledge sharing among edge devices, enhancing the collective intelligence of the network and enabling dynamic threat mitigation measures such as device quarantine in response to detected anomalies. The scalability and flexibility of this approach make it well-suited for diverse and evolving network environments, as edge devices only send suspicious information such as network traffic and system log changes, offering a resilient and efficient solution to combat emerging cyber threats at the network edge. Thus, our proposed framework can improve edge computing security by providing better security in cyber threat detection and mitigation by isolating the edge devices from the network.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633440","Edge Computing;Threat Intelligence;Machine Learning (ML);Large Language Model (LLM)","Adaptation models;Image edge detection;Computational modeling;Prevention and mitigation;Telecommunication traffic;Threat assessment;Software","","6","","4","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"State-Observer-Based Event-Trigger Bipartite Consensus Secure Control for NMASs With Deception Attacks","S. Sui; D. Shen; S. Tong; C. L. P. Chen","College of Science, Liaoning University of Technology, Jinzhou, China; College of Science, Liaoning University of Technology, Jinzhou, China; College of Science, Liaoning University of Technology, Jinzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China",IEEE Transactions on Network Science and Engineering,"20 Nov 2024","2024","11","6","5732","5743","Deception attacks are a big danger to the security and durability of multi-agent systems (MASs). This article introduces a new technique to tackle the problem of deception attacks in nonlinear multi-agent systems (NMASs). The system can be attacked through sensors and actuators, which may lead to incomplete system data transmission and render the system state inaccessible for control design. To overcome this challenge, a fuzzy state observer is constructed to estimate the system state after the attacks, and the fuzzy logic system (FLS) is used to handle unfamiliar nonlinearities. The Nussbaum function is proposed to deal with unknown control directions and reduces system complexity. In addition, considering that there are both cooperative and competitive relationships between agents, event-triggered bipartite consensus fuzzy security adaptive control is given to mitigate the effects of deception attacks and alleviate communication resources. A based-state-observer event-triggered bipartite consensus NMASs adaptive fuzzy security control is given to achieve asymptotic output consistency after the attacks. Using Lyapunov theory, it has been demonstrated that all signals within the closed-loop system remain bounded. Finally, the test simulations show that the suggested approach can maintain the security and stability of the system during deception attacks with minimal data and resources.","2327-4697","","10.1109/TNSE.2024.3436085","National Natural Science Foundation of China(grant numbers:62333004,62176111,62173172); Excellent Young Scientists Fund Program; Xingliao Talent Plan(grant numbers:XLYC 2203188); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10618996","Bipartite consensus tracking;deception attacks;event-triggered control;NMASs;secure adaptive control","Security;Observers;Fuzzy logic;Sensors;Sensor systems;Neural networks;Consensus protocol;Event detection;Adaptive control;Multi-agent systems","","4","","34","IEEE","31 Jul 2024","","","IEEE","IEEE Journals"
"An Ubiquitous Multi-agent Mobile Platform for Distributed Crowd Sensing and Social Mining","S. Bosse; E. Pournaras","Department of Mathematics & Computer Science, University of Bremen, Bremen, Germany; Chair of Sociology, in particular Modeling and Simulation ETH Zürich, Zürich, Switzerland",2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud),"20 Nov 2017","2017","","","280","287","Smart mobile devices are fundamental date sources for crowd activity tracing. Large-scale mobile networks and the Internet-of-Things (IoT) expand and become part of pervasive and ubiquitous computing offering distributed and trans-parent services. With the IoT, Crowd Sensing is extended by Things Sensing, creating heterogeneous smart environments. A unified and common data processing and communication methodology is required so that the IoT, mobile networks, and Cloud-based environments seamlessly integrate, which can be fulfilled by self-organizing mobile agents, discussed in this work. Currently, portability, resource constraints, security, and scalability of Agent Processing Platforms (APP) are essential issues for the deployment of Multi-agent Systems (MAS) in highly heterogeneous networks. Beside the operational aspects of MAS, an organizational structure is required for the deployment of MAS in crowd sensing and social mining applications. The Planetary Nervous system (Nervousnet) consists of virtual sensors building the core functionality for such applications running on smart phones with a Cloud-like architecture. The virtual sensors enable a holistic composition and modelling approach. Self-organizing and adaptive mobile agents are well known as the core cells of holistic and modular systems. In this work, both concepts are combined. JavaScript agents are introduced as virtual sensors in the Nervousnet environment, evaluated with a simulation of a distributed sensor fusion use-case in a mobile network based on real-world data from Nervousnet, showing the suitability of the hybrid approach, benefiting from local and event-based sensor processing performed by the MAS.","","978-1-5386-2074-8","10.1109/FiCloud.2017.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114494","Crowd Sensing;Pervasive Computing;Ubiquitous Computing;Agents;Self-organizing systems","Sensors;Mobile communication;Cloud computing;Mobile agents;Smart phones;Mobile computing","","3","","16","IEEE","20 Nov 2017","","","IEEE","IEEE Conferences"
"Undertaking an ERP: Evaluating the Security of Apex 5 Developed Software","E. Crespo; C. Astudillo; M. Orellana","Universidad del Azuay, Cuenca, Azuay, EC; Universidad del Azuay, Cuenca, Azuay, EC; Universidad del Azuay, Cuenca, Azuay, EC",2017 International Conference on Information Systems and Computer Science (INCISCOS),"2 Apr 2018","2017","","","174","180","La seguridad de la información es una preocupación creciente en empresas y organizaciones, siendo más alta aun cuando se vincula a plataformas financieras donde existe información sensible. El presente trabajo resume las técnicas utilizadas en el pentesting realizado tanto al servidor que aloja al producto informático, como al software ERP desarrollado en la herramienta APEX 5 por la Universidad del Azuay. Se han contemplado seis etapas que sugiere una prueba de penetración: i) la conceptualización, que es la etapa que permite definir el alcance de las pruebas a realizar; ii) la preparación del laboratorio en la que se definen algunas de las herramientas que servirán para el inicio de las pruebas de seguridad; iii) la obtención de información que hace referencia a las etapas de reconocimiento y escaneo en la que se identifican posibles objetivos para luego explorar con mayor profundidad algunas características intrínsecas que puedan ser aprovechadas; iv) el análisis de las vulnerabilidades encontradas en la etapa anterior; v) la explotación de esas vulnerabilidades mediante la selección de herramientas; y vi) la post explotación, etapa en la que se contempla la destrucción de evidencias del ataque y la conservación de la conexión y los accesos logrados para extraer información. Todas estas pruebas fueron efectuadas dentro de las instalaciones de la Universidad del Azuay, considerando el ambiente de desarrollo en el que actualmente se encuentra el proyecto ERP.","","978-1-5386-2644-3","10.1109/INCISCOS.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328103","Pentesting;Seguridad Informática;APEX;ERP;Hacking","Software;Computer crime;IP networks;Cross-site scripting;Tools;Silicon","","1","","","IEEE","2 Apr 2018","","","IEEE","IEEE Conferences"
"End-to-End Autonomous Driving: Challenges and Frontiers","L. Chen; P. Wu; K. Chitta; B. Jaeger; A. Geiger; H. Li","OpenDriveLab, Shanghai AI Lab, Shanghai, China; OpenDriveLab, Shanghai AI Lab, Shanghai, China; University of Tübingen, Tübingen, Germany; University of Tübingen, Tübingen, Germany; University of Tübingen, Tübingen, Germany; OpenDriveLab, Shanghai AI Lab, Shanghai, China",IEEE Transactions on Pattern Analysis and Machine Intelligence,"6 Nov 2024","2024","46","12","10164","10183","The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 270 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework.","1939-3539","","10.1109/TPAMI.2024.3435937","National Key R&D Program of China(grant numbers:2022ZD0160104); National Natural Science Foundation of China(grant numbers:62206172); Shanghai Committee of Science and Technology(grant numbers:23YF1462000); ERC(grant numbers:LEGO-3D (850533)); Bundesministerium für Wirtschaft und Energie(grant numbers:19A19013O); DFG EXC(grant numbers:2064/1,390727645); German Federal Ministry of Education and Research; Tübingen AI Center(grant numbers:01IS18039A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614862","Autonomous driving;end-to-end system design;policy learning;simulation","Task analysis;Planning;Autonomous vehicles;Trajectory;Surveys;Imitation learning;Benchmark testing","","120","","279","CCBYNCND","30 Jul 2024","","","IEEE","IEEE Journals"
"Exploring LLM-Based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures","S. Kwon; S. Lee; T. Kim; D. Ryu; J. Baik","Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Jeonbuk National University, Jeonju, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Journal of Web Engineering,"29 Dec 2023","2023","22","6","889","912","Edge-Cloud system requires massive infrastructures located in closer to the user to minimize latencies in handling Big data. Ansible is one of the most popular Infrastructure as Code (IaC) tools crucial for deploying these infrastructures of the Edge-cloud system. However, Ansible also consists of code, and its code quality is critical in ensuring the delivery of high-quality services within the Edge-Cloud system. On the other hand, the Large Langue Model (LLM) has performed remarkably on various Software Engineering (SE) tasks in recent years. One such task is Automated Program Repairing (APR), where LLMs assist developers in proposing code fixes for identified bugs. Nevertheless, prior studies in LLM-based APR have predominantly concentrated on widely used programming languages (PL), such as Java and C, and there has yet to be an attempt to apply it to Ansible. Hence, we explore the applicability of LLM-based APR on Ansible. We assess LLMs' performance (ChatGPT and Bard) on 58 Ansible script revision cases from Open Source Software (OSS). Our findings reveal promising prospects, with LLMs generating helpful responses in 70% of the sampled cases. Nonetheless, further research is necessary to harness this approach's potential fully.","1544-5976","","10.13052/jwe1540-9589.2263","Information Technology Research Center (ITRC)(grant numbers:IITP-2023-2020-0-01795); National Research Foundation of Korea (NRF)(grant numbers:NRF-2022R1I1A3069233); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10376418","Edge-cloud;Ansible;Bard;large langue model;automated program repairing","Java;Computer languages;Codes;Computer bugs;Big Data;Chatbots;Task analysis","","3","","32","","29 Dec 2023","","","River Publishers","River Publishers Journals"
"Developing a Framework for Autonomous Control Software for a Human Colony on Mars","B. Stoick; Z. Luo; D. Tibrewal; K. Setterstrom; A. Jones; J. Straub","Department of Mechanical Engineering, North Dakota State University, Fargo, ND, USA; Department of Communication, North Dakota State University, Fargo, ND, USA; Department of Computer Science, North Dakota State University, Fargo, ND, USA; Department of Computer Science, North Dakota State University, Fargo, ND, USA; Department of Computer Science, North Dakota State University, Fargo, ND, USA; Department of Computer Science, North Dakota State University, Fargo, ND, USA",2019 IEEE International Conference on Electro Information Technology (EIT),"12 Sep 2019","2019","","","515","520","We propose a system of systems architecture to command and control a complex colony on Mars. The architecture is structured largely around the goals of construction, discovery, operations and risk management. Each of these goals is supported by autonomous systems with the ability to perform a diverse set of tasks. As a whole, the system presented is a hybrid distributed-centralized architecture with homogeneous autonomous agents within tasks of smaller scope but heterogeneous agents across the system as a whole. The system leverages the strengths of each element of the hybrid architecture to create a more robust, capable autonomous unit.","2154-0373","978-1-7281-0927-5","10.1109/EIT.2019.8833860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833860","Martian colony;space exploration;additive manufacturing;system design;system of systems;software command and control","Task analysis;Mars;Robots;Command and control systems;Risk management;Maintenance engineering","","2","","37","IEEE","12 Sep 2019","","","IEEE","IEEE Conferences"
"Model Checking CTLK Based on Knowledge-Oriented Petri Nets","L. He; G. Liu","Department of Computer Science, Tongii University, Shanghai, China; Department of Computer Science, Tongii University, Shanghai, China",2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),"3 Oct 2019","2019","","","1139","1146","We define Knowledge-oriented Petri Nets (KPN) to model and analyze multi-agent systems (MAS) especially from the perspective of privacy and security. A KPN is a special Petri net in which some places are used to represent knowledges. Consequently, KPN can formally represent not only the interaction/collaboration process of multiple agents but also their epistemic evolutions. These epistemic evolutions are closely related with the privacy and security of MAS. For those requirements of privacy or security, we use Computation Tree Logic of Knowledge (CTLK) to specify them. We define the similar reachability graphs of KPN and then construct the equivalence classes of knowledges for each agent. Based on them, we design the model checking algorithms to verify CTLK formulas efficiently. Examples of privacy protocols illustrate the usefulness of our model and method.","","978-1-7281-2058-4","10.1109/HPCC/SmartCity/DSS.2019.00161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855484","epistemic logic;equivalence class;model checking;Petri nets","Petri nets;Protocols;Model checking;Privacy;Security;Receivers;Conferences","","7","","25","IEEE","3 Oct 2019","","","IEEE","IEEE Conferences"
"Large language model-based optical network log analysis using LLaMA2 with instruction tuning","Y. Pang; M. Zhang; Y. Liu; X. Li; Y. Wang; Y. Huan; Z. Liu; J. Li; D. Wang","State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; China Mobile Communications Corporation, Beijing 100033, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing 100876, China",Journal of Optical Communications and Networking,"24 Oct 2024","2024","16","11","1116","1132","The optical network encompasses numerous devices and links, generating a significant volume of logs. Analyzing these logs is significant for network optimization, failure diagnosis, and health monitoring. However, the large-scale and diverse formats of optical network logs present several challenges, including the high cost and difficulty of manual processing, insufficient semantic understanding in existing analysis methods, and the strict requirements for data security and privacy. Generative artificial intelligence (GAI) with powerful language understanding and generation capabilities has the potential to address these challenges. Large language models (LLMs) as a concrete realization of GAI are well-suited for analyzing DCI logs, replacing human experts and enhancing accuracy. Additionally, LLMs enable intelligent interactions with network administrators, automating tasks and improving operational efficiency. Moreover, fine-tuning with open-source LLMs protects data privacy and enhances log analysis accuracy. Therefore, we introduce LLMs and propose a log analysis method with instruction tuning using LLaMA2 for log parsing, anomaly detection and classification, anomaly analysis, and report generation. Real log data extracted from the field-deployed network was used to design and construct instruction tuning datasets. We utilized the dataset for instruction tuning and demonstrated and evaluated the effectiveness of the proposed scheme. The results indicate that this scheme improves the performance of log analysis tasks, especially a 14% improvement in exact match rate for log parsing, a 13% improvement in F1-score for anomaly detection and classification, and a 23% improvement in usability for anomaly analysis, compared with the best baselines.","1943-0639","","10.1364/JOCN.527874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734084","","Optical fiber networks;Tuning;Anomaly detection;Security;Accuracy;Data models;Knowledge engineering;Semantics;Monitoring;Analytical models","","4","","","","24 Oct 2024","","","IEEE","IEEE Journals"
"FELLMVP: An Ensemble LLM Framework for Classifying Smart Contract Vulnerabilities","Y. Luo; W. Xu; K. Andersson; M. S. Hossain; D. Xu","University of Missouri-Kansas City, Kansas City, MO, USA; University of Baltimore, Baltimore, MD, USA; Luleå University of Technology, Skellefteå, Västerbotten County, Sweden; University of Chittagong, Chittagong, Bangladesh; University of Missouri-Kansas City, Kansas City, MO, USA",2024 IEEE International Conference on Blockchain (Blockchain),"18 Sep 2024","2024","","","89","96","The rapid expansion of smart contracts on blockchain platforms has significantly advanced the automation of transactions and agreements. However, the growing reliance on smart contracts increases security risks due to their immutable nature and interactions with digital assets. Existing vulnerability detection methods often fail to adapt to new and complex attack vectors and struggle to accurately predict specific vulnerability types. This paper introduces FELLMVP 1, a novel framework that integrates ensemble learning with Large Language Models (LLMs) to classify vulnerabilities in smart contracts. FELLMVP starts with the parsing of Solidity files to construct call graphs and Contract-External Function-Call (CEC) files for contract analysis. It fine-tunes eight LLMs, each targeted at detecting specific types of vulnerabilities and culminates and deploys an ensemble model that leverages the collective predictive capabilities of these LLMs. FELLMVP was evaluated on 15,637 real-world smart contracts spanning eight types of vulnerabilities, demonstrating superior performance over existing methods with an accuracy of 98.8% and F1 scores of 88%. FELLMVP also outperforms other LLMs such as Llama2-7b, CodeLlama, and Falcon-7b by 5 % -12 % on F1 score. Additionally, a case study using ChatGPT-4 to locate vulnerable code in smart contracts reveals that FELLMVP's prediction of specific vulnerability types enhances the debugging process compared to binary outcomes.","2834-9946","979-8-3503-5159-0","10.1109/Blockchain62396.2024.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664408","Blockchain;smart contract;vulnerability;large language model;ensemble learning","Codes;Accuracy;Large language models;Smart contracts;Debugging;Predictive models;Chatbots","","1","","26","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"Hardening LLM Fine-Tuning: From Differentially Private Data Selection to Trustworthy Model Quantization","Z. Deng; R. Sun; M. Xue; W. Ma; S. Wen; S. Nepal; Y. Xiang","School of Science, Computing and Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; Cybersecurity and Quantum Systems Group, CSIRO’s Data61, Eveleigh, NSW, Australia; Cybersecurity and Quantum Systems Group, CSIRO’s Data61, Eveleigh, NSW, Australia; School of Science, Computing and Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; School of Science, Computing and Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia; Cybersecurity and Quantum Systems Group, CSIRO’s Data61, Eveleigh, NSW, Australia; School of Science, Computing and Engineering Technologies, Swinburne University of Technology, Melbourne, VIC, Australia",IEEE Transactions on Information Forensics and Security,"18 Jul 2025","2025","20","","7211","7226","Critical infrastructures are increasingly integrating artificial intelligence (AI) technologies, including large language models (LLMs), into essential systems and services that are vital to societal functioning. Fine-tuning LLMs for specific domain tasks are crucial for their effective deployment in these contexts, but this process must carefully address both privacy and security concerns. Without proper safeguards, such integration can introduce additional risks, such as data leakage during training and diminished model trustworthiness due to the need for model compression to operate within limited bandwidth and computational capacity constraints. In this paper, we propose Hardening LLM Fine-tuning framework (HardLLM), which addresses these challenges through two key components: (i) we develop a differentially private data selection method that ensures privacy protection by training the model exclusively on sampled and synthesized public data, thereby preventing any direct use of private data and enhancing leakage resilience throughout the training process, and (ii) we introduce a trustworthiness-aware model quantization approach to improve LLMs performance, such as reducing toxicity, enhancing adversarial robustness, and mitigating stereotypes, while maintaining negligible impact on model utility. Experimental results show that, the proposed algorithm ensures differential privacy when privacy budget is set at  $\epsilon = 0.5$ , with only a 1% drop in accuracy, while other state-of-the-art methods experience an accuracy drop of at least 20% under the same privacy budget. Additionally, our quantization approach improves the trustworthiness of fine-tuned LLMs by an average of 3-4%, with only a negligible utility loss (approximately 1%) at a 50% compression rate.","1556-6021","","10.1109/TIFS.2025.3581103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11040052","Differentially privacy;data selection;quantization","Critical infrastructure;Training;Servers;Data models;Quantization (signal);Satellites;Privacy;Security;Base stations;Computational modeling","","1","","69","IEEE","18 Jun 2025","","","IEEE","IEEE Journals"
"Scalable Cloud Architectures for Efficient Processing of Multi-Structured Big Data","K. Alang; S. B. Peta; R. R. Pai; B. Patil",NA; NA; NA; NA,2025 Global Conference in Emerging Technology (GINOTECH),"17 Jul 2025","2025","","","1","6","Large Language Models (LLMs) now dominate the field of intelligent cloud-native applications by providing strong generative functionality with context-aware automated operations. The achievement of large-scale benefits from LLMs depends on implementing an integrated data engineering solution which combines multi-source data pipelines and live data processing while supporting operational governance measures and maximizing scalability and cost effectiveness. This paper develops an integrated data engineering system designed for cloud applications using LLMs which applies modular design patterns with distributed control systems and automated pipeline optimization algorithms. The framework combines data ingestion along with feature transformation and metadata management capabilities and LLM-centric model services that incorporate Mops and Limos practices. Here it is explained both the design structure of the system alongside deployment tactics and measurement standards which support higher operational output and processing capacity. The system provides multiple cloud platform capabilities including AWS Azure and GCP so businesses can deploy LLMs in multi-tenant environments with standardized data management and security features. Experimental assessments prove the framework supplies scalability while minimizing latency and achieving operational stability which prepares it as a base for future-generation enterprise AI applications.","","979-8-3315-0775-6","10.1109/GINOTECH63460.2025.11077101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077101","Cloud Computing;Big Data Analytics;Multi-Structured Data;Scalable Architectures;Distributed Systems;Data Ingestion Pipelines;NoSQL Storage;Containerization;Microservices;Real-Time Processing;Resource Orchestration;Fault Tolerance","Cloud computing;Data ingestion;Scalability;Pipelines;Stability criteria;Computer architecture;Big Data;Data engineering;Real-time systems;Security","","","","18","IEEE","17 Jul 2025","","","IEEE","IEEE Conferences"
"Context Conquers Parameters: Outperforming Proprietary Llm in Commit Message Generation","A. Imani; I. Ahmed; M. Moshirpour","University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1844","1856","Commit messages provide descriptions of the modifications made in a commit using natural language, making them crucial for software maintenance and evolution. Recent developments in Large Language Models (LLMs) have led to their use in generating high-quality commit messages, such as the Omniscient Message Generator (OMG). This method employs GPT-4 to produce state-of-the-art commit messages. However, the use of proprietary LLMs like GPT-4 in coding tasks raises privacy and sustainability concerns, which may hinder their industrial adoption. Considering that open-source LLMs have achieved competitive performance in developer tasks such as compiler validation, this study investigates whether they can be used to generate commit messages that are comparable with OMG. Our experiments show that an open-source LLM can generate commit messages comparable to those produced by OMG. In addition, through a series of contextual refinements, we propose OMEGA, a commit message generation approach that uses a 4-bit quantized 8B open-source LLM. OMEGA produces state-of-the-art commit messages, surpassing the performance of GPT-4 in practitioners' preference.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029724","commit message generation;large language model;llama3;gpt4","Industries;Software maintenance;Privacy;Large language models;Source coding;Refining;Natural languages;Usability;Sustainable development;Software engineering","","","","58","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Construction and Operation of a Generative Artificial Intelligence-Assisted Language Learning System","Y. Cao; H. Lu; Y. Zhou; J. Gao; H. Wang; Y. Jiao","College of Foreign Languagesm, Chongqing University of Technology, Chongqing, China; College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China; School of Accountancy, Chongqing University of Technology, Chongqing, China; Liangjiang International College, Chongqing University of Technology, Chongqing, China; College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China; College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China",2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE),"12 Jun 2024","2024","","","1","6","The generative artificial intelligence-assisted language learning system is a system that utilizes artificial intelligence technology. It provides users with more personalized and efficient language learning services through core modules such as generative pre-trained models and personalized learning engines, It is currently one of the significant applications of artificial intelligence technology in the field of language learning. This paper aims to introduce the design, construction, and operation of a generative artificial intelligence-assisted language learning system. In this system, the generative pre-trained model GPT -3.5 is employed, incorporating core modules such as natural language processing, generative adversarial networks, and Transformer models. This paper also conducts detailed research and analysis on aspects such as text generation quality in the system, response time testing of the model within the system, and feedback on system application scenarios. Through the research presented in this paper, valuable reference and guidance can be provided for the development and application of generative artificial intelligence-assisted language learning systems.","","979-8-3503-1860-9","10.1109/ICDCECE60827.2024.10549672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549672","generative artificial intelligence;language learning system;gpt model;personalized learning engine;system design and operation","Learning systems;Adaptation models;Learning (artificial intelligence);Transformer cores;Transformers;Natural language processing;Time factors","","","","10","IEEE","12 Jun 2024","","","IEEE","IEEE Conferences"
"MAT: Medical AI-generated Text Detection Dataset from Multi-models and Multi-Methods","B. Xu; R. Wang; L. Ping; C. Zhu; X. Liu; H. Lin; L. Tian; F. Xia","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; Department of Neurology and Neurological Sciences, Stanford University, California, USA; School of Software, Dalian University of Technology, Dalian, China; College of Computer Science and Technology, Dalian University of Technology, Dalian, China; Australia School of Computing Technologies, RMIT University, Melbourne, Australia",2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),"10 Jan 2025","2024","","","2748","2753","Large language models (LLMs) have been widely used in society due to their amazing emergent capabilities, but they also bring security issues. A large amount of content on the Internet may be generated by AI. Whether it is social forums or more professional academic fields, the abuse of AI has become a problem. Especially in some professional fields, Blindly trusting what the Internet says is dangerous. For this reason, for some fields that are risky and need to limit the use of AI, such as medicine, a more comprehensive benchmark is needed to test the ability of AI-generated text detection tasks. Considering the popularity of LLMs, the data distributions used in the training process of different LLMs may lead to the differences in generated data distributions, especially for some LLMs for non-native English speakers. To address this issue, this article introduces an AI-generated text detection dataset in the field of medical question answering. This dataset is generated by various models and prompting methods, and cross validation is performed on multiple types of data between texts generated by different methods to verify the effectiveness of AI-generated text detection and model classification tasks, and to study the generalization of the dataset in different tasks. We have published the dataset for future research on https://github.com/Hellpoop/MAT.","2156-1133","979-8-3503-8622-6","10.1109/BIBM62325.2024.10822580","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10822580","AI-generated Text Detection;Large Language Model;Medical Text Dataset","Training;Large language models;Biological system modeling;Buildings;Text detection;Detectors;Question answering (information retrieval);Data models;Internet;Security","","","","18","IEEE","10 Jan 2025","","","IEEE","IEEE Conferences"
"LLM-IFT: LLM-Powered Information Flow Tracking for Secure Hardware","N. Mashnoor; M. Akyash; H. Kamali; K. Azar","Department of Electrical and Computer Engineering (ECE), University of Central Florida, Orlando, USA; Department of Electrical and Computer Engineering (ECE), University of Central Florida, Orlando, USA; Department of Electrical and Computer Engineering (ECE), University of Central Florida, Orlando, USA; Department of Electrical and Computer Engineering (ECE), University of Central Florida, Orlando, USA",2025 IEEE 43rd VLSI Test Symposium (VTS),"10 Jun 2025","2025","","","1","5","As modern hardware designs grow in complexity and size, ensuring security across the confidentiality, integrity, and availability (CIA) triad becomes increasingly challenging. Information flow tracking (IFT) is a widely-used approach to tracing data propagation, identifying unauthorized activities that may compromise confidentiality or/and integrity in hardware. However, traditional IFT methods struggle with scalability and adaptability, particularly in high-density and interconnected architectures, leading to tracing bottlenecks that limit applicability in large-scale hardware. To address these limitations and show the potential of transformer-based models in integrated circuit (IC) design, this paper introduces LLM-IFT that integrates large language models (LLM) for the realization of the IFT process in hardware. LLM-IFT exploits LLM-driven structured reasoning to perform hierarchical dependency analysis, systematically breaking down even the most complex designs. Through a multi-step LLM invocation, the framework analyzes both intra-module and inter-module dependencies, enabling comprehensive IFT assessment. By focusing on a set of Trust-Hub vulnerability test cases at both the IP level and the SoC level, our experiments demonstrate a 100% success rate in accurate IFT analysis for confidentiality and integrity checks in hardware.","2375-1053","979-8-3315-2144-8","10.1109/VTS65138.2025.11022949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022949","Information Flow Tracking;LLM;Security","Scalability;Large language models;Integrated circuit interconnections;Focusing;Very large scale integration;Transformers;Hardware;Security;IP networks;Integrated circuit modeling","","","","36","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"How About Artificial Intelligence","V. Malý; L. Buřita; P. Kozak","Department of Informatics and Cyber Operations, University of Defence, Brno, Czech Republic; Department of Informatics and Cyber Operations, University of Defence, Brno, Czech Republic; Department of Informatics and Cyber Operations, University of Defence, Brno, Czech Republic",2025 International Conference on Military Technologies (ICMT),"8 Jul 2025","2025","","","1","7","The main goal of the article is to point out the rapid development in the field of artificial intelligence. At the same time, the most common areas of current use of artificial intelligence are listed here. In the introduction are explained definitions of artificial intelligence and its parts as machine learning, natural language processing, and large language models. Special attention is paid to use in programming information systems and applications development. The article also discusses the use of artificial intelligence for teaching information security. The benefits of using artificial intelligence for this area are mentioned, in the form of chatbots and virtual assistants. On the other hand, the dangers of cyber-attacks are pointed out. The literature review is mentioned EU regulations in the field of artificial intelligence, and are summarized results in the NATO research program.","2996-4474","979-8-3315-2338-1","10.1109/ICMT65201.2025.11061310","Ministry of Defense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11061310","artificial intelligence;programming;education;information security","Virtual assistants;Large language models;Education;Information security;Machine learning;Regulation;Artificial intelligence;Programming profession;Systematic literature review;Information systems","","","","14","IEEE","8 Jul 2025","","","IEEE","IEEE Conferences"
"Defense Against Syntactic Textual Backdoor Attacks with Token Substitution","X. He; X. Li; Y. Li; M. Cheng","Statistics and Operations Research Department, University of North Carolina at Chapel Hill, NC, USA; Economics Department, University of North Carolina at Chapel Hill, NC, USA; Statistics and Operations Research Department, University of North Carolina at Chapel Hill, NC, USA; College of Information Sciences and Technology, Pennsylvania State University, PA, USA",IEEE Transactions on Information Forensics and Security,"","2025","PP","99","1","1","Textual backdoor attacks present a substantial security risk to Large Language Models (LLM). It embeds carefully chosen triggers into a victim model at the training stage and makes the model erroneously predict inputs containing the same triggers as a certain class. Prior backdoor defense methods primarily target special-token-based triggers, leaving syntax-based triggers insufficiently addressed. To fill this gap, this paper proposes a novel defense algorithm that effectively counters syntax-based as well as special-token-based backdoor attacks. The algorithm replaces semantically meaningful words in sentences with entirely different ones but preserves the syntactic templates or special tokens, and then compares the predicted labels before and after the substitution to determine whether a sentence contains triggers. Experimental results confirm the algorithm’s performance against these two types of triggers, offering a comprehensive defense strategy for model integrity.","1556-6021","","10.1109/TIFS.2025.3597216","National Science Foundation(grant numbers:DMS-2152289, DMS-2134107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121441","Backdoor Attacks;Natural Language Processing;Deep Neural Networks;Model Security","Syntactics;Data models;Prediction algorithms;Predictive models;Training data;Training;Classification algorithms;Semantics;Pain;Large language models","","","","","IEEE","8 Aug 2025","","","IEEE","IEEE Early Access Articles"
"AI-Powered, But Power-Hungry? Energy Efficiency of LLM-Generated Code","L. Solovyeva; S. Weidmann; F. Castor","University of Twente, Enschede, The Netherlands; University of Twente, Enschede, The Netherlands; University of Twente, Enschede, The Netherlands",2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge),"2 Jul 2025","2025","","","49","60","Large language models (LLMs) are used in software development to assist in various tasks, e.g., code generation and code completion, but empirical evaluations of the quality of the results produced by these models focus on correctness and ignore other relevant aspects, such as their performance and energy efficiency. Studying the performance of LLM-produced programs is essential to understand how well LLMs can support the construction of performance- and energy-critical software, such as operating systems, servers, and mobile applications. This paper presents the first study analyzing the energy efficiency and performance of LLM-generated code for three programming languages Python, Java, and C++, on two platforms, a Mac and a PC, leveraging three frontier LLMs, Github Copilot, GPT-4o, and the recently-released OpenAI o1-mini, and targeting ""hard"" programming problems from LeetCode. Our results show that the models are much more successful in generating Python and Java than C++ code. Also, LLM-generated code sometimes surpasses an efficient human-written solution, although that is language-dependent and the language with the best results, Python, is the one where application performance and energy consumption tend to matter the least in practice. Furthermore, the performance of generated code is highly correlated across the two platforms, hinting at potential for results to be portable across platforms.","","979-8-3315-0211-9","10.1109/Forge66646.2025.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052793","","Java;Codes;Correlation;Accuracy;Operating systems;C++ languages;Energy efficiency;Python;Software development management;Sorting","","1","","39","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Large Language Model vs. Stack Overflow in Addressing Android Permission Related Challenges","S. J. Oishwee; N. Stakhanova; Z. Codabux","University of Saskatchewan, Canada; University of Saskatchewan, Canada; University of Saskatchewan, Canada",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","373","383","The Android permission system regulates access to sensitive mobile device resources such as camera and location. To access these resources, third-party developers need to request permissions. However, the Android permission system is complex and fast-evolving, presenting developers with numerous challenges surrounding compatibility issues, misuse of permissions, and vulnerabilities related to permissions. Our study aims to explore whether Large Language Models (LLMs) can serve as a reliable tool to assist developers in using Android permissions correctly and securely, thereby reducing the risks of misuse and security vulnerabilities in apps. In our study, we analyzed 1,008 Stack Overflow questions related to Android permissions and their accepted answers. In parallel, we generate answers to these questions using a popular LLM tool, ChatGPT. We focused on how well the ChatGPT’s responses align with the accepted answers on Stack Overflow. Our findings show that above 50% of ChatGPT’s answers align with Stack Overflow’s accepted answers. ChatGPT offers better-aligned responses for challenges related to Documentation and Conceptual Understanding, while it provides less aligned answers for Debugging-related issues. In addition, we found that ChatGPT provides more consistent answers for 73.27% questions. Our study demonstrates the potential for using LLMs such as ChatGPT as a supporting tool to help developers navigate Android permission-related problems.CCS CONCEPTS• Security and privacy → Software and application security; • Computing methodologies → Artificial intelligence.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555796","Android Permissions;Stack Overflow;Large Language Model (LLM)","Privacy;Navigation;Documentation;Chatbots;Software;Mobile handsets;Cognition","","1","","48","","18 Jun 2024","","","IEEE","IEEE Conferences"
"GSCE: a Prompt Framework With Enhanced Reasoning for Reliable LLM-Driven Drone Control","W. Wang; Y. Li; L. Jiao; J. Yuan","Department of CIS, University of Massachusetts Dartmouth; Department of CSIS, California State University, San Marcos; Department of CIS, University of Massachusetts Dartmouth; Department of CIS, University of Massachusetts Dartmouth",2025 International Conference on Unmanned Aircraft Systems (ICUAS),"27 May 2025","2025","","","441","448","The integration of Large Language Models (LLMs) into robotic control, including drones, has the potential to revolutionize autonomous systems. Research studies have demonstrated that LLMs can be leveraged to support robotic operations. However, when facing tasks with complex reasoning, concerns and challenges are raised about the reliability of solutions produced by LLMs. In this paper, we propose a prompt framework with enhanced reasoning to enable reliable LLM-driven control for drones. Our framework consists of novel technical components designed using Guidelines, Skill APIs, Constraints, and Examples, namely GSCE. GSCE is featured by its reliable and constraint-compliant code generation. We performed thorough experiments using GSCE for the control of drones with a wide range of task complexities. Our experiment results demonstrate that GSCE can significantly improve task success rates and completeness compared to baseline approaches, highlighting its potential for reliable LLMdriven autonomous drone systems.","2575-7296","979-8-3315-1328-3","10.1109/ICUAS65942.2025.11007864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007864","","Codes;Autonomous systems;Large language models;Cognition;Complexity theory;Reliability;Aircraft;Robots;Drones;Guidelines","","","","38","IEEE","27 May 2025","","","IEEE","IEEE Conferences"
"Code Ranking with Structure Awareness Contrastive Learning","H. Huang; L. Cao; J. Wang; T. Yu; Y. Cai","School of Software Engineering, South China University of Technology, China; School of Software Engineering, South China University of Technology, China; School of Software Engineering, South China University of Technology, China; School of Software Engineering, South China University of Technology, China; Key Laboratory of Big Data and Intelligent Robot (SCUT), MOE of China, China",2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC),"17 Jun 2025","2025","","","419","430","Large language models (LLMs) have revolutionized the field of programming for developers by automatically generating code based on natural language intent (NL intent). In numerous cases, LLMs can produce correct programs after several trials. As a result, a major challenge for this task is to select the most appropriate program from the multiple samples (also called code ranking) generated by LLMs. Recent popular approaches for code ranking involve the ranker-based methods, in which we train a ranker to classify the error in code using execution results (correct or error types) of code as supervised signals select the best program. However, existing rankerbased code ranking approaches rely on classification labels, which are highly sensitive to label distribution and show weak generalization ability to other distributions. In this paper, we introduce SACL-CR to address this challenge, a novel structureaware contrastive learning framework for code ranking. This approach effectively addresses the generalization issues of existing ranker-based methods by integrating both code sequence and structural information. Encoders trained with this method can effectively identify errors in code, enhancing the model's ability to differentiate between correct and incorrect code. Our research demonstrates that SACL-CR significantly enhances the pass@k accuracy of several code generation models, including CodeLlama and DeepseekCoder, on the HumanEval and MBPP datasets. The open-source code will be released at https://github.com/Iced-Americano2001/SACL-CR.","2643-7171","979-8-3315-0223-2","10.1109/ICPC66645.2025.00053","Guangdong Provincial Natural Science Foundation for Outstanding Youth Team Project(grant numbers:2024B1515040010); Central Universities; South China University of Technology(grant numbers:x2rjD2240100); China Computer Federation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025916","code ranking;contrastive learning;multi-modal momentum contrast;pre-trained model","Codes;Accuracy;Large language models;Natural languages;Contrastive learning;Programming","","","","48","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Towards an active, autonomous and intelligent cyber defense of military systems: The NATO AICA reference architecture","P. Theron; A. Kott; M. Drašar; K. Rzadca; B. LeBlanc; M. Pihelgas; L. Mancini; A. Panico","Thales, Salon de Provence, France; U.S. Army Research Laboratory, Adelphi, MD, USA; Masaryk University, Brno, Czech Republic; University of Warsaw, Warsaw, Poland; Ecole Nationale Supérieure de Cognitique, Bordeaux, France; NATO CCDCOE, Tallinn, Estonia; Sapienza University, Rome, Italy; Sapienza University, Rome, Italy",2018 International Conference on Military Communications and Information Systems (ICMCIS),"28 Jun 2018","2018","","","1","9","Within the future Global Information Grid, complex massively interconnected systems, isolated defense vehicles, sensors and effectors, and infrastructures and systems demanding extremely low failure rates, to which human security operators cannot have an easy access and cannot deliver fast enough reactions to cyber-attacks, need an active, autonomous and intelligent cyber defense. Multi Agent Systems for Cyber Defense may provide an answer to this requirement. This paper presents the concept and architecture of an Autonomous Intelligent Cyber defense Agent (AICA). First, we describe the rationale of the AICA concept. Secondly, we explain the methodology and purpose that drive the definition of the AICA Reference Architecture (AICARA) by NATO's IST-152 Research and Technology Group. Thirdly, we review some of the main features and challenges of Multi Autonomous Intelligent Cyber defense Agent (MAICA). Fourthly, we depict the initially assumed AICA Reference Architecture. Then we present one of our preliminary research issues, assumptions and ideas. Finally, we present the future lines of research that will help develop and test the AICA / MAICA concept.","","978-1-5386-4559-8","10.1109/ICMCIS.2018.8398730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398730","intelligent agent;autonomy;cyber warfare;cyber security","Computer architecture;Sensors;Malware;Computer security;Resilience;Monitoring;Decision making","","13","","21","IEEE","28 Jun 2018","","","IEEE","IEEE Conferences"
"A framework to handle big data for cyber-physical systems","S. ur Rehman; A. Hark; V. Gruhn","University of Duisburg-Essen, Institute of Software Technology, Essen, Germany; University of Duisburg-Essen, Institute of Software Technology, Essen, Germany; University of Duisburg-Essen, Institute of Software Technology, Essen, Germany","2017 8th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","23 Nov 2017","2017","","","72","78","The use of big data for cyber-physical systems (CPS) is gaining more importance due to the ever-increasing amount of collectable data. Due to the decreasing cost of sensors and the growth of embedded systems, which are increasingly used in the industries as well as in the private sectors, new methods are needed to evaluate and process the collected data. Therefore, in this paper we proposed a framework to handle big data for cyber-physical systems. The framework considered the possible solutions that would be standardization, cloud computing, online and data stream learning, a methodology to process data and multi-agent systems for CPS. Furthermore, we examine the security challenges and big data issues of cyber-physical systems.","","978-1-5386-3371-7","10.1109/IEMCON.2017.8117153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8117153","Big data;cyber-physical system (CPS);security;real-time;standardization;infrastructure;data quality","Big Data;Cyber-physical systems;Safety;Real-time systems;Sensors","","3","","22","IEEE","23 Nov 2017","","","IEEE","IEEE Conferences"
"HITS: High-coverage LLM-based Unit Test Generation via Method Slicing","Z. Wang; K. Liu; G. Li; Z. Jin","Key Lab of HCST (PKU), MOE; SCS, Beijing, China; Key Lab of HCST (PKU), MOE; SCS, Beijing, China; Key Lab of HCST (PKU), MOE; SCS, Beijing, China; Key Lab of HCST (PKU), MOE; SCS, Beijing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1258","1268","Large language models (LLMs) have behaved well in generating unit tests for Java projects. However, the performance for covering the complex focal methods within the projects is poor. Complex methods comprise many conditions and loops, requiring the test cases to be various enough to cover all lines and branches. However, existing test generation methods with LLMs provide the whole method-to-test to the LLM without assistance on input analysis. The LLM has difficulty inferring the test inputs to cover all conditions, resulting in missing lines and branches. To tackle the problem, we propose decomposing the focal methods into slices and asking the LLM to generate test cases slice by slice. Our method simplifies the analysis scope, making it easier for the LLM to cover more lines and branches in each slice. We build a dataset comprising complex focal methods collected from the projects used by existing state-of-the-art approaches. Our experiment results show that our method significantly outperforms current test case generation methods with LLMs and the typical SBST method Evosuite regarding both line and branch coverage scores.CCS CONCEPTS• Software and its engineering → Software testing and debugging; • Computing methodologies → Natural language processing.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765010","Unit Test Generation;Large Language Model;Program Decomposition;Program Slicing;Testing and Analysis;AI for SE","Software testing;Java;Analytical models;Large language models;Debugging;Software;Natural language processing;Test pattern generators;Software engineering","","2","","33","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Exploring LLM-Based Multi-Agent Situation Awareness for Zero-Trust Space-Air-Ground Integrated Network","X. Cao; G. Nan; H. Guo; H. Mu; L. Wang; Y. Lin; Q. Zhou; J. Li; B. Qin; Q. Cui; X. Tao; H. Fang; H. Du; T. Q. S. Quek","National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; China Mobile Research Institute, Beijing, China; Department of Information Systems Technology and Design, Singapore University of Technology and Design, Tampines, Singapore",IEEE Journal on Selected Areas in Communications,"29 May 2025","2025","43","6","2230","2247","Space-air-ground integrated network (SAGIN), which integrates satellite systems, aerial networks, and terrestrial communications, offers ubiquitous coverage for a multitude of applications. Nevertheless, the highly dynamic and open nature of SAGIN increases the network’s vulnerability. Hence, zero-trust security, operating on the principle of “never trust, always verify”, holds the significant potential of securing SAGIN. However, implementing zero-trust SAGIN in practice presents three primary challenges: 1) understanding massive unstructured threat information across diverse domains, 2) performing adaptive security assessments, and 3) making in-depth security decisions. This motivates us to propose SAG-Attack and LLM-SA to enhance zero-trust SAGIN. SAG-Attack serves as a simulator that aims to mimic various attacks in SAGIN. Our LLM-SA is a novel situation awareness method that explores the multiple agents of large language model (LLM). Specifically, the output logs of SAG-Attack will be fed into LLM-SA, and LLM-SA fuses vast amounts of heterogeneous threat information from various domains, thus tackling the first challenge. Then, our LLM-SA relies on multiple LLM-based agents to perform adaptive security assessments, utilizing the chain-of-thought capabilities of LLMs to automatically generate in-depth defense strategies, thereby addressing the second and third challenges. Experiments on five benchmarks demonstrate the superiority of the proposed SAG-Attack and LLM-SA. Notably, our method based on open-sourced Llama3-8B even outperforms ChatGPT-4 under the same setting, despite involving significantly fewer parameters. To foster further research in this area, we will release our platform to the community, facilitating the advancement of zero-trust SAGIN.","1558-0008","","10.1109/JSAC.2025.3560042","National Key Research and Development Program of China(grant numbers:2022YFB2902200); National Natural Science Foundation of China(grant numbers:62471064); National Research Foundation, Singapore, and Infocomm Media Development Authority under its Future Communications Research and Development Program; Beijing Natural Science Foundation Program(grant numbers:L232002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963886","Space-air-ground integrated network;zero trust;LLM-based multi-agent;situation awareness","Satellites;Security;Space-air-ground integrated networks;Satellite broadcasting;Feature extraction;Zero Trust;Protocols;Vehicle dynamics;Network security;Low earth orbit satellites","","1","","47","IEEE","11 Apr 2025","","","IEEE","IEEE Journals"
"Reinforcement Learning for Dynamic Traffic Routing and Optimization","S. Ebadinezhad; A. Conteh; K. A. Ali; I. Khalaf Hussein","Department of Computer Information Systems, Computer Information Systems Research and Technology Center (CISRTC), Near East University, Nicosia, Cyprus; Department of Computer Information Systems, Near East University, Nicosia, Cyprus; Department of Computer Information Systems, Near East University, Nicosia, Cyprus; Department of Computer Information Systems, Near East University, Nicosia, Cyprus",2024 International Conference on Inventive Computation Technologies (ICICT),"7 Jun 2024","2024","","","346","352","This paper addresses the rapidly evolving and expanding needs of network traffic with new methods, most notably Reinforcement Learning (RL). The RL has shown significant potential in addressing the challenges of dynamic traffic routing and optimization. Despite the complexity of adapting to varying network conditions, techniques such as deep RL and multi-agent systems have been proposed to enhance network efficiency. However, the challenges persist, including the scalability of these algorithms and their adaptability to real-time changes. This research aims to address these challenges by proposing a robust RL framework that not only adapts to dynamic traffic conditions but also scales effectively across large network infrastructures. Our research raises important questions: How effective are RL algorithms? What effect do reward functions have? How do they handle big networks? Are these models flexible enough to adjust? One goal of the research, then is to test all RL methods designed for online traffic direction in real time; examine their merits and problems when applied on large networks; discover whether they could be used under various network conditions or if only certain traffic patterns would work well with them. It should also seek out possible ways RL algorithms might increase overall network performance, as well as look at security issues This study is important because it could revolutionize how we manage network traffic. It means better, stronger and more reliable networks with RL, we can develop routing protocols that are flexible and distributed to overcome changing network circumstances as well as reach different destinations or satisfy various restraints.","2767-7788","979-8-3503-5929-9","10.1109/ICICT60155.2024.10544850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10544850","Reinforcement Learning;Network Traffic;Dynamic Routing;Algorithmic Advancements;Deep Learning;Traffic Optimization;Decentralized Protocols;Adaptive Systems;Network Performance;Security and Privacy","Privacy;Heuristic algorithms;Telecommunication traffic;Reinforcement learning;Traffic control;Routing;Routing protocols","","1","","30","IEEE","7 Jun 2024","","","IEEE","IEEE Conferences"
"A Control-Theoretical Zero-Knowledge Proof Scheme for Networked Control Systems","C. Fioravanti; C. N. Hadjicostis; G. Oliva","University Campus Bio-Medico of Rome, Rome, Italy; University of Cyprus, Nicosia, Cyprus; University Campus Bio-Medico of Rome, Rome, Italy",IEEE Open Journal of Control Systems,"11 Oct 2024","2024","3","","416","428","Networked Control Systems (NCS) are pivotal for sectors like industrial automation, autonomous vehicles, and smart grids. However, merging communication networks with control loops brings complexities and security vulnerabilities, necessitating strong protection and authentication measures. This paper introduces an innovative Zero-Knowledge Proof (ZKP) scheme tailored for NCSs, enabling a networked controller to prove its knowledge of the dynamical model and its ability to control a discrete-time linear time-invariant (LTI) system to a sensor, without revealing the model. This verification is done through the controller's capacity to produce suitable control signals in response to the sensor's output demands. The completeness, soundness, and zero-knowledge properties of the proposed approach are demonstrated. The scheme is subsequently extended by considering the presence of delays and output noise. Additionally, a dual scenario where the sensor proves its model knowledge to the controller is explored, enhancing the method's versatility. Effectiveness is shown through numerical simulations and a case study on distributed agreement in multi-agent systems.","2694-085X","","10.1109/OJCSYS.2024.3455899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669168","Computer/network security;control applications;networked control systems;resilient control systems;zero knowledge proof","Noise measurement;Computational modeling;Authentication;Networked control systems;Encryption;Communication networks;Network security;Resilience;Zero knowledge proof;Autonomous vehicles;Automation;Smart grids;Multi-agent systems","","","","56","CCBYNCND","6 Sep 2024","","","IEEE","IEEE Journals"
"GAN-Guarded Fine-Tuning: Enhancing Adversarial Robustness in NLP Models","T. Ali; A. Eleyan; M. Al-Khalidi; T. Bejaoui","Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, United Kingdom; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, United Kingdom; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, United Kingdom; Computer Engineering Department, University of Carthage, Tunisia",2025 5th IEEE Middle East and North Africa Communications Conference (MENACOMM),"13 Mar 2025","2025","","","1","6","The increasing occurrence of assaults on Natural Language Processing (NLP) systems has sparked worry about their resilience and trustworthiness, particularly in crucial applications like sentiment analysis, machine translation and natural language deduction. To tackle these weaknesses this research presents GAN-Guarded Fine-Tuning (GAN-FT) an training structure that utilizes Generative Adversarial Networks (GANs) to bolster the resilience of extensive language models such, as BERT and RoBERTa. In contrast, training GAN with feature matching (GAN FW) uses a generative opponent to generate various and logically connected adversarial instances with less computational burden. Regular assessments on datasets such as IMDB, Yelp and SNLI indicate that GAN-FT consistently decreases the effectiveness of attacks while enhancing accuracy and adaptability across domains. This suggests its effectiveness in countering familiar and new word substitution forms of attack. This study highlights the impact of incorporating GANs into training methods and sheds light on understanding models better and making decisions effectively in this field of research. Though there are scalability and quick implementation challenges, in real-time scenarios, GAN-FT is a starting point for looking into adversarial defence mechanisms and broadening its use in more intricate NLP assignments. The research advances the reliability and security aspects of NLP systems, which is a move towards combatting adversarial risks in the ever-changing AI domain.","2837-4894","979-8-3315-1995-7","10.1109/MENACOMM62946.2025.10910951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910951","Adversarial machine learning (AML);machine learning (ML);natural language processing (NLP);natural languages;Large Language Model (LLMs);Generative Adversarial Networks (GAN);Adversarial Attacks","Training;Accuracy;Scalability;Generative adversarial networks;Natural language processing;Robustness;Real-time systems;Data models;Tuning;Resilience","","","","39","IEEE","13 Mar 2025","","","IEEE","IEEE Conferences"
"Distributed Secure Consensus Control With Event-Triggering for Multiagent Systems Under DoS Attacks","Y. Yang; Y. Li; D. Yue; Y. -C. Tian; X. Ding","College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; Guodian Nanrui Technology Company Ltd., Nanjing, China",IEEE Transactions on Cybernetics,"18 May 2021","2021","51","6","2916","2928","Consensus control of multiagent systems (MASs) has applications in various domains. As MASs work in networked environments, their security control becomes critically desirable in response to various cyberattacks, such as denial of service (DoS). Efforts have been made in the development of both time- and event-triggered consensus control of MASs. However, there is a lack of precise calculation of control input during the attacking periods. To address this issue, a distributed secure consensus control with event triggering is developed for linear leader-following MASs under DoS attacks. It is designed with a dual-terminal event-triggered mechanism, which schedules information transmission through two triggered functions for each follower: one on the measurement channel (sensor-to-controller) and the other on the control channel (controller-to-actuator). To deal with DoS attacks, the combined states in the triggered functions are replaced by their estimations from an observer. Sufficient conditions are established for the duration and frequency of DoS attacks. To remove continuous monitoring of the measurement errors, a self-triggered secure control scheme is further developed, which combines the system states and other information at past triggered instants. Theoretical analysis shows that the followers in MASs under DoS attacks are able to track the leader and meanwhile the Zeno behavior is excluded. Case studies are conducted to demonstrate the effectiveness of our distributed secure consensus control of MASs.","2168-2275","","10.1109/TCYB.2020.2979342","Natural Science Foundation of China(grant numbers:61833008,61873130,61833011); Australian Research Council through the Discovery Project Scheme(grant numbers:DP170103305); Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20191377); 1311 Talent Project of Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076328","Consensus secure control;denial-of-service (DoS) attack;event-triggered control;multiagent system (MAS);self-triggered control","Denial-of-service attack;Telecommunications;Multi-agent systems;Control systems;Observers;Computer crime;Monitoring","","204","","34","IEEE","22 Apr 2020","","","IEEE","IEEE Journals"
"Fault-Tolerant Consensus Control for Multiagent Systems: An Encryption-Decryption Scheme","C. Gao; Z. Wang; X. He; H. Dong","Department of Automation, BNRist, Tsinghua University, Beijing, China; Department of Computer Science, Brunel University London, Uxbridge, Middlesex, U.K.; Department of Automation, BNRist, Tsinghua University, Beijing, China; Artificial Intelligence Energy Research Institute, Northeast Petroleum University, Daqing, China",IEEE Transactions on Automatic Control,"25 Apr 2022","2022","67","5","2560","2567","In this article, the fault-tolerant consensus control problem is investigated for multiagent systems with sensor faults. A first-order difference equation is utilized to describe the sensor fault, and an observer is designed to estimate the state and the fault simultaneously. For security enhancement and/or congestion mitigation purposes, the estimated state is first encrypted into a series of finite-level codewords by an encryption algorithm and, then, transmitted to other agents through a directed topology. After being received, the codewords are then decrypted by the corresponding decryption algorithm and subsequently utilized to design the consensus controller. By constructing a novel matrix norm along with its compatible vector norm, we obtain a necessary and sufficient condition, which serves as an index in the observer and the controller design. In the end, a simulation example is given to demonstrate the validity of the results in this article.","1558-2523","","10.1109/TAC.2021.3079407","National Natural Science Foundation of China(grant numbers:61733009,61873148,61873058,61933007); National Key Research and Development Program of China(grant numbers:2017YFA0700300); Natural Science Foundation of Guangdong Province(grant numbers:2018B030311054); Beijing National Research Center for Information Science and Technology (BNRist) Program of China(grant numbers:BNR2019TD01009); Natural Science Foundation of Heilongjiang Province(grant numbers:ZD2019F001); Royal Society of the U.K.; Alexander von Humboldt Foundation of Germany; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429920","Consensus;encryption–decryption scheme;fault-tolerant control;multiagent system (MAS);sensor faults","Cryptography;Observers;Fault tolerant systems;Fault tolerance;Consensus control;Multi-agent systems;Symmetric matrices","","99","","39","IEEE","12 May 2021","","","IEEE","IEEE Journals"
"Multi-Layered Coordinated Countermeasures for DC Microgrid Clusters Under Man in the Middle Attack","S. Jena; N. P. Padhy; J. M. Guerrero","Department of Electrical Engineering, Indian Institute of Technology Roorkee, Roorkee, India; Department of Electrical Engineering, Indian Institute of Technology Roorkee, Roorkee, India; Department of Energy Technology, Aalborg University, Aalborg East, Denmark",IEEE Transactions on Industry Applications,"20 Mar 2024","2024","60","2","2127","2141","This paper aims to investigate the adversarial effects of man/machine-in-the-middle (MITM) attacks on interconnected direct current microgrid (MG) clusters, their detection and countermeasures for the first time. Therefore, a novel multi-layered attack recovery (ARF) scheme coordinated with state reconstruction has been formulated in the higher layers to identify such mishaps and provide cyber-resiliency to the MG power system operation at various levels of the hierarchical structure. The proposed countermeasures are based on synchronisation errors of the consensus variables and aid in preventive isolation of the healthy MG clusters or converters, thereby avoiding events which could potentially cause cascading effects. Its efficacy is demonstrated through theoretical analysis and extensive time domain simulations in MATLAB/Simulink under various scenarios of unidirectional and bidirectional MITM alongwith communication latencies. Lastly, controller hardware-in-loop (cHIL) implementation is employed to validate the security of real-time operations of MGs against stealthy MITM attacks.","1939-9367","","10.1109/TIA.2023.3308557","Department of Science and Technology, India Smart Grid Research Initiatives(grant numbers:UI-ASSIST: IUS-1132-EED,Indo-U.K. ZED-I: DST-1161-APD,D-SIDES:DST-1237-EED); Indo-Danish(grant numbers:ID-EDGe: DST-1390-EED); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10230867","Muti-agent systems (MAS);man-in-the-middle attack (MITM);resilient;field programmable gate array (FPGA);real-time digital simulator (RTDS)","Real-time systems;Power system stability;Control systems;Reliability;Power system reliability;Smart grids;Microgrids","","10","","34","IEEE","25 Aug 2023","","","IEEE","IEEE Journals"
"Multiagent System-Based VPPs Cooperative Power Control for Frequency Regulation Considering Diverse Communication Issues","J. Guo; C. Dou; D. Yue; B. Zhang; Z. Zhang; Z. Zhang","College of Automation, the College of Artificial Intelligence, and the Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Nanyang Avenue, Singapore; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China",IEEE Transactions on Smart Grid,"23 Jun 2025","2025","16","4","2846","2857","Virtual power plants (VPPs) possess significant potential to support power systems’ frequency regulation through the aggregation of demand-side distributed energy resources. However, due to their heavy reliance on information technology, VPPs inevitably face diverse communication issues, such as cyber-attacks, privacy disclosure, and packet losses, which poses a serious challenge to ensure efficient power control for frequency regulation. To this end, this paper proposes a multiagent system-based VPPs cooperative power control strategy to achieve frequency regulation in a resilient, optimal, and scalable manner. First, a joint design scheme of VPPs cooperative power control and information interaction mechanism is presented to determine the optimal regulation power of VPPs for frequency regulation, where a consensus-based collaborative strategy is designed for cyber-attacks and a homomorphic encryption technology is introduced for privacy protection. Also, an event-triggered mechanism is adopted for communication burden. Second, a dynamic power control scheme for inverter is presented to enable the internal units of VPPs to track the power reference from the joint design scheme, in which an improved model predictive control method is suggested for packet losses to enhance control performance. Finally, simulation results reveal that, when confronting diverse communication issues, the proposed strategy exhibits significant effects in defending against cyber-attacks, ensuring privacy security, alleviating the communication burden, and achieving fast response, thus effectively facilitating VPPs frequency regulation.","1949-3061","","10.1109/TSG.2025.3557436","Major Program of the National Natural Science Foundation of China(grant numbers:62293500,62293504); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10948420","Virtual power plants;frequency regulation;multiagent systems (MAS);cooperative power control;diverse communication issues;homomorphic encryption","Frequency control;Power control;Power generation;Regulation;Privacy;Protection;Packet loss;Automatic generation control;Predictive control;Cyberattack","","","","37","IEEE","3 Apr 2025","","","IEEE","IEEE Journals"
"Event-Triggered Fault-Tolerant Consensus Control of Multiagent Systems With Hybrid Attacks","C. Liu; B. Jiang; Y. Zhang; X. Ren; X. Wang","School of Mechatronic Engineering and Automation and the School of Future Technology (Institute of Artificial Intelligence), Shanghai University, Shanghai, China; College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Mechanical, Industrial and Aerospace Engineering, Concordia University, Montreal, QC, Canada; School of Mechatronic Engineering and Automation and the School of Future Technology (Institute of Artificial Intelligence), Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation and the School of Future Technology (Institute of Artificial Intelligence), Shanghai University, Shanghai, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","18 Jul 2025","2025","55","8","5541","5552","In this study, the fault-tolerant consensus control (FTCC) challenge is investigated for nonlinear multiagent systems (MASs) in the simultaneous occurrence of abrupt and incipient actuator/sensor faults in the physical level and hybrid Deception/Denial-of-Service (DoS) attacks in the cyber level. For security enhancement and/or safety maintenance purposes, an unknown state and fault decoupling-based augmented estimator is first devised, and a distributed event-triggered FTCC protocol is then developed to achieve strength against hostile attacks and faults, respectively, with the incorporation of augmented state estimation, neighboring sensor fault estimation, and latest successfully triggered output interaction. By constructing dual indicators along with average dwelling time and attack frequency technique, criteria of exponential mean-square consensus of the nonlinear MASs subject to hybrid attacks are obtained. In the end, simulation is outlined to illustrate the efficacy and improvements of the developed event-triggered FTCC methodology.","2168-2232","","10.1109/TSMC.2025.3571020","National Natural Science Foundation of China(grant numbers:62333011,62336005); Project of Science and Technology Commission of Shanghai Municipality(grant numbers:22JC1401401); Shanghai Aerospace Advanced Technology Joint Research Fund(grant numbers:USCAST2023-22); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029311","Event-triggered mechanism;fault-tolerant consensus control (FTCC);hybrid attacks;multiagent systems (MAS);physical faults","Actuators;Fault tolerant systems;Fault tolerance;Event detection;Security;Multi-agent systems;Denial-of-service attack;Consensus control;Switches;Safety","","","","33","IEEE","10 Jun 2025","","","IEEE","IEEE Journals"
"AidBot: a ChatGPT based chatbot for e-commerce platforms","G. Akshay; H. V. R.; L. R. R.","Department of Electrical and Electronics Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electrical and Electronics Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electrical and Electronics Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India",8th IET Smart Cities Symposium (SCS 2024),"4 Apr 2025","2024","2024","","747","751","Prompt Engineering deals with the design, refinement and implementation of prompts. The new research field guides the response of large language models to perform various tasks. Recent studies show significant emergence of chatbots for numerous e-commerce applications. Prevailing chat platforms are characterized with static response. Recently, chatbot technology has experienced a tremendous advancement with the incorporation of ChatGPT. This paper introduces AidBot, a new customer care ChatGPT based chatbot that responds dynamically by providing human like response to the customers. The AidBot, trained deploying Chain of thought process, encompass frontend for a lively conversation and a backend that embeds OpenAI API and a storage to log the conversation details. Unlike present chatbots, AidBot uses prompt engineering technology to make the conversation more human-like. The proposed system is tested for various conversations that includes type grammatical mistakes to analyse its response. Moreover, the adaptability of the model to multiple languages are also tested. The effectiveness of the model in storing the required conversation details and sharing with the associated customer care officials are tested. The suggested system is expected to provide a user friendly and convincing customer service based on the past conversations.","","978-1-83724-310-5","10.1049/icp.2025.0886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10949335","","","","","","","","4 Apr 2025","","","IET","IET Conferences"
"Writing Prompts for ChatGPT","P. Baker",NA,ChatGPT For Dummies,"","2023","","","47","60","Summary <p>This chapter helps the readers to learn how to use ChatGPT prompts like a pro. Prompting is both the easy part and the most difficult part of using a generative artificial intelligence (AI) model. Prompt engineering is the act of crafting an input, which is a deed borne partly of art and partly of logic. Prompt engineering in AI refers to the act of embedding the task description in the input in a natural‐language format, rather than entering explicit instructions via computer code. One example of a transferrable skill is a journalist's ability to tease out the answers they seek in an interview by using direct or indirect methods. Prompt‐based learning is a strategy AI engineers use to train large language models. English is more concise than many other languages and therefore usually requires fewer tokens to process prompts.</p>","","9781394204649","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10950575.pdf&bkn=10950151&pdfType=chapter","","Chatbots;Writing;Bars;Prompt engineering;User interfaces;Search engines;Vocabulary;Toy manufacturing industry;Surgery;Shape","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Chatting with Copilot","C. Minnick",NA,Microsoft Copilot For Dummies,"","2025","","","29","44","Summary <p>We can communicate with Copilot using text or speech, and Copilot understands and can communicate in at least 25 different human languages. The default way to interact with Copilot is via text prompts. There are many reasons why speech input and responses are useful or essential while using Copilot, including for accessibility, efficiency, multitasking, familiarity, and inclusion. Activating voice input and response in Copilot is just a matter of clicking the microphone input. This chapter presents the basics of prompt engineering so that we can prompt Copilot like a pro. The first rule of prompt engineering is that large language models need context. With prompt refinement, a generic zero‐shot prompt is just the first step in gradually zeroing in on results that are more specific and better tuned to what it is we're trying to accomplish.</p>","","9781394314966","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10953107.pdf&bkn=10950197&pdfType=chapter","","Electronic mail;Heating systems;Microphones;Artificial intelligence;Writing;Refining;Multitasking;Motion pictures;Meteorology;Chatbots","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Enabling Secure Wireless Communications via Movable Antennas","Z. Cheng; N. Li; J. Zhu; X. She; C. Ouyang; P. Chen","6G Research Centre, China Telecom Beijing Research Institute, Beijing, China; 6G Research Centre, China Telecom Beijing Research Institute, Beijing, China; 6G Research Centre, China Telecom Beijing Research Institute, Beijing, China; 6G Research Centre, China Telecom Beijing Research Institute, Beijing, China; University College Dublin, Dublin, Ireland; 6G Research Centre, China Telecom Beijing Research Institute, Beijing, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","9186","9190","A pioneering secure transmission scheme is proposed, which harnesses movable antennas (MAs) to optimize antenna positions for augmenting the physical layer security. Particularly, an MA-enabled secure wireless system is considered, where a multi-antenna transmitter communicates with a single-antenna receiver in the presence of an eavesdropper. The beamformer and antenna positions at the transmitter are jointly optimized under two criteria: power consumption minimization and secrecy rate maximization. For each scenario, a novel suboptimal algorithm was proposed to tackle the resulting nonconvex optimization problem, capitalizing on the approaches of alternating optimization and gradient descent. Numerical results demonstrate that the proposed MA systems significantly improve physical layer security compared to various benchmark schemes relying on conventional fixed-position antennas (FPAs).","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447471","Antenna position;movable antenna (MA);physical layer security;secure beamforming","Wireless communication;Power demand;Transmitting antennas;Signal processing algorithms;Receivers;Physical layer security;Benchmark testing","","18","","15","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"DynPen: Automated Penetration Testing in Dynamic Network Scenarios Using Deep Reinforcement Learning","Q. Li; R. Wang; D. Li; F. Shi; M. Zhang; A. Chattopadhyay; Y. Shen; Y. Li","College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Computer Science, Chongqing University, Chongqing, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; College of Electronic Engineering, National University of Defense Technology, Hefei, China; College of Electronic Engineering, National University of Defense Technology, Hefei, China",IEEE Transactions on Information Forensics and Security,"1 Oct 2024","2024","19","","8966","8981","Penetration testing, a crucial industrial practice for securing networked systems and infrastructures, has traditionally depended on the extensive expertise of human professionals. Addressing the scarcity of human experts, the development of automated penetration testing tools emerges as a promising avenue. Against the backdrop of rapid advancements in artificial intelligence technologies, reinforcement learning has demonstrated considerable potential for realizing automated penetration testing. However, existing research predominantly concentrates on reinforcement learning-based automated penetration testing tools within static scenarios, with limited exploration in dynamic network environments. This paper addresses a noteworthy challenge in developing autonomous agents for real-world applications, particularly focusing on scenarios marked by environmental changes. Such alterations necessitate autonomous agents to continuously monitor environmental characteristics, and adapt, and adjust learned actions to ensure the system’s effective operation. Consequently, the paper proposes an automated reinforcement learning-based penetration testing scheme tailored for dynamic network scenarios, named DynPen. DynPen captures observed changes in the scenario, aiding the penetration testing agent in decision-making based on historical experiences. Simulation results demonstrate the proposed scheme’s efficacy in significantly expediting the convergence speed of the penetration testing agent using reinforcement learning algorithms. Furthermore, the scheme successfully maintains the learning agility and adaptability of the agent in dynamic network scenarios.","1556-6021","","10.1109/TIFS.2024.3461950","National Key Research and Development Program of China(grant numbers:2021YFB3100500); Program of China Scholarship Council(grant numbers:202306110031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10681147","Automated penetration testing;reinforcement learning;dynamic environments;network security","Penetration testing;Planning;Network security;Decision making;Adaptation models;Training;Monitoring","","3","","40","IEEE","16 Sep 2024","","","IEEE","IEEE Journals"
"Code Vulnerability Repair with Large Language Model Using Context-Aware Prompt Tuning","A. Khan; G. Liu; X. Gao","University of Delaware, Newark, Delaware, USA; Colorado School of Mines, Golden, CO, USA; University of Delaware, Newark, Delaware, USA",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","283","287","Large Language Models (LLMs) have shown significant challenges in detecting and repairing vulnerable code, particularly when dealing with vulnerabilities involving multiple aspects, such as variables, code flows, and code structures. In this study, we utilize GitHub Copilot as the LLM and focus on buffer overflow vulnerabilities. Our experiments reveal a notable gap in GitHub Copilot's vulnerability repair abilities, with a 76% vulnerability detection rate but only a 15% vulnerability repair rate. To address this issue, we propose a context-aware prompt tuning technique to enhance Copilot's performance in repairing buffer overflow. By injecting a sequence of domain knowledge about the vulnerability, including various security and code contexts, we demonstrate that Copilot's vulnerability repair rate increases to 63%, representing more than four times the improvement compared to repairs without domain knowledge.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050839","Code vulnerability repair;large language model;buffer overflow;prompt tuning","Privacy;Codes;Large language models;Conferences;Buffer overflows;Maintenance engineering;Security;Tuning;Software development management","","1","","29","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Trusted LLM Inference on the Edge with Smart Contracts","R. Karanjai; W. Shi","Department Of Computer Science, University Of Houston; Department Of Computer Science, University Of Houston",2024 IEEE International Conference on Blockchain and Cryptocurrency (ICBC),"21 Aug 2024","2024","","","1","7","In this era, significant transformations in industries and tool utilization are driven by AI/Large Language Models (LLMs) and advancements in Machine Learning. There’s a growing emphasis on MLOps for managing and deploying these AI models, along with a focus on distributed inferences. Concurrently, the imperative for secure on-chain computation is escalating. Our paper introduces an innovative framework that integrates blockchain technology, particularly the Cosmos SDK, to facilitate distributed AI inferences on edge devices. This system, built on WebAssembly (WASM), enables interchain communication and deployment of WASM modules executing AI inferences across multiple blockchain nodes. We critically assess this system’s safety, scalability, and model security, with a special focus on its portability and engine-model agnostic deployment on edge devices.","2832-8906","979-8-3503-1674-2","10.1109/ICBC59979.2024.10634448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10634448","","Industries;Computational modeling;Scalability;Large language models;Smart contracts;Machine learning;Blockchains","","1","","42","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"The Future of AI in Test and Measurement","S. Roundy; N. Gilbert; J. Wilkinson","Testeract, Draper, UT; Testeract, Draper, UT; Testeract, Draper, UT",2024 IEEE AUTOTESTCON,"2 Oct 2024","2024","","","1","6","AI (Artificial Intelligence) has become a very popular topic in recent years. LLMs (Large Language Models) like ChatGPT, Llama, Gemini and others have started to become adopted more broadly in business. But what can AI do for the unique needs of test and measurement? It is generally a necessary cost center that can be very expensive and delay getting products out the door. This paper dives into the different ways that AI can be used to bring those costs down and shorten the time to market. As the technology progresses, AI will become an essential part of the test development workflow. Instead of taking the place of seasoned test engineers, AI will become more of an enabling tool, injected into the test development workflow, that allows test creators to move more efficiently and effectively. Using AI comes at a cost though. Governance, security and trust are all hurdles that need to be overcome for AI to become commonplace in test and measurement.","1558-4550","979-8-3503-4943-6","10.1109/AUTOTESTCON47465.2024.10697428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10697428","artificial intelligence;AI;automated test;test and measurement;test development;test workflow;test engineering;hardware test;test costs;time to market","Costs;Large language models;Time to market;Companies;Chatbots;Delays;Security;Artificial intelligence;Business","","","","10","IEEE","2 Oct 2024","","","IEEE","IEEE Conferences"
"Blockchain-Based Intelligent E-Commerce Platform for Enhancing Customer Experience in Telecom Operators","M. Guan; J. Zhang; Z. Zheng","China Mobile Internet Co., Ltd., Guangzhou, China; China Mobile Internet Co., Ltd., Guangzhou, China; China Mobile Internet Co., Ltd., Guangzhou, China",2024 10th International Conference on Computer and Communications (ICCC),"2 Apr 2025","2024","","","2007","2011","In the rapidly evolving landscape of e-commerce, the integration of blockchain technology and artificial intelligence (AI) presents unprecedented opportunities for enhancing customer experience, particularly within the telecommunications sector. This paper proposes a secure private blockchain-based intelligent e-commerce platform designed to streamline commercial and trade circulation while fostering trust and security. By leveraging the immutable nature of blockchain and implementing end-to-end encryption (E2EE), the platform ensures secure transactions and improves data privacy, addressing common pain points in digital commerce. Furthermore, the incorporation of large language models (LLMs) enhance user experience through personalized recommendation and efficient customer service. The synergy between blockchain and AI not only optimizes operational efficiency but also cultivates a more engaging and satisfying customer journey. Through empirical analysis and case studies, our proposed approach highlights its advantages over traditional platform in the perspective of customer experience.","2837-7109","979-8-3315-0707-7","10.1109/ICCC62609.2024.10942227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10942227","Blockchain;e-commerce platform;customer experience;commercial and trade circulation;artificial intelligence;large language model","Data privacy;Pain;Large language models;Customer services;User experience;Blockchains;Telecommunications;Encryption;Electronic commerce;Computer security","","","","12","IEEE","2 Apr 2025","","","IEEE","IEEE Conferences"
"Reshaping the Educational Landscape of Tomorrow","H. Scarlett; T. Graham; S. Edwards-Braham; Y. Buchanan","School of Computing and Technology - University of Technology, Jamaica; School of Computing and Technology - University of Technology, Jamaica; School of Computing and Technology - University of Technology, Jamaica; School of Computing and Technology - University of Technology, Jamaica","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","1119","1122","Large Language Models (LLMs), like ChatGPT, are potential game changers for the educational industry. Chatbots can augment the educational experience by creating personalized learning paths to address the varied needs of the learner. In this paper we seek to demystify the underlying technologies, address security concerns, provide open-source alternatives to minimize development costs and stimulate conversations about how best to leverage these tools in educational circles.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487185","Artificial Intelligence;Chatbots;ChatGPT;Education","Industries;Costs;Education;Computer bugs;Oral communication;Games;Chatbots","","","","12","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"9 Multi-Modal Data Fusion","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","241","276","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310525.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"What Is ChatGPT?","A. Lopez-Lira",University of Florida,The Predictive Edge: Outsmart the Market using Generative AI and ChatGPT in Financial Forecasting,"","2024","","","89","119","Summary <p>ChatGPT stands at the intersection of several advanced fields in artificial intelligence, primarily natural language processing (NLP), large language models (LLMs), and Generative AI. In this chapter, the authors explore ChatGPT's skills and limitations and learn how to obtain the best results using good prompting. ChatGPT has real‐time web browsing capabilities, allowing it to access and retrieve up‐to‐date information online. ChatGPT can understand and generate human language. Through fine‐tuning, ChatGPT is trained to adhere to ethical guidelines and avoid generating harmful or inappropriate content. While imperfect, this capability ensures safer and more responsible interactions. Prompt engineering is the art of designing helpful prompts to guide ChatGPT in generating the most valuable and accurate responses. The chapter explains the potential business applications of ChatGPT, highlighting its transformative potential across various sectors and functions.</p>","","9781394242733","10.1002/9781394308286.ch5","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951664.pdf&bkn=10950216&pdfType=chapter","","Chatbots;Codes;Oral communication;Investment;Biological system modeling;Python;Real-time systems;Encoding;Data models;Context awareness","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"3 Machine Learning Basics","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","53","80","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310612.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"6 State Estimation","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","163","188","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310576.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"5 Reinforcement Learning","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","127","162","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310655.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"7 Localization","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","189","214","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310618.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"10 Multi-Robot Systems","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","277","314","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9313937.pdf&bkn=9310536&pdfType=chapter","","","","","","","","5 Jan 2021","","","River Publishers","River eBook Chapters"
"4 Markov Decision Processes","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","81","126","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310598.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"Artificial Intelligence in Wireless Robotics","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","i","xxx","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310640.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"8 Robot Planning","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","215","240","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310567.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"1 Introduction to Artificial Intelligence and Robotics","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","1","24","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310607.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"2 Basic Search Algorithms","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","25","52","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310581.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
