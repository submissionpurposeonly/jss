"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"SiJesi: Large Language Model Chatbot with Augmented Retrieval Approach Generation and Prompt Engineering","H. S. Rosari; Girinoto; R. Novita Yasa; N. Qomariasih; R. Anindya Wijayanti","Crypto Software Engineering, Politeknik Siber dan Sandi Negara, Bogor, Indonesia; Crypto Software Engineering, Politeknik Siber dan Sandi Negara, Bogor, Indonesia; Crypto Software Engineering, Politeknik Siber dan Sandi Negara, Bogor, Indonesia; Crypto Software Engineering, Politeknik Siber dan Sandi Negara, Bogor, Indonesia; Crypto Software Engineering, Politeknik Siber dan Sandi Negara, Bogor, Indonesia","2024 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)","19 Feb 2025","2024","","","1","6","This research designs a chatbot based on Large Language Models (LLM) for cyber incident consultation, utilizing the Retrieval Augmented Generation (RAG) approach, integrated with GPT and prompt engineering techniques. The goal is to improve public cybersecurity awareness, especially in areas with low awareness, by enhancing community consultation services through automation. The chatbot addresses security concerns by examining measures against prompt injection attacks to ensure reliability. The research follows the Waterfall System Development Life Cycle methodology. Results show that LLM chatbots using RAG and prompt engineering generate more accurate responses compared to human-based answers and GPT 3.5, achieving a top score of 35.26% in A/B testing. Additionally, the chatbot received a high satisfaction score of 86.47% in User Acceptance Testing. These findings are expected to contribute to increased cybersecurity awareness and the development of innovative, secure chatbot technology for public services.","","979-8-3503-6880-2","10.1109/CENIM64038.2024.10882696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882696","Large Language Model;Retrieval Augmented Generation;Generative Pre-training Transformer;Prompt Engineering","Surveys;Large language models;Retrieval augmented generation;Chatbots;Transformers;Portable document format;Prompt engineering;Reliability;Computer security;Testing","","","","16","IEEE","19 Feb 2025","","","IEEE","IEEE Conferences"
"Implementing Literature-based Discovery (LBD) with ChatGPT","A. Nedbaylo; D. Hristovski","Faculty of Public Administration, University of Ljubljana, Ljubljana, Slovenia; Faculty of Public Administration, University of Ljubljana, Ljubljana, Slovenia",2024 47th MIPRO ICT and Electronics Convention (MIPRO),"28 Jun 2024","2024","","","120","125","Literature-based discovery (LBD) is a methodology for generating research hypotheses by identifying hidden connections within the scientific literature. While its application has been predominantly in the field of biomedicine, particularly through the use of Medline, the largest freely available biomedical bibliographic database, traditional LBD methodologies have relied heavily on rule-based approaches. These include utilizing co-occurrences among biomedical concepts or extracting semantic relations through natural language processing (NLP) methods. This study ventures into novel territory by exploring the use of advanced tools like ChatGPT for LBD, with a focus on leveraging prompt engineering to enhance hypothesis generation. We employed Large Language Models (LLMs) such as GPT-3.5 and GPT-4 to simulate the discovery of relationships between medical concepts. The study specifically examines the effectiveness of these models in autonomously replicating well-established medical correlations and generating potentially novel hypotheses. Our preliminary findings suggest that while LLMs show promise in generating hypotheses that occasionally deviate from established medical knowledge, challenges persist in consistently directing these models to produce truly innovative and less-explored connections. The study highlights the potential of LLMs in enriching the LBD process, yet also underscores the need for cautious evaluation and further research to optimize their application in this domain.","2623-8764","979-8-3503-8250-1","10.1109/MIPRO60963.2024.10569439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569439","Literature-based discovery;Large Language Models;Knowledge Extraction;Hidden Knowledge Connections;Prompt Engineering;Discovery Patterns","Knowledge engineering;Electric potential;Semantics;Refining;Training data;Migraine;Information services","","2","","20","IEEE","28 Jun 2024","","","IEEE","IEEE Conferences"
"PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback","Y. Peng; A. D. Gotmare; M. R. Lyu; C. Xiong; S. Savarese; D. Sahoo","The Chinese University of Hong Kong, Hong Kong, China; Salesforce Research, Singapore; The Chinese University of Hong Kong, Hong Kong, China; Salesforce Research, Singapore; Salesforce Research, Singapore; Salesforce Research, Singapore",2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge),"2 Jul 2025","2025","","","1","13","Large Language Models (LLMs) are widely adopted for assisting in software development tasks, yet their performance evaluations have narrowly focused on the functional correctness of generated code. Human programmers, however, expect AI assistants to generate not only correct but also optimally efficient code. We propose PerfCodeGen, a training-free framework that enhances the performance of LLM-generated code by incorporating feedback based on runtime during test case execution into the self-refinement iterations. With PerfCodeGen, we achieve speedups for a significantly higher proportion of problems compared to using the base LLM with sophisticated prompting techniques. Applied to open-weight language models like Phi-3-mini, PerfCodeGen achieves code optimization rates comparable to naive prompting of powerful closed models like GPT-4. We achieve state-of-the-art code optimization on benchmarks such as HumanEval, MBPP, and APPS, frequently surpassing the ground truth reference solutions with PerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the effectiveness of our approach in enhancing code quality across a range of open-weight LLMs of varying sizes including Phi-3-mini (3.8B), Llama 3 8B, Mixtral 8x7B (13B active), Command R (35B), and Llama 3 70B. PerfCodeGen’s effectiveness at generating performant code underscores the importance of integrating execution feedback into the code generation process, highlighting a path forward for more robust and reliable AI-driven software development.","","979-8-3315-0211-9","10.1109/Forge66646.2025.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052794","Large Language Models;Code Generation;Efficient Code;Runtime Efficiency;Code Optimization","Codes;Runtime;Large language models;Benchmark testing;Programming;Reliability engineering;Software reliability;Optimization;Software development management;Python","","","","64","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Prompting in the Wild: An Empirical Study of Prompt Evolution in Software Repositories","M. Tafreshipour; A. Imani; E. Huang; E. S. d. Almeida; T. Zimmermann; I. Ahmed","University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA; Federal University of Bahia (UFBA), Brazil; University of California, Irvine, Irvine, USA; University of California, Irvine, Irvine, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","686","698","The adoption of Large Language Models (LLMs) is reshaping software development as developers integrate these LLMs into their applications. In such applications, prompts serve as the primary means of interacting with LLMs. Despite the widespread use of LLM-integrated applications, there is limited understanding of how developers manage and evolve prompts. This study presents the first empirical analysis of prompt evolution in LLM-integrated software development. We analyzed 1,262 prompt changes across 243 GitHub repositories to investigate the patterns and frequencies of prompt changes, their relationship with code changes, documentation practices, and their impact on system behavior. Our findings show that developers primarily evolve prompts through additions and modifications, with most changes occurring during feature development. We identified key challenges in prompt engineering: only $21.9 \%$ of prompt changes are documented in commit messages, changes can introduce logical inconsistencies, and misalignment often occurs between prompt changes and LLM responses. These insights emphasize the need for specialized testing frameworks, automated validation tools, and improved documentation practices to enhance the reliability of LLM-integrated applications.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025760","Large Language Models;Prompt Engineering;Empirical Software Engineering","Systematics;Large language models;Documentation;Software;Software reliability;Prompt engineering;Data mining;Software development management;Testing;Software engineering","","","","58","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"ChatGPT for PLC/DCS Control Logic Generation","H. Koziolek; S. Gruener; V. Ashiwal","ABB Research, Ladenburg, Germany; ABB Research, Ladenburg, Germany; ABB Research, Ladenburg, Germany",2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA),"12 Oct 2023","2023","","","1","8","Large language models (LLMs) providing generative AI have become popular to support software engineers in creating, summarizing, optimizing, and documenting source code. It is still unknown how LLMs can support control engineers using typical control programming languages in programming tasks. Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source code generation but did not yet tackle control logic programming. A key contribution of this paper is an exploratory study, for which we created 100 LLM prompts in 10 representative categories to analyze control logic generation for of PLCs and DCS from natural language. We tested the prompts by generating answers with ChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3 Structured Text code in many cases and demonstrated useful reasoning skills that could boost control engineer productivity. Our prompt collection is the basis for a more formal LLM benchmark to test and compare such models for control logic generation.","1946-0759","979-8-3503-3991-8","10.1109/ETFA54631.2023.10275411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10275411","Generative AI;Large Language Models;Automation engineering;Control Logic Generation;IEC 61131-3;Structured Text;Control engineering;Benchmark","Productivity;Logic programming;Source coding;Natural languages;Chatbots;Software;Task analysis","","21","","21","IEEE","12 Oct 2023","","","IEEE","IEEE Conferences"
"Generating P4 Dataplanes Using LLMs","M. -V. Dumitru; V. -A. Bădoiu; A. M. Gherghescu; C. Raiciu",University Politehnica of Bucharest; University Politehnica of Bucharest; University Politehnica of Bucharest; University Politehnica of Bucharest,2024 IEEE 25th International Conference on High Performance Switching and Routing (HPSR),"20 Aug 2024","2024","","","31","36","Large Language Models (LLMs) have recently become the source of impressive results in code generation, but there are still areas left neglected. Virtually all small and mediumsized LLMs are unable to produce code in P4, the most popular language for programmable dataplanes. Automatically generating dataplane code carries the promise of flexible networks that can quickly adapt to their specific conditions at the lowest level. P4 is structurally simpler than general-purpose languages, but also offers a much smaller corpus of existing programs, thus setting up interesting challenges for deep-learning based code generation. In this paper, we set out to investigate the extent to which current State-of-the-Art LLMs can produce P4 code and we push these boundaries by experimenting with finetuning to produce code generators that are open, robust and use low resources (1B-3B parameters). To evaluate the quality of the generated code, we have developed a novel benchmark for P4 auto-completion tasks. Our results show that fine-tuned models using the specialized dataset outperform ChatGPT 4 and Gemini Ultra, both in terms of compilability and alignment.","2325-5609","979-8-3503-6385-2","10.1109/HPSR62440.2024.10635926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10635926","P4;programmable dataplanes;LLM;code generation","Training;Codes;Large language models;Buildings;Switches;Programming;Routing","","3","","36","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Generative AI for Smart Contracts in Real Estate Business","W. Zhao; L. Pobbathi; S. Ramprasath; M. Patibandla","University of North Texas, Denton, TX, U.S.A.; University of North Texas, Denton, TX, U.S.A.; University of North Texas, Denton, TX, U.S.A.; University of North Texas, Denton, TX, U.S.A.",2024 11th International Conference on Dependable Systems and Their Applications (DSA),"1 Jan 2025","2024","","","49","59","The rapid advancements in Generative AI have opened new possibilities for automating complex processes, such as the generation of smart contracts within the real estate industry. This paper presents a comprehensive review of existing literature and research on the application of Gen AI in creating smart contracts, with a focus on ensuring correctness, fairness, and data privacy. We explore the methodologies employed in using large language models (LLMs) like GPT-4 to develop smart contract requirements that are not only precise but also adaptable to the evolving needs of stakeholders in real estate transactions. Additionally, we discuss the critical role of human oversight in refining AI-generated specifications to meet regulatory and ethical standards, thereby enhancing the reliability and transparency of automated contracts. Through this analysis, we highlight the potential of Gen AI to revolutionize the real estate industry by streamlining the creation of smart contracts, reducing the risk of human error, and ensuring that transactions are secure, fair, and compliant with privacy regulations.","2767-6684","979-8-3315-3239-0","10.1109/DSA63982.2024.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818322","Generative AI;smart contracts;blockchain;real estate;requirements specification;automation;security;transparency","Data privacy;Generative AI;Smart contracts;Refining;Real estate industry;Regulation;Security;Reliability;Standards;Testing","","","","31","IEEE","1 Jan 2025","","","IEEE","IEEE Conferences"
"Intelligent Automation for Accelerating the Repair of Software Build Failures","G. Sun","Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","205","207","Society has an insatiable hunger for software. It keeps our planes in the air, our cars on the road, and even guides surgical procedures. Yet as software enriches more and more aspects of our lives, its complexity (and that of its maintenance) presents an ever-growing challenge. To manage the development of complex software, build systems are widely adopted to perform routine checks after code submissions. The build system lies at the core of the software delivery process, responsible for transforming source code (pseudo-English machine instructions) into release-ready software that users can install or interact with. While build systems provide numerous benefits, the rapid pace of modern software development generates heavy workloads for them to process. Executing builds requires substantial computing resources and energy, and when a build fails, the consequences ripple throughout the development process. Failures not only block others from validating their work, but also necessitate repeated executions, incurring more resource consumption. In a case study of a software organization, 18% of builds failed, with an average of 56 minutes spent resolving each failure. Such inefficiencies contribute to wasted computing resources and energy and hinder productivity, emphasizing the need for more cost-effective solutions. This proposal aims to develop automated methods for repairing build failures by addressing four key areas: (1) compilation errors, (2) dependency-induced errors, (3) test execution errors, and (4) a comprehensive solution that integrates these aspects. The approach involves parsing and analyzing build action traces to identify root causes, cataloging and exploiting patterns of reusable build fixes to enable rapid resolution, and leveraging machine learning approaches, such as the fine-tuning and prompting of large language models, to assist developers in reimplementing failed test cases. These innovations will streamline the build repair process, reducing delays and improving overall development efficiency.","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024452","build system;automated program repair","Productivity;Technological innovation;Source coding;Roads;Surgery;Maintenance engineering;Software;Proposals;Software engineering;Software development management","","","","24","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Software Engineering Educational Experience in Building an Intelligent Tutoring System","Z. Fan; Y. Noller; A. Dandekar; A. Roychoudhury","National University of Singapore, Singapore; Ruhr University Bochum, Germany; National University of Singapore, Singapore; National University of Singapore, Singapore",2025 IEEE/ACM 37th International Conference on Software Engineering Education and Training (CSEE&T),"12 Jun 2025","2025","","","75","86","The growing number of students enrolling in Computer Science (CS) programmes is pushing CS educators to their limits. This poses significant challenges to computing education, particularly the teaching of introductory programming and advanced software engineering (SE) courses. First-year programming courses often face overwhelming enrollments, including interdisciplinary students who are not CS majors. The high teacher-to-student ratio makes it challenging to provide timely and highquality feedback. Meanwhile, software engineering education comes with inherent difficulties like acquiring industry partners and the dilemma that such software projects are often under or over-specified and one-time efforts within one team or one course. To address these challenges, we designed a novel foundational SE course. This SE course envisions building a full-fledged Intelligent Tutoring System (ITS) of Programming Assignments to provide automated, real-time feedback for novice students in programming courses over multiple years. Each year, SE students contribute to specific short-running SE projects that improve the existing ITS implementation, while at the same time, we can deploy the ITS for usage by students for learning programming. This project setup builds awareness among SE students about their contribution to a “to-be-deployed” software project. In this multi-year teaching effort, we have incrementally built an ITS that is now deployed in various programming courses. This paper discusses the Intelligent Tutoring System architecture, our teaching concept in the SE course, our experience with the built ITS, and our view of future computing education.","2832-7578","979-8-3315-3709-8","10.1109/CSEET66350.2025.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024295","computer science education;software engineering;CS-1;automated program repair;large language models;intelligent tutoring","Industries;Large language models;Education;Buildings;Systems architecture;Maintenance engineering;Software;Real-time systems;Programming profession;Software engineering","","","","36","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned with HDL Engineers","Y. Yang; F. Teng; P. Liu; M. Qi; C. Lv; J. Li; X. Zhang; Z. He","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Software Technology, Zhejiang University, Ningbo, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Independent Researcher; School of Software Technology, Zhejiang University, Ningbo, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","7","Recently, the use of large language models (LLMs) for Verilog code generation has attracted great research interest to enable hardware design automation. However, previous works have shown a gap between the ability of LLMs and the practical demands of hardware description language (HDL) engineering. This gap includes differences in how engineers phrase questions and hallucinations in the code generated. To address these chal-lenges, we introduce Haven, a novel LLM framework designed to mitigate hallucinations and align Verilog code generation with the practices of HDL engineers. Haven tackles hallucination issues by proposing a comprehensive taxonomy and employing a chain-of-thought (CoT) mechanism to translate symbolic modalities (e.g. truth tables, state diagrams, etc.) into accurate natural language descriptions. Furthermore, Haven bridges this gap by using a data augmentation strategy. It synthesizes high-quality instruction-code pairs that match real HDL engineering practices. Our experiments demonstrate that Haven significantly improves the correctness of Verilog code generation, outperforming state-of-the-art LLM-based Verilog generation methods on VerilogEval and RTLLM benchmark. Haven is publicly available at https://github.com/Intelli2ent-Computing-Research-Group/HaVen.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10993072","National Key R&D Program of China(grant numbers:2022YFB4500200); National Natural Science Foundation of China(grant numbers:62102257); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993072","Verilog Code Generation;LLM","Bridges;Codes;Translation;Design automation;Large language models;Taxonomy;Europe;Data augmentation;Hardware;Hardware design languages","","1","","34","","21 May 2025","","","IEEE","IEEE Conferences"
"Generative-AI(with Custom-Trained Meta's Llama2 LLM), Blockchain, NFT, Federated Learning and PBOM Enabled Data Security Architecture for Metaverse on 5G/6G Environment","E. Bandara; P. Foytik; S. Shetty; A. Hassanzadeh","Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Old Dominion University, Norfolk, VA, USA; Accenture Technology Labs, Arlington, VA, USA",2024 IEEE 21st International Conference on Mobile Ad-Hoc and Smart Systems (MASS),"25 Oct 2024","2024","","","118","124","The Metaverse is an integrated network of 3D virtual worlds accessible through a virtual reality headset. Its impact on data privacy and security is increasingly recognized as a major concern. There is a growing interest in developing a reference architecture that describes the four core aspects of its data: acquisition, storage, sharing, and interoperability. Establishing a secure data architecture is imperative to manage users' personal data and facilitate trusted AR/VR and AI/ML solutions within the Metaverse. This paper details a reference architecture empowered by Generative-AI, Blockchain, Federated Learning, and Non-Fungible Tokens (NFTs). Within this archi-tecture, various resource providers collaborate via the blockchain network. Handling personal user data and resource provider identities is executed through a Self-Sovereign Identity-enabled privacy-preserving framework. AR/NR devices in the Metaverse are represented as NFT tokens available for user purchase. Software updates and supply-chain verification for these devices are managed using a Software Bill of Materials (SBOM) and a Pipeline Bill of Materials (PBOM) verification system. Moreover, a custom-trained Llama2 LLM from Meta has been integrated to generate PBOMs for AR/NR devices' software updates, thereby preventing malware intrusions and data breaches. This Llama2-13B LLM has been quantized and fine-tuned using Qlora to ensure optimal performance on consumer-grade hardware. The provenance of AI/ML models used in the Metaverse is encapsu-lated as Model Card objects, allowing external parties to audit and verify them, thus mitigating adversarial learning attacks within these models. To the best of our knowledge, this is the very first research effort aimed at standardizing PBOM schemas and integrating Language Model algorithms for the generation of PBOMs. Additionally, a proposed mechanism facilitates different AI/ML providers in training their machine learning models using a privacy-preserving federated learning approach. Authorization of communications among AR/VR devices in the Metaverse is conducted through a Zero-Trust security-enabled rule engine. A system testbed has been implemented within a 5G environment, utilizing Ericsson new Radio with Open5GS 5G core.","2155-6814","979-8-3503-6399-9","10.1109/MASS62177.2024.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10723538","Metaverse;Generative-AI;LLM;Llama2;5G;6G;Blockchain;Federated Learning;NFT","Training;Solid modeling;Three-dimensional displays;Metaverse;Federated learning;5G mobile communication;Bills of materials;Computer architecture;Virtual reality;Nonfungible tokens","","","","25","IEEE","25 Oct 2024","","","IEEE","IEEE Conferences"
"Leveraging RAG-LLM to Translate C++ to Rust","A. Okutan; S. Merten; C. C. Michael; B. Ryjikov","Leidos, Reston, VA, USA; Leidos, Reston, VA, USA; Leidos, Reston, VA, USA; Leidos, Reston, VA, USA",2024 International Conference on Assured Autonomy (ICAA),"27 Nov 2024","2024","","","102","105","Despite their similarities, translating C++ code into the Rust language is a challenging task on account of differences in syntax, ecosystem, philosophy, and idioms. Large Language Models (LLMs) using Retrieval Augmented Generation (RAG) are effective at solving challenging programming language tasks, including source code generation and program translation. We leveraged RAG LLMs for translating C++ code into Rust and created Cpp2Rust, an LLM-based C++-to-Rust transpiler grounding the OpenAI ChatGPT4 model with similar C++ and Rust code snippet pairs from LeetCode. Preliminary analysis results show that 84% of the solutions produced by Cpp2Rust that had no compile errors were accepted as correct solutions on LeetCode.","","979-8-3315-2101-1","10.1109/ICAA64256.2024.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765951","Transpilation;C++ to Rust;Large Language Models","Computer languages;Codes;Program processors;Philosophical considerations;Grounding;Source coding;Large language models;Ecosystems;C++ languages;Syntactics","","","","22","IEEE","27 Nov 2024","","","IEEE","IEEE Conferences"
"Detection and Identification of Cyberattacks and Physical Faults in Multi-Agent Systems: A Distributed Disturbance Decoupling Observer","Y. Hu; X. Dai; D. Cui; T. Chai","State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; Department of Mathematics, Physics and Electrical Engineering, Northumbria University, Newcastle-upon-Tyne, U.K.; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China",IEEE Transactions on Industrial Informatics,"22 Jan 2024","2024","20","2","2991","3001","This article investigates the detection and identification of physical faults in devices and false-data-injection attacks in communication networks for multi-agent systems with event-triggered transmission mechanisms and subject to external periodic disturbances. First, a new detection and identification scheme, including a local disturbance decoupling (LDD) observer and a distributed disturbance decoupling (DDD) observer, is proposed. Then, based on zero-assignment and the rank-deficiency of the transfer function matrix at zeros, a co-design method for the LDD observer and DDD observer is proposed, which enables the decoupling of periodic disturbances from the residuals for detection and identification. This new scheme no longer requires the transmission of control signals from the node being monitored or the exchange of information between its neighbors, significantly reducing the communication overhead and enhancing the system's security. Finally, a simulation based on a multi-two-wheeled trolley system is used to verify the effectiveness of the proposed method.","1941-0050","","10.1109/TII.2023.3299622","National Key Research and Development Program of China(grant numbers:2022ZD0115402); National Natural Science Foundation of China(grant numbers:61790574,U1834211,61773111,61833004,61991404); Heilongjiang Provincial Key Science and Technology(grant numbers:2020ZX03A02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214187","Attacks;detection and identification;disturbance decoupling;event-triggered mechanism;multiagent system (MAS)","Observers;Computer crime;Security;Image edge detection;Transfer functions;Object recognition;Detection algorithms","","9","","28","IEEE","9 Aug 2023","","","IEEE","IEEE Journals"
"NLP4ReF: Requirements Classification and Forecasting: From Model-Based Design to Large Language Models","J. Peer; Y. Mordecai; Y. Reich","Faculty of Engineering, Tel Aviv University, Tel-Aviv, Israel; Faculty of Engineering, Tel Aviv University, Tel-Aviv, Israel; Faculty of Engineering, Tel Aviv University, Tel-Aviv, Israel",2024 IEEE Aerospace Conference,"13 May 2024","2024","","","1","16","We introduce Natural Language Processing for Requirement Forecasting (NLP4ReF), a model-based machine learning and natural language processing solution for enhancing the Requirements Engineering (RE) process. RE continues to face significant challenges and demands innovative approaches for process efficiency. Traditional RE methods relying on natural language struggle with incomplete, hidden, forgotten, and evolving requirements during and after the critical design review, risking project failures and setbacks. NLP4ReF tackles several key challenges: a) distinguishing between functional and non-functional requirements, b) classification of requirements by their respective system classes, and c) generation of unanticipated requirements to enhance project success. NLP4ReF employs a common natural language toolkit (NLTK) package and the recently-trending Chat-GPT. We tested NLP4ReF on PROMISE_exp, a pre-existing dataset with 1000 software requirements, and PROMISE_IoT, an enhanced dataset with 2000 software and IoT requirements. We validated NLP4ReF on a genuine IoT project. NLP4ReF swiftly generated dozens of new requirements, verified by a team of systems engineers, of which over 70% were crucial for project success. We found that GPT is superior in authentic requirement generation, while NLTK excels at requirement classification. NLP4ReF offers significant time saving, effort reduction, and improved future-proofing. Our model-based design approach provides a foundation for enhanced RE practices and future research in this domain.","1095-323X","979-8-3503-0462-6","10.1109/AERO58975.2024.10521022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10521022","Natural Language Processing;Requirements Engineering Requirement Forecasting;Internet of Things;Machine Learning;Model-Based Systems Engineering","Software algorithms;Training data;Software;Natural language processing;Data models;Classification algorithms;Requirements engineering","","1","","38","IEEE","13 May 2024","","","IEEE","IEEE Conferences"
"Guardian Angel: A Secure and Efficient Retrieval-Augmented Generation Framework","X. Fang; L. Qiao; J. Shi; H. An","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China",2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA),"1 Jul 2025","2025","","","1773","1777","In recent years, large language models (LLMs) like ChatGPT have seen increased usage across various domains. Despite their effectiveness in routine tasks, LLMs face chal-lenges in scientific applications due to inaccurate outputs and limited logical reasoning capabilities. To address these shortcomings, Retrieval-Augmented Generation (RAG) has emerged as a promising approach that enhances prompt quality with relevant resources. While RAG improves inference speed and performance through cloud-based solutions, it introduces significant security risks, such as data breaches and unauthorized access. This paper proposes a secure RAG paradigm named Guardian Angel that preserves high-performance cloud-based LLM inference by employing a novel symbol substitution scheme. This approach ensures data security by replacing sensitive keywords with patterned strings that do not disrupt LLM processing. Our contributions include the development of an end-to-end encrypted RAG pipeline and a cost model to evaluate performance and overhead, guiding researchers in optimizing cloud deployment strategies while balancing security and efficiency.","","979-8-3315-0976-7","10.1109/AIITA65135.2025.11047845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047845","Retrieval-Augmented Generation;Privacy Protection;Large Language Models","Privacy;Data privacy;Costs;Large language models;Retrieval augmented generation;Semantics;Pipelines;Symbols;Resource management;Protection","","","","16","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Evaluating the Repair Ability of LLM Under Different Prompt Settings","X. Tian","Southern University of Science and Technology, Shenzhen, China",2024 IEEE International Conference on Software Services Engineering (SSE),"18 Sep 2024","2024","","","313","322","As the increase of complexity and scale of software, the number of software bugs increases as well, which causes huge financial losses and poses a great threat to our lives. To address this issue, researchers have devoted themselves to automated program repair(APR), which aims to release programmers from the time-consuming manual debugging. In the last few decades, lots of APR tools have been proposed, such as constraint-based, heuristic-based, template-based and learning-based APRs. Unfortunately, traditional APRs are confronted with numerous challenges. Neither do they deeply understand the program's semantics, nor they can fix many types of bugs in different scenarios. Recently, researchers directly applied Large Language Models (LLMs) for APR and demonstrated that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on many datasets. However, there is a lack of study that fully reveals which information is useful for LLM-based APR. There is neither a study that reveals how we can further increase the repair ability of large language models by better utilizing prompts. In this study, we conduct an extensive study to figure out how bug descriptions, fault locations and few-shot prompting affect the repair ability of LLM on Defects4J dataset. We found that 1) Concise bug description is critical for the model to fix bugs. 2) Fault locations can improve LLM's repair ability in most cases, but it does not always helpful. 3) Few-shot prompting is not beneficial for enhancing the understanding of LLM regarding the faulty program and we'd better not use few-shot prompting. We are fully convinced that our findings will provide not only some theory evidences but also some insights for future research.","","979-8-3503-6851-2","10.1109/SSE62657.2024.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664337","APR;LLM;Fault Location;Bug Report;Few-shot prompting","Zero-shot learning;Large language models;Computer bugs;Semantics;Debugging;Maintenance engineering;Fault location","","","","48","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"On Evaluating the Efficiency of Source Code Generated by LLMs","C. Niu; T. Zhang; C. Li; B. Luo; V. Ng","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; School of Computing and Information Systems, Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA",2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym:,"30 Jul 2024","2024","","","103","107","Recent years have seen the remarkable capabilities of large language models (LLMs) for code generation. Different from existing work that evaluate the correctness of the code generated by LLMs, we propose to further evaluate its efficiency. More efficient code can lead to higher performance and execution efficiency of pro-grams and software completed by LLM-assisted programming. First, we evaluate the efficiency of the code generated by LLMs on two benchmarks, HumanEval and MBPP. Then, we choose a set of pro-gramming problems from the online judge platform LeetCode to conduct a more difficult evaluation. Finally, we explore several prompts that would enable LLMs to generate more efficient code.","","979-8-4007-0536-6","10.1145/3650105.3652295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599574","","Codes;Terminology;Source coding;Large language models;Programming;Benchmark testing;Software","","5","","27","","30 Jul 2024","","","IEEE","IEEE Conferences"
"Tool-Augmented LLMs as a Universal Interface for IDEs","Y. Zharov; Y. Khudyakov; E. Fedotova; E. Grigorenko; E. Bogomolov","JetBrains Research, Karlsruhe, Germany; JetBrains Research, Bremen, Germany; JetBrains Research, Belgrade, Serbia; JetBrains Research, Belgrade, Serbia; JetBrains Research, Amsterdam, the Netherlands",2024 IEEE/ACM First IDE Workshop (IDE),"16 Oct 2024","2024","","","40","42","Modern-day Integrated Development Environments (IDEs) have come a long way from the early text editing utilities to the complex programs encompassing thousands of functions to help developers. However, with the increasing number of efficiency-enhancing tools incorporated, IDEs gradually became sophisticated software with a steep learning curve. The rise of the Large Language Models (LLMs) capable of both natural language dialogue and code generation leads to a discourse on the obsolescence of the concept of IDE. In this work, we offer a view on the place of the LLMs in the IDEs as the universal interface wrapping the IDE facilities. We envision a model that is able to perform complex actions involving multiple IDE features upon user command, stripping the user experience of the tedious work involved in searching through options and actions. For the practical part of the work, we engage with the works exploring the ability of LLMs to call for external tools to expedite a given task execution. We showcase a proof-of-concept of such a tool.","","979-8-4007-0580-9","10.1145/3643796.3648451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10713945","IDE;LLM;ToolFormer","Codes;Large language models;Conferences;Natural languages;Aging;User experience;Software;Lead compounds;Wrapping","","","","15","","16 Oct 2024","","","IEEE","IEEE Conferences"
"TOGLL: Correct and Strong Test Oracle Generation with LLMS","S. B. Hossain; M. B. Dwyer","Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1475","1487","Test oracles play a crucial role in software testing, enabling effective bug detection. Despite initial promise, neural methods for automated test oracle generation often result in a large number of false positives and weaker test oracles. While LLMs have shown impressive effectiveness in various software engineering tasks, including code generation, test case creation, and bug fixing, there remains a notable absence of large-scale studies exploring their effectiveness in test oracle generation. The question of whether LLMs can address the challenges in effective oracle generation is both compelling and requires thorough investigation. In this research, we present the first comprehensive study to investigate the capabilities of LLMs in generating correct, diverse, and strong test oracles capable of effectively identifying a large number of unique bugs. To this end, we fine-tuned seven code LLMs using six distinct prompts on a large dataset consisting of 110 Java projects. Utilizing the most effective finetuned LLM and prompt pair, we introduce TOGLL, a novel LLM-based method for test oracle generation. To investigate the generalizability of TOGLL, we conduct studies on 25 unseen large-scale Java projects. Besides assessing the correctness, we also assess the diversity and strength of the generated oracles. We compare the results against EvoSuite and the state-of-the-art neural method, TOGA. Our findings reveal that TOGLL can produce 3.8 times more correct assertion oracles and 4.9 times more exception oracles than TOGA. Regarding bug detection effectiveness, TOGLL can detect 1,023 unique mutants that EvoSuite cannot, which is ten times more than what TOGA can detect. Additionally, TOGLL significantly outperforms TOGA in detecting real bugs from the Defects4J dataset.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00098","National Science Foundation(grant numbers:2129824,221707); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029748","test oracle generation;llms;evosuite;bug detection effectiveness","Software testing;Java;Codes;Accuracy;Large language models;Computer bugs;Software engineering","","","","56","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Harnessing Large Language Models for Automated Intrusion Detection Rule Generation in Cyber Range","L. Du; J. Li; H. Yan; Y. Chai; B. Fang; Z. Gu","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; Department of New Networks, Peng Cheng Laboratory, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China",IEEE Network,"","2025","PP","99","1","1","Rule-based network intrusion detection systems hold great promise in cybersecurity due to their remarkable performance in identifying cyberattacks. Unfortunately, these detection rules are manually written by security experts for known attacks and are ineffective against unknown intrusion threats. Despite the progress made in existing work on automatic detection rule generation, the majority of such work focuses on synthesizing overly specific detection rules for input attack samples, neglecting the detection of these attack sample variants. Furthermore, most detection rule generation approaches rely on the content of the rule as an explanation, failing to provide a high-level understanding of both detection rules and attack samples. To tackle these challenges, we propose a novel detection rule generation framework, LLM4Rule, which aims to reproduce and automatically generate detection rules for discovered attacks in a cyber range without compromising real networks and endpoints. LLM4Rule leverages the knowledge reasoning capabilities of large language models (LLMs) to generate detection rules through interaction with LLMs, which consists of three components: preprocessing, detection rule generation, and attack sample mapping. The preprocessing component extracts and converts payloads from discovered attack samples. In the detection rule generation component, we propose a two-stage detection rule generation prompt approach that utilizes the self-correction ability of LLMs to filter invalid rules and enhances the generalization of valid rules to attack variants over the initially generated detection rules. Finally, the attack sample mapping component maps the attack samples to cybersecurity knowledge bases to help security operators better understand the generated detection rules and the attack samples. We conduct extensive experiments to demonstrate the effectiveness of LLM4Rule against four representative detection rule generation approaches on two datasets. The experimental results show that the detection rules generated by LLM4Rule can accurately detect cyberattack variants and effectively map attack samples to cybersecurity knowledge bases.","1558-156X","","10.1109/MNET.2025.3582330","Shenzhen Science and Technology Program(grant numbers:KJZD20231023094701003); Major Key Project of PCL(grant numbers:PCL2024A05); National Natural Science Foundation of China(grant numbers:62372137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048554","Network intrusion detection;detection rule generation;large language model","Computer security;Security;Payloads;Knowledge based systems;Computer crime;Network intrusion detection;Large language models;Training;Cognition;Manuals","","","","","IEEE","23 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving","X. Zheng; L. Wu; Z. Yan; Y. Tang; H. Zhao; C. Zhong; B. Chen; J. Gong","Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China",2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"25 Dec 2024","2024","","","980","985","Motion prediction is among the most fundamental tasks in autonomous driving. Traditional methods of motion forecasting primarily encode vector information of maps and historical trajectory data of traffic participants, lacking a comprehensive understanding of overall traffic semantics, which in turn affects the performance of prediction tasks. In this paper, we utilized Large Language Models (LLMs) to enhance the global traffic context understanding for motion prediction tasks. We first conducted systematic prompt engineering, visualizing complex traffic environments and historical trajectory information of traffic participants into image prompts— Transportation Context Map (TC-Map), accompanied by corresponding text prompts. Through this approach, we obtained rich traffic context information from the LLM. By integrating this information into the motion prediction model, we demonstrate that such context can enhance the accuracy of motion predictions. Furthermore, considering the cost associated with LLMs, we propose a cost-effective deployment strategy: enhancing the accuracy of motion prediction tasks at scale with 0.7% LLM-augmented datasets. Our research offers valuable insights into enhancing the understanding of traffic scenes of LLMs and the motion prediction performance of autonomous driving. The source code is available at https://github.com/AIR-DISCOVER/LLM-Augmented-MTR and https://aistudio.baidu.com/projectdetail/7809548.","2153-0866","979-8-3503-7770-5","10.1109/IROS58592.2024.10802397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802397","","Accuracy;Systematics;Large language models;Transportation;Predictive models;Vectors;Trajectory;Prompt engineering;Autonomous vehicles;Context modeling","","4","","25","IEEE","25 Dec 2024","","","IEEE","IEEE Conferences"
"LLM-based Interactive Code Generation: Empirical Evaluation","D. Shaikhelislamov; M. Drobyshevskiy; A. Belevantsev","Moscow Institute of Physics and Technology (State University), Moscow, Russia; Moscow Institute of Physics and Technology (State University), Moscow, Russia; Ivannikov Institute for System Programming of the Russian Academy of Sciences, Moscow, Russia",2024 Ivannikov Ispras Open Conference (ISPRAS),"28 Feb 2025","2024","","","1","5","Recently, large language models (LLMs), those pretrained on code, have demonstrated strong capabilities in generating programs from informal natural language intent. However, LLM -generated code is prone to bugs. Developers interacting with LLMs seek trusted code and, ideally, clear indications of potential bugs and vulnerabilities. Verified code can mitigate potential business risks associated with adopting generated code. We use model-agnostic framework CodePatchLLM, an extension for LLM that utilizes Svace feedback to enhance code generation quality. We evaluate CodePatchLLM on four popular LLMs across three datasets. Our experiments show an average absolute reduction of 19.1 % in static analyzer warnings for Java across all datasets and models, while preserving pass@ 1 code generation accuracy.","2767-9535","979-8-3315-2602-3","10.1109/ISPRAS64596.2024.10899123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10899123","Large Language Model;Code verification;Trusted code","Analytical models;Codes;Accuracy;Large language models;Computer bugs;Natural languages;Programming;Safety;Security;Reliability","","","","36","IEEE","28 Feb 2025","","","IEEE","IEEE Conferences"
"Automated question generation from job descriptions using large language models: an evaluation of role-fit and fairness","N. Ahmed; Z. Iqbal; R. Khan; F. N. Al-Aswadi; G. S. AlDharhani; H. Y. Chan","Smart Zone Leaders, Kharian, Dist. Gujrat, Pakistan; Department of Computer Science, Air University, Kharian, Pakistan; Smart Zone Leaders, Kharian, Dist. Gujrat, Pakistan; Institute of Computer Science & Digital Innovation (ICSDI), UCSI University, Kuala Lumpur 56000, Malaysia; Institute of Computer Science & Digital Innovation (ICSDI), UCSI University, Kuala Lumpur 56000, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","International Conference on Energy, Power, Environment, Control and Computing (ICEPECC 2025)","18 Apr 2025","2025","2025","","628","635","This paper introduces an automated framework for generating high-quality, role-specific interview questions directly from complex job descriptions using an ensemble of Large Language Models (LLMs). We leverage seven advanced LLMs (gemma2-9b-it,gemma-7b-it,llama-3.3-70b-versatile,llama-3.1-8b-instant,llama3-70b-8192,mixtral-8x7b-32768, andOpenAI-3.5) to produce a diverse pool of questions. Our approach integrates prompt engineering and debiasing strategies to ensure that the generated questions are contextually relevant, role-aligned, and free from harmful biases. We compare the LLMs’ outputs against a strong baseline (ChatGPT o1 Pro) and human domain experts’ assessments, employing a multi-faceted evaluation framework including relevance, clarity, specificity, and fairness metrics. Our results, validated on a curated set of job descriptions across multiple industries, demonstrate that a multi-model generation strategy, combined with bias mitigation and expert-informed prompt design, yields superior interview question sets. This research offers insights into enhancing recruitment practices, improving efficiency, and fostering equitable candidate assessment.","","978-1-83724-315-0","10.1049/icp.2025.1174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969684","","","","","","","","18 Apr 2025","","","IET","IET Conferences"
"HoneyLLM: Enabling Shell Honeypots with Large Language Models","C. Guan; G. Cao; S. Zhu","Department of Computer Science and Engineering, The Pennsylvania State University; Department of Computer Science and Engineering, The Pennsylvania State University; Department of Computer Science and Engineering, The Pennsylvania State University",2024 IEEE Conference on Communications and Network Security (CNS),"31 Oct 2024","2024","","","1","9","Large Language Models (LLMs) have shown significant potential across various domains, including cybersecurity. This paper introduces HoneyLLM, a novel approach to creating high-fidelity shell honeypots using LLMs. We first investigate the potential of different commercial LLMs to emulate shell environments, identifying their characteristics and key challenges in accuracy and consistency. To address these issues, we propose leveraging various prompt engineering techniques, including incontext learning to tackle accuracy-related issues and the chain-of-thought method to maintain response consistency across complex, multi-step attack sessions. Additionally, we design a hybrid architecture for HoneyLLM to handle real-world limitations and improve cost-effectiveness. Through comprehensive offline evaluations, we demonstrate that HoneyLLM can effectively emulate shell environments and handle complex attack scenarios. Our online deployment results show that HoneyLLM, particularly when powered by advanced models like GPT-4, significantly outperforms traditional honeypots in maintaining longer, more effective attack sessions.","2994-5895","979-8-3503-7596-1","10.1109/CNS62487.2024.10735663","Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10735663","","Accuracy;Filters;Large language models;Network security;Prompt engineering;History;Computer security","","","","34","IEEE","31 Oct 2024","","","IEEE","IEEE Conferences"
"Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks","M. A. Ferrag; M. Debbah; M. Al-Hawawreh","Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, UAE; Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, UAE; School of Information Technology, Deakin University, Australia","2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)","19 Jul 2023","2023","","","16","25","The next generation of cellular technology, 6G, is being developed to enable a wide range of new applications and services for the Internet of Things (IoT). One of 6G’s main advantages for IoT applications is its ability to support much higher data rates and bandwidth as well as to support ultralow latency. However, with this increased connectivity will come to an increased risk of cyber threats, as attackers will be able to exploit the large network of connected devices. Generative Artificial Intelligence (AI) can be used to detect and prevent cyber attacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we discuss the use of generative AI for cyber threat-hunting (CTH) in 6G-enabled IoT networks. Then, we propose a new generative adversarial network (GAN) and Transformer-based model for CTH in 6Genabled IoT Networks. The experimental analysis results with a new cyber security dataset demonstrate that the Transformer-based security model for CTH can detect IoT attacks with a high overall accuracy of 95%. We examine the challenges and opportunities and conclude by highlighting the potential of generative AI in enhancing the security of 6G-enabled IoT networks and call for further research to be conducted in this area.","","979-8-3503-0208-0","10.1109/CCGridW59191.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181170","Generative AI;Security;GPT;GAN;IoT;6G","6G mobile communication;Analytical models;Scalability;Training data;Transformers;Generative adversarial networks;Tokenization","","39","","17","IEEE","19 Jul 2023","","","IEEE","IEEE Conferences"
"A Generative AI Approach for Ensuring Data Integrity Security Resilience in Fintech Systems","P. Chatterjee; D. Das; D. B. Rawat","Department of EE and CS, Howard University, Washington, DC, USA; Department of CS and DS, Meharry Medical College, TN, USA; Department of EE and CS, Howard University, Washington, DC, USA","2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)","11 Oct 2024","2024","","","168","173","The Fintech industry represents the convergence of finance and technology through innovative digital solutions from mobile banking to cryptocurrency. However, it faces big challenges with keeping data safe and systems strong. Traditional methods struggle to keep pace with sophisticated threats and complexities inherent in modern Fintech ecosystems. This paper proposes an approach to address these challenges using Generative AI and blockchain integration to make Fintech systems more resilient. Advanced machine learning algorithms detect and prevent data tampering in the proposed systems. Generative AI is used for threat detection, anomaly recognition, and real-time monitoring in system security. Then, we integrate blockchain technology to enhance the overall resilience of systems. Blockchain technology enhances the reliability of financial services in secure transactions, validating blocks, and distributing control across decentralized networks. These combined methodologies address the critical challenges of data integrity, security, and system resilience in dynamic Fintech systems. The performance analysis demonstrates the efficacy of our proposed framework in enhancing data integrity, security measures, and system resilience within Fintech systems.","","979-8-3503-7751-4","10.1109/CCGridW63211.2024.00027","Impact Fund; Howard University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707467","Fintech;Data Integrity;Security;Resilience;Generative Artificial Intelligence;Machine Learning;Cybersecurity","Fault tolerance;Generative AI;Data integrity;Smart contracts;Threat assessment;Real-time systems;Blockchains;Security;Faces;Resilience","","2","","22","IEEE","11 Oct 2024","","","IEEE","IEEE Conferences"
"Can ChatGPT Repair Non-Order-Dependent Flaky Tests?","Y. Chen; R. Jabbarvand",University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign,2024 IEEE/ACM International Flaky Tests Workshop (FTW),"10 Sep 2024","2024","","","22","29","Regression testing helps developers check whether the latest code changes break software functionality. Flaky tests, which can non-deterministically pass or fail on the same code version, may mislead developers’ concerns, resulting in missing some bugs or spending time pinpointing bugs that do not exist. Existing flakiness detection and mitigation techniques have primarily focused on general order-dependent (OD) and implementation-dependent (ID) flaky tests. There is also a dearth of research on repairing test flakiness, out of which, mostly have focused on repairing OD flaky tests, and a few have explored repairing a subcategory of non-order-dependent (NOD) flaky tests that are caused by asynchronous waits. As a result, there is a demand for devising techniques to reproduce, detect, and repair NOD flaky tests. Large language models (LLMs) have shown great effectiveness in several programming tasks. To explore the potential of LLMs in addressing NOD flakiness, this paper investigates the possibility of using ChatGPT to repair different categories of NOD flaky tests. Our comprehensive study on 118 from the IDoFT dataset shows that ChatGPT, despite as a leading LLM with notable success in multiple code generation tasks, is ineffective in repairing NOD test flakiness, even by following the best practices for prompt crafting. We investigated the reasons behind the failure of using ChatGPT in repairing NOD tests, which provided us valuable insights about the next step to advance the field of NOD test flakiness repair.CCS CONCEPTS• Software and its engineering → Software testing and debugging.","","979-8-4007-0558-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669636","Software Testing;Test Flakiness;Large Language Models","Software testing;Codes;Prevention and mitigation;Large language models;Computer bugs;Debugging;Maintenance engineering","","1","","59","","10 Sep 2024","","","IEEE","IEEE Conferences"
"Secure and Scalable LLM-Based Recommendation Systems: An MLOps and Security by Design","A. Saputra; E. Suryani; N. A. Rakhmawati","Interdisciplinary School of Management Technology Institut Teknologi Sepuluh November, Surabaya, Indonesia; Dept. of Information Systems Institut Teknologi, Sepuluh November, Surabaya, Indonesia; Dept. of Information Systems Institut Teknologi, Sepuluh November, Surabaya, Indonesia",2024 IEEE International Symposium on Consumer Technology (ISCT),"17 Dec 2024","2024","","","623","629","Integrating Large Language Models (LLMs) into e-commerce recommendation systems promises to transform consumer interactions with products, enhancing discovery and engagement through personalized recommendations. This approach has become vital for improving user experience and boosting sales. However, the adoption of LLMs introduces significant security and scalability challenges. To address these issues, this paper proposes an innovative framework that combines machine learning operations (MLOps) with security-by-design principles, with the aim of creating LLM -based recommendation systems that are secure and scalable for e-commerce platforms. This study explores the entire life cycle of an LLM-based recommendation system, from data preprocessing and model training to deployment and continuous monitoring, while embedding security and scalability. By implementing Machine Learning Operations (MLOps) with security-by-design principles, e-commerce businesses can leverage the advanced capabilities of LLMs to provide personalized shopping experiences, increase user engagement, and drive sales without compromising user trust and system performance.","2159-1423","979-8-3503-6519-1","10.1109/ISCT62336.2024.10791207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10791207","LLMs;MLOps;security-by-design principles;LLM-based recommendation systems;Machine Learning Operations;Consumer","Training;Scalability;Large language models;System performance;Transforms;User experience;Safety;Security;Electronic commerce;Recommender systems","","","","38","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Enabling Architecture Traceability by LLM-based Architecture Component Name Extraction","D. Fuchß; H. Liu; T. Hey; J. Keim; A. Koziolek","KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Germany; KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Germany; KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Germany; KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Germany; KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Germany",2025 IEEE 22nd International Conference on Software Architecture (ICSA),"30 Apr 2025","2025","","","1","12","Traceability Link Recovery (TLR) is an enabler for various software engineering tasks. One important task is the recovery of trace links between Software Architecture Documentation (SAD) and source code. Here, the main challenge is the semantic gap between the two artifact types. Recent research has shown that this semantic gap can be bridged by using Software Architecture Models (SAMs) as intermediates. However, the creation of SAMs is a manual and time-consuming task. This paper investigates the use of Large Language Models (LLMs) to extract component names as simple SAMs for TLR based on SAD and source code. By doing so, we aim to bridge the semantic gap between SAD and source code without the need for manual SAM creation. We compare our approach to the state-of-the-art TLR approaches TransArC and ArDoCode. TransArC is the currently best-performing approach for TLR between SAD and source code, but it requires SAMs as an additional artifact. Our evaluation shows that our approach performs comparable to TransArC (weighted average F1 with GPT-4o: 0.86 vs. TransArC’s 0.87), while only needing the SAD and source code. Moreover, our approach significantly outperforms the best baseline that does not need SAMs (weighted average F1 with GPT-4o: 0.86 vs. ArDoCode’s 0.62). In summary, our approach shows that LLMs can be used to make TLR between SAD and source code more applicable by extracting component names and omitting the need for manually created SAMs.","2835-7043","979-8-3315-2090-8","10.1109/ICSA65012.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978943","Traceability Link Recovery;Large Language Models;Software Architecture;Model Extraction","Bridges;Software architecture;Source coding;Large language models;Semantics;Manuals;Computer architecture;Documentation","","1","","50","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"Research on the LLM-Driven Vulnerability Detection System Using LProtector","Z. Sheng; F. Wu; X. Zuo; C. Li; Y. Qiao; H. Lei","Computer and Information Science, University of Pennsylvania, Philadelphia, USA; Integrated Circuit Science & Engineering, University of Electronic Science & Technology of China, Chengdu, China; Computer Science & Engineering, Texas A&M University, College Station, USA; Graduate School of Arts and Sciences, Georgetown University, Washington, D.C., USA; Computer Information Technology, Northern Arizona University, Flagstaff, USA; LG Energy Solution(Nanjing)Co., Ltd, Nanjing, China",2024 IEEE 4th International Conference on Data Science and Computer Application (ICDSCA),"6 Feb 2025","2024","","","192","196","The security issues of large-scale software systems and frameworks have become increasingly severe with the development of technology. As complexity of software grows, vulnerabilities are becoming more challenging to detect. Although traditional machine learning methods have been applied in cybersecurity for a long time, there has been no significant breakthrough until now. With the recent rise of large language models (LLMs), a turning point seems to have arrived. The powerful code comprehension and generation capabilities of LLMs make fully automated vulnerability detection systems a possibility. This paper presents LProtector, an automated vulnerability detection system for C/C++ codebases based on GPT-4o and Retrieval-Augmented Generation (RAG). LProtector performs binary classification to identify vulnerabilities in target codebases. To evaluate its effectiveness, we conducted experiments on the Big- Vul dataset. Results show that LProtector outperforms two state-of-the-art baselines in terms of F1 score, demonstrating the potential of integrating LLMs with vulnerability detection.","","979-8-3503-6823-9","10.1109/ICDSCA63855.2024.10859408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859408","Large Language Models;Deep Learning;Defect Detection;Operating System;Cybersecurity;Software Engineering","Codes;Accuracy;Retrieval augmented generation;Machine learning;Predictive models;Maintenance engineering;Software systems;Turning;Cognition;Mobile applications","","2","","18","IEEE","6 Feb 2025","","","IEEE","IEEE Conferences"
"Toward Integrating ChatGPT Into Satellite Image Annotation Workflows: A Comparison of Label Quality and Costs of Human and Automated Annotators","J. Beck; L. M. Kemeter; K. Dürrbeck; M. H. I. Abdalla; F. Kreuter","Munich Center for Machine Learning (MCML), Ludwig-Maximilians-Universität München Institut für Informatik, München, Germany; Center for Applied Research on Supply Chain Services, Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany; Center for Applied Research on Supply Chain Services, Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany; Center for Applied Research on Supply Chain Services, Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany; Munich Center for Machine Learning (MCML), Ludwig-Maximilians-Universität München Institut für Informatik, München, Germany",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"3 Feb 2025","2025","18","","4366","4381","High-quality annotations are a critical success factor for machine learning (ML) applications. To achieve this, we have traditionally relied on human annotators, navigating the challenges of limited budgets and the varying task-specific expertise, costs, and availability. Since the emergence of large language models (LLMs), their popularity for generating automated annotations has grown, extending possibilities and complexity of designing an efficient annotation strategy. Increasingly, computer vision capabilities have been integrated into general-purpose LLMs like ChatGPT. This raises the question of how effectively LLMs can be used in satellite image annotation tasks and how they compare to traditional annotator types. This study presents a comprehensive investigation and comparison of various human and automated annotators for image classification. We evaluate the feasibility and economic competitiveness of using the ChatGPT4-V model for a complex land usage annotation task and compare it with alternative human annotators. A set of satellite images is annotated by a domain expert and 15 additional human and automated annotators, differing in expertise and costs. Our analyzes examine the annotation quality loss between the expert and other annotators. This comparison is conducted through, first, descriptive analyzes, second, fitting linear probability models, and third, comparing F1-scores. Ultimately, we simulate annotation strategies where samples are split according to an automatically assigned certainty score. Routing low-certainty images to human annotators can cut total annotation costs by over 50% with minimal impact on label quality. We discuss implications regarding the economic competitiveness of annotation strategies, prompt engineering, and the task-specificity of expertise.","2151-1535","","10.1109/JSTARS.2025.3528192","Munich Center for Machine Learning; Bavarian Ministry of Economic Affairs; Regional Development and Energy through the Center for Analytics — Data — Applications; BAYERN DIGITAL II(grant numbers:20-3410-2-9-8); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841407","Automated annotations;ChatGPT;label quality;large language models (LLMs);satellite image annotation","Annotations;Satellite images;Biological system modeling;Costs;Chatbots;Training;Image annotation;Visualization;Remote sensing;Data models","","2","","71","CCBY","14 Jan 2025","","","IEEE","IEEE Journals"
"Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries","Y. Deng; C. S. Xia; C. Yang; S. D. Zhang; S. Yang; L. Zhang","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","841","853","Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TITANFUZZ work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pretraining corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced. To fill this gap, this paper proposes FuzzGPT, the first approach to priming LLMs to synthesize unusual programs for fuzzing. Fuz-zGPT is mainly built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/ semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and Codegen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruction-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TITANFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623343","NSF(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548124","","Deep learning;Image edge detection;Computer bugs;Semantics;Fuzzing;Chatbots;Libraries","","17","","87","","14 Jun 2024","","","IEEE","IEEE Conferences"
"LLM-FIN: Large Language Models Fingerprinting Attack on Edge Devices","N. Nazari; F. Xiang; C. Fang; H. M. Makrani; A. Puri; K. Patwari; H. Sayadi; S. Rafatirad; C. -N. Chuah; H. Homayoun","University of California-Davis; University of California-Davis; University of California-Davis; University of California-Davis; California State University, Long Beach; University of California-Davis; University of California-Davis; University of California-Davis; University of California-Davis; University of California-Davis",2024 25th International Symposium on Quality Electronic Design (ISQED),"16 May 2024","2024","","","1","6","The deployment of Large Language Models (LLMs) into edge and embedded devices marks a transformative step in integrating Artificial Intelligence (AI) into real-world applications. This integration is crucial as it enables efficient, localized processing, reducing reliance on cloud computing and enhancing data privacy by keeping sensitive information on the device. In the domain of machine learning (ML) security, concealing the architecture of LLMs is imperative. Shielding the architecture protects intellectual property and thwarts malicious attempts to exploit model-specific weaknesses. Our research proposes an efficient fingerprinting method tailored to identify the architectural family of LLMs specifically within edge and embedded devices. Uniquely, our technique hinges on analyzing memory usage patterns, one of the few accessible data points in a secured edge environment. Employing a supervised machine learning classifier, our methodology demonstrates remarkable efficacy, achieving over 95% accuracy in classifying known LLMs into their architectural families. Notably, it also exhibits robust adaptability, accurately identifying previously unseen models. By focusing on memory usage patterns, our approach paves the way for a new dimension in understanding and securing AI on edge devices, balancing the need for open functionality and essential confidentiality.","1948-3295","979-8-3503-0927-0","10.1109/ISQED60706.2024.10528736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10528736","","Graphics processing units;Focusing;Computer architecture;Machine learning;Intellectual property;Fingerprint recognition;Security","","5","","23","IEEE","16 May 2024","","","IEEE","IEEE Conferences"
"Live Streaming Surveillance Video Upscaling Using Generative AI With Anomaly Identification","D. Ajalkar; A. Mahindrakar; A. Popale; A. Meshram; P. Khillarkar","Dept. of Data Science, G H Raisoni College of Engineering and Management (Affiliated to SPPU), Pune, India; Dept. of Data Science, G H Raisoni College of Engineering and Management (Affiliated to SPPU), Pune, India; Dept. of Data Science, G H Raisoni College of Engineering and Management (Affiliated to SPPU), Pune, India; Dept. of Data Science, G H Raisoni College of Engineering and Management (Affiliated to SPPU), Pune, India; Dept. of Data Science, G H Raisoni College of Engineering and Management (Affiliated to SPPU), Pune, India",2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI),"24 Apr 2024","2024","2","","1","5","This research addresses the challenge of low-resolution CCTV footage in criminal investigations through the application of generative artificial intelligence (AI). Leveraging Generative Adversarial Networks (GANs) and Super-Resolution Convolutional Neural Networks (SRCNNs), our approach focuses on real-time upscaling to improve the quality of surveillance video. The proposed system involves preprocessing low-resolution frames and utilizing generative AI models to produce high-resolution images, enhancing crucial visual details for effective crime scene analysis. Extensive experiments on real-world CCTV datasets demonstrate the superiority of our method in terms of accuracy, visual fidelity, and real-time processing compared to conventional upscaling techniques. Furthermore, our research explores the novel use of generative AI for crime scene identification. By automatically analyzing the enhanced footage, the system detects and identifies potential evidence such as objects, vehicles, and individuals. This capability contributes to more efficient criminal investigations, aiding law enforcement agencies in solving cases effectively. While advancing the field of computer vision and AI-assisted law enforcement, our work provides a practical and effective solution for real-time CCTV footage upscaling and crime scene identification. The deployment of this technology has the potential to significantly improve the speed and accuracy of investigations, thereby enhancing public safety and security. However, ethical considerations, including privacy and potential biases, are crucial aspects that require careful attention during implementation.","","979-8-3503-6052-3","10.1109/IATMSI60426.2024.10503047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10503047","GANs;upscaling;surveillance;CCTV;crime;security","Visualization;Technological innovation;Generative AI;Law enforcement;Surveillance;Superresolution;Streaming media","","","","27","IEEE","24 Apr 2024","","","IEEE","IEEE Conferences"
"Transforming Network Intrusion Detection Using Large Language Models","D. Wu; Z. Peng; M. Chen; Y. Liu","North Carolina State University, USA; North Carolina State University, USA; University of Miami, USA; North Carolina State University, USA",2025 IEEE 22nd Consumer Communications & Networking Conference (CCNC),"5 May 2025","2025","","","1","9","Network intrusion detection systems analyze network traffic to monitor and identify potential cyber threats. Recent research has primarily focused on enhancing detection performance using advanced deep-learning techniques, yet there is a notable gap in exploring the interpretability and transparency of these systems. Building upon advancements in large language models (LLMs) that enable reasoning-aware predictions, we propose integrating LLMs with conventional decision trees to jointly enhance interpretability, reasoning, and detection performance. Decision trees discover numerical patterns from input traffic features, which can be formulated as reasoning paths through tree traversal. These paths are then serialized into natural language descriptions and fed into LLMs to make final predictions, accompanied by detailed explanations. Such fusion strategy enables the strengths of both the numerical analysis capabilities of decision trees for pattern recognition and the embedded general logic in LLMs. Experimental results on a real-world network security dataset demonstrate multi-dimensional performance gains, even in scenarios with missing data features.","2331-9860","979-8-3315-0805-0","10.1109/CCNC54725.2025.10976105","National Science Foundation(grant numbers:SaTC-2350075,CNS-2312138,SaTC-2350076,CNS-2332834); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976105","","Large language models;Natural languages;Network intrusion detection;Telecommunication traffic;Network security;Performance gain;Cognition;Robustness;Decision trees;Tree traversal","","","","32","IEEE","5 May 2025","","","IEEE","IEEE Conferences"
"Secure Encoding Scheme for Consensus of Second-order Multi-Agent Systems","B. Zhao; Y. Zhang","School of Automation, Southeast University, Nanjing, China; School of Automation, Southeast University, Nanjing, China",2022 41st Chinese Control Conference (CCC),"11 Oct 2022","2022","","","4700","4705","We consider the problem of consensus of a second-order multi-agent system in the situation where an eavesdropper tends to impact the security of the network. A secure encoding scheme that guarantees both consensus and security of the multi-agent network is designed. In the network, the agents transmit messages to one another through digital channels, and there exists an eavesdropper whose aim is to overhear the state information of the agents in the network. Instead of transmitting the states of themselves, the agents in the network send states of auxiliary systems to defend against the eavesdropper. The concept of topological entropy is utilized to restrict the eigenvalues of the encoding matrix. A sufficient condition is given to guarantee that the network achieves consensus, and the eavesdropper cannot get the accurate estimation of the state of any agent. A simulation example is given to show the performance of the agents and the eavesdropper under the designed encoding scheme.","1934-1768","978-988-75815-3-6","10.23919/CCC55666.2022.9901605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9901605","Multi-agent system;secure encoding scheme;consensus;topological entropy;maximum transmission rate","Sufficient conditions;Delay effects;Packet loss;Encoding;Entropy;Eigenvalues and eigenfunctions;Security","","","","28","","11 Oct 2022","","","IEEE","IEEE Conferences"
"AI-Integrated Traffic Information System: A Synergistic Approach of Physics Informed Neural Network and GPT-4 for Traffic Estimation and Real-Time Assistance","T. Syum Gebre; L. Beni; E. Tsehaye Wasehun; F. Elikem Dorbu","Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA; Geomatics Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA; Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA; Department of Computational Data Science and Engineering, North Carolina A&T State University, Greensboro, NC, USA",IEEE Access,"13 May 2024","2024","12","","65869","65882","Traffic management systems have primarily relied on live traffic sensors for real-time traffic guidance. However, this dependence often results in uneven service delivery due to the limited scope of sensor coverage or potential sensor failures. This research introduces a novel approach to overcome this limitation by synergistically integrating a Physics-Informed Neural Network-based Traffic State Estimator (PINN-TSE) with a powerful Natural Language Processing model, GPT-4. The purpose of this integration is to provide a seamless and personalized user experience, while ensuring accurate traffic density prediction even in areas with limited data availability. The innovative PINN-TSE model was developed and tested, demonstrating a promising level of precision with a Mean Absolute Error of less than four vehicles per mile in traffic density estimation. This performance underlines the model’s ability to provide dependable traffic information, even in regions where conventional traffic sensors may be sparsely distributed or data communication is likely to be interrupted. Furthermore, the incorporation of GPT-4 enhances user interactions by understanding and responding to inquiries in a manner akin to human conversation. This not only provides precise traffic updates but also interprets user intentions for a tailored experience. The results of this research showcase an AI-integrated traffic guidance system that outperforms traditional methods in terms of traffic estimation, personalization, and reliability. While the study primarily focuses on a single road segment, the methodology shows promising potential for expansion to network-level traffic guidance, offering even greater accuracy and usability. This paves the way for a smarter and more efficient approach to traffic management in the future.","2169-3536","","10.1109/ACCESS.2024.3399094","North Carolina Department of Transportation (NC DOT)(grant numbers:TCE2020-03); “NC Transportation Center of Excellence on Connected and Autonomous Vehicle Technology (NC-CAV)”; Microsoft’s Accelerate Foundation Models Academic Research Initiative (AFMR); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10526250","AI-integrated traffic information system;physics informed neural network (PINN);traffic state estimation (TSE);traffic data processing;GPT-4;prompt engineering;natural language processing (NLP);large language models (LLM);foundation models","Sensors;Biological neural networks;Real-time systems;Mathematical models;Predictive models;Information systems;Sensor systems;Traffic control;Traffic congestion;Intelligent transportation systems;Mathematical models;Information systems;Artificial intelligence;Natural language processing","","6","","40","CCBYNCND","8 May 2024","","","IEEE","IEEE Journals"
"Developing an integrated virtual support system based on navigational information in the framework of ensuring the security of moving vehicles","R. V. Senchenko; N. V. Krapukhina","MISiS, National University of Science and Technology, Moscow, Russia; MISiS, National University of Science and Technology, Moscow, Russia",2017 24th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS),"31 Jul 2017","2017","","","1","3","In this research the authors suggest an approach to developing an integrated navigational system based on the multi-level multi-agent simulation model. The model allows to conduct a series of simulation experiments based on the data from various on-board informational subsystems, make a forecast for the development of the navigational framework, and make recommendations on adjusting own movement parameters. Accumulated navigational data on the current road scene are used to identify the elements of the model. This model can be efficiently used in case of failure or temporary loss of connection with any of the navigational subsystems, as the model allows conducting virtual monitoring of the surrounding moving objects. The system provides the modeling of the road scene in real time mode based on the data from the technical vision subsystem, as well as provides opportunity to do virtual positioning on the system's electronic maps. The information from the electronic maps helps to improve the recognition of the road scene structure thanks to additional `a priori' information. The suggested approach can be used for describing other types of moving objects with various structures of the navigation environment.","","978-1-5386-0978-1","10.23919/ICINS.2017.7995597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7995597","Simulation modeling;intellectual multi-agent systems;heterogeneous traffic flows","Roads;Data models;Splines (mathematics);Satellite navigation systems;Real-time systems;Predictive models","","1","","2","","31 Jul 2017","","","IEEE","IEEE Conferences"
"An Integrated Approach to Enhancing Equipment Anomaly Detection Efficiency in Large Language Models Using Multiple Machine Learning Algorithms","Z. Jin; J. Zhao; W. Li; C. Sheng; T. Sun; F. Lv","Key Laboratory of Networked Control Systems, Chinese Academy of Sciences, Shenyang, China; Key Laboratory of Networked Control Systems, Chinese Academy of Sciences, Shenyang, China; Key Laboratory of Networked Control Systems, Chinese Academy of Sciences, Shenyang, China; University of Chinese Academy of Sciences, Beijing, China; National Petroleum Pipeline Network Group Co., Ltd, Beijing, China; National Petroleum Pipeline Network Group Co., Ltd, Beijing, China",2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA),"1 Jul 2025","2025","","","1467","1472","As the application of Industrial Control Systems (ICS) in cyberspace continues to expand, cyberattacks targeting ICS have become increasingly sophisticated and frequent. Such attacks not only threaten the normal operation of systems but also pose significant risks, including substantial economic losses and social impacts. This paper focuses on enhancing the cybersecurity protection capabilities of ICS, particularly improving the detection efficiency in identifying typical threats such as Denial-of-Service (DoS), Man-in-the-Middle (MITM) attacks, and malware infiltration. We introduce large language models as a novel analytical tool to conduct deep analysis of network traffic, aiming to achieve more accurate identification of anomalous behaviors and establish faster response mechanisms. Through a series of experiments using datasets, the effectiveness of this method has been validated. However, our research also uncovers limitations in the existing technological framework, such as the extensive computational resources required for model training and the need to improve real-time processing performance. To address these issues, the paper further explores optimization measures, including refining algorithm structures and reducing feature dimensions, as well as other improvements. Moreover, suggestions for future research directions are proposed, aiming to advance the security and reliability of ICS operations and support continuous socio-economic development.","","979-8-3315-0976-7","10.1109/AIITA65135.2025.11047652","National Key R&D Program of China(grant numbers:2023YFB3107700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047652","Industrial Control Systems (ICS) Security;Anomaly Detection;Machine Learning Algorithm;Large Language Model","Training;Machine learning algorithms;Accuracy;Databases;Large language models;Industrial control;Fingerprint recognition;Water conservation;Feature extraction;Anomaly detection","","","","9","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Unified Data Engineering Frameworks for LLM-Powered Cloud Applications at Scale","B. Krishnan; A. Shirdi; B. Patil; S. R. Kosna",NA; NA; NA; NA,2025 Global Conference in Emerging Technology (GINOTECH),"17 Jul 2025","2025","","","1","6","Large Language Models (LLMs) now dominate the field of intelligent cloud-native applications by providing strong generative functionality with context-aware automated operations. The achievement of large-scale benefits from LLMs depends on implementing an integrated data engineering solution which combines multi-source data pipelines and live data processing while supporting operational governance measures and maximizing scalability and cost effectiveness. This paper develops an integrated data engineering system designed for cloud applications using LLMs which applies modular design patterns with distributed control systems and automated pipeline optimization algorithms. The framework combines data ingestion along with feature transformation and metadata management capabilities and LLM-centric model services that incorporate Mops and Limos practices. Here it is explained both the design structure of the system alongside deployment tactics and measurement standards which support higher operational output and processing capacity. The system provides multiple cloud platform capabilities including AWS Azure and GCP so businesses can deploy LLMs in multi-tenant environments with standardized data management and security features. Experimental assessments prove the framework supplies scalability while minimizing latency and achieving operational stability which prepares it as a base for future-generation enterprise AI applications.","","979-8-3315-0775-6","10.1109/GINOTECH63460.2025.11076719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076719","Large Language Models (LLMs);Unified Data Engineering;Cloud-Native Applications;Limos;Mops;Scalable Data Pipelines;Real-Time Processing;Metadata Management;Model Deployment;Cloud Computing Platforms","Cloud computing;Scalability;Large language models;Pipelines;Stability criteria;Metadata;Data engineering;Real-time systems;Security;Optimization","","","","15","IEEE","17 Jul 2025","","","IEEE","IEEE Conferences"
"SoapFL: A Standard Operating Procedure for LLM-Based Method-Level Fault Localization","Y. Qin; S. Wang; Y. Lou; J. Dong; K. Wang; X. Li; X. Mao","Key Laboratory of Software Engineering for Complex Systems, National University of Defense Technology, Changsha, China; Key Laboratory of Software Engineering for Complex Systems, National University of Defense Technology, Changsha, China; Fudan University, Shanghai, China; Peking University, Beijing, China; Fudan University, Shanghai, China; Key Laboratory of Software Engineering for Complex Systems, National University of Defense Technology, Changsha, China; Key Laboratory of Software Engineering for Complex Systems, National University of Defense Technology, Changsha, China",IEEE Transactions on Software Engineering,"17 Apr 2025","2025","51","4","1173","1187","Fault Localization (FL) is an essential step during the debugging process. With the strong capabilities of code comprehension, the recent Large Language Models (LLMs) have demonstrated promising performance in diagnosing bugs in the code. Nevertheless, due to LLMs’ limited performance in handling long contexts, existing LLM-based fault localization remains on localizing bugs within a small code scope (i.e., a method or a class), which struggles to diagnose bugs for a large code scope (i.e., an entire software system). To address the limitation, this paper presents SoapFL, which builds an LLM-driven standard operating procedure (SOP) to automatically localize buggy methods from the entire software. By simulating the behavior of a human developer, SoapFL models the FL task as a three-step process, which involves comprehension, navigation, and confirmation. Within specific steps, SoapFL provides useful test behavior or coverage information to LLM through program analysis. Particularly, we adopt a series of auxiliary strategies such as Test Behavior Tracking, Document-Guided Search, and Multi-Round Dialogue to overcome the challenges in each step. The evaluation on the widely used Defects4J-V1.2.0 benchmark shows that SoapFL can localize 175 out of 395 bugs within Top-1, which outperforms the other LLM-based approaches and exhibits complementarity to the state-of-the-art learning-based techniques. Additionally, we confirm the indispensability of the components in SoapFL with the ablation study and demonstrate the usability of SoapFL through a user study. Finally, the cost analysis shows that SoapFL spends an average of only 0.081 dollars and 92 seconds for a single bug.","1939-3520","","10.1109/TSE.2025.3543187","National Natural Science Foundation of China(grant numbers:62402506,62474196); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10891926","Large Language Model;Fault Localization","Codes;Location awareness;Computer bugs;Navigation;Standards;Debugging;Benchmark testing;Usability;Large language models;Electronic mail","","1","","54","IEEE","18 Feb 2025","","","IEEE","IEEE Journals"
"The Machine Learning Solutions Architect Handbook: Practical strategies and best practices on the ML lifecycle, system design, MLOps, and generative AI","D. Ping",NA,"The Machine Learning Solutions Architect Handbook: Practical strategies and best practices on the ML lifecycle, system design, MLOps, and generative AI","","2024","","","","","Design, build, and secure scalable machine learning (ML) systems to solve real-world business problems with Python and AWS Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesGo in-depth into the ML lifecycle, from ideation and data management to deployment and scalingApply risk management techniques in the ML lifecycle and design architectural patterns for various ML platforms and solutionsUnderstand the generative AI lifecycle, its core technologies, and implementation risksBook DescriptionDavid Ping, Head of GenAI and ML Solution Architecture for global industries at AWS, provides expert insights and practical examples to help you become a proficient ML solutions architect, linking technical architecture to business-related skills. You'll learn about ML algorithms, cloud infrastructure, system design, MLOps , and how to apply ML to solve real-world business problems. David explains the generative AI project lifecycle and examines Retrieval Augmented Generation (RAG), an effective architecture pattern for generative AI applications. You’ll also learn about open-source technologies, such as Kubernetes/Kubeflow, for building a data science environment and ML pipelines before building an enterprise ML architecture using AWS. As well as ML risk management and the different stages of AI/ML adoption, the biggest new addition to the handbook is the deep exploration of generative AI. By the end of this book , you’ll have gained a comprehensive understanding of AI/ML across all key aspects, including business use cases, data science, real-world solution architecture, risk management, and governance. You’ll possess the skills to design and construct ML solutions that effectively cater to common use cases and follow established ML architecture patterns, enabling you to excel as a true professional in the field.What you will learnApply ML methodologies to solve business problems across industriesDesign a practical enterprise ML platform architectureGain an understanding of AI risk management frameworks and techniquesBuild an end-to-end data management architecture using AWSTrain large-scale ML models and optimize model inference latencyCreate a business application using artificial intelligence services and custom modelsDive into generative AI with use cases, architecture patterns, and RAGWho this book is forThis book is for solutions architects working on ML projects, ML engineers transitioning to ML solution architect roles, and MLOps engineers. Additionally, data scientists and analysts who want to enhance their practical knowledge of ML systems engineering, as well as AI/ML product managers and risk officers who want to gain an understanding of ML solutions and AI risk management, will also find this book useful. A basic knowledge of Python, AWS, linear algebra, probability, and cloud infrastructure is required before you get started with this handbook.","","9781805124825","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10522581.pdf&bkn=10522580&pdfType=book","","","","","","","","8 May 2024","","","Packt Publishing","Packt Publishing eBooks"
"Enhancing Agricultural Advisory Services with Multilingual LLaMA and RAG","G. B. Mohan; C. M. J. Adhitya; A. Mithilesh","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India",2025 International Conference on Next Generation Communication & Information Processing (INCIP),"9 Jun 2025","2025","","","550","556","Agriculture, being a vital component of global food security, necessitates the development of innovative solutions to address the knowledge gap experienced by numerous farmers, particularly in developing countries where access to expert advice is scarce. In these areas, agricultural producers often depend on helplines for essential guidance, but the exorbitant costs and limited accessibility of these services create substantial obstacles. By automating responses to agricultural inquiries, the burden on traditional helpline systems can be alleviated, enabling farmers to access prompt and precise information. The combination of artificial intelligence and agriculture offers a chance to tackle these challenges, with advanced language models, especially transformers, demonstrating significant potential in comprehending intricate agricultural queries and delivering appropriate responses. This paper investigates how large language models (llms) can simplify the process of finding answers for farmers by utilizing their advanced language processing abilities. By analyzing a vast collection of over four million farmer inquiries from tamil nadu, india, encompassing diverse agricultural scenarios, this study showcases the efficacy of llms in bridging information gaps and equipping farmers with immediate access to crucial knowledge.","","979-8-3315-2814-0","10.1109/INCIP64058.2025.11019716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11019716","Agriculture;Artificial Intelligence (AI);Large Language Models (LLMs);Transformers;Farmer Inquiries;Natural Language Processing (NLP);Precision Agriculture;Agricultural Information Systems","Precision agriculture;Large language models;Biological system modeling;Food security;Information processing;Metadata;Transformers;Solids;Natural language processing;Multilingual","","","","17","IEEE","9 Jun 2025","","","IEEE","IEEE Conferences"
"An RE'23 Workshop on Environment-Driven Requirements Engineering (EnviRE'23)","Z. Jin; N. Niu; Y. Yu","Peking University, Beijing, China; University of Cincinnati, Cincinnati, OH, USA; The Open University, Milton Keynes, UK",2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),"28 Sep 2023","2023","","","168","169","We organize a one-day workshop on Environment-Driven Requirements Engineering (EnviRE'23) in conjunction with the 31st IEEE International Requirements Engineering Conference. With the rising influence of AI, IoT, and cyber-physical systems, we realize that the environment, in which the software operates, becomes more open and evolves rapidly with stakeholders' changing needs. EnviRE'23 features one keynote and seven accepted papers. In addition, we organize an interactive session with workshop participants to explore the role of large language models (LLMs), specifically ChatGPT, in requirements elicitation and modeling. Overall, the workshop is aimed at bringing the interested researchers and practitioners together, exchanging ideas and visions, and exploring a set of open problems to pursue in the years to come. Since the first edition of EnviRE in 2021, this is the first time that our workshop is held in person. We are excited to continue our workshop after the pandemic.","2770-6834","979-8-3503-2691-8","10.1109/REW57809.2023.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260948","open environment;modeling;adaptation;learning;requirements elicitation;AI-based systems","Pandemics;Conferences;Cyber-physical systems;Chatbots;Software;Requirements engineering;Stakeholders","","","","10","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"Zero-Shot and Few-Shot Learning for Telugu News Classification: A Large Language Model Approach","K. Boyina; G. M. Reddy; G. Akshita; P. C. Nair","Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","7","Telugu news classification involves categorizing news articles written in the Telugu language into five categories: business, editorial, entertainment, nation, and sport. Zero-shot classification enables categorization into unseen classes without any prior training on those specific classes. Few-shot classification generalizes with minimal training data by leveraging a limited number of labeled examples per class. This work leverages Large Language Models (LLMs) such as mBERT, Indic-BERT, XLM-Roberta, and Flan-T5 Large for zero-shot classification. For few-shot classification, models like Flan-T5 and BART are used in 1 -shot, 3 -shot, and 5 -shot scenarios. Traditional machine learning models including Support Vector Machines (SVM), Naive Bayes, AdaBoost, Random Forest, and Logistic Regression are also explored for comparison. Prompt engineering is employed with various prompts to enhance zero-shot classification performance. Among the LLMs, mBERT achieves the highest F1-score of 0.58 in zero-shot classification. For few-shot classification, Flan-T5 achieved an F1-score of $\mathbf{0. 2 3}$.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724558","Zero-shot;Few-shot;Large Language Models;Prompt Engineering;mBERT;Flan-T5;Text Classification","Support vector machines;Training;Logistic regression;Large language models;Computational modeling;Training data;Prompt engineering;Few shot learning;Random forests;Sports","","5","","32","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Detecting Security Requirements in GitHub Issues -Novel Dataset and SmallBERT-based model","P. Minina; A. Sadovykh; V. Ivanov","SOFTEAM, Paris, France; SOFTEAM, Paris, France; SOFTEAM, Paris, France",2023 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),"25 Mar 2024","2023","","","315","318","Cloud application security initiates with the analysis of security requirements in DevOps. This involves gathering, managing, and tracking requirements within integrated issue-tracking systems found in repositories like GitHub. DevOps offers advantages in cloud app development, such as accelerated deployment, improved collaboration, and enhanced reliability. In DevOps, while many security verification tools are automated, security requirements analysis often relies on manual procedures. User feedback plays a pivotal role in shaping cloud application requirements, and the industry actively seeks automation solutions to expedite development. Prior research has demonstrated the limited performance of conventional NLP models trained on established datasets, such as PROMISE, when employed in the context of GitHub Issues. Recent studies have explored the integration of deep learning, particularly leveraging modern large language models and transfer learning architectures, to address requirements engineering challenges. However, a significant issue persists - the transferability of these models. While these models excel when applied to datasets similar to those they were trained on, their performance often drastically falls when dealing with external domains.In our paper, we introduce an automated method for classifying requirements within issue trackers. This method utilizes a novel dataset comprising 12,000 security and non-security issues collected from open GitHub repositories. We employed a SmallBERT-based model for training and conducted a series of experiments. Our research reaffirms the challenge related to the transferability of NLP models. Simultaneously, our model yields highly promising results when applied to GitHub Issues, even in challenging scenarios involving issues from projects that were not part of the training dataset and structured requirements texts from the PROMISE dataset. In summary, our approach significantly contributes to enhancing DevOps practices within cloud applications by automating security requirements analysis.","2380-8004","979-8-3503-3982-6","10.1109/CloudCom59040.2023.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475803","Security requirements;GitHub Issues;NLP;Classification;Dataset;Machine Learning;Deep learning;BERT","Training;Cloud computing;DevOps;Transfer learning;Natural language processing;Data models;Security","","","","34","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"Implementation of Graphical User Interface using Virtual Assistants based on LLMs","L. Bajčetić; D. Drašković; D. Bojić","School of Electrical Engineering, Innovation Center, University of Belgrade; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia",2023 31st Telecommunications Forum (TELFOR),"1 Jan 2024","2023","","","1","4","This paper describes the process of implementing a graphical user interface (GUI) using two currently popular virtual assistants: ChatGPT 3.5 (OpenAI) and Bard (Google). The implementation process was divided into three phases: in the first phase, we defined the features of our GUI and selected Python Tkinter as the framework for building the application; in the second phase the user interface was implemented, and in the third phase the generated code was refactored and evaluated using the Flake8 linter. We have shown that virtual assistants can be efficient and convenient in the process of implementing a user interface, but they occasionally make unpredictable errors, so it is necessary to critically assess the software code they generate. ChatGPT proved to be easier to use because it less frequently produces unpredictable errors, but linting analysis showed that Bard generates code that adheres better to the PEP8 standard.","","979-8-3503-0313-1","10.1109/TELFOR59449.2023.10372613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10372613","Code generation;GPT-3.5;Bard;Graphical User Interface;Python Tkinter;Flake8.","Codes;Virtual assistants;Chatbots;Software;Skeleton;Telecommunications;Task analysis","","","","6","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Large Model Fine-tuning for Suicide Risk Detection Using Iterative Dual-LLM Few-Shot Learning with Adaptive Prompt Refinement for Dataset Expansion","J. Bi; W. Zhu; J. He; X. Zhang; C. Xian","The Hong Kong Polytechnic University, HKSAR, China; The Hong Kong Polytechnic University, HKSAR, China; The Hong Kong Polytechnic University, HKSAR, China; The Hong Kong Polytechnic University, HKSAR, China; The Hong Kong Polytechnic University, HKSAR, China",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","8520","8526","An approach to detecting suicide risk in social media posts is presented, addressing the challenges of limited and imbalanced datasets. The proposed workflow combines large language models (LLMs), few-shot learning, and expert-supervised prompt optimization. To address class imbalance, a novel Iterative Dual-LLM Few-Shot Learning with Adaptive Prompt Refinement (IDFL-APR) method for dataset expansion is introduced. This method employs two LLMs: one for classifying posts using few-shot learning, and another for dynamically optimizing prompts, with expert oversight to prevent overfitting. The optimized LLM then identifies high-confidence samples from unclassified data, focusing on underrepresented categories. Back-translation techniques are further applied to enhance textual diversity and achieve dataset balance across all categories. Subsequently, the bloomz-3b model is fine-tuned using optimized hyperparameters, implementing an active learning strategy to iteratively augment the training set. The proposed approach significantly enhances suicide risk detection accuracy. The best-performing model achieved a weighted F1-score of 0.7154 on the test set provided by the Suicide Ideation Detection on Social Media Challenge, a track of the IEEE Big Data 2024 BigData Cup. These results demonstrate a robust solution to the inherent challenges in suicide detection tasks.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825974","large language models;imbalanced dataset;prompt engineering;fine-tuning;active learning;social media analysis;suicide detection","Adaptation models;Accuracy;Social networking (online);Prevention and mitigation;Large language models;Active learning;Big Data;Data models;Iterative methods;Few shot learning","","","","29","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Advanced Smart Contract Vulnerability Detection Using Large Language Models","F. Erfan; M. Yahyatabar; M. Bellaiche; T. Halabi","Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Computer Science, Université Laval, Québec, QC, Canada",2024 8th Cyber Security in Networking Conference (CSNet),"28 Jan 2025","2024","","","289","296","With the rapid expansion of using smart contracts, protecting the security of these contracts has become crucial. Existing analysis tools for detecting vulnerabilities in smart contracts are unreliable as they often fall short in accuracy, primarily due to their low recall rates-a significant challenge in this field. In this work, we utilize the open-source SolidiFi benchmark dataset to detect vulnerabilities related to Integer overflow/underflow (IoU), reentrancy (RE), and timestamp dependency (TD). These contracts, verified and available on Etherscan, proved unsuitable for direct application of LLMs due to comments, functions, and variables that might reveal the nature of the vulnerabilities. To address this, we performed several preprocessing steps to prepare the dataset for further research. We utilize a large language model to identify vulnerable code, provide reasoning for the vulnerabilities, explain how an attacker might exploit them, and propose fixed code. We design our prompts using chain-of-thought and expert patterns. Finally, we evaluate the results using various metrics and expert reviewers to assess the correctness of the reasoning, potential security risks, and code fixes. Our experiments demonstrate that our approach outperforms existing tools and methods. Notably, our recall rates are significantly high-93.5%, 95.4%, and 93.8%-addressing the challenge of low recall in detecting IoU, RE, and TD vulnerabilities, respectively.","2768-0029","979-8-3315-3410-3","10.1109/CSNet64211.2024.10851734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851734","smart contract vulnerability;large language model;GPT;security detection;Ethereum;solidity code analysis","Measurement;Analytical models;Codes;Accuracy;Large language models;Smart contracts;Benchmark testing;Cognition;Security;Computer crime","","1","","42","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"Keep it Local: Comparing Domain-Specific LLMs in Native and Machine Translated Text using Parallel Corpora on Political Conflict","J. Osorio; S. Alsarra; A. Converse; A. Alshammari; D. Heintze; L. Khan; N. Alatrush; P. T. Brandt; V. D’Orazio; N. Zawad; M. Billah","School of Government and Public Policy, University of Arizona, Tucson, United States; Department of Software Engineering, King Saud University, Riyadh, Saudi Arabia; Department of Linguistics, University of Arizona, Tucson, United States; Department of Computer Science, University of Texas – Dallas, Dallas, United States; School of Economic, Political and Policy Sciences, University of Texas – Dallas, Dallas, United States; Department of Computer Science, University of Texas – Dallas, Dallas, United States; Department of Computer Science, University of Texas – Dallas, Dallas, United States; School of Economic, Political and Policy Sciences, University of Texas – Dallas, Dallas, United States; Department of Political Science, West Virginia University, Morgantown, United States; Department of Computer Science, University of Texas – Dallas, Dallas, United States; Department of Computer Science, University of Texas – Dallas, Dallas, United States",2024 2nd International Conference on Foundation and Large Language Models (FLLM),"28 Jan 2025","2024","","","542","552","The dynamics of political conflict and cooperation require powerful computerized tools capable of effectively tracking security threats and cooperation around the world. This study compares the performance of domain-specific Large Language Models (LLMs) against generically-trained LLMs in binary and multi-class classification using native text in English, Spanish, and Arabic, and their corresponding machine translations. This endeavor yields four key contributions. 1) We present and make available a novel database of annotations using a multi-lingual parallel corpus from the United Nations. 2) Using various metrics, we assess the quality of different machine translation tools. 3) Our results indicate that the ConfliBERT family of LLMs, a set of domain-specific models tailored for political conflict, outperform generically-trained LLMs in English, Spanish, and Arabic in both binary and multi-class tasks. 4) We also disentangle the heterogeneous effects of machine translation on LLM performance in different languages. Overall, results reveal the comparative advantage of native-language domain-specific LLMs specialized on political conflict to understand the dynamics of violence and cooperation worldwide using native text. Our multi-lingual ConfliBERT LLMs provide critical cyber-infrastructure enabling scholars and government agencies use their local languages and information to foster safer, more stable political environments.","","979-8-3503-5479-9","10.1109/FLLM63129.2024.10852489","Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852489","Multilingual LLMs;machine translation;political conflict;United Nations","Measurement;Translation;Databases;Annotations;Computational modeling;Large language models;Government;Multilingual;Machine translation;Security","","","","72","IEEE","28 Jan 2025","","","IEEE","IEEE Conferences"
"Generative Artificial Intelligence: Principles, Potentials and Challenges","S. K. Routray; M. K. Jha; K. P. Sharmila; A. Javali; M. Pappa; M. Singh","Department of Computer Science and Engineering, CMR University, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India",2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),"28 Nov 2024","2024","","","211","216","In recent years, we have witnessed the raise of several generative artificial intelligence (AI) products and services which have strong disruptive capabilities. Majority of these AI-based products and services are also very popular since their public availability. These generative AI products and services have a lot of potentials to do the common office works, writing codes, doing accounting tasks, predicting common patterns, generating creative contents, marketing products and services, increasing efficiencies in the systems, translating to different languages, designing products, and many such things. These effects of generative AI are phenomenal and it is going to start a large scale automation in the product design and service sectors. In addition to the benefits, several challenges are associated with generative AI. Starting from the bias to security risks to fake content creation, there are many challenges with these products and services. In this paper, we go through the basic principles of generative AI and then study its present and future prospects. We analyze its perilous effects and the common challenges with a few examples. Overall, generative AI can be beneficial tool if it is used positively under appropriate regulatory systems.","","979-8-3503-6841-3","10.1109/ICSSAS64001.2024.10760992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760992","Artificial intelligence;generative AI;prospects of generative AI;challenges of generative AI;applications of generative AI","Industries;Ethics;Codes;Generative AI;Navigation;Regulation;Product design;Security;Fake news;Standards","","1","","20","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Enhancing AI Systems with Agentic Workflows Patterns in Large Language Model","A. Singh; A. Ehtesham; S. Kumar; T. T. Khoei","Department of Computer Science, Cleveland State University; The Davey Tree Expert Company; The Mathworks Inc; Khoury College of Computer Science, Roux Institute at Northeastern University",2024 IEEE World AI IoT Congress (AIIoT),"10 Jul 2024","2024","","","527","532","This paper explores the significant shift towards agentic workflows in the application of Large Language Models (LLMs), moving away from traditional, linear interactions between users and AI. Through a case study analysis, we highlight the effectiveness of agentic workflows, which facilitate a more dynamic and iterative engagement, in improving outcomes in tasks such as question answering, code generation or stock analysis. Central to the agentic workflow are four foundational design patterns: reflection, planning, multi-agent collaboration, and tool utilization. These components are crucial for boosting LLM productivity and enhancing performance. The study demonstrates how agentic workflows, by promoting an iterative and reflective process, can serve as a crucial step towards achieving Artificial General Intelligence (AGI).","","979-8-3503-8780-3","10.1109/AIIoT61789.2024.10578990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578990","Agentic Workflows;Agentic Patterns;Large Language Models;LLM Agent;AI Planning;Reflective AI;Multi-agent;Tools;Agent Collaboration","Productivity;Large language models;Artificial general intelligence;Collaboration;Reflection;Question answering (information retrieval);Planning","","17","","14","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"Generative AI for Cyber Threat Simulation and Defense","R. Vadisetty; A. Polamarasetti","Electrical Engineering, Wayne State University, Detroit, USA; ComputerScience, Anandra University, Visakhapatnam, India","2024 12th International Conference on Control, Mechatronics and Automation (ICCMA)","20 Jan 2025","2024","","","272","279","Generative AI enhances cybersecurity by simulating various cyber threats and strengthening possible defense mechanisms. The paper proposes using generative adversarial networks and variational auto-encoders for cyber threat simulation and defense. The main contributions include new methodologies to simulate realistic cyber-attacks and develop robust defense strategies. Experimental results show that generative AI can hugely improve threat detection and response time compared to traditional methods. The results underline the vast potential for generative AI to transform cybersecurity practice and lay the foundations for a much more resilient and adaptive security framework.","2837-5149","979-8-3315-1751-9","10.1109/ICCMA63715.2024.10843938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843938","Generative AI;Cybersecurity;Cyber Threat Simulation;Defense Mechanisms;Generative Adversarial Networks;Variational Autoencoders;Machine Learning;Intrusion Detection Systems;Anomaly Detection;Security Frameworks","Ethics;Silver;Generative AI;Weapons;Roads;Transforms;Threat assessment;Regulation;Time factors;Computer security","","1","","28","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Designing and Implementing LLM Guardrails Components in Production Environments","M. Devino; E. Ju; P. M. Caldeira Junior","watsonx Platform Engineering, IBM Research, Rio de Janeiro, Brazil; watsonx Platform Engineering, IBM Research, Denver, United States; watsonx Platform Engineering, IBM Research, São Paulo, Brazil",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","12","17","With advancements in generative Artificial Intelligence (AI), there has been an increasing need for tools that rely on Large Language Model (LLM)s. As these models may produce undesired answers, there is a need to prevent such events, especially in enterprise environments. Even if models are trained on safe data, user inputs and even model behavior can be unpredictable, leading to problems such as leakage of confidential data that could result in revenue loss. In this paper, we describe our experiences on developing tools for “guardrailing” LLMs. We describe how we started with a quick monolith implementation, and later transitioned to a microservices architecture. As results, we share our lessons learned throughout the process, and how the re-architecture to microservices led to runtime performance gains, easier maintenance and extensibility, and also allowed us to open source the main component of the solution, so anyone can contribute to and use it.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029999","microservices;software architecture;generative AI;large language models;machine learning;guardrails;sentence tokenizers","Runtime;Software architecture;Generative AI;Large language models;Microservice architectures;Production;Computer architecture;Performance gain;Data models;Servers","","","","26","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Innovating Robotic Garment Handling Through the Integration of Large Language Models and Behavior Trees","S. S. Ghidary; D. Chen; F. Mohammadi; A. E. Petrilli Barceló; J. V. Salazar Luces; Y. Hirata","Department of Robotics, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Tohoku University, Sendai, Miyagi, Japan; Department of Robotics, Tohoku University, Sendai, Miyagi, Japan",2024 IEEE International Conference on Robotics and Biomimetics (ROBIO),"7 Mar 2025","2024","","","595","600","Natural language offers a highly flexible and intuitive way for humans to communicate tasks to robots. This paper explores the potential of Large Language Models (LLMs) agents in enhancing industrial robotics, with a particular focus on textile manufacturing and garment handling tasks. The primary goal is to reduce the level of expertise required to develop robotic applications. Our framework comprises three key components: an LLM for code generation and common-sense reasoning, a vision-language model for open-vocabulary visual recognition, and a specialized 3D object recognition model. We introduce a novel four-stage prompt engineering process that customizes prompts to meet the specific needs of behavior tree generation. This process facilitates the development of programs for complex tasks, including safety management and parallel processing in a multi-arm robotic workspace, ensuring the robot executes actions safely and reliably. A RealSense RGB-D camera provides depth information, combined with foreground-background segmentation and curvature analysis, allows for precise grasping and manipulation. Both real-world tests and simulated trials in a Gazebo environment underscore the potential of this approach, demonstrating the LLM's capability to enhance safe robotic operations in industrial settings.","2994-3574","979-8-3315-0964-4","10.1109/ROBIO64047.2024.10907326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10907326","","Solid modeling;Visualization;Three-dimensional displays;Service robots;Large language models;Clothing;Robot vision systems;Safety management;Robots;Textiles","","","","16","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Next Steps in LLM-Supported Java Verification","S. Teuber; B. Beckert","Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",2025 IEEE/ACM 1st International Workshop on Neuro-Symbolic Software Engineering (NSE),"19 Jun 2025","2025","","","1","4","Recent work has shown that Large Language Models (LLMs) are not only a suitable tool for code generation but also capable of generating annotation-based code specifications. Scaling these methodologies may allow us to deduce provably correctness guarantees for large-scale software systems. In comparison to other LLM tasks, the application field of deductive verification has the notable advantage of providing a rigorous toolset to check LLM-generated solutions. This short paper provides early results on how this rigorous toolset can be used to reliably elicit correct specification annotations from an unreliable LLM oracle.","","979-8-3315-1460-0","10.1109/NSE66660.2025.00007","Helmholtz Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039275","Large Language Models;Program Verification;Formal Specification;Java;JML","Java;Codes;Annotations;Large language models;Conferences;Software systems;Software reliability;Formal specifications;Software engineering","","","","19","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code Generation","J. Li; S. Hyun; M. A. Babar","University of Adelaide, Adelaide, SA, Australia; University of Adelaide, Adelaide, SA, Australia; University of Adelaide, Adelaide, SA, Australia",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","190","200","Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation. However, the quality of the generated code is heavily dependent on the structure and composition of the prompts used. Crafting high-quality prompts is a challenging task that requires significant knowledge and skills of prompt engineering. To advance the automation support for the prompt engineering for LLM-based code generation, we propose a novel solution Diffusion-Driven Prompt Tuning (DDPT) that learns how to generate optimal prompt embedding from Gaussian Noise to automate the prompt engineering for code generation. We evaluate the feasibility of diffusion-based optimization and abstract the optimal prompt embedding as a directional vector toward the optimal embedding. We use the code generation loss given by the LLMs to help the diffusion model capture the distribution of optimal prompt embedding during training. The trained diffusion model can build a path from the noise distribution to the optimal distribution at the sampling phrase, the evaluation result demonstrates that DDPT helps improve the prompt optimization for code generation.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030001","Large Language Model;Prompt Optimisation;Diffusion;Soft Prompt","Training;Visualization;Codes;Large language models;Gaussian noise;Diffusion models;Vectors;Prompt engineering;Optimization;Tuning","","","","43","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Distributed event-triggered cloud predictive control for consensus of multi-agent systems under DoS attacks","Y. Deng; X. Yin; S. Hu","Department of Mathematics, School of Science, Nanchang University, Nanchang, P.R. China; Department of Mathematics, School of Science, Nanchang University, Nanchang, P.R. China; Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China",2020 Chinese Automation Congress (CAC),"29 Jan 2021","2020","","","46","51","In this paper, a novel distributed event-triggered cloud predictive controller is designed for networked multi-agent control systems subject to periodic DoS attacks. In order to solve the collaboration problem of multi-agent system, a distributed event-triggered control strategy is proposed under the constraint that all agents can only communicate with one cloud server intermittently and reduce the communication burden. Meanwhile, we propose a new cloud predictive control scheme to achieve consensus and compensate for periodic DoS attacks actively. By using Lyapunov function method and system analysis method, the security of multi-agent system under attack is considered and give sufficient conditions to realize the consensus. Effectiveness of the proposed theoretical algorithm is demonstrated by simulation result.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9327449","National Natural Science Foundation of China; Natural Science Foundation of Jiangxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9327449","distributed event-triggered;networked multi-agent control systems;DoS attacks;cloud predictive control","Sufficient conditions;Simulation;Control systems;Servers;Security;Predictive control;Multi-agent systems","","","","15","IEEE","29 Jan 2021","","","IEEE","IEEE Conferences"
"Comparative Analysis of ChatGPT, DeepSeek, and Gemini for Automated Code Generation","K. Shahzad; S. Iqbal","School of Electrical Engineering & Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering & Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan",2025 18th International Conference on Engineering of Modern Electric Systems (EMES),"27 Jun 2025","2025","","","1","4","Code generation using artificial intelligence (AI) has revolutionized software development, providing automated coding solutions. This study conducts a systematic comparative analysis of three leading large language models (LLMs) such as ChatGPT (O1), DeepSeek (R1) and Gemini (2.0 Flash thinking), for Python code generation, evaluating their performance in correctness, code quality, and computational efficiency. Using a curated dataset of Codeforces programming problems that span various difficulty levels $(\mathbf{8 0 0 - 2 0 0 0}$ complexity), the research employs a rigorous evaluation framework that integrates online judge validation, static code analysis, and runtime profiling. The experimental results reveal that DeepSeek achieves comparatively higher correctness by consistently producing accepted solutions in fewer attempts, although its reasoning time increases with problem complexity. Gemini, on the other hand, is remarkably fast, delivering results in a fraction of the time, but its correctness deteriorates on more complex tasks. ChatGPT offers balanced performance with intermediate correctness and efficiency; however, it sometimes exhibits lower code quality. Overall, our findings underscore the inherent trade-offs between efficiency, accuracy, and quality in AI-generated code. The study provides actionable insights for developers, emphasizing the need to align model selection with project requirements, and contributes a replicable framework for future evaluations of AI code generation tools.","2836-9866","979-8-3315-2577-4","10.1109/EMES65692.2025.11045587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11045587","Software Development;Artificial Intelligence;ChatGPT;DeepSeek;Gemini;Large Language Model","Hands;Codes;Systematics;Runtime;Large language models;Chatbots;Cognition;Complexity theory;Software development management;Python","","","","12","IEEE","27 Jun 2025","","","IEEE","IEEE Conferences"
"Cypress Copilot: Development of an AI Assistant for Boosting Productivity and Transforming Web Application Testing","S. B. Nettur; S. Karpurapu; U. Nettur; L. S. Gajja","Independent Researcher, Virginia Beach, VA, USA; Independent Researcher, Virginia Beach, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, BML Munjal University, Gurugram, Haryana, India",IEEE Access,"8 Jan 2025","2025","13","","3215","3229","In today’s fast-paced software development environment, Agile methodologies demand rapid delivery and continuous improvement, making automated testing essential for maintaining quality and accelerating feedback loops. Our study addresses the challenges of developing and maintaining automation code for web-based application testing. In this paper, we propose a novel approach that leverages large language models (LLMs) and a novel prompt technique, few-shot chain, to automate code generation for web application testing. We chose the Behavior-Driven Development (BDD) methodology owing to its advantages and selected the Cypress tool for automating web application testing, as it is one of the most popular and rapidly growing frameworks in this domain. We comprehensively evaluated various OpenAI models, including GPT-4-Turbo, GPT-4o, and GitHub Copilot, using zero-shot and few-shot chain prompt techniques. Furthermore, we extensively validated with a vast set of test cases to identify the optimal approach. Our results indicate that the Cypress automation code generated by GPT-4o using a few-shot chained prompt approach excels in generating complete code for each test case, with fewer empty methods and improved syntactical accuracy and maintainability. Based on these findings, we developed a novel open-source Visual Studio Code (IDE) extension, “Cypress Copilot” utilizing GPT-4o and a few-shot chain prompt technique, which has shown promising results. Finally, we validate the Cypress Copilot tool by generating automation code for end-to-end web tests, demonstrating its effectiveness in testing various web applications and its ability to streamline development processes. More importantly, we are releasing this tool to the open-source community, as it has the potential to be a promising partner in enhancing productivity in web application automation testing.","2169-3536","","10.1109/ACCESS.2024.3521407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812696","Agile software development;behavior driven development;large language model;machine learning;prompt engineering;software testing;cypress;selenium;web application;AI assistant tools;GitHub Copilot;code generation;test case generation;test automation;zero-shot;few-shot;OpenAI;GPT-3;GPT3.5;GPT-4;GPT-4o","Automation;Codes;Testing;Graphical user interfaces;Stakeholders;Productivity;Java;Business;Accuracy;Visualization","","6","","41","CCBYNCND","23 Dec 2024","","","IEEE","IEEE Journals"
"Demystifying Faulty Code: Step-by-Step Reasoning for Explainable Fault Localization","R. Widyasari; J. W. Ang; T. G. Nguyen; N. Sharma; D. Lo",Singapore Management University; Singapore Management University; Singapore Management University; Singapore Management University; Singapore Management University,"2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","16 Jul 2024","2024","","","568","579","Fault localization is a critical process that involves identifying specific program elements responsible for program failures. Manually pinpointing these elements, such as classes, methods, or statements, which are associated with a fault is laborious and time-consuming. To overcome this challenge, various fault localization tools have been developed. These tools typically generate a ranked list of suspicious program elements. However, this information alone is insufficient. A prior study emphasized that automated fault localization should offer a rationale. In this study, we investigate the step-by-step reasoning for explainable fault localization. We explore the potential of Large Language Models (LLM) in assisting developers in reasoning about code. We proposed FuseFL that utilizes several combinations of information to enhance the LLM results which are spectrum-based fault localization results, test case execution outcomes, and code description (i.e., explanation of what the given code is intended to do). We conducted our investigation using faulty code from Refactory dataset. First, we evaluate the performance of the automated fault localization. Our results demonstrate a 32.3 % increase in the number of successfully localized faults at Top-1 compared to the baseline. To evaluate the explanations generated by FuseFL, we create a dataset of human explanations that provide step-by-step reasoning as to why specific lines of code are considered faulty. This dataset consists of 324 faulty code files, along with explanations for 600 faulty lines. Furthermore, we also conducted human studies to evaluate the explanations. We found that for 22 out of the 30 randomly sampled cases, FuseFL generated correct explanations.","2640-7574","979-8-3503-3066-3","10.1109/SANER60148.2024.00064","National Research Foundation(grant numbers:NRF-NRF108-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589899","fault localization;explanation;dataset;LLM;ChatGPT","Location awareness;Fault diagnosis;Codes;Large language models;Cognition;Software","","5","","64","IEEE","16 Jul 2024","","","IEEE","IEEE Conferences"
"Optimizing Wellness: A Comprehensive Examination of a Conversational AI-Driven Healthcare BOT for Personalized Fitness Guidance","S. N. Thakur; A. Sinha; M. K. Singh; M. K. Bagaria; R. Grover; K. Shrivastava","Graphic Era Hill University, India; IGNOU, School of Computing and Information Science, New Delhi, India; Pal College of Technology and Management, Haldwani, India; Guru Ghasidas Vishwavidyalaya, Bilaspur; Founder & Head Coach of Adapt Fitness Club, Gurugram, Haryana, India; Department of Computer Engineering and Applications, GLA University, Mathura, India",2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI),"15 Apr 2024","2023","1","","1","8","A specialized fitness advice bot is the subject of this investigation, which looks at the application of conversational artificial intelligence (AI) in healthcare. By utilizing machine learning and natural language processing, the bot offers customized exercise recommendations. Studying the system's capacity to adjust to different users' health profiles and preferences, it looks at its technological architecture, user experience, and personalization features. Robust user data protection is ensured by taking into account privacy and security concerns, including compliance with laws such as HIPAA. A thorough overview of implementing a healthcare bot for fitness advice is provided by the report, which also shows significant obstacles including scalability and algorithmic biases. This study provides insightful information to the rapidly changing field of artificial intelligence in healthcare, assisting educates policymakers and directing developments in this exciting area where technology and wellbeing meet.","","979-8-3503-3091-5","10.1109/ICAIIHI57871.2023.10489319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489319","Conversational AI;Healthcare Bot;Fitness Advisory;Natural Language Processing;Machine Learning;Personalization;User Experience;Privacy;Security;HIPAA Compliance;User Engagement;Technology Integration","Technological innovation;Scalability;Medical services;Reinforcement learning;Organizations;Oral communication;Chatbots;User experience;Security;Wearable sensors","","1","","10","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"The Dark Side of AI: Large Language Models as Tools for Cyber Attacks on Vehicle Systems","Y. Usman; P. K. Gyawali; S. Gyawali; R. Chataut","School of Computing and Engineering, Quinnipiac University, Hamden, CT, USA; LANE Department of Computer Science, West Virginia University, Morgantown, WV, USA; Department of Technology Systems, East Carolina University, Greenville, NC, USA; Department of Computer Science, Texas Christian University, Fort Worth, TX, USA","2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","20 Nov 2024","2024","","","169","175","The rapid evolution of autonomous vehicles (AVs) presents significant opportunities for enhancing transportation safety and efficiency. However, with increasing connectivity and complex electronic systems, AVs also become vulnerable to cyberattacks. This paper investigates cybersecurity challenges in the realm of AVs, highlighting the role of artificial intelligence (AI), specifically Large Language Models (LLMs), in exploiting vulnerabilities. We analyze various attack vectors, including Controller Area Network (CAN) manipulation, Bluetooth vulnerabilities, and Key Fob hacking, emphasizing the need for proactive cybersecurity measures. Recent incidents, such as the remote compromise of various vehicle models, underscore the urgent need for robust security solutions in the automotive industry. By leveraging LLMs, attackers can craft sophisticated cyber threats targeting AVs, posing risks to both safety and privacy. We introduce HackerGPT, a customized LLM tailored for cyber attack generation, and demonstrate attacks on virtual CAN networks, Bluetooth systems, and Key Fobs. At the same time, our experiments reveal successful compromises in certain vehicle models; limitations exist, particularly in vehicles with advanced encryption and robust signal transmission protocols. However, this research underscores the broader need for increased awareness and proactive security measures in the automotive sector. Our findings aim to contribute significantly to the ongoing discourse on automotive cybersecurity, offering actionable insights for manufacturers and cybersecurity professionals to safeguard the future of mobility.","","979-8-3315-4090-6","10.1109/UEMCON62879.2024.10754676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754676","Artificial Intelligence;Large Language Model;Cyberattacks;Cybersecurity;Autonomous Vehicle","Training;Industries;Ethics;Bluetooth;Protocols;Large language models;Vectors;Safety;Cyberattack;Automotive engineering","","","","18","IEEE","20 Nov 2024","","","IEEE","IEEE Conferences"
"Visiorag: A Multimodal Framework for Enhancing Recommendation System Using Vision Transformers and Rag","A. Balachandran; M. Masum","Department of Applied Data Science, San Jose State University, San Jose, CA; Department of Applied Data Science, San Jose State University, San Jose, CA",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","114","119","In the rapidly advancing field of visual search technology, traditional methods relying solely on visual features often struggle with accuracy and relevance, especially in ecommerce, where precise recommendations are crucial. Issues like keyword stuffing in product descriptions further compound these challenges. To overcome these limitations, we present VisioRAG, a multimodal recommendation framework that integrates visual and textual features. By utilizing Vision Transformers (ViT) for input query categorization and Retrieval-Augmented Generation (RAG) with large language models (LLMs) for image captioning and query enhancement, VisioRAG converts image queries into contextual word embeddings. These embeddings, along with the original image queries, form the multimodal input to the framework. The system leverages Florence-2-large for image captioning, BERT for contextual embedding generation, and Google's Gemini for caption enhancement via prompt engineering. An early fusion technique effectively merges visual and textual vectors. Recommendations are made using cosine similarity, ensuring product matches that align with user intent and preferences. Our evaluation using Amazon product data across five categories shows that the fusion approach with RAG achieves the highest precision ($0.9333 \pm 0.1294$), surpassing other methods. This demonstrates VisioRAG's potential to improve product recommendations and customer satisfaction by leveraging generative AI for human-like text generation.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050521","E-commerce Recommendation;Large language Models (LLMs);Retrieval Augmented Generation;Vision Transformers;Image Captioning","Visualization;Computer vision;Large language models;Retrieval augmented generation;Transformers;Vectors;User experience;Electronic commerce;Prompt engineering;Recommender systems","","","","38","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Understanding Users' Security and Privacy Concerns and Attitudes Towards Conversational AI Platforms","M. Ali; A. Arunasalam; H. Farrukh","University of California, Irvine; Purdue University; University of California, Irvine",2025 IEEE Symposium on Security and Privacy (SP),"16 Jun 2025","2025","","","298","316","The widespread adoption of conversational AI platforms has introduced new security and privacy risks. While these risks and their mitigation strategies have been extensively researched from a technical perspective, users' perceptions of these platforms' security and privacy remain largely unexplored. In this paper, we conduct a large-scale analysis of over 2.5M user posts from the r/ChatGPT Reddit community to understand users' security and privacy concerns and attitudes toward conversational AI platforms. Our qualitative analysis reveals that users are concerned about each stage of the data lifecycle (i.e., collection, usage, and retention). They seek mitigations for security vulnerabilities, compliance with privacy regulations, and greater transparency and control in data handling. We also find that users exhibit varied behaviors and preferences when interacting with these platforms. Some users proactively safeguard their data and adjust privacy settings, while others prioritize convenience over privacy risks, dismissing privacy concerns in favor of benefits, or feel resigned to inevitable data sharing. Through qualitative content and regression analysis, we discover that users' concerns evolve over time with the evolving AI landscape and are influenced by technological developments and major events. Based on our findings, we provide recommendations for users, platforms, enterprises, and policymakers to enhance transparency, improve data controls, and increase user trust and adoption.","2375-1207","979-8-3315-2236-0","10.1109/SP61157.2025.00241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023504","","Privacy;Data privacy;Conversational artificial intelligence;Social networking (online);Prevention and mitigation;Regulation;Regression analysis;Security;Time factors;Stakeholders","","","","111","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Conversational Agents for Dementia using Large Language Models","J. Favela; D. Cruz-Sandoval; M. O. Parra","Computer Science Department, CICESE, Ensenada, MEXICO; Healthcare Robotics Lab, University of California San Diego, San Diego, USA; Computer Science Department, CICESE, Ensenada, MEXICO",2023 Mexican International Conference on Computer Science (ENC),"30 Apr 2024","2023","","","1","7","Conversational robots are a type of social robot that emphasize verbal communication. One of their main application areas centers on assisting people with dementia and their caregivers, particularly in dealing with problematic behaviors. Recent advances in Large Language Models (LLMs) have increased their potential in developing conversational assistive agents. In this paper, we explore the use of a LLM (ChatGPT) to conduct cognitive stimulation therapies with people with dementia. We compare a conversational robot which includes personalized hand-coded conversational strategies with one using an LLM and prompt engineering. We conclude that the use of LLMs produces engaging conversations and has the potential to facilitate caregiver customization of social robots for dementia.","2332-5712","979-8-3503-9315-6","10.1109/ENC60556.2023.10508610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10508610","Social Robots;Lar ge Language Models;Dementia;ChatGPT;Conversational agents","Computer science;Computational modeling;Social robots;Medical treatment;Oral communication;Chatbots;Robustness","","2","","22","IEEE","30 Apr 2024","","","IEEE","IEEE Conferences"
"Using Large Language Models to Automate Flight Planning Under Wind Hazards","A. Tabrizian; P. Gupta; A. Taye; J. Jones; E. Thompson; S. Chen; T. Bonin; D. Eberle; P. Wei","George Washington University, Washington, DC, USA; Duke University, Durham, NC, USA; George Washington University, Washington, DC, USA; MIT Lincoln Laboratory, Lexington, MA, USA; George Washington University, Washington, DC, USA; George Washington University, Washington, DC, USA; MIT Lincoln Laboratory, Lexington, MA, USA; MIT Lincoln Laboratory, Lexington, MA, USA; George Washington University, Washington, DC, USA",2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC),"15 Nov 2024","2024","","","1","8","We introduce a novel framework to automate flight planning processes using large language models (LLMs) to identify flight operator's preferences. Our framework integrates the recent advancements in LLM and prompt engineering, low-altitude wind hazard forecasts, flight mission energy estimation, and pre-departure strategic deconfliction. First, our approach begins with the forecast of wind hazard polygons to ensure safety in flight planning. Second, we generate a diverse set of candidate flight plans to avoid these wind hazard polygons. The flight plan features include total flight distance, cruising altitude, flight mission energy consumption, and number of waypoints. Third, human flight operator specifies their preferences through natural language prompts or plain words, which are fed to the LLM to extract and prioritize these features. Our framework then evaluates and scores each flight plan based on extracted user-defined preferences, recommending the flight plan that best matches the flight operator's needs. For the purpose of demonstration, we focus on a flight planning use case for an electric vehicle take-off and landing (eVTOL) aircraft in an advanced air mobility (AAM) mission in Dallas-Fort Worth area. Our simulation experiments show the effectiveness of this approach in generating personalized, safe, and efficient flight plans. To our best knowledge, this work is among the first attempts using LLMs to enable a human-centric flight planning automation for AAM operations.","2155-7209","979-8-3503-4961-0","10.1109/DASC62030.2024.10749512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749512","Flight planning;Large Language Model;Wind hazard forecast;Advanced air mobility","Wind energy generation;Energy consumption;Automation;Large language models;Estimation;Feature extraction;Hazards;Planning;Active appearance model;Wind forecasting","","","","30","IEEE","15 Nov 2024","","","IEEE","IEEE Conferences"
"SWDG: Service Workflow Deep Generation Using Large Language Model and Graph Neural Network","R. Zhu; H. Xiao; Q. Hu; W. Li; J. Wang; T. Bait","The Key Laboratory in Software Engineering, Yunnan Province, Kunming, China; School of Software, Yunnan University, Yunnan Province, Kunming, China; School of Software, Yunnan University, Yunnan Province, Kunming, China; School of Software, Yunnan University, Yunnan Province, Kunming, China; School of Software, Yunnan University, Yunnan Province, Kunming, China; School of Software, Yunnan University, Yunnan Province, Kunming, China",2024 IEEE International Conference on Software Services Engineering (SSE),"18 Sep 2024","2024","","","153","159","The increasing production of service description documents by enterprises and service providers has prompted the need for automated service workflow generation. This paper explores a method that combines large language models (LLMs) and graph neural network (GNNs) to address this challenge. Automatically extracting service workflows from documents also provides a convenient and efficient solution for situations where process mining algorithms cannot be utilized due to the absence of logs. The proposed method begins by employing LLMs to extract activity nodes and conditional nodes from service workflow description documents. These nodes are then organized into an initial graph using chain connections and auxiliary connections provided by the LLMs. Subsequently, an inductive GNN is utilized to analyze node embeddings within the service workflow, enabling the learning of semantic representations and connection rules. This facilitates the discovery of potential connections among nodes, leading to the generation of efficient service workflows. The experimental results demonstrate that the proposed method achieves an F1-Score of 0.818 in predicting node relationships. Furthermore, ablation experiments have been conducted to validate the effectiveness of incorporating both LLMs and GNNs.","","979-8-3503-6851-2","10.1109/SSE62657.2024.00032","National Natural Science Foundation of China(grant numbers:62362067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664324","service workflow;software services engineering;large language models;graph neural networks;prompt engineering","Process mining;Accuracy;Annotations;Large language models;Semantics;Production;Graph neural networks","","1","","15","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"An Architecture and Protocol for Decentralized Retrieval Augmented Generation","T. Hecking; T. Sommer; M. Felderer","German Aerospace Center (DLR), Institute of Software Technology, Cologne, Germany; German Aerospace Center (DLR), Institute of Software Technology, Cologne, Germany; German Aerospace Center (DLR), Institute of Software Technology, University of Cologne, Cologne, Germany",2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C),"30 May 2025","2025","","","31","35","Retrieval-augmented generation (RAG) has become a widely adopted approach for the integration of knowledge bases and large language models (LLMs). This paper proposes a decentralized software architecture for RAG, where retrieval, augmentation, and generation components are operated independently by distributed entities. This approach addresses challenges like efficient usage of resources when building LLM-based software systems as well as data protection issues in centralized systems. By allowing data providers to implement their own retrieval mechanisms, they fully retain control over data access and the flexibility to use their own data infrastructure. An interaction platform implements communication between client applications, data providers, and model providers. To standardize this process, the paper introduces introduces an architecture and protocol called External Retrieval Interface (ERI), which ensures compatibility of services, enforces data restrictions, and simplifies the development of decentralized RAG systems.","2768-4288","979-8-3315-3336-6","10.1109/ICSA-C65153.2025.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014986","Large Language Models;Retrieval Augmented Generation;Distributed Systems","Protocols;Software architecture;Large language models;Retrieval augmented generation;Knowledge based systems;Buildings;Data protection;Computer architecture;Software systems;Data models","","","","17","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"An Adaptive Framework Embedded With LLM for Knowledge Graph Construction","Q. Wang; C. Li; Y. Liu; Q. Zhu; J. Song; T. Shen","Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China",IEEE Transactions on Multimedia,"28 May 2025","2025","27","","2912","2923","Knowledge graph construction is aimed at storing and representing the knowledge of the objective world in a structured form. Existing methods for automatic construction of knowledge graphs have problems such as difficulty in understanding potential semantics and low precision. The emergence of Large Language Models (LLMs) provides an effective way for automatic knowledge graph construction. However, using LLMs as automatic knowledge graph construction engines relies on the embedding of schema layers, which brings challenges to the input length of LLMs. In this paper, we present a framework for Adaptive Construction of Knowledge Graph by leveraging the exceptional generation capabilities of LLMs and the latent relational semantic information of triples, named ACKG-LLM. Our proposed framework divides the knowledge graph construction task into three subtasks within a unified pipeline: triple extraction of open information, additional relational semantic information embedding and knowledge graph normalization based on schema-level embedding. The framework can construct knowledge graphs in different domains, making up for the defects of existing frameworks that need to retrain and fine-tune the internal model. Extensive experiments demonstrate that our proposed ACKG-LLM performs favorably against representative methods on the REBEL and WiKi-NRE datasets.","1941-0077","","10.1109/TMM.2025.3557717","Major Science and Technology Projects in Yunnan Province(grant numbers:202302AG050009,202302AB080014); Yunnan Fundamental Research Projects(grant numbers:202401AW070019,202301AV070003,202101BE070001-008); National Natural Science Foundation of China(grant numbers:62201237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10948338","Knowledge graph construction;schema layer;large language models;prompt engineering","Knowledge graphs;Semantics;Accuracy;Encyclopedias;Data mining;Online services;Costs;Training;Prompt engineering;Multilingual","","","","52","IEEE","3 Apr 2025","","","IEEE","IEEE Journals"
"DomainLynx: Advancing LLM Techniques for Robust Domain Squatting Detection","D. Chiba; H. Nakano; T. Koide","NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan; NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan; NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan",IEEE Access,"20 Feb 2025","2025","13","","29914","29931","Domain squatting, the malicious registration of deceptive domain names, poses a significant threat to Internet security. This study presents an enhanced version of DomainLynx, a system leveraging Large Language Models (LLMs) for detecting domain squatting. We introduce novel techniques that combine LLMs with domain-specific knowledge to identify a wide range of squatting tactics, including complex hybrid methods that merge multiple deception techniques. Our improved system features refined detection algorithms and an advanced validation process that significantly reduces false positives while maintaining high accuracy. Comprehensive evaluations using various LLM configurations demonstrate DomainLynx’s superior performance. Using a state-of-the-art LLM, the system achieved 94.7% accuracy on a diverse dataset of 1,649 squatting domains. In a month-long real-world test, DomainLynx detected 34,359 potential squatting domains from 2.09 million new registrations, outperforming existing methods by 2.5 times. Further analysis confirmed the system’s effectiveness across different squatting types. We also present case studies of hybrid-squatting domains, such as those combining typos with brand impersonation, offering insights into emerging threats. This research advances Internet security by providing a more accurate, adaptable, and thoroughly evaluated LLM-based tool for combating evolving domain squatting threats, contributing to safer online environments for users and organizations worldwide.","2169-3536","","10.1109/ACCESS.2025.3542036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884775","Domain squatting;large language models (LLMs);cybersecurity;compound AI system","Upper bound;Accuracy;Systems architecture;Visualization;Phishing;Measurement;Large language models;Internet security;Compounds;Writing","","","","31","CCBY","13 Feb 2025","","","IEEE","IEEE Journals"
"IDD-GPT: A Human-Computer Interaction Dialogue Framework Based on the Fine-Tuning of Large Language Models","W. Xiao","College of Foreign Languages, Northeastern University, Shenyang, China",2025 37th Chinese Control and Decision Conference (CCDC),"5 Aug 2025","2025","","","189","194","With the advancement of artificial intelligence (AI) and big data, large language models (LLMs) have made significant strides in various fields. However, their generalization ability in specialized domains, such as industry, remains limited due to a lack of domain-specific data. Defect detection plays a pivotal role in industrial workflow which ensures product quality, but traditional deep learning methods are constrained by model parameters and prior knowledge, limiting their performance. Some efforts have been made to fine-tune large vision-language models (LVLMs) using industrial datasets, but challenges like high training costs and the need for specialized data hinder progress. This paper proposes a novel method, Industrial Defect Detection-GPT (IDD-GPT), to effectively fine-tune LVLMs using small-scale industrial datasets. By constructing a cache model from few-shot industrial data, the method compares image features with the cache to improve defect detection accuracy. Additionally, multiple cache models are aggregated to enhance performance without exposing sensitive data. The results are converted into human-understandable text via prompt engineering. Experimental results demonstrate the effectiveness and efficiency of the proposed method in defect detection.","1948-9447","979-8-3315-1056-5","10.1109/CCDC65474.2025.11090546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11090546","large vision-language model;few-shot learning;industrial defect detection","Training;Accuracy;Limiting;Large language models;Feature extraction;Data models;Product design;Quality assessment;Prompt engineering;Defect detection","","","","47","IEEE","5 Aug 2025","","","IEEE","IEEE Conferences"
"Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications","H. Zhang; J. Wu; Z. Wu; Z. Chen; D. Lin; J. Chen; Y. Zhou; Z. Zheng","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Faculty of Engineering, The University of Hong Kong, Hong Kong, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China",IEEE Transactions on Software Engineering,"17 Jul 2025","2025","51","7","2197","2210","Decentralized applications (DApps) have long been sitting ducks for hackers due to their valuable cryptocurrency assets, exposing them to various security risks. When a DApp is attacked, promptly identifying faults is crucial to minimizing financial losses and ensuring effective fault repair. However, existing fault localization methods, which mostly rely on code coverage, often fall short for DApps, particularly when dealing with only one fault case. Furthermore, according to a prior survey, most developers expect fault localization tools to provide reasonable explanations. In this paper, we present Malo, a method for DApp-specific explainable fault localization. It identifies fault functions through suspicious token transfer-guided analysis, and then employs Large Language Models (LLMs) to generate explanations for these identified fault functions. Specifically, Malo examines function call traces and source codes of fault cases to acquire internal knowledge, and also retrieves relevant project documents from the Web to obtain external knowledge. By integrating internal and external knowledge, Malo generates reasonable explanations for faults in DApps. Our evaluation on a dataset of 68 real-world DApp faults demonstrates that Malo can locate 62% of faults within the Top-5, 9% higher than the state-of-the-art method. The experiment results also demonstrate a remarkable alignment accuracy of 71% between the explanations generated by Malo and the ground truth. In addition, we conduct a user study, which confirms that explanations generated by Malo can aid developers in comprehending the root cause of faults. Our code and dataset are available online: https://github.com/SodalimeZero/Malo_Code.git.","1939-3520","","10.1109/TSE.2025.3578816","National Natural Science Foundation of China(grant numbers:62372485,623B2102,62332004); Natural Science Foundation of Guangdong Province(grant numbers:2023A1515011314); Department of Education of Guangdong Province(grant numbers:2024ZDZX1001); Major Key Project of PCL(grant numbers:PCL2023A05); Fundamental Research Funds for the Central Universities, Sun Yat-sen University(grant numbers:24lgqb018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034691","Fault localization;fault explanation;decentralized applications","Decentralized applications;Location awareness;Codes;Smart contracts;Standards;Fault diagnosis;Computer bugs;Logic;Large language models;Knowledge engineering","","","","55","IEEE","13 Jun 2025","","","IEEE","IEEE Journals"
"The First ChatGPT4PCG Competition","F. Abdullah; P. Taveekitworachai; M. F. Dewantoro; R. Thawonmas; J. Togelius; J. Renz","Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; NYU Tandon School of Engineering, New York University, New York, NY, USA; School of Computing, Australian National University, Canberra, ACT, Australia",IEEE Transactions on Games,"17 Dec 2024","2024","16","4","971","980","This article summarizes the first ChatGPT4PCG competition held at the 2023 IEEE Conference on Games. The goal of the competition is to explore emergent abilities of publicly available large language models (LLMs) in performing complex tasks related to procedural content generation, specifically physics-based level generation for Angry Birds-like games. Participants are tasked with submitting their prompts for ChatGPT to generate Angry Birds-like game structures that resemble English uppercase characters. A structure is a collection of stacked game objects comprising a part of an entire Angry Birds-like level. A prompt is an input for LLMs, including ChatGPT. Two evaluation metrics, i.e., stability and similarity, are used to evaluate the submitted prompts. Stability measures the sturdiness of a structure to withstand in-game gravity, while similarity measures a structure's resemblance to the target character. With such evaluation, participants are challenged to produce not only character-like but also stable structures by utilizing prompt engineering techniques. Finally, the competition's results are discussed to provide valuable insights for future studies and competitions.","2475-1510","","10.1109/TG.2024.3376429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10470422","Angry birds;ChatGPT;large language models (LLMs);procedural content generation (PCG)","Games;Birds;Task analysis;Chatbots;Measurement;Codes;Artificial intelligence","","3","","60","IEEE","12 Mar 2024","","","IEEE","IEEE Journals"
"Unforgettable Password Generation Using LoRA Fine-Tuned Large Language Model","M. Sameer; K. Sudharsan; A. Benazir Begum","Dept.of Computer Science & Engineering, Hindustan Institute of Technology and Science, Chennai, India; Dept.of Computer Science & Engineering, Hindustan Institute of Technology and Science, Chennai, India; Dept.of Computer Science & Engineering, Hindustan Institute of Technology and Science, Chennai, India",2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS),"23 May 2024","2024","","","1","5","In response to the challenges posed by complex and hard-to-remember passwords in traditional authentication systems, this research introduces an innovative approach leveraging Low Rank Adaption (LoRA) fine-tuned Large Language Models (LLMs) to generate natural language-like strong passwords. Focused on striking a balance between usability and security, proposed system methodology employs smaller-sized pre-trained LLMs, adapted using LoRA fine-tuning, to produce passwords that are both strong and memorable. By addressing the limitations of current password generation practices, proposed system framework aims to encourage user adoption of secure practices, contributing to a positive societal impact through improved cybersecurity hygiene. The proposed solution involves deploying a fine-tuned LLM and serving them through an frontend web UI which emphasizes resource efficiency scalability of deployment of such model, and ease of using the generated passwords in real life authentication purposes fostering good cybersecurity practices among non-technical users.","","979-8-3503-6482-8","10.1109/ADICS58448.2024.10533548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533548","password generation;large language models;LoRA fine-tuning;pcfg;omen","Computational modeling;Scalability;Authentication;Passwords;Data engineering;Data models;Usability","","1","","20","IEEE","23 May 2024","","","IEEE","IEEE Conferences"
"Chain-of-Thought Enhanced Content Detection in Large Language Models","C. Zou; Z. Feng; H. Guan; C. Xing","School of Computer Science and Technology, Heilongjiang Institute of Technology, Harbin, China; School of Computer Science and Technology, Heilongjiang Institute of Technology, Harbin, China; School of Computer Science and Technology, Heilongjiang Institute of Technology, Harbin, China; School of Computer Science and Technology, Heilongjiang Institute of Technology, Harbin, China","2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)","14 Jan 2025","2024","","","610","617","This paper proposes and explores a content detection method for large language models based on the Chain of Thought (CoT) logic chain. By incrementally extracting logic chains from text or code and converting them into feature vectors, this method enables logical plagiarism detection and content verification for complex tasks. Particularly for classical algorithmic problems, such as dynamic programming, this approach effectively mitigates plagiarism attempts through variable renaming. The paper first delves into the theoretical foundation of CoT logic chains and analyzes their application mechanisms within large language models. It then provides a detailed account of the steps for feature extraction and similarity detection algorithms, including how to efficiently convert logic chains into feature vectors for comparison. To validate the effectiveness of this method, several classical algorithmic instances were selected for experimentation. Results indicate that the CoT logic chain-based content detection method offers significant advantages in detecting originality in academic papers and code. This approach not only substantially improves the detection rate of academic misconduct but also assists editors and reviewers in more accurately identifying AI-generated content, thereby holding broad applications in academic publishing, code review, and educational fields. Additionally, the paper discusses the potential application of this method in other domains, such as patent plagiarism detection and legal document similarity analysis.","","979-8-3315-0658-2","10.1109/CBASE64041.2024.10824407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824407","Content Detection;Similarity Detection;Algorithmic Plagiarism Detection;Chain of Thought (CoT);Artificial Intelligence-Generated Content (AIGC)","Codes;Text analysis;Reviews;Publishing;Plagiarism;Large language models;Feature extraction;Vectors;Logic;Software engineering","","","","6","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Research on Toxic Speech Detection Based on Large Language Models","W. Li; Y. Gao; Y. Zhang; L. Yang; R. Gao","Digital Industry College, Inner Mongolia University of Science & Technology, Baotou, China; Digital Industry College, Inner Mongolia University of Science & Technology, Baotou, China; Digital Industry College, Inner Mongolia University of Science & Technology, Baotou, China; Digital Industry College, Inner Mongolia University of Science & Technology, Baotou, China; Technical Network Team Baotou Public Security Bureau, Baotou, China","2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","4 Apr 2025","2024","","","2191","2196","Toxic Speech (TS) is widely spread in social media and is increasingly harmful to the online networking environment. At the same time, words and their variants containing implicit toxic semantics are influenced by the humanistic and social environment of the language and are extremely rich in form and shape, and the lack of background knowledge related to the ""discourse body"" of existing research has led to the confusion of Implicit Toxic Speech (ITS) with Non-Toxic Speech (NTS). Therefore, this paper proposes the Prompt-enhanced Attention Head Fusion (PAHF) toxic text classification model based on the generative language model. We optimize the hidden layer vectors by intervening in the hidden layer information through prompt, then filter the vectors by combining linear probes to locate those vectors in the hidden layer information that are strongly correlated with the encoding of the background knowledge, and finally construct an attention fusion mechanism to fuse the filtered features, which provides a higher detection accuracy compared with the existing algorithms.","2324-9013","979-8-3315-0620-9","10.1109/TrustCom63139.2024.00302","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10945182","Implicit Toxic Speech;Linear Probe;Prompt Engineering;Attention Mechanism","Maximum likelihood detection;Social networking (online);Text categorization;Semantics;Speech recognition;Nonlinear filters;Filtering algorithms;Information filters;Vectors;Probes","","","","30","IEEE","4 Apr 2025","","","IEEE","IEEE Conferences"
"Utilizing Large Language Models for Advanced Optimization and Intelligent Management in Space-Air-Ground Integrated Networks","J. Tang; F. Tang; S. Long; M. Zhao; N. Kato","Central South University, China; Central South University, China; Central South University, China; Central South University, China; Tohoku University, Japan",IEEE Network,"","2024","PP","99","1","1","Space-Air-Ground Integrated Networks (SAGIN) present stringent and complex requirements for network design and management due to their heterogeneity, self-organizing nature, dynamic characteristics and so on. Despite extensive research on deep learning in the context of SAGIN, challenges such as inflexibility, lack of generalization, limited robustness, and insufficient scalability persist. Large language models (LLMs), with their powerful natural language processing, understanding, and generation capabilities, show significant potential in meeting the complex demands of SAGIN. We thoroughly analyze the application of LLMs in optimizing channel models, improving communication algorithms, and enhancing network management and security performance to address the unique characteristics and requirements of SAGIN. Additionally, it identifies the challenges faced during the deployment of LLMs, including computational resource constraints, data transmission limitations, model updates, real-time processing, and system integration. Corresponding solutions are proposed to ensure the efficient operation and reliability of SAGIN. Through this research, we aim to provide innovative solutions for the intelligent management of SAGIN, promoting the continuous development and application of SAGIN.","1558-156X","","10.1109/MNET.2024.3519664","Natural Science Foundation of Hunan Province(grant numbers:no.2023jj40774); Changsha Municipal Natural Science Foundation (Grant no.kq2208284)(grant numbers:no.kq2208284); National Natural Science Foundation of China(grant numbers:no.62302527); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806847","","Data models;Adaptation models;Natural language processing;Deep learning;Space-air-ground integrated networks;Reliability;Analytical models;Security;Real-time systems;Prediction algorithms","","1","","","IEEE","18 Dec 2024","","","IEEE","IEEE Early Access Articles"
"Semantic-Enhanced Indirect Call Analysis with Large Language Models","B. Cheng; C. Zhang; K. Wang; L. Shi; Y. Liu; H. Wang; Y. Guo; D. Li; X. Chen","Peking University, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China; Peking University, China; Peking University, China; Peking University, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","430","442","In contemporary software development, the widespread use of indirect calls to achieve dynamic features poses challenges in constructing precise control flow graphs (CFGs), which further impacts the performance of downstream static analysis tasks. To tackle this issue, various types of indirect call analyzers have been proposed. However, they do not fully leverage the semantic information of the program, limiting their effectiveness in real-world scenarios.To address these issues, this paper proposes Semantic-Enhanced Analysis (SEA), a new approach to enhance the effectiveness of indirect call analysis. Our fundamental insight is that for common programming practices, indirect calls often exhibit semantic similarity with their invoked targets. This semantic alignment serves as a supportive mechanism for static analysis techniques in filtering out false targets. Notably, contemporary large language models (LLMs) are trained on extensive code corpora, encompassing tasks such as code summarization, making them well-suited for semantic analysis. Specifically, SEA leverages LLMs to generate natural language summaries of both indirect calls and target functions from multiple perspectives. Through further analysis of these summaries, SEA can determine their suitability as caller-callee pairs. Experimental results demonstrate that SEA can significantly enhance existing static analysis methods by producing more precise target sets for indirect calls.CCS CONCEPTS•Software and its engineering → Software maintenance tools.","2643-1572","979-8-4007-1248-7","","National Science and Technology Major Project; National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764802","Indirect-call analysis;Semantic analysis;LLM","Software maintenance;Codes;Limiting;Large language models;Semantics;Natural languages;Static analysis;Programming;Software engineering;Software development management","","","","67","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Investigating Numerical Translation with Large Language Models","W. Tang; J. Yu; Y. Li; Y. Zhao; W. Zhang; W. Feng; M. Zhang; H. Yang","Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China; Huawei Translation Services Center, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","The inaccurate translation of numbers can lead to significant security issues, ranging from financial setbacks to medical inaccuracies. While large language models (LLMs) have made significant advancements in machine translation, their capacity for translating numbers has not been thoroughly explored. This study focuses on evaluating the reliability of LLM-based machine translation systems when handling numerical data. In order to systematically test the numerical translation capabilities of currently open source LLMs, we have constructed a numerical translation dataset between Chinese and English based on real business data, encompassing ten types of numerical translation. Experiments on the dataset indicate that errors in numerical translation are a common issue, with most open-source LLMs faltering when faced with our test scenarios. Especially when it comes to numerical types involving large units like ""million"", ""billion"", and ""亿"" , even the latest llama3.1 8b model can have error rates as high as 20%. Finally, we introduce three potential strategies to mitigate the numerical mistranslations for large units.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10887726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887726","LLM;Numerical Translation","Translation;Error analysis;Large language models;Signal processing;Distance measurement;Numerical models;Machine translation;Security;Reliability;Speech processing","","","","23","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"PEARL: An Adaptive and Explainable Hardware Trojan Detection Using Open Source and Enterprise Large Language Models","R. Kumar Kundu; K. Khalil; E. Garcia; E. Grassia; P. Calyam; K. A. Hoque","Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA; Columbia College, Columbia, MO, USA; Department of Computer Science, Loyola University, Chicago, IL, USA; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA",IEEE Access,"1 Aug 2025","2025","13","","133755","133772","The Integrated Circuit (IC) supply chain risk allows attackers to implant hardware Trojans (HT) in various stages of chip production. To counter this, different machine learning (ML) and deep learning (DL)-based methods have been developed to detect HTs. However, these methods require massive amounts of high-quality labeled data for effective training, extended training times for accurate HT detection, limited generalization to novel or unseen HTs, and insufficient capability to explain the detected HTs. Recent studies have started exploring the potential of Large language models (LLMs) for hardware security tasks. However, there are no current studies that explore, study, and compare the applicability of open-source vs. enterprise LLMs for efficient HT detection and explanation of the detected HT. To close the gap, we propose an innovative HT detection and explanation method by leveraging the knowledge of a pre-trained LLM, namely enterprise application programming interface (API)-enabled a Generative Pre-trained Transformer (GPT)-3.5 Turbo, Google Gemini 1.5 Pro and open-source LLMs: Meta AI Llama-3.1 and DeepSeek AI DeepSeek-V2 models, which have already been trained on massive and diverse datasets and is capable of providing the reasoning of the detected HT. Specifically, we apply In-Context Learning (ICL)-based mechanisms: zero-shot, one-shot, and few-shot learning strategies (e.g., register transfer level (RTL) files (Verilog) of the circuit) to adopt this model for HT detection and explanation tasks. We validate our proposed approach on diverse circuit design benchmarks from Trust-Hub and ISCAS (85 and 89). Our experimental results show that the proposed few-shot learning-based enterprise-API-enabled GPT-3.5 Turbo and open-source DeepSeek-V2 LLM models detect unknown HTs with an accuracy of 97% and 91% and drastically reduce the training time compared to state-of-the-art techniques. Furthermore, after detecting the HT, they provide human-centric reasoning/explanation, reinforcing transparency and trust in the IC supply chain through its understanding.","2169-3536","","10.1109/ACCESS.2025.3592030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091291","Hardware trojan;deep learning;large language model;in-context learning;explainable AI","Trojan horses;Training;Computational modeling;Integrated circuit modeling;Accuracy;Data models;Cognition;Benchmark testing;Register transfer level;Predictive models","","","","65","CCBY","23 Jul 2025","","","IEEE","IEEE Journals"
"Exploring the Privacy Protection Capabilities of Chinese Large Language Models","Y. Yang; X. Huang; J. Sang","Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China",IEEE MultiMedia,"","2025","PP","99","1","9","Large language models (LLMs) are renowned for their advanced capabilities, significantly enhancing artificial intelligence. However, these advancements have also raised increasing concerns about privacy and security. To address these issues, we developed a three-tiered framework designed to evaluate privacy in language systems through progressively complex tests. Our primary goal is to measure the sensitivity of LLMs to private information, studying their ability to identify, manage, and protect sensitive data across different scenarios. This systematic evaluation helps determine how well these models comply with privacy guidelines and the effectiveness of their safeguards against breaches. Our findings suggest that current Chinese LLMs show widespread privacy protection issues, indicating that this challenge remains common and may pose corresponding privacy risks in applications based on these models.","1941-0166","","10.1109/MMUL.2025.3542508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893707","","Privacy;Large language models;Data privacy;Protection;Context modeling;Testing;Security;Electronic mail;Data models;Training","","","","","IEEE","19 Feb 2025","","","IEEE","IEEE Early Access Articles"
"Irony Detection, Reasoning and Understanding in Zero-shot Learning","P. Yi; Y. Xia; Y. Long",NA; NA; NA,IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","14","Irony is a powerful figurative language (FL) on social media that can potentially mislead various NLP tasks, such as recommendation systems, misinformation checks, and sentiment analysis. Understanding the implicit meaning of this kind of subtle language is an essential step to mitigate the negative impact of irony in NLP tasks. However, existing efforts are limited to domain-specific datasets and struggle to generalize across diverse real-world scenarios. Moreover, reasoning for model decisions that accurately capture semantic and affective meaning remains underexplored. To address these limitations, this paper proposes a conceptual framework called IDADP, which leverages Large language models(LLMs)’ in-context learning capabilities to detect irony and generate human-like explanations across diverse datasets and platforms without prior training on ironic samples. Extensive experiments on six widely used irony detection datasets, utilising two large language models (GPT and Gemini), demonstrate that IDADP consistently outperforms six competitive zero-shot baselines and approaches the performance of three fine-tuned supervised learning baselines. Additionally, we examine GPT’s ability to understand the true intent behind ironic text within the IDADP framework, highlighting its strong potential to recognize and interpret statements where the intended meaning differs from or contrasts with the literal meaning. Furthermore, we conduct qualitative analyses to identify remaining challenges. This work, in turn, opens an avenue for transparent decision-making in irony detection.","2691-4581","","10.1109/TAI.2025.3579452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036129","Large Language Models;Prompt engineering;Zero-shot learning","Cognition;Prompt engineering;Training;Zero shot learning;Social networking (online);Feature extraction;Sentiment analysis;Semantics;Scalability;Manuals","","","","","IEEE","13 Jun 2025","","","IEEE","IEEE Early Access Articles"
"ℬ4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests","M. Chen; Z. Liu; H. Tao; Y. Hong; D. Lo; X. Xia; J. Sun","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Singapore Management University Singapore, Singapore; Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1693","1705","Selecting the best code solution from multiple generated ones is an essential task in code generation, which can be achieved by using some reliable validators (e.g., developer-written test cases) for assistance. Since reliable test cases are not always available and can be expensive to build in practice, researchers propose to automatically generate test cases to assess code solutions. However, when both code solutions and test cases are plausible and not reliable, selecting the best solution becomes challenging. Although some heuristic strategies have been proposed to tackle this problem, they lack a strong theoretical guarantee and it is still an open question whether an optimal selection strategy exists. Our work contributes in two ways. First, we show that within a Bayesian framework, the optimal selection strategy can be defined based on the posterior probability of the observed passing states between solutions and tests. The problem of identifying the best solution is then framed as an integer programming problem. Second, we propose an efficient approach for approximating this optimal (yet uncomputable) strategy, where the approximation error is bounded by the correctness of prior knowledge. We then incorporate effective prior knowledge to tailor code generation tasks. Both theoretical and empirical studies confirm that existing heuristics are limited in selecting the best solutions with plausible test cases. Our proposed approximated optimal strategy ℬ4 significantly surpasses existing heuristics in selecting code solutions generated by large language models (LLMs) with LLM-generated tests, achieving a relative performance improvement by up to 50% over the strongest heuristic and 246% over the random selection in the most challenging scenarios. Our code is publicly available at https://github.com/ZJU-CTAG/B4.CCS CONCEPTS• Computing methodologies → Artificial intelligence; • Software and its engineering → Software design engineering.","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765071","Code Generation;Software Engineering;Large Language Models","Integer programming;Codes;Software design;Posterior probability;Large language models;Computational modeling;Reliability theory;Software;Bayes methods;Software engineering","","","","49","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Code Detection for Hardware Acceleration Using Large Language Models","P. A. Martínez; G. Bernabé; J. M. García","Huawei Technologies Research and Development, Cambridge, U.K; Computer Engineering Department, University of Murcia, Murcia, Spain; Computer Engineering Department, University of Murcia, Murcia, Spain",IEEE Access,"8 Mar 2024","2024","12","","35271","35281","Large language models (LLMs) have been massively applied to many tasks, often surpassing state-of-the-art approaches. While their effectiveness in code generation has been extensively studied (e.g., AlphaCode), their potential for code detection remains unexplored. This work presents the first analysis of code detection using LLMs. Our study examines essential kernels, including matrix multiplication, convolution, fast-fourier transform and LU factorization, implemented in C/C++. We propose both a preliminary, naive prompt and a novel prompting strategy for code detection. Results reveal that conventional prompting achieves great precision but poor accuracy (67.5%, 22.5%, 79.5% and 64% for GEMM, convolution, FFT and LU factorization, respectively) due to a high number of false positives. Our novel prompting strategy substantially reduces false positives, resulting in excellent overall accuracy (91.2%, 98%, 99.7% and 99.7%, respectively). These results pose a considerable challenge to existing state-of-the-art code detection methods.","2169-3536","","10.1109/ACCESS.2024.3372853","Ministerio de Ciencia e Innovación (MCIN)/Agencia Estatal de Investigación (AEI)/10. 13039/501100011033(grant numbers:TED2021-129221B-I00,PID2022-136315OB-I00); “European Union (EU) NextGenerationEU/Plan de Recuperación, Transformación y Resiliencia (PRTR);”; “European Regional Development Fund (ERDF) A way of making Europe,” EU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458137","Code detection;compilers;heterogeneous computing;high-performance computing;large language model","Codes;Task analysis;Computational modeling;Convolution;Kernel;Hardware acceleration;Transforms;Detection algorithms;Program processors;Large language models","","4","","48","CCBY","1 Mar 2024","","","IEEE","IEEE Journals"
"AutoIoT: Automated IoT Platform Using Large Language Models","Y. Cheng; M. Xu; Y. Zhang; K. Li; R. Wang; L. Yang","School of Computer Science and Technology, Shandong University, Jinan, China; School of Computer Science and Technology, Shandong University, Jinan, China; Department of Computer Science, Drexel University, Philadelphia, PA, USA; School of Computer Science and Technology, Shandong University, Jinan, China; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Tendering and Procurement Department, Shandong Cancer Hospital and Institute, Shandong Academy of Medical Sciences, Shandong First Medical University, Tai’an, China",IEEE Internet of Things Journal,"8 May 2025","2025","12","10","13644","13656","Internet of Things (IoT) platforms, particularly smart home platforms providing significant convenience to people’s lives, such as Apple HomeKit and Samsung SmartThings, allow users to create automation rules through trigger-action programming. However, some users may lack the necessary knowledge to formulate automation rules, thus preventing them from fully benefiting from the conveniences offered by smart home technology. To address this, smart home platforms provide predefined automation policies based on the smart home devices registered by the user. Nevertheless, these policies, being pregenerated and relatively simple, fail to adequately cover the diverse needs of users. Furthermore, conflicts may arise between automation rules, and integrating conflict detection into the IoT platform increases the burden on developers. In this article, we propose AutoIoT, an automated IoT platform based on large language models (LLMs) and formal verification techniques, designed to achieve end-to-end automation through device information extraction, LLM-based rule generation, conflict detection, and avoidance. AutoIoT can help users generate conflict-free automation rules and assist developers in generating codes for conflict detection, thereby enhancing their experience. A code adapter has been designed to separate logical reasoning from the syntactic details of code generation, enabling LLMs to generate code for programming languages beyond their training data. Finally, we evaluated the performance of AutoIoT and presented a case study demonstrating how AutoIoT can integrate with existing IoT platforms.","2327-4662","","10.1109/JIOT.2024.3523907","National Natural Science Foundation of China(grant numbers:62302266,62232010,U23A20302); Shandong Science Fund for Excellent Young Scholars(grant numbers:2023HWYQ-008); Natural Science Foundation of Shandong Province(grant numbers:ZR2022ZD02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818469","Automation rules;conflict detection;formal verification;Internet of Things (IoT);large language model (LLM);smart home","Internet of Things;Automation;Smart homes;Codes;Formal verification;Cognition;Training data;Programming;Monitoring;Large language models","","3","","49","IEEE","30 Dec 2024","","","IEEE","IEEE Journals"
"Programming Computational Electromagnetic Applications Assisted by Large Language Models [Em Programmer’s Notebook]","L. C. Fernandes","Federal Court of Accounts, Brasília, Brazil",IEEE Antennas and Propagation Magazine,"12 Feb 2024","2024","66","1","63","71","This article discusses the possibilities and limitations of using large language models (LLMs) in software development with applications in computational electromagnetics (EM). Three tasks are discussed: code translation, code generation, and code description. The tests showed that LLMs are generally very useful. Even when errors occurred, they could provide useful hints to find a solution.","1558-4143","","10.1109/MAP.2023.3336708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10432963","","Codes;Software;Libraries;Task analysis;Antenna radiation patterns;Python;Matlab","","1","","20","IEEE","12 Feb 2024","","","IEEE","IEEE Magazines"
"From LLMs to Randomness: Analyzing Program Input Efficacy With Resource and Language Metrics","G. Black; E. Yocam; V. Mathew Vaidyan; G. Comert; Y. Wang","Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; Department of Computer Science, College of Engineering, North Carolina Agricultural and Technical State University, Greensboro, NC, USA; Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA",IEEE Access,"23 May 2025","2025","13","","87928","87940","Security-focused program testing typically focuses on crash detection and code coverage while overlooking additional system behaviors that can impact program confidentiality and availability. To address this gap, we propose a statistical framework that combines embedding-based anomaly detection, resource usage metrics, and resource-state distance measures to systematically profile software behaviors beyond traditional coverage-based methods. Leveraging over 5 million labeled samples from 50 Python programs, we evaluate how these independent scoring terms distinguish among different sources of input, including Large Language Model (LLM)-generated inputs, and demonstrate how standard statistical tests (e.g., Kolmogorov—Smirnov and Kendall’s  $\tau $ ) confirm their effectiveness. Our findings show that LLM-generated samples can trigger diverse behaviors but are often less effective at exploring resource usage dynamics (CPU, memory) compared with conventional fuzzing. However, combining LLM outputs with existing techniques broadens behavior coverage and reveals commonalities between commercial LLM outputs. We provide open-source tools for this evaluation framework, demonstrating the potential to refine software testing by integrating behavior metrics into security-testing workflows.","2169-3536","","10.1109/ACCESS.2025.3571205","U.S. Department of Energy Minority Serving Institutions Partnership Program (MSIPP); Savannah River National Laboratory under BSRA Contract(grant numbers:TOA0000525174CN1); MSIPP-Claflin(grant numbers:FM-MHP-0678-22-01-00); National Science Foundation(grant numbers:2131080,2200457,OIA-2242812,2234920,2305470); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11006641","Software profiling;program behavior analysis;fuzzing techniques;resource usage metrics;large language models;anomaly detection","Measurement;Software;Fuzzing;Testing;Memory management;Computer crashes;Codes;Anomaly detection;Python;Statistical analysis","","","","49","CCBY","19 May 2025","","","IEEE","IEEE Journals"
"SpecGen: Automated Generation of Formal Program Specifications via Large Language Models","L. Ma; S. Liu; Y. Li; X. Xie; L. Bu","State Key Laboratory for Novel Software Technology, Nanjing University, P.R. China; State Key Laboratory for Novel Software Technology, Nanjing University, P.R. China; Nanyang Technological University, Singapore; Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, P.R. China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","16","28","In the software development process, formal program specifications play a crucial role in various stages, including requirement analysis, software testing, and verification. However, manually crafting formal program specifications is rather difficult, making the job time-consuming and labor-intensive. Moreover, it is even more challenging to write specifications that correctly and comprehensively describe the semantics of complex programs. To reduce the burden on software developers, automated specification generation methods have emerged. However, existing methods usually rely on predefined templates or grammar, making them struggle to accurately describe the behavior and functionality of complex real-world programs. To tackle this challenge, we introduce SpecGen, a novel technique for formal program specification generation based on Large Language Models (LLMs). Our key insight is to overcome the limitations of existing methods by leveraging the code comprehension capability of LLMs. The process of SpecGen consists of two phases. The first phase employs a conversational approach that guides the LLM in generating appropriate specifications for a given program, aiming to utilize the ability of LLM to generate high-quality specifications. The second phase, designed for where the LLM fails to generate correct specifications, applies four mutation operators to the model-generated specifications and selects verifiable specifications from the mutated ones through a novel heuristic selection strategy by assigning different weights of variants in an efficient manner. We evaluate SpecGen on two datasets, including the SV-COMP Java category benchmark and a manually constructed dataset containing 120 programs. Experimental results demonstrate that SpecGen succeeds in generating verifiable specifications for 279 out of 385 programs, outperforming the existing LLM-based approaches and conventional specification generation tools like Houdini and Daikon. Further investigations on the quality of generated specifications indicate that SpecGen can comprehensively articulate the behaviors of the input program.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00129","Nanjing University; National Natural Science Foundation of China(grant numbers:62232008,62172200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029962","program verification;specification inference;large language model","Software testing;Java;Codes;Large language models;Semantics;Benchmark testing;Software;Grammar;Software engineering;Software development management","","2","","79","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"CD-LLMCARS: Cross Domain Fine-Tuned Large Language Model for Context-Aware Recommender Systems","A. A. Cheema; M. S. Sarfraz; U. Habib; Q. U. Zaman; E. Boonchieng","Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan; FAST School of Computing, National University of Computer and Emerging Sciences, Islamabad Campus, Islamabad, Pakistan; Department of Software Engineering, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan; Department of Computer Science, Faculty of Science, Chiang Mai University, Chiang Mai, Thailand",IEEE Open Journal of the Computer Society,"9 Jan 2025","2025","6","","49","59","Recommender systems are essential for providing personalized content across various platforms. However, traditional systems often struggle with limited information, known as the cold start problem, and with accurately interpreting a user's comprehensive preferences, referred to as context. The proposed study, CD-LLMCARS (Cross-Domain fine-tuned Large Language Model for Context-Aware Recommender Systems), presents a novel approach to addressing these issues. CD-LLMCARS leverages the substantial capabilities of the Large Language Model (LLM) Llama 2. Fine-tuning Llama 2 with information from multiple domains can enhance the generation of contextually relevant recommendations that align with a user's preferences in areas such as movies, music, books, and CDs. Techniques such as Low-Rank Adaptation (LoRA) and Half Precision Training (FP16) are both effective and resource-efficient, allowing CD-LLMCARS to perform optimally in cold start scenarios. Extensive testing of CD-LLMCARS indicates outstanding accuracy, particularly in challenging scenarios characterized by limited user history data relevant to the cold start problem. CD-LLMCARS offers precise and pertinent recommendations to users, effectively mitigating the limitations of traditional recommender systems.","2644-1268","","10.1109/OJCS.2024.3509221","Fundamental Fund 2025; Chiang Mai University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771726","Collaborative filtering;context-aware recommeder systems (CARS);cross-domain recommender systems (CDRS);large language models (LLMs);prompt engineering","Recommender systems;Large language models;Reviews;Accuracy;History;Context modeling;Collaborative filtering;Tuning;Training;User experience","","","","51","CCBYNCND","28 Nov 2024","","","IEEE","IEEE Journals"
"Introducing the Art of Prompt Engineering","P. Baker",NA,Generative AI For Dummies,"","2025","","","23","33","Summary <p>Prompting is a crucial skill set in the era of Generative AI. ChatGPT is a chatbot application built on GPT, which is a Generative AI model. The secret sauce of prompt engineering is a combination of clarity, context, and creativity. Two ways of using steps in prompting are iterative prompting and prompt chaining, which are related but distinct techniques: iterative prompting, and prompt chaining. Data analysis requires prompts that are precise and data‐driven. The chapter provides some examples across various industries that illustrate how prompts can be tailored for domain‐specific applications: legal domain, healthcare domain, education domain, finance domain, software development domain, and customer service domain. As AI continues to evolve, the ability to engineer precise and effective prompts becomes an increasingly valuable skill across all sectors. The point of prompt engineering is to carefully compose a prompt that can shape the AI's learning curve and fine‐tune its responses to perfection.</p>","","9781394270767","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10953029.pdf&bkn=10950188&pdfType=chapter","","Prompt engineering;Chatbots;Art;Iterative methods;User interfaces;Generators;Bars;Creativity;Writing;Windings","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Preference-Guided Refactored Tuning for Retrieval Augmented Code Generation","X. Gao; Y. Xiong; D. Wang; Z. Guan; Z. Shi; H. Wang; S. Li","Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; National University of Defense Technology, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; College of Design and Innovation, Tongji University, Shanghai, China; National University of Defense Technology, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","65","77","Retrieval-augmented code generation utilizes Large Language Models as the generator and significantly expands their code generation capabilities by providing relevant code, documentation, and more via the retriever. The current approach suffers from two primary limitations: 1) information redundancy. The indiscriminate inclusion of redundant information can result in resource wastage and may misguide generators, affecting their effectiveness and efficiency. 2) preference gap. Due to different optimization objectives, the retriever strives to procure code with higher ground truth similarity, yet this effort does not substantially benefit the generator. The retriever and the generator may prefer different golden code, and this gap in preference results in a suboptimal design. Additionally, differences in parameterization knowledge acquired during pre-training result in varying preferences among different generators.To address these limitations, in this paper, we propose RRG (Retrieve, Refactor, Generate), a novel framework for effective and efficient code generation. This framework introduces a code refactorer module between the retriever and the generator to bridge them. The refactoring process transforms the raw retrieved code into a more concise, efficient, and model-friendly version. It eliminates redundant information and noise, reducing the input length. Consequently, the generator receives higher-quality context, enabling it to produce more accurate results with lower inference costs. We conducted comprehensive experiments on multiple datasets. In the experiments, we confirmed the existence of a preference gap between the retriever and the generator, and RRG effectively bridges this gap. Specifically, RRG achieved significant performance improvements, with increases of up to 28% on EM, 13% on BLEU, and 6.8% on CodeBLEU.","2643-1572","979-8-4007-1248-7","","Technology Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764875","Retrieval-augmented Code Generation;Preference-guided Refactorer;Deep Reinforcement Learning","Bridges;Codes;Redundancy;Noise;Transforms;Reinforcement learning;Generators;Tuning;Optimization;Software engineering","","1","","68","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Improving LLM Outputs Against Jailbreak Attacks With Expert Model Integration","T. Tsmindashvili; A. Kolkhidashvili; D. Kurtskhalia; N. Maghlakelidze; E. Mekvabishvili; G. Dentoshvili; O. Shamilov; Z. Gachechiladze; S. Saporta; D. Dachi Choladze","Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA; Impel, Syracuse, NY, USA",IEEE Access,"4 Aug 2025","2025","13","","134976","134988","Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address, may be irrelevant to that field. These problems can be mitigated for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient and reliable. In response to these challenges, we introduce Archias, an expert model, adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model’s ability to understand the user’s intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be simply customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.","2169-3536","","10.1109/ACCESS.2025.3592458","Impel; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095693","Expert model;generative AI;jailbreak attacks;large language models;prompt injections","Artificial intelligence;Benchmark testing;Pipelines;Chatbots;Adaptation models;Security;Industries;Automotive engineering;Training;Pricing","","","","51","CCBY","24 Jul 2025","","","IEEE","IEEE Journals"
"A Dynamic Mechanism for Security Management in Multi-Agent Networked Systems","S. Navabi; A. Nayyar","Electrical and Computer Engineering Department, University of Southern California, Los Angeles, USA; Electrical and Computer Engineering Department, University of Southern California, Los Angeles, USA",IEEE INFOCOM 2020 - IEEE Conference on Computer Communications,"4 Aug 2020","2020","","","1628","1637","We study the problem of designing a dynamic mechanism for security management in an interconnected multi-agent system with N strategic agents and one coordinator. The system is modeled as a network of N vertices. Each agent resides in one of the vertices of the network and has a privately known security state that describes its safety level at each time. The evolution of an agent's security state depends on its own state, the states of its neighbors in the network and on actions taken by a network coordinator. Each agent's utility at time instant t depends on its own state, the states of its neighbors in the network and on actions taken by a network coordinator. The objective of the network coordinator is to take security actions in order to maximize the long-term expected social surplus. Since agents are strategic and their security states are private information, the coordinator needs to incentivize agents to reveal their information. This results in a dynamic mechanism design problem for the coordinator. We leverage the inter-temporal correlations between the agents' security states to identify sufficient conditions under which an incentive compatible expected social surplus maximizing mechanism can be constructed. We then identify two special cases of our formulation and describe how the desired mechanism is constructed in these cases.","2641-9874","978-1-7281-6412-0","10.1109/INFOCOM41043.2020.9155295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155295","dynamic mechanism design;interdependent valuations;social surplus maximization;incentive compatibility;network security;multi-agent systems","Cost accounting;Computer security;Silicon;Communication networks;Computer networks;Probability distribution","","","","10","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Event Temporal Relation Extraction based on Retrieval-Augmented on LLMs","X. Zhang; L. Zang; Q. Liu; S. Wei; S. Hu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","Event temporal relation (TempRel) is a primary subject of the event relation extraction task. However, the inherent ambiguity of TempRel increases the difficulty of the task. With the rise of prompt engineering, it is important to design effective prompt templates and verbalizers to extract relevant knowledge. The traditional manually designed templates struggle to extract precise temporal knowledge. This paper introduces a novel retrieval-augmented TempRel extraction approach, leveraging knowledge retrieved from large language models (LLMs) to enhance prompt templates and verbalizers. Our method capitalizes on the diverse capabilities of various LLMs to generate a wide array of ideas for template and verbalizer design. Our proposed method fully exploits the potential of LLMs for generation tasks and contributes more knowledge to our design. Empirical evaluations across three widely recognized datasets demonstrate the efficacy of our method in improving the performance of event temporal relation extraction tasks.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10651084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10651084","TempRel;LLMs;Retrieval-Augmented","Phased arrays;Knowledge engineering;Large language models;Neural networks;Prompt engineering;Tuning","","1","","33","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Demo: Blockchain Shield - Advanced Threat Detection & Forensic Analysis Platform","N. Zhu; J. Sun; S. Zhang; X. Sun; I. Cheng","White Matrix Inc., Nanjing, China; The Chinese University of Hong Kong, Shenzhen, China; White Matrix Inc., Nanjing, China; University of Alberta, Edmonton, Canada; University of Alberta, Edmonton, Canada",2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS),"22 Aug 2024","2024","","","1400","1403","In the rapidly evolving landscape of blockchain technology, security emerges as a paramount concern. This paper introduces an innovative blockchain security threat awareness platform, designed to comprehensively address the multifaceted security challenges within blockchain networks, particularly focusing on Ethereum contracts. Central to the platform is a dual-database architecture, blending a NoSQL database with a graph database, enhancing data management, and enabling intricate transaction network visualizations. The platform's Threat Detection module, utilizing Large Language Models (LLMs) in conjunction with traditional methods, offers a novel approach to identifying and categorizing vulnerabilities in Ethereum smart contracts. Complementing this, the Threat Evidence Collection module provides detailed post-attack analysis, tracing transactions to their sources and evaluating address risks. This module's capabilities extend to producing statistical reports, including the transactional history and risk evaluation of individual addresses. Demonstrated on the Ethereum blockchain, the platform showcases its proficiency in handling complex data, rapid threat detection, and extensive forensic analysis, presenting a robust solution to fortifying blockchain security and offering a proactive defense mechanism for users and developers in the blockchain environment.","2575-8411","979-8-3503-8605-9","10.1109/ICDCS60910.2024.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10631082","Blockchain Security;Threat Detection;Forensic Analysis;Smart Contracts;Graph Database;LLMs;Vulnerability Analysis","Forensics;NoSQL databases;Large language models;Smart contracts;Threat assessment;Blockchains;Cryptocurrency","","","","8","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Towards Autonomous Network Management: An Intelligent and Secure Agentic Framework for Network Configuration","T. Liu; X. Huang; K. Xie","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science(National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China",IEEE Network,"","2025","PP","99","1","1","The increasing scale and complexity of network infrastructures demand efficient and secure automated configuration solutions. Existing approaches often face challenges such as incompatibility with devices from different manufacturers, limited flexibility in network resource allocation, high demands for personnel expertise, and insufficient security in configuration content. To address these issues, we propose an innovative agent-based framework that leverages large language models (LLMs) to achieve secure and intelligent network configuration. The framework integrates a multi-agent system, which includes: an intent recognition and rewriting agent that uses the Chain of Thought (CoT) method to accurately interpret user intent; a self-reflection retrieval agent that combines hybrid retrieval methods with self-reflection mechanisms to optimize knowledge retrieval; a security agent specialized in network security verification; and a content integration agent that generates final configuration files. Experimental results on a custom dataset demonstrate transformative improvements in accuracy, efficiency, and security. Our framework substantially outperforms both original large language models and strong Retrieval-Augmented Generation (RAG) baselines, with metric scores such as CodeBLEU and BLEU increasing by over 44% compared to the RAG baseline.","1558-156X","","10.1109/MNET.2025.3583298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052733","Agent;Security;Network Management;Large Language Models;NETCONF","Security;Accuracy;Knowledge based systems;Codes;Large language models;Automation;Network topology;Intent recognition;Collaboration;Semantics","","","","","IEEE","26 Jun 2025","","","IEEE","IEEE Early Access Articles"
"C2HLSC: Can LLMs Bridge the Software-to-Hardware Design Gap?","L. Collini; S. Garg; R. Karri",NA; NA; NA,2024 IEEE LLM Aided Design Workshop (LAD),"1 Oct 2024","2024","","","1","12","High Level Synthesis (HLS) tools offer rapid hardware design from C code, but their compatibility is limited by code constructs. This paper investigates Large Language Models (LLMs) for refactoring C code into HLS-compatible formats. We present several case studies by using an LLM to rewrite C code for NIST 800-22 randomness tests, a QuickSort algorithm and AES-128 into HLS-synthesizable c. The LLM iteratively transforms the C code guided by user prompts, implementing functions like streaming data and hardware-specific signals. This evaluation demonstrates the LLM’s potential to assist hardware design refactoring regular C code into HLS synthesizable C code.","","979-8-3503-7608-1","10.1109/LAD62341.2024.10691856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691856","Chip Design;LLM;Catapult HLS;Cryptocores","Bridges;Codes;Large language models;Conferences;Transforms;NIST;Hardware;High level synthesis;Chip scale packaging","","7","","11","IEEE","1 Oct 2024","","","IEEE","IEEE Conferences"
"Exploring LLM Tools Through the Eyes of Industry Experts and Novice Programmers","C. Tona; R. Juárez-Ramírez; S. Jiménez; M. Durán","Facultad de Ciencias Químicas e Ingeniería, Universidad Autónoma de Baja California, Tijuana, México; Facultad de Ciencias Químicas e Ingeniería, Universidad Autónoma de Baja California, Tijuana, México; Facultad de Ciencias de la Ingeniería y Tecnología, Universidad Autónoma de Baja California, Tijuana, México; Facultad de Ciencias de la Ingeniería y Tecnología, Universidad Autónoma de Baja California, Tijuana, México",2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT),"18 Dec 2024","2024","","","313","321","At present, Large Language Models (LLM) and Generative AI models have emerged and impacted industry and society. LLMs are Artificial intelligence (AI) systems designed to understand and generate human language. The rise in popu-1arity of LLM-based systems has motivated research into their use in education, including code generation tools, automated feedback systems, and support for student software projects. The release of ChatGPT™ marked a significant milestone, providing an accessible tool for IA interaction. ChatGPT™ has gained popularity among students, not only in software areas. This study analyzes the perspectives of software engineering students and software engineers on using LLM tools such as ChatGPT™ for software development projects. In this study, we use a questionnaire to analyze different viewpoints and graphics to show the experiment results between these groups. The findings of this study are expected to provide valuable contributions to the understanding of how LLM tools are perceived in the context of software development and their potential implications for educational practices and industry standards.","","979-8-3315-3211-6","10.1109/CONISOFT63288.2024.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795589","Programming Education;Generative AI;Large Language Models;Software Engineering","Industries;Graphics;Technological innovation;Generative AI;Large language models;Software;Standards;Programming profession;Software engineering;Software development management","","","","17","IEEE","18 Dec 2024","","","IEEE","IEEE Conferences"
"Exploring the Potential of Llama Models in Automated Code Refinement: A Replication Study","G. Caumartin; Q. Qin; S. Chatragadda; J. Panjrolia; H. Li; D. E. Costa","Dept of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Dept of Computer Engineering and Software Engineering, Polytechnique Montreal, Montreal, Canada; Dept of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Dept of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Dept of Computer Engineering and Software Engineering, Polytechnique Montreal, Montreal, Canada; Dept of Computer Science and Software Engineering, Concordia University, Montreal, Canada","2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","21 May 2025","2025","","","681","692","Code reviews are an integral part of software development and have been recognized as a crucial practice for minimizing bugs and favouring higher code quality. They serve as an important checkpoint before committing code and play an essential role in knowledge transfer between developers. However, code reviews can be time-consuming and can stale the development of large software projects. In a recent study, Guo et al. assessed how ChatGPT3.5 can help the code review process. They evaluated the effectiveness of ChatGPT in automating the code refinement tasks, where developers recommend small changes in the submitted code. While Guo et al.'s study showed promising results, proprietary models like ChatGPT pose risks to data privacy and incur extra costs for software projects. In this study, we explore alternatives to ChatGPT in code refinement tasks by including two open-source, smaller-scale large language models: CodeLlama and Llama 2 (7B parameters). Our results show that, if properly tuned, the Llama models, particularly CodeLlama, can achieve reasonable performance, often comparable to ChatGPT in auto-mated code refinement. However, not all code refinement tasks are equally successful: tasks that require changing existing code (e.g., refactoring) are more manageable for models to automate than tasks that demand new code. Our study highlights the potential of open-source models for code refinement, offering cost-effective, privacy-conscious solutions for real-world software development.","2640-7574","979-8-3315-3510-0","10.1109/SANER64311.2025.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992366","code review;large language models;software engineering","Temperature measurement;Data privacy;Codes;Reviews;Large language models;Documentation;Chatbots;Software;Data models;Software development management","","","","54","IEEE","21 May 2025","","","IEEE","IEEE Conferences"
