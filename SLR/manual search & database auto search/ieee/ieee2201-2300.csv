"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Fingerprint Networked Reinforcement Learning via Multiagent Modeling for Improving Decision Making in an Urban Food–Energy–Water Nexus","W. Zhang; A. Valencia; N. -B. Chang","R&D Division, Operation Technology (ETAP), Irvine, CA, USA; Department of Civil, Environmental, Construction Engineering, University of Central Florida, Orlando, FL, USA; Department of Civil, Environmental, Construction Engineering, University of Central Florida, Orlando, FL, USA","IEEE Transactions on Systems, Man, and Cybernetics: Systems","15 Jun 2023","2023","53","7","4324","4338","Food–energy–water (FEW) nexus analyses are critical to sustainable development. Nexus analyses form a unique multiagent decision-making arena that requires using a system engineering approach to simultaneously improve food and water security as well as energy efficiency. To tackle the complexity in decision making within a FEW nexus with respect to dynamic behaviors and interactive logics, we model the FEW nexus as a multiagent system (MAS) under a mixed competitive and cooperative environment from the perspective of a Markov game. Then, we propose a fingerprint networked reinforcement learning (FNRL) framework for the collective learning of a MAS by following the logic flows of human decision making. FNRL can alleviate the problems caused by stationary issues in a MAS environment by integrating a long short-term-memory-driven neural network model into the context of multiagent reinforcement learning (RL) to extract fingerprint information via historical data. Numerical simulations for an urban FEW nexus analysis in Florida (USA) demonstrate that applying the FNRL framework can drive agents in the MAS toward achieving optimality via RL in a dynamic environment.","2168-2232","","10.1109/TSMC.2023.3250620","National Science Function(grant numbers:1830036); Florida Department of Environmental Protection(grant numbers:INV008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070569","Decision making;fingerprint networked reinforcement learning (FNRL);food–energy–water (FEW) nexus;long short-term memory (LSTM) network;multiagent system (MAS)","Decision making;Games;Training;Sustainable development;Analytical models;Optimization;Numerical models","","2","","36","IEEE","14 Mar 2023","","","IEEE","IEEE Journals"
"FhGenie: A Custom, Confidentiality-Preserving Chat AI for Corporate and Scientific Use","I. Weber; H. Linka; D. Mertens; T. Muryshkin; H. Opgenoorth; S. Langer","Fraunhofer Society. Headquarters, Munich, Germany; Fraunhofer Society. Headquarters, Munich, Germany; Fraunhofer Society. Headquarters, Munich, Germany; Fraunhofer Society. Headquarters, Munich, Germany; Fraunhofer Society. Headquarters, Munich, Germany; Fraunhofer Society. Headquarters, Munich, Germany",2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C),"21 Aug 2024","2024","","","26","31","Since OpenAI's release of ChatGPT, generative AI has received significant attention across various domains. These AI-based chat systems have the potential to enhance the productivity of knowledge workers in diverse tasks. However, the use of free public services poses a risk of data leakage, as service providers may exploit user input for additional training and optimization without clear boundaries. Even subscription-based alternatives sometimes lack transparency in handling user data. To address these concerns and enable Fraunhofer staff to leverage this technology while ensuring confidentiality, we have designed and developed a customized chat AI called FhGenie (genie being a reference to a helpful spirit). Within few days of its release, thousands of Fraunhofer employees started using this service. As pioneers in implementing such a system, many other organizations have followed suit. Our solution builds upon commercial large language models (LLMs), which we have carefully integrated into our system to meet our specific requirements and compliance constraints, including confidentiality and GDPR. In this paper, we share detailed insights into the architectural considerations, design, implementation, and subsequent updates of FhGenie. Additionally, we discuss challenges, observations, and the core lessons learned from its productive usage.","2768-4288","979-8-3503-6625-9","10.1109/ICSA-C63560.2024.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628294","software architecture;practical experience;artificial intelligence;chatbot;LLM;enterprise;production system;GPT;ChatGPT;Azure;OpenAI","Training;Productivity;Software architecture;Generative AI;Large language models;Organizations;Chatbots","","2","","13","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Working Alongside Non-Human Agents","A. H. Duin; I. Pedersen","Writing Studies Department, College of Liberal Arts, University of Minnesota, Minneapolis, USA; Writing Studies Department, College of Liberal Arts, University of Minnesota, Minneapolis, USA",2021 IEEE International Professional Communication Conference (ProComm),"13 Jun 2022","2021","","","1","5","We coexist with non-human AI agents, and we now must plan for human and non-human-agent teaming, for cooperation and collaboration, as a means to expand collaborative intelligence in our ongoing quest for user advocacy. For practice and experimentation, we provide links to current non-human agents. We then distinguish automation and autonomy, and discuss humanness design, teaming. A deeper understanding of usability and ethical considerations for working alongside these systems, deploying robots and building bonds and trust with nonhuman agents, begins with differentiation of automation and autonomy, human-autonomy teaming, and a humanness design approach as a means to prevent undesirable autonomy. While TPC scholarship attends to privacy, accountability, safety and security, and transparency and explainability, we need additional vigilance regarding fairness and non-discrimination, human control of technology, TPC professional responsibility, and continued promotion of human values as we work alongside non-human agents.","2158-1002","978-1-6654-4327-2","10.1109/ProComm52174.2021.00005","Canada Research Chairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793412","artificial intelligence;autonomous agents;collaboration;non-human agents","Automation;Scholarships;Collaboration;Safety;Security;Artificial intelligence;Usability","","","","28","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"Language Models in Software Development Tasks: An Experimental Analysis of Energy and Accuracy","N. Alizadeh; B. Belchev; N. Saurabh; P. Kelbert; F. Castor","Utrecht University, Utrecht, The Netherlands; University of Twente, Enschede, The Netherlands; Utrecht University, Utrecht, The Netherlands; Fraunhofer IESE, Kaiserslautern, Germany; University of Twente, Enschede, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","725","736","The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development. Many of these tools are provided as remote APIs. Using third-party APIs raises data privacy and security concerns for client companies, which motivates the use of locallydeployed language models. In this study, we explore the tradeoff between model accuracy and energy consumption, aiming to provide valuable insights to help developers make informed decisions when selecting a language model. We investigate the performance of 18 families of LLMs in typical software development tasks on two real-world infrastructures, a commodity GPU and a powerful AI-specific GPU. Given that deploying LLMs locally requires powerful infrastructure which might not be affordable for everyone, we consider both full-precision and quantized models. Our findings reveal that employing a big LLM with a higher energy budget does not always translate to significantly improved accuracy. Additionally, quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized ones. Apart from that, not a single model is suitable for all types of software development tasks.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025589","LLMs;Energy Efficiency;Trade-Offs;Software Development;Coding Assistant;Model Quantization","Energy consumption;Analytical models;Accuracy;Translation;Graphics processing units;Predictive models;Energy efficiency;Encoding;Software reliability;Software development management","","","","56","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"A Cross-Layer Approach to Energy-Efficient and Secure EdgeAI: Architectures, Systems and Applications","M. Shafique","NYU Abu Dhabi, United Arab Emirates",2024 5th CPSSI International Symposium on Cyber-Physical Systems (Applications and Theory) (CPSAT),"11 Nov 2024","2024","","","1","1","Modern Machine Learning (ML) and Artificial Intelligence (AI) approaches, such as, the Deep Neural Networks (DNNs) and Large Language Models (LLMs), have shown tremendous improvement over the past years to achieve a significantly high accuracy for a certain set of tasks, like image classification, object detection, natural language processing, medical data analytics, and generative AI. However, these DNNs/LLMs require huge processing, memory, and energy costs, thereby posing gigantic challenges on building energy-efficient tinyML and EdgeAI solutions for a wide range of applications from Smart Cyber Physical Systems (CPS) and Internet of Thing (IoT) domains on resource/energy-constrained devices subjected to unpredictable and harsh scenarios. Moreover, in the era of growing cyber-security threats and nano-scale devices, the intelligent features of a smart CPS and IoT system face new type of attacks and reliability threats, requiring novel design principles for robust ML.In my eBRAIN lab at New York University (AD, US), I have been extensively investigating the foundations for the next-generation energy efficient, dependable and secure AI/ML computing systems, while addressing the above-mentioned challenges across different layers of the hardware and software stacks. This talk will present design challenges, advanced techniques and cross-layer frameworks for building highly energy-efficient and robust cognitive systems for the tinyML and EdgeAI applications, which jointly leverage optimizations at different layers of the software and hardware stacks, and at different design stages (e.g., design-time vs. run-time approaches). These techniques provide crucial steps towards enabling the wide-scale deployment of energy-efficient and secure embedded AI in autonomous systems like UAVs, UGVs, autonomous vehicles, Robotics, IoT-Healthcare / Wearables, Industrial-IoT, smart transportation, smart homes and cities, etc. Towards the end, I will show some glimpses of our recent advanced projects on Quantum Machine Learning, Continual Learning, and Multimodal LLMs.","2833-7514","979-8-3315-2928-4","10.1109/CPSAT64082.2024.10745418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10745418","","Cross layer design;Tiny machine learning;Urban areas;Energy efficiency;Hardware;Software;Software reliability;Smart transportation;Internet of Things;Wearable devices","","3","","0","IEEE","11 Nov 2024","","","IEEE","IEEE Conferences"
"Securing Rag: A Risk Assessment and Mitigation Framework","L. Ammann; S. Ott; C. R. Landolt; M. P. Lehmann","Eastern Switzerland University of Applied Sciences (OST), Rapperswil, Switzerland; Eastern Switzerland University of Applied Sciences (OST), Rapperswil, Switzerland; Eastern Switzerland University of Applied Sciences (OST), Rapperswil, Switzerland; Eastern Switzerland University of Applied Sciences (OST), Rapperswil, Switzerland",2025 IEEE Swiss Conference on Data Science (SDS),"18 Jul 2025","2025","","","127","134","Retrieval Augmented Generation (RAG) has emerged as the de facto industry standard for user-facing NLP applications, offering the ability to integrate data without retraining or fine-tuning Large Language Models (LLMs). This capability enhances the quality and accuracy of responses but also introduces novel security and privacy challenges, particularly when sensitive data is integrated. With the rapid adoption of RAG, securing data and services has become a critical priority. This paper first reviews the vulnerabilities of RAG pipelines, and outlines the attack surface from data pre-processing and data storage management to integration with LLMs. The identified risks are then paired with corresponding mitigations in a structured overview. In a second step, the paper develops a framework that combines RAG-specific security considerations, with existing general security guidelines, industry standards, and best practices. The proposed framework aims to guide the implementation of robust, compliant, secure, and trustworthy RAG systems.","2835-3420","979-8-3315-9467-1","10.1109/SDS66131.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081501","Large Language Model (LLM);RetrievalAugmented Generation (RAG);RAG Systems Security;Secure Data Retrieval;AI System Vulnerabilities","Industries;Accuracy;Prevention and mitigation;Large language models;System performance;Retrieval augmented generation;Vectors;Security;Standards;Guidelines","","","","65","IEEE","18 Jul 2025","","","IEEE","IEEE Conferences"
"AI-driven Natural Language Processing: ChatGPT's Potential and Future Advancements in Generative AI","H. Kumar; M. Damle; N. A. Natraj; A. A. Afzal; M. Lapina","Symbiosis Institute of Digital and Telecom Management Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Digital and Telecom Management Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Digital & Telecom Management, Symbiosis International (Deemed University), Pune, India; College of Engineering, Prince Mohammad Bin Fahd University, Al-Khobar, Saudi Arabia; Institute of Digital Development North-Caucasus Federal University, Stavropol, Russia",2024 6th International Symposium on Advanced Electrical and Communication Technologies (ISAECT),"19 Dec 2024","2024","","","1","6","This research paper delves into the operational mechanisms, strengths, and future potential of ChatGPT, an intelligent chatbot developed by OpenAI. ChatGPT's architecture, rooted in the transformer model, enables it to generate contextually relevant text using attention mechanisms and tokenisation. While excelling in generative capability and versatility, the paper highlights challenges, including context understanding and sensitivity to phrasing, sparking discussions on refinement strategies. The study explores opportunities for efficient, prompt engineering, emphasising tokenization strategies to optimise interactions within ChatGPT's token limits. Future advancements envision enhanced context understanding, reduced sensitivity to phrasing, and ethical considerations, addressing verbosity and response diversity concerns. A comparative analysis with competing models like Google's Bard and Meta's LLaMA provides insights into their architectures, parameters, strengths, weaknesses, and target use cases. The paper concludes by emphasising ChatGPT's transformative impact on AI, shaping a future marked by interdisciplinary applications, ethical considerations, and user-centric design.","","979-8-3315-2998-7","10.1109/ISAECT64333.2024.10799591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10799591","ChatGPT;natural language processing (NLP);language models;transformative AI;open AI;AI chatbot","Ethics;Sensitivity;Chatbots;Transformers;Tokenization;Communications technology;Trajectory;Internet;Prompt engineering;Context modeling","","","","23","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Mari: Automating Responses to Thai Legal Debt Queries Using Generative AI and Retrieval-Augmented Generation","T. Nethassanai; N. Seehabong; S. Roteaim; P. Mongkolnam; B. Watanapa","School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; School of Information Technology, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand","2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","8 Aug 2025","2025","","","1","6","Over the years, there have been lots of reports that point out the problems of Thailand’s high personal debt levels. With limited public knowledge of legal debt rights, these problems result in right violation between the creditors and debtors. Mari is designed to address such issues. It is an AI-powered system that offers automated legal consultations pertaining to the Thai Debt Collection Act of 2015. Main focus is on aiding creditors, debtors, or any individual, to understand their rights which contribute a boon of addressing information gaps, and enhancing accessibility to legal knowledge without requiring costly consultations. Mari is a website that uses a large language model (LLM) with integrated Retrieval-Augmented Generation (RAG) to ensure the precise responses for the required scope and semantics of the concerned legal statute. In order to achieve the effectiveness of these responses, we considered several LLM models, namely OpenThaiGPT, Typhoon, and SambaNova under the evaluation based on a set of human-generated multiple-choice and open-end questions. The comparison score showed that SambaNova’s LLM, with English prompt engineering, was the best for this case. Lastly the semantic difference, representing the level of hallucination effect, of the final model is measured by the BERT score with satisfaction of 0.726.","2837-6471","979-8-3315-2223-0","10.1109/ECTI-CON64996.2025.11101123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101123","legal;chatbot;LLM;RAG;Thai Debt Collection Act","Law;Tropical cyclones;Large language models;Computational modeling;Semantics;Retrieval augmented generation;Chatbots;Telecommunications;Prompt engineering;Information technology","","","","17","IEEE","8 Aug 2025","","","IEEE","IEEE Conferences"
"Examining the Accuracy of AI Detection Software Tools in Education","M. Halaweh; G. E. Refae","College of Business, Al Ain University, Al Ain, UAE; College of Business, Al Ain University, Al Ain, UAE",2024 Fifth International Conference on Intelligent Data Science Technologies and Applications (IDSTA),"12 Nov 2024","2024","","","186","190","Educators have raised concerns about the utilization of ChatGPT in generating unoriginal text and the possibility of plagiarism. To address these concerns, various AI text detection software tools have been developed to evaluate whether a text is AI generated or human generated. The aim of this research is to empirically examine the accuracy of AI detection tools in identifying AI-generated texts. An experiment was conducted using textual data generated by ChatGPT, which was assessed using Turnitin and four other AI detection tools. Through multiple iterations and interventions, the text was paraphrased by ChatGPT until it appeared original and could not be detected as AI-generated by Turnitin’s AI detection tool. The findings revealed that all the AI detection software tools that were examined failed to detect the AI-generated text by ChatGPT in the final iteration. The findings provide valuable insights that have implications for various stakeholders, including educators, researchers, and AI text detection software developers. Based on the tools examined, educators and researchers do not need to set a specific threshold or percentage, including 0%, to determine what qualifies as acceptable AI-generated text. This is because establishing such a threshold can be misleading, considering the current limitations in the algorithms of these tools. Furthermore, the data generated in this paper can provide a solid basis for replicated research or software testing and assessment. It can be utilized to evaluate the accuracy of alternative AI detection tools and any future advancements in the tools mentioned in this investigation.","","979-8-3503-5475-1","10.1109/IDSTA62194.2024.10747004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10747004","Artificial Intelligence;Education;Generative AI;AI Detection Tools;Turnitin;ChatGPT","Software testing;Accuracy;Plagiarism;Software algorithms;Text detection;Chatbots;Solids;Stakeholders;Artificial intelligence;Software tools","","2","","21","IEEE","12 Nov 2024","","","IEEE","IEEE Conferences"
"Few-Shot Evaluation of Vision Language Models for Detecting Visual Defects in Autonomous Vehicle Software Requirement Specifications","N. Bukhary; M. Ahmad; K. Rashad; S. Rai; S. Shapsough; Y. Kaddoura; D. Dghaym; I. Zualkernan","Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",IEEE Access,"11 Jul 2025","2025","13","","117914","117942","Software Requirements Specifications (SRS) are crucial for defining system functionality, constraints, and objectives, particularly in safety-critical applications like autonomous vehicles (AV). Ensuring these requirements are precise, unambiguous, and complete is important for developing reliable self-driving systems. While traditional SRS are predominantly text-based, AV requirements pose unique challenges as they often include visual elements such as images and diagrams. Although Large Language Models (LLMs) have enhanced traditional text-based requirements, Vision-Language Models (VLMs) remain largely unexplored for evaluating defects in visual elements. This paper investigates the few-shot performance of three large-scale VLMs on their ability to detect various types of ambiguities, inconsistencies, and incompleteness in visual traffic scenario images that could be used in AV requirements specifications. Using Soft prompting and Chain-of-Thought (CoT) prompting, we evaluated the effectiveness of GPT-4, GEMINI, and ClaudeAI in detecting six types of visual defects. GPT-4 achieved the highest overall performance among the evaluated models, with the highest F1-score of 0.63 in detecting Spatial Incompleteness. CoT prompting notably enhanced defect detection performance for both GEMINI and ClaudeAI across all defect types. While CoT prompting did not significantly improve GPT-4’s detection capabilities, it significantly enhanced the ability of all models to explain the reasoning behind the identified defects. Despite promising results, none of the models could fully automate the requirements validation process, primarily due to their lack of domain-specific knowledge. Nevertheless, our findings suggest that fine tuning the models and structured prompt design offer the potential to improve VLM precision in visual defect detection.","2169-3536","","10.1109/ACCESS.2025.3586554","Open Access Program from the American University of Sharjah; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072138","Ambiguity;ClaudeAI;completeness;defects;GEMINI;GPT;inconsistency;vision language models (VLMs);requirements engineering;software engineering;software requirements specifications (SRS)","Visualization;Stakeholders;Software;Unified modeling language;Requirements engineering;Defect detection;Software engineering;Software development management;Safety;Complexity theory","","","","91","CCBY","7 Jul 2025","","","IEEE","IEEE Journals"
"MACoMal: A Multi-Agent Based Collaborative Mechanism for Anti-Malware Assistance","M. Belaoued; A. Derhab; S. Mazouzi; F. A. Khan","Software Technologies and Information Systems Department, LIRE Laboratory, University of Constantine 2, Constantine, Algeria; Center of Excellence in Information Assurance (COEIA), King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, Université 20 Août 1955-Skikda, Skikda, Algeria; Center of Excellence in Information Assurance (COEIA), King Saud University, Riyadh, Saudi Arabia",IEEE Access,"24 Jan 2020","2020","8","","14329","14343","Anti-malware tools remain the primary line of defense against malicious software. There is a wide variety of commercial anti-malware tools in the IT security market. However, no single tool is able to provide a full protection against the overwhelming number of daily released malware. Hence, collaboration among malware detection tools is of paramount importance. In this paper, we propose MACoMal, a multi-agent based decision mechanism, which assists heterogeneous anti-malware tools to collaborate with each other in order to reach a consensual decision about the maliciousness of a suspicious file. MACoMal consists of two main elements: (1) an executable file identification model, and (2) a collaborative decision-making scheme. MACoMal is analyzed with respect to network connectivity and global decision correctness. By leveraging a multi-agent simulation tool and a set of real malware samples, we present a simulation methodology to assess its effectiveness and efficiency. Experimental results show that MACoMal is able to immunize a network against a malware threat within a time that ranges from a few seconds to a few minutes after the threat detection.","2169-3536","","10.1109/ACCESS.2020.2966321","King Saud University(grant numbers:RG-1439-021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957477","Malware;anti-malware assistance;multi-agent systems;modelling;analysis;simulation;collaboration","Malware;Tools;Collaboration;Decision making;Security;Multi-agent systems;Computer architecture","","13","","44","CCBY","13 Jan 2020","","","IEEE","IEEE Journals"
"About the Problems of Ensuring Information Security on Unmanned Ships","I. S. Shipunov; K. S. Voevodskiy; A. P. Nyrkov; Y. F. Katorin; Y. A. Gatchin","Chair of Complex Provision of Information Security, Admiral Makarov State University of Maritime and Inland Shipping, St. Petersburg, Russia; Chair of Complex Provision of Information Security, Admiral Makarov State University of Maritime and Inland Shipping, St. Petersburg, Russia; Chair of Complex Provision of Information Security, Admiral Makarov State University of Maritime and Inland Shipping, St. Petersburg, Russia; Chair of Complex Provision of Information Security, Admiral Makarov State University of Maritime and Inland Shipping, St. Petersburg, Russia; Faculty of Information Technology Security, Saint-Petersburg National Research University of Information Technologies, Mechanics and Optics, St. Petersburg, Russia",2019 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus),"3 Mar 2019","2019","","","339","343","This paper assesses cyber risks on crewless vessels. Projects of crewless vessels AAWA, MAS, YARA are considered. The list of risks is formed on the basis of the analysis of systems of traditional vessels.","2376-6565","978-1-7281-0339-6","10.1109/EIConRus.2019.8657219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657219","crewless vessels;cyber risks;risk assessment;Rolls-Royce AAWA;YARA Birkeland;Mayflower Autonomous Ship","Marine vehicles;Sensor systems;Cyberattack;Companies;Automation;Cameras","","10","","10","IEEE","3 Mar 2019","","","IEEE","IEEE Conferences"
"Leveraging Natural Language Processing for a Consistency Checking Toolchain of Automotive Requirements","V. Bertram; H. Kausch; E. Kusmenko; H. Nqiri; B. Rumpe; C. Venhoff","Software Engineering, RWTH Aachen University, Aachen, Germany; Software Engineering, RWTH Aachen University, Aachen, Germany; Software Engineering, RWTH Aachen University, Aachen, Germany; Software Engineering, RWTH Aachen University, Aachen, Germany; Software Engineering, RWTH Aachen University, Aachen, Germany; Software Engineering, RWTH Aachen University, Aachen, Germany",2023 IEEE 31st International Requirements Engineering Conference (RE),"28 Sep 2023","2023","","","212","222","In the automotive industry, specifications often consist of a large number of textual requirements. These requirements are linguistically ambiguous and written in informal language. Utilizing Structured English for requirements eliminates ambiguity, improves data quality, and supports further automated processing while maintaining readability. The recent development of large language models enables a fully automated translation approach using few-shot learning. To deal with the limited context size of large language models, an improved algorithm, OptKATE, is presented to find an ideal set of requirements for few-shot learning. Structured English can be used as a basis for further formalization. This capability is key in creating an interface between natural language processing and verification, in our case, consistency analysis using the Z3 SMT solver. We implemented a grammar for translating Structured English into TCTL using the MontiCore workbench. Furthermore, since SMT-based methods currently rely on manual precondition satisfaction and do not tackle conflicting preconditions automatically, we propose a scenario generation algorithm that generates potential scenarios using the specification and checks the requirements against them. Through this approach, we can better identify and resolve conflicting preconditions, ultimately improving the consistency of requirements. Our toolchain is evaluated using an automotive requirements dataset provided by former Daimler AG.","2332-6441","979-8-3503-2689-5","10.1109/RE57278.2023.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260788","Classification;Natural Language Processing (NLP);Neural Networks;Requirements Engineering","Industries;Data integrity;Manuals;Natural language processing;Grammar;Requirements engineering;Automotive engineering","","8","","34","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"CAL: A Smart Home Environment for Monitoring Cognitive Decline","E. M. Fredericks; K. M. Bowers; K. A. Price; R. H. Hariri","Department of Computer Science and Engineering, Oakland University, USA; Department of Communication Studies, Albion College, USA; Department of Computer Science and Engineering, Oakland University, USA; Department of Computer Science and Engineering, Oakland University, USA",2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS),"23 Jul 2018","2018","","","1500","1506","The increased growth of the aging population (i.e., 65 years or older) has led to emerging technologies in health care that provide in-home support to patients using devices throughout the household. Such smart home environments can monitor and interact with patients and their doctors/caregivers to augment patient medical data for diagnosis than can be generated via traditional doctor visits. Moreover, smart homes are enabling older adults to stay at home longer as opposed to permanent moves to assisted living or nursing facilities, increasing health and well-being and decreasing overall costs to the individual and society at large. This paper proposes Cognitive Assisted Living (CAL), a cyber-physical system comprising a network of embedded devices for collecting and analyzing patient speech patterns over time for monitoring cognitive function beginning in the early stages of Alzheimer's disease. Specifically, CAL will analyze patient speech patterns and spatial abilities, via a set of daily interactions, to provide a longitudinal analysis of speech deterioration, a significant indicator of cognitive decline resulting from Alzheimer's disease. Understanding the rate of cognitive decline can enable caregivers and health care professionals to better manage the patient's daily care and medical requirements. Additionally, the patient's cognitive state can be shared across household devices to increase the patient's comfort and better accommodate lifestyle changes. To these ends, we describe the architecture of the proposed system, the methods to which we will detect cognitive decline, and specify how the system will provide continuing fault tolerance and data security at run time.","2575-8411","978-1-5386-6871-9","10.1109/ICDCS.2018.00155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416418","smart home;multi-agent systems;cyber-physical systems;health care;software engineering","Dementia;Monitoring;Smart homes;Biomedical monitoring;Natural language processing","","7","","35","IEEE","23 Jul 2018","","","IEEE","IEEE Conferences"
"Seeking Secure Adaptive Distributed Discrete-Time Observer for Networked Agent Systems Under External Cyber Attacks","W. Li; R. Ren; M. Shi; B. Lin; K. Qin","School of Aeronautics and Astronautics, and the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, and the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, and the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, and the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, and the Aircraft Swarm Intelligent Sensing and Cooperative Control Key Laboratory of Sichuan Province, University of Electronic Science and Technology of China, Chengdu, China",IEEE Transactions on Consumer Electronics,"17 Jun 2025","2025","71","1","918","930","In the era of Industry 5.0, the cooperation among components in Cyber-Physical Systems (CPS) plays a crucial role in achieving digital transformation and intelligent development. Distributed observers can simplify the design complexity of cooperative control schemes in intelligent networked industrial systems. However, the open nature of the information exchange network in these systems makes them vulnerable to cyber attacks. With this in mind, this paper designs a discrete-time secure adaptive distributed observer for networked agent systems under Denial of Service (DoS) attacks. The observer enables agents to monitor reference state information effectively, even when the system matrix is globally unknown and unstable. To enhance security, we propose adaptive secure update rules that respond to compromised communication links, ensuring the ability of the observer to generate reference trajectories during DoS attacks. Furthermore, sufficient algebraic conditions are obtained for the convergence of the proposed observer, employing the analysis approach based on infinite products of sub-stochastic matrices. Finally, some numerical simulation results are provided to verify the effectiveness of the proposed secure adaptive distributed observer.","1558-4127","","10.1109/TCE.2025.3535083","Natural Science Foundation of Sichuan Province(grant numbers:2024NSFSC0021); Sichuan Science and Technology Programs(grant numbers:2024NSFSC0021,MZGC20240139); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10855513","Networked industry systems;multi-agent systems;adaptive distributed observer;denial-of-service attacks;general linear dynamics","Observers;Adaptive systems;Denial-of-service attack;Complexity theory;Eigenvalues and eigenfunctions;Cyberattack;Vehicle dynamics;Trajectory;Topology;Switches","","7","","50","IEEE","27 Jan 2025","","","IEEE","IEEE Journals"
"An exact penalty method for constrained distributed optimization","H. Zhou; X. Zeng; Y. Hong","Key Laboratory of Systems and Control, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Systems and Control, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Systems and Control, Chinese Academy of Sciences, Beijing, China",2017 36th Chinese Control Conference (CCC),"11 Sep 2017","2017","","","8827","8832","This paper focuses on a distributed non-smooth constrained optimization problem, in which the non-smoothness means the continuity but non-differentiability. Distributed optimization deals with optimizing a sum of objective functions, each function is known by one agent due to many reasons such as privacy and security. And all the agent reach an global optimal by communicating through an interaction graph. We proposed an exact penalty algorithm for constrained distributed optimization, which has some good properties when we design a continuous-time algorithm. Then we rigorously prove the efficiency of this method. We also put a numerical example to show the efficacy of the proposed algorithm.","1934-1768","978-988-15639-3-4","10.23919/ChiCC.2017.8028760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8028760","Exact penalty method;distributed algorithm;non-smooth optimization;continuous-time multi-agent systems","Optimization;Algorithm design and analysis;Linear programming;Laplace equations;Newton method;Graph theory;Upper bound","","6","","26","","11 Sep 2017","","","IEEE","IEEE Conferences"
"Distributed Policy Synthesis of Multiagent Systems With Graph Temporal Logic Specifications","M. Cubuktepe; Z. Xu; U. Topcu","Department of Aerospace Engineering and Engineering Mechanics, and the Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin, Austin, TX, USA; School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; Department of Aerospace Engineering and Engineering Mechanics, and the Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin, Austin, TX, USA",IEEE Transactions on Control of Network Systems,"17 Dec 2021","2021","8","4","1799","1810","We study the distributed synthesis of policies for multiagent systems to perform spatial–temporal tasks. We formalize the synthesis problem as a factored Markov decision process subject to graph temporal logic specifications. The transition function and the task of each agent are functions of the agent itself and its neighboring agents. In this work, we develop another distributed synthesis method, which improves the scalability and runtime by two orders of magnitude compared to our prior work. The synthesis method decomposes the problem into a set of smaller problems, one for each agent by leveraging the structure in the model, and the specifications. We show that the running time of the method is linear in the number of agents. The size of the problem for each agent is exponential only in the number of neighboring agents, which is typically much smaller than the number of agents. We demonstrate the applicability of the method in case studies on disease control, urban security, and search and rescue. The numerical examples show that the method scales to hundreds of agents with hundreds of states per agent and can also handle significantly larger state spaces than our prior work.","2325-5870","","10.1109/TCNS.2021.3084553","Office of Naval Research(grant numbers:N00014-19-1-2054); National Science Foundation(grant numbers:1646522,1652113); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442919","Cyber-physical systems;multi-agent systems;networked control systems;optimization","Cyber-physical systems;Networked control systems;Multi-agent systems;Optimization","","3","","40","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"Minimal Schedule with Minimal Number of Agents in Attack-Defence Trees","J. Arias; L. Petrucci; Ł. Maśko; W. Penczek; T. Sidoruk","LIPN, CNRS UMR 7030, Universite Sorbonne Paris Nord, Villetaneuse, France; LIPN, CNRS UMR 7030, Universite Sorbonne Paris Nord, Villetaneuse, France; Polish Academy of Sciences, Institute of Computer Science; Polish Academy of Sciences, Institute of Computer Science; Polish Academy of Sciences, Institute of Computer Science",2022 26th International Conference on Engineering of Complex Computer Systems (ICECCS),"3 May 2022","2022","","","1","10","Expressing attack-defence trees in a multi-agent setting allows for studying a new aspect of security scenarios, namely how the number of agents and their task assignment impact the performance, e.g. attack time, of strategies executed by opposing coalitions. Optimal scheduling of agents' actions, a non-trivial problem, is thus vital. We discuss associated caveats and propose an algorithm that synthesises such an assignment, targeting minimal attack time and using minimal number of agents for a given attack-defence tree.","","978-1-6654-0162-3","10.1109/ICECCS54210.2022.00009","MoSART, and of NCBR Poland and FNR Luxembourg(grant numbers:POLLUX-VII/l/2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763747","attack-defence trees;multi-agent systems;scheduling","Schedules;Costs;Scheduling algorithms;Optimal scheduling;Encoding;Security;Task analysis","","2","","25","IEEE","3 May 2022","","","IEEE","IEEE Conferences"
"Cooperative Multi-Agent Jamming of Multiple Rogue Drones Using Reinforcement Learning","P. Valianti; K. Malialis; P. Kolios; G. Ellinas","KIOS Research and Innovation Center of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus; KIOS Research and Innovation Center of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus; KIOS Research and Innovation Center of Excellence (KIOS CoE) and the Department of Computer Science, University of Cyprus, Nicosia, Cyprus; KIOS Research and Innovation Center of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus",IEEE Transactions on Mobile Computing,"6 Nov 2024","2024","23","12","12345","12359","The wide adoption and use of unmanned aerial vehicles (UAVs) has created not only opportunities but also threats to the security of sensitive areas. Thus, effective and efficient counter-drone systems are required to protect these areas. This work tackles this issue by developing cooperative multi-agent jamming techniques using reinforcement learning (RL) to counter the operation of one or multiple rogue drones flying over a sensitive area. The aim of the proposed RL approach is to optimize the joint mobility and power control actions of the pursuer UAVs in order to maximize the received jamming power at the rogue drones aiming at disrupting communication links and sensing circuitry, while at the same time keeping the interference to surrounding pursuer agents below a predefined threshold. The effectiveness of the proposed approach in terms of scalability, learning speed, and agents’ final joint performance is demonstrated through extensive simulation experiments for various agent and target configurations.","1558-0660","","10.1109/TMC.2024.3409050","European Union's Horizon 2020 research and innovation program(grant numbers:101017258,739551); Deputy Ministry of Research, Innovation and Digital Policy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547296","Multi-agent systems;jamming;reinforcement learning;q-learning;optimization","Drones;Jamming;Autonomous aerial vehicles;Radar tracking;Scalability;Radio frequency;Sensors","","1","","54","IEEE","4 Jun 2024","","","IEEE","IEEE Journals"
"iConPAL: LLM-guided Policy Authoring Assistant for Configuring IoT Defenses","M. Alam; S. Zhang; E. Rodriguez; A. Nafis; E. Hoque","Syracuse University, NY, USA; Syracuse University, NY, USA; Syracuse University, NY, USA; Syracuse University, NY, USA; Syracuse University, NY, USA",2024 IEEE Secure Development Conference (SecDev),"30 Oct 2024","2024","","","76","92","Safety and security concerns surrounding Internet-of-Things (IoT) platforms for smart homes have spurred the development of defense mechanisms to safeguard against unexpected behaviors in accordance with safety and security policies. However, the need to manually craft policies in tool-specific languages increases the burden on humans. Previous attempts to address this issue have fallen short, either lacking portability or requiring human intervention in other forms. Therefore, in this paper, we propose iConPAL, an automated policy authoring assistant for IoT environments. iConPAL accepts a policy description in natural language (English) and translates it into a specific formal policy language. iConPAL leverages the capabilities of modern large language models (LLMs), employs prompt engineering to automatically generate few-shot learning prompts for the LLM, and post-processes the LLM’s response to ensure the validity of the translated policy. We implemented a prototype of iConPAL and evaluated it on our curated dataset of 290 policies. We observed that iConPAL successfully translated 93.61% policies, of which 93.57% were semantically correct. iConPAL’s high accuracy makes it suitable for assisting ordinary users in drafting policies for smart homes.","","979-8-3503-9193-0","10.1109/SecDev61143.2024.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734044","Index Terms—IoT Security;Policy Authoring and Enforcement","Accuracy;Large language models;Prototypes;Smart homes;Safety;Security;Prompt engineering;Indexes;Few shot learning","","","","56","IEEE","30 Oct 2024","","","IEEE","IEEE Conferences"
"A generic framework for a Peer to Peer Blockchain based Fog Architecture in Industrial Automation","E. N. Lallas; A. Xenakis; G. Stamoulis","University of Thessaly, Lamia, Greece; University of Thessaly, Lamia, Greece; University of Thessaly, Lamia, Greece","2019 4th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)","21 Nov 2019","2019","","","1","5","Industrial Internet of things (IIoT) is referred exclusively to smart and cheap sensor based devices lying on top of machines or machine parts, to collect and process massive raw data and therefore to make intelligent decisions autonomously, without human intervention, according to the Industry 4.0 requirements. However, there are still challenges to address, such as the massive amount of data generated in high speeds and the fast processing requirements and also challenges in the security domain, such as data integrity and ID authentication. Currently decentralized IoT/Fog network architectures would come in handy, in order to release data processing “burden” from isolated Cloud servers. On the other hand, Blockchain has emerged as a key technology for handling manufacturing, raw or processed data, in safety and security environment, while distributing it to the physical world, consisting of heterogeneous entities, such as manufacturers, retailers, suppliers, logistics agents or simple clients, thus reinforcing the IT and automation potentials of product supply chain. In this paper we propose an abstraction layer architecture that solves all that issues. On the one hand, there is a decentralized IOT/Fog and cloud framework for real time machine condition monitoring (MCM) and fault prediction, where computational demanding tasks are distributed across fog nodes and decision fusion rules are set and controlled by the Cloud. On the other hand, a peer to peer Blockchain ledger is also proposed for integrating the IOT/Fog, MCM network architecture along with other entities of the physical world, making supply chain network more efficient and intelligent. The proposed generic architecture can be applied to other application areas as well.","","978-1-7281-4757-4","10.1109/SEEDA-CECNSM.2019.8908360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908360","IIoT;Industry 4.0;MCM;Fog;Blockchain;ADMM;VMN;peer to peer;MAS","Peer-to-peer computing;Blockchain;Cloud computing;Logic gates;Computer architecture;Servers;Supply chains","","9","","16","IEEE","21 Nov 2019","","","IEEE","IEEE Conferences"
"MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding","X. Cao; T. Zhou; Y. Ma; W. Ye; C. Cui; K. Tang; Z. Cao; K. Liang; Z. Wang; J. M. Rehg; C. Zheng","Tencent T Lab; Tencent T Lab; Purdue University; University of Virginia; Purdue University; Tencent T Lab; Tencent T Lab; SambaNova Systems, Inc.; Purdue University; University of Illinois Urbana-Champaign; Tencent T Lab",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","21819","21830","Vision-language generative AI has demonstrated re-markable promise for empowering cross-modal scene understanding of autonomous driving and high-definition (HD) map systems. However, current benchmark datasets lack multi-modal point cloud, image, and language data pairs. Recent approaches utilize visual instruction learning and cross-modal prompt engineering to expand vision-language models into this domain. In this paper, we pro-pose a new vision-language benchmark that can be used to finetune traffic and HD map domain-specific foundation models. Specifically, we annotate and leverage large-scale, broad-coverage traffic and map data extracted from huge HD map annotations, and use CLIP and LLaMA-2 / Vi-cuna to finetune a baseline model with instruction-following data. Our experimental results across various algorithms reveal that while visual instruction-tuning large language models (LLMs) can effectively learn meaningful represen-tations from MAPLM-QA, there remains significant room for further advancements. To facilitate applying LLMs and multi-modal data into self-driving research, we will release our visual-language QA data, and the baseline models at GitHub.com/LLVM-AD/MAPLM.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.02061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657418","Vision-Language Model;High-definition (HD) Map;Visual Question Answering;Large Language Model;Multimodal Learning","Point cloud compression;Visualization;Solid modeling;Three-dimensional displays;Laser radar;Large language models;Benchmark testing","","8","","87","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"BISCUIT: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks","R. Cheng; T. Barik; A. Leung; F. Hohman; J. Nichols",Apple; Apple; Apple; Apple; Apple,2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),"16 Oct 2024","2024","","","13","23","Programmers frequently engage with machine learning tutorials in computational notebooks and have been adopting code generation technologies based on large language models (LLMs). However, they encounter difficulties in understanding and working with code produced by LLMs. To mitigate these challenges, we introduce a novel workflow into computational notebooks that augments LLM-based code generation with an additional ephemeral UI step, offering users UI scaffolds as an intermediate stage between user prompts and code generation. We present this workflow in Biscuit, an extension for JupyterLab that provides users with ephemeral UIs generated by LLMs based on the context of their code and intentions, scaffolding users to understand, guide, and explore with LLMgenerated code. Through a user study where 10 novices used Biscuit for machine learning tutorials, we found that Biscuit offers users representations of code to aid their understanding, reduces the complexity of prompt engineering, and creates a playground for users to explore different variables and iterate on their ideas.","1943-6106","979-8-3503-6613-6","10.1109/VL/HCC60511.2024.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714542","","Visualization;Codes;Large language models;Tutorials;Machine learning;Encoding;Complexity theory;Prompt engineering;Programming environments","","","","44","IEEE","16 Oct 2024","","","IEEE","IEEE Conferences"
"Automated Testing and Deployment Strategies for Quantum Algorithms","M. C. Saxena; A. Tamrakar; U. Arranz","Universidad Politécnica de Madrid, Madrid, Spain; Universidad Politécnica de Madrid, Madrid, Spain; Universidad Politécnica de Madrid, Madrid, Spain",2024 7th International Conference on Contemporary Computing and Informatics (IC3I),"15 Jan 2025","2024","7","","771","779","The advent of quantum computing has ushered in a new era of technological innovation, promising unprecedented computational power and efficiency. As quantum technology matures, the need for robust, scalable, and efficient software development practices becomes increasingly critical. This paper proposes a novel DevOps framework tailored specifically for quantum software development, addressing unique challenges posed by quantum computing. The proposed architecture incorporates continuous integration and continuous deployment (CI/CD) pipelines, optimized for quantum algorithms, facilitating seamless integration and deployment of quantum applications. Key components include a Quantum Circuit Service for circuit design and optimization, a Quantum CI Service for continuous integration, and a comprehensive testing suite encompassing unit, integration, functional, and probabilistic testing. The framework emphasizes the use of large language models (LLMs) for automated microservice code generation, Kubernetes (K8s) cluster deployment for scalable infrastructure management, and a central quantum artifacts registry for efficient version control and resource management. A significant portion of this paper is dedicated to addressing the unique aspects of quantum computing, including the probabilistic nature of quantum algorithms, the need for specialized testing strategies, and the integration of classical and quantum software components. The proposed framework not only enhances the efficiency and reliability of quantum software development but also provides a structured approach to managing the complexities associated with quantum computing.","","979-8-3503-5006-7","10.1109/IC3I61595.2024.10829232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829232","DevOps;Quantum DevOps;Quantum CI;Quantum CD;Quantum Software Testing","Software testing;Technological innovation;Quantum computing;DevOps;Quantum algorithm;Continuous integration;Probabilistic logic;Software;Software reliability;Resource management","","","","32","IEEE","15 Jan 2025","","","IEEE","IEEE Conferences"
"Smartphone Usage Data Cleaning Using LLM-Based Processing","M. Zaeifi; B. Lin","University of Oklahoma, Norman, USA; University of Oklahoma, Norman, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","8871","8873","The proliferation of smartphone technology has generated unprecedented volumes of data, creating challenges in under-standing digital behavior patterns. We present a new computational system that integrates Large Language Models (LLMs) with conventional data processing techniques using a novel three-levelOur system employs LLMs for zero-shot learning capabilities to classify usage patterns, achieving 95% accuracy in task classification through automated pattern identification. The system implements pattern verification reaching 98% validation accuracy and utilizes automated validation that reduces data loss by 75%. This hierarchical approach demonstrates consistent performance across diverse device types and usage scenarios while maintaining processing efficiency through automated prompt engineering and code generation.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825647","University of Oklahoma; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825647","","Performance evaluation;Accuracy;Codes;Large language models;Zero shot learning;Big Data;Data processing;Cleaning;Prompt engineering","","","","9","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"GPT Based Malware: Unveiling Vulnerabilities and Creating a Way Forward in Digital Space","S. K. Shandilya; G. Prharsha; A. Datta; G. Choudhary; H. Park; I. You","Division of Cyber Security and Digital Forensics, VIT Bhopal University, Bhopal, India; Division of Cyber Security and Digital Forensics, VIT Bhopal University, Bhopal, India; Division of Cyber Security and Digital Forensics, VIT Bhopal University, Bhopal, India; Center for Industrial Software, University of Southern Denmark, Sonderborg, Denmark; Dept. of Information Security Engineering, Soonchunhyang University, South Korea; Dept of Information Security, Cryptology, and Mathematics, Kookmin University, South Korea",2023 International Conference on Data Security and Privacy Protection (DSPP),"25 Jan 2024","2023","","","164","173","The rise and development of AI-based solutions like ChatGPT have significantly changed the functioning of many enterprises, organizations, and domains including cybersecurity. The public’s open access to ChatGPT and its resources does, however, present significant security challenges. This review study aims to shed light on the emergence of GPT-based malware. As traditional malware detection systems, have advanced to mitigate many sophisticated malware attacks, threat actors are now aiming to utilize GPT and other Large Language Models (LLMs) to create sophisticated tactics to infect systems with new malware. Furthermore, this study seeks to present a select number of methods that may be utilized to reduce the hazards posed by malware developed with ChatGPT and other LLM-based tools.","","979-8-3503-0315-5","10.1109/DSPP58763.2023.10404552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404552","ChatGPT;Polymorphism;Malware;Large Language Model/s(LLMs)","Open Access;Organizations;Chatbots;Malware;Hazards;Computer security;Artificial intelligence","","5","","22","IEEE","25 Jan 2024","","","IEEE","IEEE Conferences"
"“You’re on a bicycle with a little motor”: Benefits and Challenges of Using AI Code Assistants","W. Mendes; S. Souza; C. R. B. De Souza","Federal University of Pará, Belém, Pará, Brazil; Federal University of Pará, Belém, Pará, Brazil; Federal University of Pará, Belém, Pará, Brazil",2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE),"18 Jun 2024","2024","","","144","152","AI code assistants, such as Tabnine, GitHub CoPilot, and ChatGPT, employ Large Language Models (LLMs) trained on extensive source code and other documents. They receive prompts and generate code suggestions aimed to facilitate programming tasks. Previous research in this field has explored the correctness, complexity, quality, and security of the code suggestions. Software developers’ experiences have been studied in the context of controlled experiments. Based on 14 interviews with software developers, this paper describes the developers’ daily and continuous experiences with AI code assistants, presenting benefits and challenges grounded in actual development work, along with strategies to address these challenges.","2574-1837","979-8-4007-0533-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556449","AI Code Assistants;Developer Experiences;Code Generation","Codes;Source coding;Programming;Motors;Software;Security;Task analysis","","","","29","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Code Summarization Beyond Function Level","V. Makharev; V. Ivanov","AIRI, Innopolis University, Innopolis, Russia; Research Center of the Artificial Intelligence Institute, Innopolis University, Innopolis, Russia",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","153","160","Code summarization is a critical task in natural language processing and software engineering, which aims to generate concise descriptions of source code. Recent advancements have improved the quality of these summaries, enhancing code readability and maintainability. However, the content of a repository or a class has not been considered in function code summarization. This study investigated the effectiveness of code summarization models beyond the function level, exploring the impact of class and repository contexts on the summary quality. The study involved revising benchmarks for evaluating models at class and repository levels, assessing baseline models, and evaluating LLMs with in-context learning to determine the enhancement of summary quality with additional context. The findings revealed that the fine-tuned state-of-the-art CodeT5+ base model excelled in code summarization, while incorporating few-shot learning and retrieved code chunks from RAG significantly enhanced the performance of LLMs in this task. Notably, the Deepseek Coder 1.3B and Starcoder2 15B models demonstrated substantial improvements in metrics such as BLEURT, METEOR, and BLEU4 at both class and repository levels. Repository-level summarization exhibited promising potential but necessitates significant computational resources and gains from the inclusion of structured context. Lastly, we employed the recent SIDE code summarization metric in our evaluation. This study contributes to refining strategies for prompt engineering, few-shot learning, and RAG, addressing gaps in benchmarks for code summarization at various levels. Finally, we publish all study details, code, datasets, and results of evaluation in the GitHub repository available at https://github.com/kilimanj4r0/code-summarization-beyond-function-level.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00024","Innopolis University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028203","code summarization;Python;LLM;retrieval-augmented generation;prompt engineering;few-shot learning","Measurement;Codes;Computational modeling;Source coding;Benchmark testing;Prompt engineering;Few shot learning;Context modeling;Software engineering;Software development management","","","","31","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Cloud Computing: A Framework for Balancing Accountability and Privacy Based on Multi-Agent System","Y. Alagrash; F. Alghayadh; A. Alshammari; D. Debnath","School of Engineering and Computer Science, Oakland university, Rochester, Michigan, USA; School of Engineering and Computer Science, Oakland university, Rochester, Michigan, USA; School of Engineering and Computer Science, Oakland university, Rochester, Michigan, USA; School of Engineering and Computer Science, Oakland university, Rochester, Michigan, USA",2019 Cybersecurity and Cyberforensics Conference (CCC),"3 Oct 2019","2019","","","6","12","The rise of cloud computing gives community's advantages to an open environment. Outsourcing of data and applications to third parties can cause serious harm to the organizations. Security in cloud computing is a challenging issue. In this paper, we design a framework for balancing accountability and privacy in cloud computing through the development of intelligent techniques. The proposed solution is based on multi-agent systems.","","978-1-7281-2600-5","10.1109/CCC.2019.00-16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854536","Cloud computing security, privacy, accountable privacy, accountability","Cloud computing;Privacy;Data privacy;Law;Multi-agent systems;Security","","1","","21","IEEE","3 Oct 2019","","","IEEE","IEEE Conferences"
"Medical Text and Image Reasoning for Radiation Oncology via Large Language Model","A. Beary; L. Xia; Y. Yuan; H. Wang; M. Ma","Department of Graduate Computer Science and Engineering, Katz School of Science and Health, Yeshiva University, New York, United States; Capital Normal University, Beijing, China; Department of Radiation Oncology, Columbia University Irving Medical Center, New York, United States; Department of Graduate Computer Science and Engineering, Katz School of Science and Health, Yeshiva University, New York, United States; Department of Graduate Computer Science and Engineering, Katz School of Science and Health, Yeshiva University, New York, United States",2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI),"12 May 2025","2025","","","1","4","Evaluating text based logical reasoning and medical image reasoning abilities in large language models (LLMs) within the domain of radiation oncology is often challenging. Testing LLMs without fine-tuning in this context often fails to achieve high accuracy, particularly when dealing with domain-specific questions, limiting their utility in medical decision-making. In this paper, five prominent LLMs - ChatGPT-4o, Claude-3.5 Sonnet, Llama 3.2, Gemini 1.5 Flash, and o1-preview are evaluated to assess their text based logical reasoning and medical image reasoning performances on two publicly available datasets. We propose a new challenging benchmark dataset featuring a mixture of single-choice questions as well as multiple choice questions in radiation oncology for the reasoning task. To overcome the limitation of LLMs in handling complex and specialized tasks, we also propose a new hybrid fine-tuning method, where Llama 3.2 is fine-tuned using QLoRA, combined with prompt engineering technique to enhance its reasoning performance. Extensive experiments demonstrate that o1-preview outperforms the other models in overall accuracy, while the fine-tuned Llama 3.2 using our proposed method achieves improved performance, showcasing the effectiveness of hybrid fine-tuning for enhancing LLMs reasoning performance.","1945-8452","979-8-3315-2052-6","10.1109/ISBI60581.2025.10981179","Beijing Natural Science Foundation(grant numbers:4242033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981179","Large Language Model (LLM);Text based Logical Reasoning;Medical Image Reasoning;Radiation Oncology;Fine-tuning","Accuracy;Limiting;Large language models;Decision making;Benchmark testing;Oncology;Cognition;Prompt engineering;Biomedical imaging","","","","14","IEEE","12 May 2025","","","IEEE","IEEE Conferences"
"Graph-Based Filtering to Prevent Prompt-Engineered LLM Training Data Leaks","A. Barnett; S. Ahearne; P. Barry; M. Globin; C. Duggan","Dell Technologies, Cork, Ireland; Dell Technologies, Cork, Ireland; Dell Technologies, Cork, Ireland; Dell Technologies, Cork, Ireland; Dell Technologies, Cork, Ireland",2025 IEEE International Conference on Smart Computing (SMARTCOMP),"3 Jul 2025","2025","","","480","485","Machine-learning generative Artificial Intelligence tools, specifically large-language models, provide varied functionality, like content generation, user-facing chatbots, and code generation. The LLM typically works with a decision engine, such as a neural network. LLMs suffer issues with training data poisoning, copyright of generated content, and this paper's focus; prompt engineering attacks and training data leaks. The authors propose an architecture to co-locate a filtering mechanism with the LLM chatbot to identify and preventing disclosure of leaked LLM training data before communication to the end-user. Implementation of a resource description framework (RDF) based filtering mechanism compares LLM outputs against a bank of training data using three approaches; the first uses a bank of hash-codes generated from training data artifacts, the second uses a bank of training data stored as plaintext, and the third couples natural language processing (NLP) with the plaintext training data bank. Accuracy, overhead and acceleration results are detailed, and observed anomalies in LLM responses to testing including plausible leaks are also discussed.","2693-8340","979-8-3315-8646-1","10.1109/SMARTCOMP65954.2025.00089","Horizon Europe project RESCALE(grant numbers:101120962); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058635","LLM;AI;Filtering;Security;RDF","Filtering;Neural networks;Training data;Machine learning;Life estimation;Chatbots;Resource description framework;Security;Prompt engineering;Testing","","","","25","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"MtArtGPT: A Multi-Task Art Generation System With Pre-Trained Transformer","C. Jin; R. Zhu; Z. Zhu; L. Yang; M. Yang; J. Luo","School of Information and Communication Engineering, Communication University of China, Beijing, China; School of Information and Communication Engineering, Communication University of China, Beijing, China; School of Information and Communication Engineering, Communication University of China, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; University of Rochester, Rochester, NY, USA",IEEE Transactions on Circuits and Systems for Video Technology,"12 Aug 2024","2024","34","8","6901","6912","Instruction tuning large language models are making rapid advances in the field of artificial intelligence where GPT-4 models have exhibited impressive multi-modal perception capabilities. Such models have been used as the core assistant for many tasks including art generation. However, high-quality art generation relies heavily on human prompt engineering which is in general uncontrollable. To address these issues, we propose a multi-task AI generated content (AIGC) system for art generation. Specifically, a dense representation manager is designed to process multi-modal user queries and generate dense and applicable prompts to GPT. To enhance artistic sophistication of the whole system, we fine-tune the GPT model by a meticulously collected prompt-art dataset. Furthermore, we introduce artistic benchmarks for evaluating the system based on professional knowledge. Experiments demonstrate the advantages of our proposed MtArtGPT system.","1558-2205","","10.1109/TCSVT.2024.3349567","National Natural Science Foundation of China(grant numbers:62207029,62271454); National Key Research and Development Program of China(grant numbers:2018YFB1403903,2021YFF0900700); Beijing Natural Science Foundation(grant numbers:L223033); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380595","Dense representation;art generation;prompt engineering;vision-language representation;AI generated content","Training;Transformers;Task analysis;Artificial intelligence;Data models;Chatbots;Visualization","","5","","73","IEEE","4 Jan 2024","","","IEEE","IEEE Journals"
"Electromechanical Design and Control Using a Large Language Model","K. Gashi; M. Chacin; G. Tang","Centre for Robotics and Assembly, Cranfield University, UK; Centre for Robotics and Assembly, Cranfield University, UK; Centre for Robotics and Assembly, Cranfield University, UK","2024 12th International Conference on Control, Mechatronics and Automation (ICCMA)","20 Jan 2025","2024","","","354","360","Lately, artificial intelligence (AI) has seen a rapid increase in both adoption and capabilities, with one distinct area of interest being Large Language Models (LLM). This article investigates the use of an LLM, OpenAI’s GPT–4o, as a tool for the speed control and design of a DC motor with benchmark results identified for comparison. A prompt engineering approach was used with a trial–and–error by adjusting the prompt to identify the knowledge areas and capabilities of the LLM. As a result, the LLM was able to solve and interpret mathematical equations, methods, symbols and terminologies relating to control engineering, and could design controllers analytically, while struggling with manual and graphical tuning processes.","2837-5149","979-8-3315-1751-9","10.1109/ICCMA63715.2024.10843811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843811","Control;PID;AI;LLM;Prompt Engineering","Motor drives;Automation;Large language models;Frequency-domain analysis;Process control;Manuals;Manipulators;Software;Iterative methods;Tuning","","","","11","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"ChatGPT in the Classroom: A Shift in Engineering Design Education","E. Ambikairajah; T. Sirojan; T. Thiruvaran; V. Sethu","School of Electrical Engineering & Telecommunications, University of New South Wales, Sydney, Australia; School of Electrical Engineering & Telecommunications, University of New South Wales, Sydney, Australia; Department of Electrical and Electronic Engineering, University of Jaffna, Sri Lanka; School of Electrical Engineering & Telecommunications, University of New South Wales, Sydney, Australia",2024 IEEE Global Engineering Education Conference (EDUCON),"8 Jul 2024","2024","","","1","5","Artificial intelligence tools like ChatGPT are increasingly being incorporated into our education paradigm. This paper explores how ChatGPT was used in an Electrical Engineering Design Proficiency course at the University of New South Wales in Sydney. The course is a term-long laboratory-based class that centres on independent student work in system design, implementation, and validation. Students were encouraged to consult ChatGPT for design solutions, explanations, and suggestions, with the requirement that they declare any use of AI tools. The assessment process was carefully designed to determine whether responses originated from AI tools or the students' own understanding. Notably, 70% of the fifty students in the class utilised ChatGPT to enhance their understanding of the subject. The paper will also discuss the specific design tasks given to students, the assessment process, and explore ChatGPT's potential as a supportive educational tool in other courses.","2165-9567","979-8-3503-9402-3","10.1109/EDUCON60312.2024.10578884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578884","Generative AI;ChatGPT;Engineering Education;Engineering Design;Learning and Teaching","Industries;Electrical engineering;Codes;Debugging;Chatbots;Artificial intelligence;Task analysis","","5","","11","IEEE","8 Jul 2024","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks-Driven Cyber Threat Intelligence Detection Framework for Securing Internet of Things","M. A. Ferrag; D. Hamouda; M. Debbah; L. Maglaras; A. Lakas","Technology Innovation Institute, Masdar City, Abu Dhabi, UAE; Labstic Laboratory, Guelma University, Guelma, Algeria; Technology Innovation Institute, Masdar City, Abu Dhabi, UAE; Blockpass ID Lab, Edinburgh Napier University, Edinburgh, UK; College of Information Technology, United Arab Emirates University, Al-Ain, UAE",2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT),"27 Sep 2023","2023","","","196","200","While the benefits of 6G-enabled Internet of Things (IoT) are numerous, providing high-speed, low-latency communication that brings new opportunities for innovation and forms the foundation for continued growth in the IoT industry, it is also important to consider the security challenges and risks associated with the technology. In this paper, we propose a two-stage intrusion detection framework for securing IoTs, which is based on two detectors. In the first stage, we propose an adversarial training approach using generative adversarial networks (GAN) to help the first detector train on robust features by supplying it with adversarial examples as validation sets. Consequently, the classifier would perform very well against adversarial attacks. Then, we propose a deep learning (DL) model for the second detector to identify intrusions. We evaluated the proposed approach's efficiency in terms of detection accuracy and robustness against adversarial attacks. Experiment results with a new cyber security dataset demonstrate the effectiveness of the proposed methodology in detecting both intrusions and persistent adversarial examples with a weighted avg of 96%, 95%, 95 %, and 95% for precision, recall, f-score, and accuracy, respectively.","2325-2944","979-8-3503-4649-7","10.1109/DCOSS-IoT58021.2023.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257196","IoT;Generative AI;GAN;Adversarial deep learning;Adversarial attacks","Training;Technological innovation;Intrusion detection;Detectors;Generative adversarial networks;Robustness;Software","","10","","7","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"Advanced Cyber Deception Framework (ACDF): A Comprehensive Study","M. Maldonado; C. Johnson; M. Gulati; T. Jaspers; P. F. Roysdon",Leidos AI/ML Accelerator; Leidos AI/ML Accelerator; Leidos AI/ML Accelerator; Leidos AI/ML Accelerator; Leidos AI/ML Accelerator,"2024 International Conference on Computing, Networking and Communications (ICNC)","21 Jun 2024","2024","","","203","208","Deception frameworks provide an effective environment for data collection on cyber criminals. Using deception techniques these frameworks help security professionals identify and deceive attackers. Information security is an increasingly complex problem as cyber attacks evolve and attackers become more competent in exploitation. Honeypots or honey networks provide an opportunity for counter-intelligence collection. The current State-of-the-Art (SotA) honeypot deployments are easily identified and cataloged by adversaries. Using machine learning, specifically a Tabular Masked Transformer (TabMT) model, we generate honeypots with a realistic host and network traffic to prolong engagement and improve intelligence gathering efforts.","2473-7585","979-8-3503-7099-7","10.1109/ICNC59896.2024.10555891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555891","Deception;Honeypot;Tabular Masked Transformer;Generative AI;Threat Monitoring","Text analysis;Image synthesis;Computer hacking;Information security;Telecommunication traffic;Machine learning;Data collection","","3","","16","IEEE","21 Jun 2024","","","IEEE","IEEE Conferences"
"Survey of Non-malicious User Actions that Introduce Network and System Vulnerabilities and Exploits","A. Robles; J. Norris; S. Watson; A. F. Browne","College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, North Carolina; College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, North Carolina; College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, North Carolina; William Lee College of Engineering, University of North Carolina at Charlotte, Charlotte, North Carolina",SoutheastCon 2018,"4 Oct 2018","2018","","","1","5","Security is a growing concern in modern computer networks. Despite the implementation of significant security measures, a network can still be exposed to attackers by the actions of its users. Both attackers and penetration testers use social engineering tactics to exploit the mistakes made by users. For example, a user being tricked into clicking on a malicious link in a phishing email. Network security administrators seek ways to prevent intrusion into the network initiated by users performing such risky actions, and use methodologies to detect and respond safely when those actions occur. If we were able to simulate these user actions in a controlled network, it would help prepare networks to be sufficiently hardened to prevent exposure. The goal of this paper is to seek out different ways users create vulnerabilities, and use that information to determine the feasibility of replicating them in a network as semi-autonomous agents for evaluating security. We seek to determine existing research on network breaches caused by unwitting-users, the common and current exploits attackers use to trick users, and the mitigations that can prevent intrusion into the network.","1558-058X","978-1-5386-6133-8","10.1109/SECON.2018.8478938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478938","Networking;human behavior;network vulnerability;social engineering;phishing;browser security;human fallibility;virtual machine;virtual network","Phishing;Browsers;Tools;Electronic mail;Companies;Malware","","3","","29","IEEE","4 Oct 2018","","","IEEE","IEEE Conferences"
"Autonomous surface / sub-surface survey system ASSSS","A. Ziegwied","Autonomous Surface Vehicles, LLC ASV Global, Portland, OR, USA",OCEANS 2017 - Anchorage,"25 Dec 2017","2017","","","1","6","The Autonomous Surface / Sub-surface Survey System (ASSSS) research program combines long endurance autonomous surface vessels (ASVs) and long endurance autonomous underwater vehicles (AUVs) to create an integrated cooperative navigation system effectively transforming the capabilities and accuracy of AUV survey. ASV is leading the project, working alongside National Oceanography Centre, a world leading research center and developer of AUV systems, Sonardyne International a leading developer of subsea acoustic positioning, communications and sonar systems and SeeByte a developer of software solutions for autonomous systems. The system architecture enables an ASV to provide regular position updates to the AUV system removing the need for the AUV to surface from depth to update its internally calculated position, a Cooperative Localization Scheme will increase the efficiency and accuracy of AUV survey. With the combination of the high accuracy sonar systems positioned close to the seabed on the AUV and accurate position from the ASV this will provide game changing solutions. The ASV communicates with the AUV through 2 key methods; acoustics to provide short mission updates and positioning information and optical communication technology to enable the system to upload the data from the survey sensors. With the data uploaded to the ASV it is then possible for it to process this data to enable summary data to be passed back through satellite communications. Future projects will look at how the data processed onboard can be used to adaptively update the mission in situations where data may indicate further investigation is required. Due to the endurance and autonomy, this system will also bring the possibility of completing subsea operations from a shore base, without the need for ships to be mobilized, significantly reducing data acquisition costs and improving safety. This transition to autonomy will save cost, reduce risk, and increase flexibility across a range of applications including mine countermeasures, weapons testing, hydrography, environmental science, security, and surveillance.","","978-0-6929-4690-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8232202","MAS;ASV;USV;AUV;Hydrographic Survey;Force Multiplier;Autonomy","Acoustics;Sea surface;Sensors;Marine vehicles;Global Positioning System;Sonar","","1","","14","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security","Y. Fan; Y. Cao; Z. Zhao; Z. Liu; S. Li","School of Electronics and Information Engineering, TongJi University, China; School of Computing, National University of Singapore, Singapore; Fan Gongxiu Honors College, Beijing University of Technology, China; Nanyang Technological University, Singapore; School of Computer Science and Engineering, Southeast University, China","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","3428","3433","Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities that increasingly influence various aspects of our daily lives, constantly defining the new boundary of Artificial General Intelligence (AGI). Image modalities, enriched with profound semantic information and a more continuous mathematical nature compared to other modalities, greatly enhance the functionalities of MLLMs when integrated. However, this integration serves as a double-edged sword, providing attackers with expansive vulnerabilities to exploit for highly covert and harmful attacks. The pursuit of reliable AI systems like powerful MLLMs has emerged as a pivotal area of contemporary research. In this paper, we endeavor to demostrate the multifaceted risks associated with the incorporation of image modalities into MLLMs. Initially, we delineate the foundational components and training processes of MLLMs. Subsequently, we construct a threat model, outlining the security vulnerabilities intrinsic to MLLMs. Moreover, we analyze and summarize existing scholarly discourses on MLLMs' attack and defense mechanisms, culminating in suggestions for the future research on MLLM security. Through this comprehensive analysis, we aim to deepen the academic understanding of MLLM security challenges and propel forward the development of trustworthy MLLM systems.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831129","","Threat modeling;Surveys;Training;Reviews;Large language models;Artificial general intelligence;Semantics;Safety;Security;Reliability","","1","","50","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Coordinated Control Strategy of AGC and AVC Based on Multi-Agent System","C. Song; D. Zhao; J. Yin; Q. Zhang","School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Grid Jiangsu Electric Power Company, Nanjing, China",2018 2nd IEEE Conference on Energy Internet and Energy System Integration (EI2),"20 Dec 2018","2018","","","1","5","With the development of the energy Internet, the coupling of active power and reactive power in modern power grid is increasingly inseparable, while the operation of automatic generation control (AGC) and automatic voltage control (AVC) is in the way of decoupling in the power grid. The operation of AGC and AVC will affect the control effect of each other as a result of the different targets, and even may cause the repeating regulation of equipment or other safety issues. According to the above issues, this paper establishes a coordinated control strategy of AGC and A VC based on multi agent system. By means of the establishment of three level multi agent architecture, the coordinated control of AGC and A VC is realized by classification and partition. The comprehensive coordination model of AGC and A VC is established in the organization level agent, and the AGC and A VC controls are synthesized based on the ultrashort term load forecasting for the advanced AGC optimization and the correction of AVC on account of the adjustment of active power. The independent and cooperative control strategy of voltage correction is set at the coordination level and the executive level agent to achieve the independent operation of the voltage correction, the independent cooperation between the intelligent bodies and the local compensation of reactive power. Finally, the simulation prove that, the proposed control strategy can improve the economy and security of the system operation and suppress the mutual interference between AGC and AVC.","","978-1-5386-8549-5","10.1109/EI2.2018.8582407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8582407","AGC;AVC;MAS;coordinated control","Automatic voltage control;Reactive power;Automatic generation control;Power grids;Optimization;Organizations","","","","15","IEEE","20 Dec 2018","","","IEEE","IEEE Conferences"
"Performance Analysis of Fault-Tolerant Multiagent Coordination Mechanisms","R. Pinciroli; C. Trubiani","Gran Sasso Science Institute, L'Aquila, Italy; Gran Sasso Science Institute, L'Aquila, Italy",IEEE Transactions on Industrial Informatics,"24 Jul 2023","2023","19","9","9821","9832","Performance evaluation of multiagent systems (MAS) embraces several challenges due to uncertain operational environments, such as software/hardware failures and unfaithful communications that facilitate the spread of deceptive messages. One way to smooth the impact of reliability and security potential issues in MAS is to enforce different coordination mechanisms among agents (i.e., coordinating multiple agents that need to perform a sequence of actions to maximize a system-level reward), and evaluate their efficiency. In this article, we propose a tool-based approach, namely COORDINATE, that simulates and compares the performance characteristics of different coordination mechanisms for MAS while considering fault-tolerant and corrupted agents. A smart hospital is adopted as an illustrative example to show the need of performance-based analysis results pointing out which coordination mechanism is more efficient. Experimental results indicate that the interarrival time of tasks to be accomplished, the failure probability of agents, and the ratio of faithful to malicious agents contribute to determining the efficiency of different coordination mechanisms. When varying these parameters in the considered scenarios, the system latency can be reduced up to 4.2× by selecting the optimal coordination mechanism. This way, software developers are informed on the system peculiarities that trigger the switching among such coordination mechanisms for a performance-based optimal solution.","1941-0050","","10.1109/TII.2023.3234606","MUR PRIN Project SEDUCE(grant numbers:2017TWRCNB); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013943","Coordination;multiagent systems (MAS);performance evaluation;system latency","Robots;Robot kinematics;Task analysis;Security;Reliability;Fault tolerant systems;Fault tolerance","","5","","49","CCBY","10 Jan 2023","","","IEEE","IEEE Journals"
"Enhancing Black-box Compiler Option Fuzzing with LLM through Command Feedback","T. Wang; R. Wang; Y. Chen; L. Yu; Z. Pan; M. Zhang; H. Ma; J. Zheng","CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China; CEE, NUDT, Hefei, China",2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE),"3 Dec 2024","2024","","","319","330","Since the compiler acts as a core component in software building, it is essential to ensure its availability and reliability through software testing and security analysis. Most research has focused on compiler robustness when compiling various test cases, while the reliability of compiler options lacks attention, especially since each option can activate a specific compiler function. Although some researchers have made efforts in testing it, the insufficient utilization of compiler command feedback messages leads to the poor efficiency, which hinders more diverse and in-depth testing.In this paper, we propose a novel solution to enhance black-box compiler option fuzzing by utilizing command feedback, such as error messages, standard output and compiled files, to guide the error fixing and option pruning via prompting large language models for suggestions. We have implemented the prototype and evaluated it on 4 versions of LLVM. Experiments show that our method significantly improves the detection of crashes, reduces false negatives, and even increase the success rate of compilation when compared to the baseline. To date, our method has identified hundreds of unique bugs, and 9 of them are previously unknown. Among these, 8 have been assigned CVE numbers, and 1 has been fixed following our report.","2332-6549","979-8-3503-5388-4","10.1109/ISSRE62328.2024.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771447","software testing;compiler options;fuzzing;large language model","Large language models;Computer bugs;Buildings;Closed box;Prototypes;Fuzzing;Robustness;Software reliability;Security;Standards","","2","","46","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"A Multi-Agent Collaborative Framework for Constructing Knowledge Graphs from Text","G. Chen; X. Liu","College of Electronic and Information Engineering, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China",2024 IEEE International Conference on Knowledge Graph (ICKG),"19 Feb 2025","2024","","","9","16","Recent advancements in large language models (LLMs) have significantly improved natural language understanding and generation, making them valuable tools for knowledge graph construction. However, a single LLM often struggles with the complexity of this task, leading to suboptimal results. To address this challenge, we propose a robust multi-agent collaborative framework for constructing knowledge graphs from text. This framework leverages dynamic interactions among specialized agents, including knowledge graph experts, knowledge extraction experts, data processing experts, and domain-specific experts, to effectively build accurate knowledge graphs from text. Additionally, we introduce a novel prompt construction method tailored for knowledge extraction and a revision mechanism to revise preliminary knowledge graphs. These innovations address common issues in knowledge extraction and enhance the quality of model-generated content. Experimental results on four datasets across two tasks (Named Entity Recognition and Relation Extraction) demonstrate that our approach achieves superior performance in the F1 score compared to baseline methods, highlighting its effectiveness and robustness.","","979-8-3315-0882-1","10.1109/ICKG63256.2024.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884217","knowledge graph construction;multi-agent;large language model;knowledge extraction;prompt engineering","Knowledge engineering;Technological innovation;Large language models;Collaboration;Knowledge graphs;Named entity recognition;Ontologies;Data processing;Robustness;Data mining","","1","","48","IEEE","19 Feb 2025","","","IEEE","IEEE Conferences"
"How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?","A. S. Nipu; K. M. S. Islam; P. Madiraju","Computer Science & Software Engineering, University of Wisconsin-Platteville, Platteville, WI, USA; Computer Science, Marquette University, Milwaukee, WI, USA; Computer Science, Marquette University, Milwaukee, WI, USA",2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI),"8 Oct 2024","2024","","","210","215","Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs) are gaining traction in healthcare for their potential to automate patient interactions and aid clinical decision-making. This study examines the reliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini Ultra 1.0, in predicting diseases from patient complaints in the emergency department. The methodology includes few-shot learning techniques to evaluate the chatbots’ effectiveness in disease prediction. We also fine-tune the transformer-based model BERT and compare its performance with the AI chatbots. Results suggest that GPT 4.0 achieves high accuracy with increased fewshot data, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3 Opus maintains consistent performance. BERT’s performance, however, is lower than all the chatbots, indicating limitations due to limited labeled data. Despite the chatbots’ varying accuracy, none of them are sufficiently reliable for critical medical decision-making, underscoring the need for rigorous validation and human oversight. This study reflects that while AI chatbots have potential in healthcare, they should complement, not replace, human expertise to ensure patient safety. Further refinement and research are needed to improve AI-based healthcare applications’ reliability for disease prediction.","2835-5776","979-8-3503-5118-7","10.1109/IRI62200.2024.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703824","ChatGPT;Claude;Gemini;BERT;LLM;patient complaint;electronic health record;few-shot learning;prompt engineering","Accuracy;Decision making;Training data;Medical services;Chatbots;Transformers;Safety;Reliability;Artificial intelligence;Diseases","","1","","28","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"COSMosFL: Ensemble of Small Language Models for Fault Localisation","H. Cho; S. Kang; G. An; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","17","24","LLMs are rapidly being adopted to build powerful tools and agents for software engineering, but most of them rely heavily on extremely large closed-source models. This, in turn, can hinder wider adoption due to security issues as well as financial cost and environmental impact. Recently, a number of open source Small Language Models (SLMs) are being released and gaining traction. While SLMs are smaller, more energy-efficient, and therefore easier to locally deploy, they tend to show worse performance when compared to larger closed LLMs. We present COSMos, a task-level LLM ensemble technique that uses voting mechanism, to provide a broader range of choice between SLMs and LLMs. We instantiate COSMos with an LLM-based Fault Localisation technique, AutoFL, and report the cost-benefit trade-off between LLM accuracy and various costs such as energy consumption, inference time, and the number of tokens used. An empirical evaluation using Defects4J shows that COSMos can build effective ensembles that can achieve Pareto-optimality in terms of FL accuracy and inference cost, when compared to individual models.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00007","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028363","Fault Localization;Ensemble Methods;Small Language Models;Evolutionary Algorithms","Location awareness;Costs;Accuracy;Large language models;Evolutionary computation;Routing;Security;Ensemble learning;Optimization;Software engineering","","","","45","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Linking Threat Agents to Targeted Organizations: A Pipeline for Enhanced Cybersecurity Risk Metrics","S. Massengale; P. Huff","University of Arkansas, Little Rock, USA; University of Arkansas, Little Rock, USA",2024 4th Intelligent Cybersecurity Conference (ICSC),"25 Feb 2025","2024","","","132","141","In this study, we present a methodology leveraging Large Language Models (LLMs) to transform Cybersecurity Threat Intelligence (CTI) narratives into actionable insights for individual organizations. Our approach automates the extraction of machine-readable adversary SKRAM (Skills, Knowledge, Resources, Authorities, and Motivation) attributes from open-source reports, extending LLM utility beyond typical interactions. This innovation enables precise, automated assessments of cybersecurity risks posed by various adversaries. Using a chain-of-thought and multi-shot prompting strategy, our methodology advances the automation of cybersecurity feature extraction for new machine-learning models that predict the risk of adversary targeting. This approach is refined using a substantial dataset of over 150 analyst-validated threat reports and synthetic organizational data from 900 companies. By bootstrapping the training data with a rule-based heuristic over synthetic data, we have developed a high-accuracy machine-learning model that allows entities to dynamically prioritize threats and defensive actions.","","979-8-3503-5477-5","10.1109/ICSC63108.2024.10895328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895328","Cyber Threat Intelligence;cybersecurity;LLM;prompt engineering;machine learning","Technological innovation;Pipelines;Training data;Transforms;Predictive models;Feature extraction;Cyber threat intelligence;Reliability;Random forests;Synthetic data","","","","31","IEEE","25 Feb 2025","","","IEEE","IEEE Conferences"
"Optimizing Experiment Configurations for LLM Applications Through Exploratory Analysis","N. Busany; H. Hadad; Z. Maszlanka; R. Shelke; G. Price; O. Akhigbe; D. Amyot","Accenture Labs, Herzelia, Israel; Accenture Labs, Herzelia, Israel; Avanade, Krakow, Poland; EECS, University of Ottawa, Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada",2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),"10 Jun 2025","2025","","","46","50","The integration of Large Language Models (LLMs) into software applications necessitates informed design choices across various configurations, including LLM selection, prompting techniques, and their parameters, and prompt templates. Many of these choices are arbitrary, and developers often lack guidance on optimizing configurations. In this work, we define the Experiment Configuration Optimization Problem and illustrate it with a real-world Text-to-SQL application we developed. Our results show that most configurations are sub-optimal, with only a few offering a favorable trade-off between accuracy and cost. Highlighting the critical need for systematic exploration, we show that extensive experimentation is expensive, underscoring the importance for cost-effective methods to navigate the configuration space. Our findings motivate further research into methodologies that effectively optimize LLM application configurations.","2832-7632","979-8-3315-3711-1","10.1109/ICSE-NIER66352.2025.00015","Accenture; Mitacs; University of Ottawa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023950","Feature Modeling;Prompt Engineering;Prompting Techniques;LLM;Retrieval-Augmented Generation","Analytical models;Systematics;Costs;Navigation;Large language models;Retrieval augmented generation;Software;Prompt engineering;Optimization;Software engineering","","","","29","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"Ai-Based Automated Grading of Source Code of Introductory Programming Assignments","J. Havare; V. Apte; K. Maharajan; N. C. G. Samudrala; G. Ramakrishnan; S. Tamilselvam; S. Vavilapalli","IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; IBM Research, India; IIT Bombay, Mumbai, India",2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC),"17 Jun 2025","2025","","","171","181","In a typical introductory programming course, grading of student submitted programs is often done manually by examining the source code prior to assigning the final grade for reasons such as checking for compliance to some criteria (e.g. ‘Use iteration, not recursion’, or ‘do not use additional arrays'), or for allotting partial marks. A rubric is often used by graders to grade according such criteria. However, manual grading of source code can be labor-intensive and impractical for large-scale online courses. Therefore, in this paper, we propose techniques based on Large Language Models (LLM) for code to automatically grade student programs according to instructor-specified rubrics. Leveraging a dataset of 27966 datapoints that we created, we study a total of 44 combinations of different open source LLMs and methodologies including Zero-Shot prompting, Few-Shot prompting, Supervised Fine Tuning, QLoRA, Direct Preference Optimization (DPO), code scrambling and code augmentation. To our knowledge, we are the first to address the generalized source code grading problem and to propose a solution with promising results. We find that among the models we studied, while Codestral 22B achieves a high micro-accuracy of 85% without any fine-tuning, Qwen-2.5-Coder-7B-Instruct with DPO fine-tuning achieves the same micro-accuracy with only 35 % of the GPU memory usage and 10 % of the inference time taken by Codestral 22B.","2643-7171","979-8-3315-0223-2","10.1109/ICPC66645.2025.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025882","Prompt Engineering;Instruction finetuning","Codes;Source coding;Large language models;Graphics processing units;Manuals;Programming;Prompt engineering;Tuning;Optimization","","","","38","IEEE","17 Jun 2025","","","IEEE","IEEE Conferences"
"Enhancing Bug Report Summaries Through Knowledge-Specific and Contrastive Learning Pre-Training","Y. Shao; B. Xiang","Zhejiang College of Security Technology, Wenzhou, China; Zhejiang College of Security Technology, Wenzhou, China",IEEE Access,"14 Mar 2024","2024","12","","37653","37662","Bug reports are crucial in software maintenance, with concise summaries significantly enhancing the efficiency of bug triagers and ultimately contributing to the development of high-quality software products. Contemporary methods for automatic bug report summarization primarily utilize neural networks’ robust learning capabilities. However, these approaches often produce suboptimal summaries due to two primary limitations: 1) the difficulty in assimilating the domain-specific knowledge inherent in bug reports, and 2) the limitations of purely supervised learning in comprehending the comprehensive context of bug reports. To address the above two problems, in this paper, we propose a new approach for bug report summarization, namely KSCLP, which leverages large language models and domain-specific pre-training strategies, i.e., Knowledge-Specific and Contrastive Learning Pre-training. Specifically, the Knowledge-Specific strategy allows to pre-train KSCLP on project-specific bug reports corpus, by which the model can fully learn internal knowledge of bug reports, learning bug report-aware representation. As for the Contrastive Learning strategy, it performs a sequence-level pre-training for KSCLP, helping it capture the semantic information of bug reports on a global level. Upon completion of the pre-training phase, KSCLP undergoes further refinement through a Sequence-to-Sequence framework specifically tailored for bug report summarization. The efficacy of KSCLP is rigorously evaluated against five baseline models using a publicly available dataset. The empirical results demonstrate that KSCLP outperforms all baselines, achieving remarkable improvements by up to 23.73, 13.97, and 20.89 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, thereby setting new benchmarks in the field of bug report summarization.","2169-3536","","10.1109/ACCESS.2024.3368915","Wenzhou Municipal Science and Technology Plan Project(grant numbers:2023R0016); Wenzhou Philosophy and Social Sciences Planning Annual Topic(grant numbers:23WSK208YBM); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10443461","Bug report summarization;domain-specific pre-training;software maintenance;representation learning","Computer bugs;Task analysis;Codes;Self-supervised learning;Software maintenance;Semantics;Representation learning;Domain specific languages;Computer bugs;Software packages","","1","","39","CCBYNCND","22 Feb 2024","","","IEEE","IEEE Journals"
"Movable-Antenna Aided Secure Transmission for Integrated Sensing and Communication Systems","Y. Ma; K. Liu; Y. Liu","School of Electronics and Information Engineering, Beihang University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China",2024 IEEE Globecom Workshops (GC Wkshps),"12 Aug 2025","2024","","","1","6","This paper studies the deployment of movable antennas (MAs) for enhancing the physical layer security (PLS) performance of integrated sensing and communication (ISAC) systems. To evaluate the performance gain provided by MAs, we formulate an optimization problem for maximizing the sum-rate of the users by jointly optimizing the transmit/receive beamformers of the BS, and the positions of MAs at communication users, subject to a minimum communication rate requirement for each user, a minimum radar sensing requirement, and a maximum secrecy leakage to the eavesdropping target. To solve this non-convex problem, a two-layer penalty-based algorithm is developed by updating the penalty parameter in the outer-layer iterations. In the inner-layer iterations, the auxiliary variables are first obtained with semi-closed-form solutions using Lagrange duality. Then, the receive beamformer filter at the BS is optimized by solving a Rayleigh-quotient subproblem. Subsequently, the transmit beamformer matrix is obtained by solving a convex subproblem. Finally, the majorization-minimization (MM) algorithm is employed to optimize the positions of MAs. Extensive simulation results validate the considerable benefits of the proposed MAs-aided ISAC systems in enhancing security performance compared to traditional fixed position antenna (FPA)-based systems.","2166-0077","979-8-3315-0567-7","10.1109/GCWkshp64532.2024.11101203","Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101203","Movable antenna (MA);physical-layer security (PLS);integrated sensing and communication (ISAC)","","","","","12","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Leveraging Zero Trust for Enhanced Security and Connectivity in Ad-Hoc Mesh Networks","G. N. N. Barbosa; M. Andreoni; D. M. F. Mattos","LabGen/MídiaCom – PPGEET/TET/PGC/TCC, Universidade Federal Flumimense – UFF, Brazil; Technology Innovation Institute (TII), Abu Dhabi, UAE; LabGen/MídiaCom – PPGEET/TET/PGC/TCC, Universidade Federal Flumimense – UFF, Brazil","2025 12th IFIP International Conference on New Technologies, Mobility and Security (NTMS)","18 Jul 2025","2025","","","229","237","The increasing complexity of cyber threats and the dynamic nature of mesh networks demand adaptive security solutions to ensure resilience, secure connectivity, and automated service configuration. Traditional security approaches struggle with the constantly changing topology and ad-hoc nature, making Zero Trust a promising paradigm for enhancing security while maintaining flexibility. This paper proposes ZETIn, a Zero Trust Infrastructure that leverages Generative AI and LLM-based chatbots to automate the configuration of security services in the Cloud Continuum, integrating a consensus protocol to enable seamless communication across ad-hoc mesh networks while enforcing strict security policies. Our experiments demonstrate that the Zero Trust architecture introduces minimal overhead, yet significantly improves connectivity, security, and automated service orchestration-making it a viable solution for missioncritical ad-hoc mesh networks.","2157-4960","979-8-3315-5276-3","10.1109/NTMS65597.2025.11077020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077020","Intent-Based Management System;Network Configuration Automation;Natural Language Processing;Mesh Networks;Zero Trust","Mesh networks;Network topology;Generative AI;Autonomous systems;Mission critical systems;Chatbots;Routing protocols;Zero Trust;Topology;Resilience","","","","24","IEEE","18 Jul 2025","","","IEEE","IEEE Conferences"
"Enhancing Vehicular Edge Intelligence through Distributed Collaborative Generative AI Inference","G. Xie; R. Xie; X. Zhang; J. Nie; Q. Tang; Q. Chen; D. Niyato","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore",ICC 2024 - IEEE International Conference on Communications,"20 Aug 2024","2024","","","4560","4565","In recent years, there has been a proliferation of Edge Intelligence (EI) services, especially within Internet of Vehicles (IoV) scenarios, accompanied by a growing demand for multi-modal content generation. In response, Generative Artificial Intelligence (GAI) has emerged as a promising solution, equipping EI to produce diverse Artificial Intelligence-Generated Content (AIGC) for ubiquitous edge services. However, existing cloud-based GAI capabilities, which are mostly provided via the web and the Internet, introduce unacceptable latency overhead and heightened security risks for vehicular services. To address the above shortcomings and the lack of endogenous mechanisms for applying GAI to IoV scenarios, in this paper, we propose a layered vehicular GAI framework that seamlessly integrates GAI and EI. Within this framework, we devise a distributed collaborative inference mechanism between Road-Side Units (RSUs) and vehicles. Furthermore, we formulate the shared and local inference splitting problem, a pivotal challenge influencing both GAI service latency and content-generation capability. To tackle this issue, we introduce a backward induction-based algorithm, which enables the system can make splitting decisions using a simple threshold-based policy. Simulation results underscore the remarkable performance of the proposed system and vehicular collaborative inference mechanism, promising to facilitate diverse content generation within vehicular networks.","1938-1883","978-1-7281-9054-9","10.1109/ICC51166.2024.10622951","National Natural Science Foundation of China(grant numbers:92367104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10622951","Edge Intelligence (EI);generative artificial intelligence (GAI);collaborative inference;vehicular networks","Cloud computing;Inference mechanisms;Generative AI;Simulation;Collaboration;Inference algorithms;Security","","2","","15","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Toward Proactive, Secure and Efficient Space-Air-Ground Communications: Generative AI-Based DRL Framework","A. Kakati; G. Li; E. Moustapha Diallo; L. Chiru Kawala; N. Hussain; A. B. M. Adam","School of Communications and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communications and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communications and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communications and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg City, Luxembourg",IEEE Open Journal of the Communications Society,"21 Feb 2025","2025","6","","1284","1298","The rapid growth of low-Earth-orbit (LEO) satellites has enabled integrated space-air-ground networks to provide seamless connectivity to mobile users. However, these networks face challenges such as physical layer security risks from line-of-sight channels and the energy constraints of high-altitude platforms (HAPs), necessitating solutions for secure communication and energy efficiency. In this work, we address the challenges of energy efficiency and secure communication in space-air-ground networks, which are becoming critical with the increasing deployment of LEO satellites to support high-mobility users. We propose a novel downlink architecture where high-altitude platforms (HAPs) assist the LEO satellite in serving ground users. To tackle the demands of secrecy energy efficiency (SEE) in this dynamic and complex network, we formulate a non-convex optimization problem that jointly considers HAP trajectory, user-HAP association, and beamforming. The problem’s non-convexity makes it computationally challenging to solve in polynomial time. To overcome these challenges, we introduce a generative artificial intelligence (GAI)-based deep reinforcement learning (DRL) framework, named Gen-DRL, which leverages generative adversarial networks to empower its agents. This framework dynamically predicts and adapts to changes in the space-air-ground network environment by optimizing key parameters such as channel states, HAP trajectories, user associations, and beamforming. Compared to conventional methods, the proposed Gen-DRL achieves significant improvements in SEE by effectively managing complex interdependencies among multiple agents and intelligently adapting to the network’s goals and constraints. Extensive simulation results demonstrate that Gen-DRL consistently outperforms existing state-of-the-art frameworks in terms of secrecy energy efficiency, robustness to dynamic user locations, and adaptability to varying network parameters. This work provides new insights into the design of secure and energy-efficient space-air-ground networks, highlighting the potential of GAI-based DRL for future communication systems.","2644-125X","","10.1109/OJCOMS.2025.3539355","innovative group project of the Natural Science foundation of Chongqing under grant cstc2020jcyj-cxttX0002(grant numbers:cstc2020jcyj-cxttX0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876168","Generative artificial intelligence;space-air-ground network;deep reinforcement learning;beamforming;user association;high altitude platform","Optimization;Energy efficiency;Security;Satellites;Low earth orbit satellites;Array signal processing;Space-air-ground integrated networks;Autonomous aerial vehicles;Trajectory;Resource management","","1","","39","CCBY","6 Feb 2025","","","IEEE","IEEE Journals"
"Integrating Generative AI into Circular Supply Chain Safety Management: A Forward-Looking Perspective","Z. Chen; J. Sarkis; A. Yildizbasi","School of Business, Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA, USA; School of Business, Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA, USA; School of Business, Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA, USA",IEEE Engineering Management Review,"","2025","PP","99","1","17","Circular supply chains (CSCs) aim to minimize ecological footprints by closing the loop on resource use. However, safety concerns in CSCs, especially in activities like recycling and remanufacturing, present significant barriers. Current safety management systems in CSCs are often reactive and limited in scope, failing to address safety concerns in inter-organizational complexities. Therefore, we explore how generative artificial intelligence (Gen AI) can revolutionize safety management in CSCs by providing proactive monitoring, predictive analysis, and enhanced training. Nevertheless, integrating this technology requires addressing technical, data security, operational, trust, and ethical issues. Future research and practices should focus on overcoming these barriers to harness Gen AI's potential for enhancing safety in CSCs.","1937-4178","","10.1109/EMR.2025.3541542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10883968","Generative artificial intelligence;Circular economy;Health;Safety;Supply Chain;Sustainability","Safety;Safety management;Artificial intelligence;Supply chains;Training;Organizations;Generative AI;Sustainable development;Recycling;Software","","1","","","IEEE","13 Feb 2025","","","IEEE","IEEE Early Access Articles"
"Generative AI and Sustainability Optimizing Retail Supply Chain","S. Das","Tata Institute of Social Sciences, Hyderabad",2025 International Conference on Networks and Cryptology (NETCRYPT),"12 Aug 2025","2025","","","472","477","The kingdom is changing previous than we continuously hypothetical probable. Powerful original knowhows bear sacking conservatively uncooperative before difficult proceedings, creation a large change in what technique we alive previously effort. Currently is the period meant at skills to revenue a robed lengthy arrival on in what way they're employed formerly in pardon method to industrialized a part of this enormous increase of innovation? A productive occupational strategy often is depending on being a first Digital change through adopters of these new services, which is added goal vital to pay maintenance to innovations parallel artificial intelligence (AI), block chain, as well cyber security. Numerical / digital change ensues the minute alphanumeric data is collective bowed on a industry's goods, dealings, in accumulation products to gain waged proficiency, rally patron facts, expand curved on different markets, then as well realize peril. Convinced corporations power detection it inspiring to bear arithmetical change. However thru method of arithmetical services alike the haze, IoT, AI, big data, also portable continue increasingly used in extra subdivisions of saleable before development, it eats grow robust that digitalization is the only idea that ampule give skills a shy advantage. Sole of the chief interests of relaxed AI is its aptitude to assistance businesses delivers healthier purchaser provision. This software permits manufactures to automate errands analogous replying investigations or responding to comments on shared TV seats similar Facebook besides Twitter. This pays they won't vital by technique of many folks working in sound canters or organization infrastructures afterward patrons announcement up old-fashioned intended at runs who vessel do slightly diverse supplementary inspired via their dated. In today's arithmetical creation, employments recurrently attendance used for behaviours to tradition facts to rally their procurer data. Artificial intelligence (AI) is a convincing tool to provision finished this box. The main goals of this education are to discovery out: tranquil AI destined at improved customer delivery; powerful aide's support nearby bonds former; uniqueness society; clash resolve; documentations party; Designed for this task regular crucial cystography as well as lopsided key cryptography, mess function——these arrangements will be castoff.","","979-8-3315-2605-4","10.1109/NETCRYPT65877.2025.11102522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11102522","CPU mining;Mining Hardware;FPGAs and ASICs;Mining cloud services;sustainability","Technological innovation;TV;Social networking (online);Supply chains;Organizations;Software;Hardware;Maintenance;Artificial intelligence;Sustainable development","","","","27","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Towards Automated and Explainable Threat Hunting with Generative AI","M. D. Purba; B. Chu; W. French","University of North Carolina at Charlotte, USA; University of North Carolina at Charlotte, USA; University of North Carolina at Charlotte, USA",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),"11 Jul 2025","2025","","","664","677","This paper describes an attempt to automate threat hunting, taking cyber threat intelligence messages as input and generating queries to search logs for attack evidence using a popular query language, Kibana, used in Security Operations Centers (SOC). Our prototype implementation, AIThreatTrack, uses GPT-4 to extract actionable threat intelligence from real-time messages like X and Slack. The core idea is to explain the extracted intelligence in terms of MITRE ATT&CK TTPs using a knowledge graph containing ""is-a"" and ""part-of"" relationships (extracted using GPT-4) with the following benefits:(a) Significantly reduced hallucinations from 47% (GPT-4) to 1.5% using two orthogonal ways to cross-check answers. (b) Gaining analysts’ trust with explained results. (c) Using chain-of-knowledge prompting to significantly improve query generation accuracy. This approach supports expanding the scope of the knowledge graph to further improve query generation. Our approach significantly outperforms the Retrieval-Augmented Generation (RAG) approach and chain-of-thought reasoning LLM in reducing hallucinations.","2158-3927","979-8-3315-1201-9","10.1109/DSN64029.2025.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068856","Threat hunting;Large Language Model;GPT-4;OpenAI o1;Knowledge Graph;Kibana;Prompt;RAG","Generative AI;Large language models;Retrieval augmented generation;Prototypes;Knowledge graphs;Real-time systems;Cognition;Cyber threat intelligence;Security;Database languages","","","","61","IEEE","11 Jul 2025","","","IEEE","IEEE Conferences"
"Prompt Tuning Empowering Downstream Tasks in Multimodal Federated Learning","Y. Bao","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China",2024 11th International Conference on Behavioural and Social Computing (BESC),"12 Dec 2024","2024","","","1","7","Federated learning (FL) has made it possible to train global models using decentralized data in a privacy-preserving manner through the aggregation of model updates. Current FL methods have been expanded to incorporate multi-modal data for training a global model across multiple data modalities. However, global model performs poorly on downstream tasks. Recently, Prompt engineering has emerged as an indispensable technique for extending the capabilities of large language models (LLMs) and vision-language models (VLMs). This approach leverages task-specific instructions, known as prompts, to enhance model efficacy without modifying the core model parameters. Since prompt engineering is only applied to pre-trained language models and has not been widely used in other domains, in this paper, we propose a framework to apply prompt engineering from language models to multi-modal federated learning. We design prompts for representative downstream tasks including image classification task, text classification task, and multimodal retrieval task. Then, we freeze the backbone of the global model and do a few-shot sample study on prompts. Afterwards, we empirically analyze our framework via extensive experiments, and show its superiority in performance.","2689-8284","979-8-3315-3190-4","10.1109/BESC64747.2024.10780716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780716","federated learning;prompt tuning;downstream task;multimodality","Training;Visualization;Social computing;Large language models;Computational modeling;Text categorization;Data models;Prompt engineering;Tuning;Image classification","","","","60","IEEE","12 Dec 2024","","","IEEE","IEEE Conferences"
"Hey, Your Secrets Leaked! Detecting and Characterizing Secret Leakage in the Wild","J. Zhou; Z. Zhang; L. Ying; H. Chai; J. Cao; H. Duan","Southeast University; QI-ANXIN Technology Research Institute; QI-ANXIN Technology Research Institute; QI-ANXIN Technology Research Institute; Southeast University; Quancheng Lab, Tsinghua University; Tsinghua University-QI-ANXIN Group JCNS",2025 IEEE Symposium on Security and Privacy (SP),"16 Jun 2025","2025","","","449","467","Secrets, whether structured like API keys or un-structured like passwords, are essential for securing applications and services. However, the growing use of open -source projects and rapid development cycles has amplified the risk of secret leakage. Current detection tools suffer from high false positive rates and low recall due to simplistic methods like regular expressions and entropy checks, often missing unstructured secrets or mislabeling non-sensitive data. In this paper, we introduce Keysentinel, an advanced automated secret detection tool that addresses these limitations through machine learning, semantic analysis, and prefix matching. To evaluate KEYSENTINEL, we created the first cross-platform benchmark with 11,826 labeled secrets in 1,806,530 files across GitHub, PyPI, and WeChat. We compare Key-sentinelwith six currently available tools. The results show KEYSENTINEL achieves state-of-the-art performance, with precision (91.18%), recall (81.71%), and an F1 score (0.86), surpassing industry-standard tools and significantly reducing false positives. It also outperforms large language models like GPT-4 and o1 in accuracy and cost-effectiveness. Besides, we conduct a large-scale measurement study, analyzing 80,330,098 files from GitHub, PyPI, and WeChat. We found that up to 30% of projects are at risk of secret leaks. Furthermore, we also scan the code base of an IT company to assess real-world secret leakage risks. Our findings underscore the pervasive nature of secret leaks and highlight the urgent need for enhanced secret management practices across platforms.","2375-1207","979-8-3315-2236-0","10.1109/SP61157.2025.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023280","secret detection;software supply chain security;security and privacy metrics","Privacy;Social networking (online);Large language models;Semantics;Passwords;Machine learning;Message services;Security;Pattern matching;Software development management","","","","82","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"The Rise of Generative Artificial Intelligence in Healthcare","M. Kuzlu; Z. Xiao; S. Sarp; F. O. Catak; N. Gurler; O. Guler","Electrical Engineering Technology, Old Dominion University, Norfolk, VA, USA; Computational Operations Research, The College of William and Mary, Williamsburg, VA, USA; Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; Department of Electrical Engineering and Computer Science, University of Stavanger, Rogaland, Norway; eKare, Inc., Fairfax, VA, USA; eKare, Inc., Fairfax, VA, USA",2023 12th Mediterranean Conference on Embedded Computing (MECO),"26 Jun 2023","2023","","","1","4","Generative Artificial Intelligence (GAI) is transforming various fields, including finance, education, marketing, and healthcare. Especially in healthcare, GAI has the potential to revolutionize various aspects, such as medical imaging, drug development, patient care, and treatment planning. Key stakeholders who stand to benefit from these advancements include hospitals, clinics, pharmaceutical companies, medical device manufacturers, and research institutions. However, the implementation of GAI in healthcare presents several challenges, such as ensuring data privacy and security, addressing ethical considerations, maintaining quality and accuracy, adhering to regulatory compliance, and integrating with existing systems. This paper examines the current state of GAI in healthcare, discusses its potential benefits and challenges, and highlights future directions that must be addressed to fully harness the power of GAI in improving patient outcomes and healthcare systems.","2637-9511","979-8-3503-2291-0","10.1109/MECO58584.2023.10155107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155107","Generative AI (GAI);Large Language Model (LLM);Generative Pre-trained Transformer (GPT);AI in Healthcare","Ethics;Data privacy;Medical devices;Hospitals;Medical services;Companies;Transformers","","21","","15","IEEE","26 Jun 2023","","","IEEE","IEEE Conferences"
"Gaze Based Online Examination Cheat Detection with future integration of Deep Learning Models","A. Padmavathi; D. P. Kumar; K. N. K. Reddy","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India","2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","14 May 2024","2024","","","1","5","The popularity of online exams increasing rapidly because of this rapid change in education has resulted in both convenience and integrity concerns. but with this raise in popularity of online exams comes a big problem. how to maintain exam security and integrity in a connected and ever-evolving technology environment? the students also finding their own strategies over the time for cheating in online examinations. Online exams cheating has been developed into complex and difficult problem which includes techniques like false behavioral actions and accessing the unauthorized sites to find the solutions to the exam questions.","2769-2884","979-8-3503-5035-7","10.1109/ICRITO61523.2024.10522427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10522427","Online exams;Cheat detection;Eye Gaze;Deep Learning;Generative AI","Deep learning;Visualization;Education;Market research;Data models;Calibration;Security","","8","","25","IEEE","14 May 2024","","","IEEE","IEEE Conferences"
"AI Powered Image Annotation and Object Detection Platform for Workplace Safety","D. Ayata; U. Horasan","AIATUS AI, İstanbul, Türkiye; AIATUS AI, İstanbul, Türkiye",2024 32nd Signal Processing and Communications Applications Conference (SIU),"23 Jul 2024","2024","","","1","4","It is very critical within the scope of occupational health and safety that employees use the necessary personal protective equipment (PPE) in workplaces such as construction, mines, factories, warehouses and shipyards. Not using PPE puts employees at great risk. In this study, various object detection models are trained in order to continuously monitor employee safety through IP cameras in the workplace for various industries. An advanced AI-powered image labeling tool has been developed and used, which provides data security standards, has various data augmentation options and has auxiliary model support in the labeling process. With the developed tool, a data set was obtained by marking the images containing various personal protective equipments and people that are obtained from the internet in the context of occupational health and safety, and this data set was expanded with data augmentation. By trying different methods, up to 95.3% success was achieved.","2165-0608","979-8-3503-8896-1","10.1109/SIU61531.2024.10600985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10600985","Personal Protective Equipment (PPE);Object detection;YOLO;Transformers;Segmentation;Computer vision;Deep learning;Generative ai;Workplace safety","Personal protective equipment;Employment;Object detection;Signal processing;Occupational health;Data augmentation;Data models","","1","","0","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Towards Architectural Pen Test Case Generation and Attack Surface Analysis to Support Secure Design","M. J. Sarvejahani","KASTEL - Institute of Information Security and Dependability, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C),"30 May 2025","2025","","","143","148","In today's interconnected world, software systems have become indispensable components of complex frameworks, such as cyber-physical systems, e-commerce platforms, and healthcare information systems. This widespread integration highlights the importance of security more than ever, as these systems often function in critical environments where vulnerabilities can lead to significant destructive consequences. Pen-etration testing is a key method for identifying vulnerabilities but is often conducted after deployment, making remediation costly and time-consuming. On the other hand, back to the early phases of the Software Development Life Cycle (SDLC), software architects often lack the security expertise and feedback mechanisms needed to make informed design decisions, leading to vulnerabilities that remain undetected until later stages. In this paper, to address these challenges, we propose a research plan to integrate security considerations into the design phase. Our approach involves generating architecture-based penetration test cases, evaluating the attack surface of alternative architectures by using the generated test cases, and supporting software architects in making secure design decisions afterward. We plan to leverage threat modeling and Large Language Models (LLMs) to fulfill our target ambitions. To validate the applicability and effectiveness of our approach, we aim to conduct case studies in areas such as autonomous vehicles (AVs), which present significant security challenges.","2768-4288","979-8-3315-3336-6","10.1109/ICSA-C65153.2025.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014883","security by design;penetration testing;attack surface analysis;architectural decision support;autonomous vehicle systems","Threat modeling;Software architecture;Computer architecture;Medical services;Software systems;Security;Autonomous vehicles;Surface treatment;Penetration testing;Software development management","","","","30","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"From Bugs to Benefits: Improving User Stories by Leveraging Crowd Knowledge with CrUISE-AC","S. Schwedt; T. Ströder","Heriot Watt University, Edinburgh, Scotland; Fachhochschule der Wirtschaft (FHDW), Mettmann, Germany",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1385","1395","Costs for resolving software defects increase exponentially in late stages. Incomplete or ambiguous requirements are one of the biggest sources for defects, since stakeholders might not be able to communicate their needs or fail to share their domain specific knowledge. Combined with insufficient developer experience, teams are prone to constructing incorrect or incomplete features. To prevent this, requirements engineering has to explore knowledge sources beyond stakeholder interviews. Publicly accessible issue trackers for systems within the same application domain hold essential information on identified weaknesses, edge cases, and potential error sources, all documented by actual users. Our research aims at (1) identifying, and (2) leveraging such issues to improve an agile requirements artifact known as a “user story”. We present CrUISE-AC (Crowd and User Informed Suggestion Engine for Acceptance Criteria) as a fully automated method that investigates issues and generates non-trivial additional acceptance criteria for a given user story by employing NLP techniques and an ensemble of LLMs. CrUISE-AC was evaluated by five independent experts in two distinct business domains. Our findings suggest that issue trackers hold valuable information pertinent to requirements engineering. Our evaluation shows that 80–82 % of the generated acceptance criteria add relevant requirements to the user stories. Limitations are the dependence on accessible input issues and the fact that we do not check generated criteria for being conflict-free or non-overlapping with criteria from other user stories.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029950","Agile requirements engineering;User stories;Acceptance criteria;Issue tracker;NLP;NLP4RE;LLM","Knowledge engineering;Costs;Computer bugs;Software;Requirements engineering;Stakeholders;Interviews;Engines;Software engineering;Business","","","","68","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Automatic Visual Citation Generation for Text-to-Image Generation","N. Xu; S. Doken","Advanced R&D, Adeia Inc., San Jose, USA; Advanced R&D, Adeia Inc., San Jose, USA",2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR),"15 Oct 2024","2024","","","49","54","As generative artificial intelligence (GenAl) systems increasingly influence the fields of art and design, they raise critical challenges regarding copyright and artistic attribution. This paper introduces a novel system for generating visual citations within AI-generated images, thereby addressing copyright concerns while fostering ethical use and sharing of digital art. The proposed system aims to efficiently identify elements and styles that are possibly derived from existing artworks within the outputs of text-to-image AI systems. This system enhances privacy and security as it operates on image features and embeddings, rather than accessing the images directly, thus avoiding the handling of copyrighted materials. The system automatically embeds metadata into the images, detailing the origins of the included artistic elements. Moreover, the system enhances compliance by enabling automatic or manual modifications of generation prompts, ensuring that generated images are free of copyright infringements. This functionality not only protects artists' intellectual property but also supports transparent acknowledgment in digital media creation. The proposed system has the potential to facilitate respectful interactions between AI technologies and creative content.","2770-4319","979-8-3503-5142-2","10.1109/MIPR62202.2024.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707973","Generative AI;Text-to-Image;Visual Citation;Copyright Compliance;Digital Art","Visualization;Ethics;Privacy;Navigation;Text to image;Intellectual property;Metadata;Security;Artificial intelligence;Creativity","","","","13","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"Large Language Model for Qualitative Research: A Systematic Mapping Study","C. F. Barros; B. B. Azevedo; V. V. Graciano Neto; M. Kassab; M. Kalinowski; H. A. D. Do Nascimento; M. C. G. S. P. Bandeira","Informatics Institute, Federal University of Goiás, Goiânia, Brazil; Informatics Institute, Federal University of Goiás, Goiânia, Brazil; Informatics Institute, Federal University of Goiás, Goiânia, Brazil; Boston University, Boston, USA; Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Informatics Institute, Federal University of Goiás, Goiânia, Brazil; Faculty of Science and Technology, Federal University of Goiás, Aparecida de Goiânia, Brazil",2025 IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE),"10 Jul 2025","2025","","","48","55","The exponential growth of text-based data in domains such as healthcare, education, and social sciences has outpaced the capacity of traditional qualitative analysis methods, which are time-intensive and prone to subjectivity. Large Language Models (LLMs), powered by advanced generative AI, have emerged as transformative tools capable of automating and enhancing qualitative analysis. This study systematically maps the literature on the use of LLMs for qualitative research, exploring their application contexts, configurations, methodologies, and evaluation metrics. Findings reveal that LLMs are utilized across diverse fields, demonstrating the potential to automate processes traditionally requiring extensive human input. However, challenges such as reliance on prompt engineering, occasional inaccuracies, and contextual limitations remain significant barriers. This research highlights opportunities for integrating LLMs with human expertise, improving model robustness, and refining evaluation methodologies. By synthesizing trends and identifying research gaps, this study aims to guide future innovations in the application of LLMs for qualitative analysis.","","979-8-3315-0225-6","10.1109/WSESE66602.2025.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071443","Qualitative Research;Qualitative Analysis;Large Language Model;LLM;Software Engineering","Technological innovation;Systematics;Large language models;Soft sensors;Education;Social sciences;Medical services;Robustness;Prompt engineering;Software engineering","","1","","21","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"About the Author","K. -C. Chen",NA,Artificial Intelligence in Wireless Robotics,"","2020","","","323","324","Robots, autonomous vehicles, unmanned aerial vehicles, and smart factory, will significantly change human living style in digital society. Artificial Intelligence in Wireless Robotics introduces how wireless communications and networking technology enhances facilitation of artificial intelligence in robotics, which bridges basic multi-disciplinary knowledge among artificial intelligence, wireless communications, computing, and control in robotics. A unique aspect of the book is to introduce applying communication and signal processing techniques to enhance traditional artificial intelligence in robotics and multi-agent systems. The technical contents of this book include fundamental knowledge in robotics, cyber-physical systems, artificial intelligence, statistical decision and Markov decision process, reinforcement learning, state estimation, localization, computer vision and multi-modal data fusion, robot planning, multi-agent systems, networked multi-agent systems, security and robustness of networked robots, and ultra-reliable and low-latency machine-to-machine networking. Examples and exercises are provided for easy and effective comprehension. Engineers wishing to extend knowledge in the robotics, AI, and wireless communications, would be benefited from this book. In the meantime, the book is ready as a textbook for senior undergraduate students or first-year graduate students in electrical engineering, computer engineering, computer science, and general engineering students. The readers of this book shall have basic knowledge in undergraduate probability and linear algebra, and basic programming capability, in order to enjoy deep reading.","","9788770221177","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9310635.pdf&bkn=9310536&pdfType=chapter","","","","","","","","29 Dec 2020","","","River Publishers","River eBook Chapters"
"LLM-Based Generation of Solidity Smart Contracts from System Requirements in Natural Language: The AstraKode Case","G. De Vito; D. D'Amici; F. Izzo; F. Ferrucci; D. Di Nucci","Software Engineering (SeSa) Lab - University of Salerno, Salerno, Italy; AstraKode S.r.l., Pescara, Italy; AstraKode S.r.l., Pescara, Italy; Software Engineering (SeSa) Lab - University of Salerno, Salerno, Italy; Software Engineering (SeSa) Lab - University of Salerno, Salerno, Italy","2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","21 May 2025","2025","","","170","180","As blockchain technology continues to evolve, the need for accessible solutions for developing smart contracts has grown, especially for non-technical users. This paper addresses practitioners' challenges in generating Solidity smart contracts from natural language requirements within the AstraKode Blockchain no-code platform (AKB). Our goal is to lower the barrier of entry into smart contract development, making it more accessible to users with limited technical expertise. We propose three methods, i.e., Naive Generation, Augmented Generation, and Enhanced Generation, each utilizing large language models to streamline the code generation process. These methods cater to different user needs, from rapid prototyping to handling complex business scenarios, improving accessibility and usability within AKB. We demonstrate their practical relevance, potential, and limitations in addressing real-world challenges in smart contract development through empirical evaluations and practitioner feedback. Thanks to collaboration with academia and effective knowledge transfer, these methods provide innovative solutions to the challenges of smart contract generation. Furthermore, they have been integrated into AKB to enhance user services, ultimately promoting the development and deployment of secure and efficient smart contracts in the industry.","2640-7574","979-8-3315-3510-0","10.1109/SANER64311.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992387","Smart Contracts;No-Code Platform;Code Generation;Large Language Model","Industries;Codes;Large language models;Smart contracts;Natural languages;Rapid prototyping;Software;Blockchains;Usability;Knowledge transfer","","","","34","IEEE","21 May 2025","","","IEEE","IEEE Conferences"
"Consensus of Switched Nonlinear Multiagent Systems Subject to Cyber Attacks","S. Li; W. Zou; J. Guo; Z. Xiang","School of Automation, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China",IEEE Systems Journal,"25 Aug 2022","2022","16","3","4423","4432","In this article, the output consensus problem is investigated for a class of switched nonlinear multiagent systems, where denial-of-service attacks and faults are considered in communication channels and agents’ actuators, respectively. The cyber attacks can damage the communication channels, which will cause the consensus performance degradation or even failure to achieve consensus. Compared with the existing results on consensus of multiagent systems under cyber attacks, the agents’ dynamics in this article are described by higher order heterogeneous switched nonlinear systems. The cyber attacks, actuator faults, asynchronous switchings, and the high complexity of the system make the existing consensus algorithms ineffective. A novel control scheme for the output consensus of the multiagent system subject to cyber attacks is proposed. By the graph theory, switched system theory and Lyapunov function method, sufficient conditions are presented to check whether the consensus objective can be achieved. Finally, the effectiveness of the proposed scheme is illustrated by two numerical simulations.","1937-9234","","10.1109/JSYST.2021.3110501","National Natural Science Foundation of China(grant numbers:61873128,61673219); Jiangsu Key Research and Development Plan(grant numbers:BE2021016-1); UM Macao Talent Programme(grant numbers:UMMTP-2020-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548008","Cyber attacks;fault-tolerant consensus;multiagent systems (MAS);security control;switched systems","Topology;Switches;Cyberattack;Actuators;Denial-of-service attack;Consensus protocol;Fault tolerant systems","","26","","49","IEEE","24 Sep 2021","","","IEEE","IEEE Journals"
"LuaTaint: A Static Analysis System for Web Configuration Interface Vulnerability of Internet of Things Devices","J. Xiang; L. Fu; T. Ye; P. Liu; H. Le; L. Zhu; W. Wang","College of Control Science and Engineering, Zhejiang University, Hangzhou, China; School of Cyberspace Security, Hangzhou Dianzi University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Information Centre, China Tobacco Zhejiang Industrial Company Ltd., Hangzhou, China; Information Centre, China Tobacco Zhejiang Industrial Company Ltd., Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China",IEEE Internet of Things Journal,"25 Feb 2025","2025","12","5","5970","5984","The diversity of Web configuration interfaces for Internet of Things (IoT) devices has exacerbated issues, such as inadequate permission controls and insecure interfaces, resulting in various vulnerabilities. Owing to the varying interface configurations across various devices, the existing methods are inadequate for identifying these vulnerabilities precisely and comprehensively. This study addresses these issues by introducing an automated vulnerability detection system, called LuaTaint. It is designed for the commonly used Web configuration interface of IoT devices. LuaTaint combines static taint analysis with a large language model (LLM) to achieve widespread and high-precision detection. The extensive traversal of the static analysis ensures the comprehensiveness of the detection. The system also incorporates rules related to page handler control logic within the taint detection process to enhance its precision and extensibility. Moreover, we leverage the prodigious abilities of LLM for code analysis tasks. By utilizing LLM in the process of pruning false alarms, the precision of LuaTaint is enhanced while significantly reducing its dependence on manual analysis. We develop a prototype of LuaTaint and evaluate it using 2447 IoT firmware samples from 11 renowned vendors. LuaTaint has discovered 111 vulnerabilities. Moreover, LuaTaint exhibits a vulnerability detection precision rate of up to 89.29%.","2327-4662","","10.1109/JIOT.2024.3490661","National Natural Science Foundation of China(grant numbers:62302443); Fellowship of China National Postdoctoral Program for Innovative Talents(grant numbers:BX20230307); Fundamental Research Funds for the Central Universities (Zhejiang University NGICS Platform); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10742550","Device security;large language model (LLMs);static analysis;Web configuration interface","Internet of Things;Microprogramming;Static analysis;Security;Codes;Uniform resource locators;Performance evaluation;Dispatching;Bandwidth;Web servers","","2","","55","IEEE","4 Nov 2024","","","IEEE","IEEE Journals"
"How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks Before and After Fine-tuning","F. Salerno; A. Al-Kaswan; M. Izadi","Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","465","477","Code language models, while widely popular, are often trained on unsanitized source code gathered from across the Internet. Previous work revealed that pre-trained models can remember the content of their training data and regurgitate them through data extraction attacks. Due to the large size of current models, only a few entities have the resources for pre-training such models. However, fine-tuning requires fewer resources and is increasingly used by both small and large entities for its effectiveness on specialized data. Such small curated data for finetuning might contain sensitive information or proprietary assets. In this study, we attack both pre-trained and fine-tuned code language models to investigate the extent of data extractability. We first develop a custom benchmark to assess the vulnerability of both pre-training and fine-tuning samples to extraction attacks. Our findings reveal that $54.9 \%$ of extractable pre-training data could be retrieved from StarCoder2-15B, whereas this number decreased to $\mathbf{2 3. 5 \%}$ after fine-tuning. This indicates that finetuning reduces the extractability of pre-training data. However, compared to larger models, fine-tuning smaller models increases their vulnerability to data extraction attacks on fine-tuning data. Given the potential sensitivity of fine-tuning data, this can lead to more severe consequences. Lastly, we also manually analyzed 2000 extractable samples before and after fine-tuning. We also found that data carriers and licensing information are the most likely data categories to be memorized from pre-trained and finetuned models, while the latter is the most likely to be forgotten after fine-tuning.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025762","Security and privacy;Software and its engineering;LLMs for code;Memorization;Fine-Tuning","Codes;Sensitivity;Source coding;Training data;Benchmark testing;Data models;Software;Data mining;Security;Research and development","","1","","48","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Byzantine-Resilient Multi-Agent Distributed Optimization under Redundancy","Y. Zhai; Z. -W. Liu; D. Yue; S. Hu; C. Deng; L. Ye","Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology for Carbon Neutrality, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Control of Network Systems,"","2025","PP","99","1","12","This paper investigates the distributed multi-agent resilient optimization problem under the $f$-total Byzantine attacks, i.e., at most $f$ agents transmitting different false information to different out-neighbors in the system. Compared with the previous research on Byzantine-resilient multi-agent optimization problems, we do not impose the requirement of a fully connected communication topology. Under the redundancy of cost functions, we propose the distributed comparative gradient elimination resilient optimization algorithm based on the traditional assumptions on strongly convex global costs and Lipschitz continuous gradients. Under this algorithm, we address the limitation of previous relevant research, which only ensures that the estimates converge to a neighborhood of the optimal solution. We successfully prove that the normal agents' local estimates will converge to the optimal solution if the number of neighbors of normal agents is greater than a certain constant. Finally, a numerical experiment is provided to verify the correctness of the obtained results.","2325-5870","","10.1109/TCNS.2025.3583622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052777","Multi-agent system (MAS);cyber-security;distributed optimization;Byzantine attack;cost redundancy","Optimization;Cost function;Redundancy;Topology;Costs;Vectors;Nickel;Fake news;Convergence;Artificial intelligence","","","","","IEEE","26 Jun 2025","","","IEEE","IEEE Early Access Articles"
"DRMiner: Extracting Latent Design Rationale from Jira Issue Logs","J. Zhao; Z. Yang; L. Zhang; X. Lian; D. Yang; X. Tan","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Software, Beihang University, Beijing, China; CCSE, Beihang University, Beijing, China; CCSE, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; CCSE, Beihang University, Beijing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","468","480","Software architectures are usually meticulously designed to address multiple quality concerns and support long-term maintenance. However, there may be a lack of motivation for developers to document design rationales (i.e., the design alternatives and the underlying arguments for making or rejecting decisions) when they will not gain immediate benefit, resulting in a lack of standard capture of these rationales. With the turnover of developers, the architecture inevitably becomes eroded. This issue has motivated a number of studies to extract design knowledge from open-source communities in recent years. Unfortunately, none of the existing research has successfully extracted solutions alone with their corresponding arguments due to challenges such as the intricate semantics of on-line discussions and the lack of benchmarks for design rationale extraction.In this paper, we propose a novel approach, named DRMiner, to automatically mine latent design rationales from developers’ live discussion in open-source community (i.e., issue logs in Jira). To better identify solutions and their relevant arguments, DRMiner skillfully decomposes the problem into multiple text classification tasks and tackles them using prompt tuning of large language models (LLMs) and specific heuristic features. To evaluate DRMiner, we acquire issue logs from Cassandra, Flink, and Solr repositories in Jira and form a dataset for design rationale mining. Experimental results show that DRMiner outperforms all baselines and achieves F1 improvements of 24%, 22%, and 20% for mining design rationales, solutions, and arguments, respectively, compared to the best baseline. Furthermore, we investigate the usefulness of the design rationales mined by DRMiner for automated program repair (APR) and find that advanced LLMs, when prompted with these extracted rationales, generate 10×-18× more full-match patches and achieve a 10%-13% gain in CodeBLEU scores.CCS CONCEPTS• Software and its engineering → Maintaining software.","2643-1572","979-8-4007-1248-7","","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764909","Design rationale;Issue logs;Design discussion;Design recovery;Program maintenance","Software architecture;Large language models;Text categorization;Semantics;Maintenance engineering;Software;Maintenance;Data mining;Tuning;Standards","","1","","69","","29 Nov 2024","","","IEEE","IEEE Conferences"
"The Seeds of the Future Sprout from History: Fuzzing for Unveiling Vulnerabilities in Prospective Deep-Learning Libraries","Z. Li; J. Wu; X. Ling; T. Luo; Z. Rui; Y. Wu","Institute of Software, Chinese Academy of Sciences, China; Institute of Software, Chinese Academy of Sciences, China; Institute of Software, Chinese Academy of Sciences, China; Institute of Software, Chinese Academy of Sciences, China; Institute of Software, Chinese Academy of Sciences, China; Institute of Software, Chinese Academy of Sciences, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1616","1627","The widespread application of large language models (LLMs) underscores the importance of deep learning (DL) technologies that rely on foundational DL libraries such as PyTorch and TensorFlow. Despite their robust features, these libraries face challenges with scalability and adaptation to rapid advancements in the LLM community. In response, tech giants like Apple and Huawei are developing their own DL libraries to enhance performance, increase scalability, and safeguard intellectual property. Ensuring the security of these libraries is crucial, with fuzzing being a vital solution. However, existing fuzzing frameworks struggle with target flexibility, effectively testing bug-prone API sequences, and leveraging the limited available information in new libraries. To address these limitations, we propose FUTURE, the first universal fuzzing framework tailored for newly introduced and prospective DL libraries. FUTURE leverages historical bug information from existing libraries and fine-tunes LLMs for specialized code generation. This strategy helps identify bugs in new libraries and uses insights from these libraries to enhance security in existing ones, creating a cycle from history to future and back. To evaluate FUTURE's effectiveness, we conduct comprehensive evaluations on three newly introduced DL libraries. Evaluation results demonstrate that FUTURE significantly outperforms existing fuzzers in bug detection, success rate of bug reproduction, validity rate of code generation, and API coverage. Notably, FUTURE has detected 148 bugs across 452 targeted APIs, including 142 previously unknown bugs. Among these, 10 have been assigned CVE IDs. Additionally, FUTURE detects 7 bugs in PyTorch, demonstrating its ability to enhance security in existing libraries in reverse.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00132","Chinese Academy of Sciences(grant numbers:XDA0320401); National Natural Science Foundation of China(grant numbers:62202457); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029791","Fuzzing;DL Libraries;Historical Bug","Codes;Scalability;Computer bugs;Fuzzing;Libraries;Security;History;Testing;Software engineering;Software development management","","1","","65","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Efficiency of Architectural Innovations in Deep Learning for Enhanced Age Prediction and Gender Classification","G. Vinod; K. S; V. J. Panicker","Dept. of Computer Science Engineering, Amrita School of Computing,Amritapuri Amrita Vishwa Vidyapeetham, India; Dept. of Computer Science Engineering, Amrita School of Computing,Amritapuri Amrita Vishwa Vidyapeetham, India; Dept. of Computer Science Engineering, Amrita School of Computing,Amritapuri Amrita Vishwa Vidyapeetham, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","Advancements in facial recognition technology have sparked significant interest in enhancing the precision of age and gender classification, crucial for applications ranging from personalized advertising to security systems. This paper introduces a sophisticated deep learning framework, utilizing inputs of facial imagery to deploy innovative architectural methods for age and gender classification. We detail our approach from data preprocessing, model training using Generative Adversarial Networks (GANs) and Transformer models, to the evaluation of model efficacy, ultimately achieving enhanced predictive accuracy.It meticulously navigates the landscape of existing methodologies to delineate the most efficacious models, spotlighting the transformative impact of architectural ingenuity on enhancing performance in such complex classification endeavors. The culmination of this research not only illuminates the expansive capabilities of deep learning in intricate classification scenarios but also paves the way for its application in scenarios demanding unparalleled precision in age and gender predictions, such as sophisticated security protocols in access control systems. Through a comprehensive exposition of the model’s design, the intricacies of its training regimen, and the indispensable value of a heterogenous training dataset, this work enriches the existing corpus of knowledge, providing a beacon for forthcoming explorations and practical implementations in akin domains.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724502","Deep Learning Architectures;Age Prediction;Gender Classification;Convolutional Neural Networks;Recurrent Neural Networks;Generative Adversarial Networks;Transformer Models;Computational Efficiency;Demographic Attribute Prediction","Deep learning;Training;Analytical models;Technological innovation;Protocols;Computational modeling;Neural networks;Predictive models;Transformers;Data models","","","","15","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Quality Assessment of ChatGPT Generated Code and their Use by Developers","M. L. Siddiq; L. Roney; J. Zhang; J. C. S. Santos","University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA; University of Notre Dame, Notre Dame, IN, USA",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","152","156","The release of large language models (LLMs) like ChatGPT has revolutionized software development. Prior works explored ChatGPT’s generated response quality, the effectiveness of different prompting techniques, its performance in programming contests, etc. However, there is limited information regarding the practical usage of ChatGPT by software developers. This data mining challenge focuses on DevGPT, a curated dataset of developer-ChatGPT conversations encompassing prompts with ChatGPT’s responses, including code snippets. Our paper leverages this dataset to investigate (RQ1) whether ChatGPT generates Python & Java code with quality issues; (RQ2) whether ChatGPT-generated code is merged into a repository, and, if it does, to what extent developers change them; and (RQ3) what are the main use cases for ChatGPT besides code generation. We found that ChatGPT-generated code suffers from using undefined/unused variables and improper documentation. They also have security issues related to improper resources and exception management. Our results show that ChatGPT-generated codes are hardly merged, and they are significantly modified before merging. Based on an analysis of developers’ discussions and the developer-ChatGPT chats, we found that developers use ChatGPT for every stage of software development and leverage it to learn about new frameworks and development kits.CCS CONCEPTS• Software and its engineering → Software performance; Software usability; Empirical software validation.","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555682","datasets;ChatGPT;security;quality;pull-request;open-coding","Codes;Software performance;Programming;Chatbots;Quality assessment;Data mining;Security","","11","","44","","18 Jun 2024","","","IEEE","IEEE Conferences"
"IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge Delivery","D. R. Arikkat; A. M.; N. Binu; P. M.; N. Biju; K. S. Arunima; V. P; R. Rehiman K. A.; M. Conti","Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Mathematics, University of Padua, Padua, Italy; Department of Computer Applications, Cochin University of Science and Technology, Kerala, India; Department of Mathematics, University of Padua, Padua, Italy",2024 IEEE 16th International Conference on Computational Intelligence and Communication Networks (CICN),"27 Jan 2025","2024","","","644","651","In the evolving field of cybersecurity, AI-driven chatbots are valuable. Unlike rigid rule-based bots, Large Language Model (LLM) based chatbots can provide flexible, context-aware responses across various domains. This research introduces IntellBot, a sophisticated cybersecurity chatbot built using advanced LLMs, Langchain, and a Retrieval-Augmented Generation model. IntellBot aggregates data from diverse sources, creating a comprehensive knowledge base on vulnerabilities, recent cyber threats, and emerging trends. It offers intelligent responses to enhance threat intelligence, incident response, and overall security awareness. A two-stage evaluation yielded high accuracy, with a BERT score above 0.8 and cosine similarity from 0.8 to 1, while RAGAS assessments scores consistently over 0.77, confirming the system's effectiveness.","2472-7555","979-8-3315-0526-4","10.1109/CICN63059.2024.10847404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10847404","Large Language Model;Security Chatbot;Threat Intelligence;Cyber Security;Retrieval-Augmented Generation","Accuracy;Soft sensors;Large language models;Retrieval augmented generation;Knowledge based systems;Reinforcement learning;Chatbots;Market research;Vectors;Distance measurement","","1","","19","IEEE","27 Jan 2025","","","IEEE","IEEE Conferences"
"A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories","Z. Ding; Q. Fu; J. Ding; G. Deng; Y. Liu; Y. Li","UNSW Sydney, Australia; Commonwealth Scientific and Industrial Research Organisation (CSIRO) Data61, Australia; UNSW Sydney, Australia; Nanyang Technological University, Singapore; Quantstamp; UNSW Sydney, Australia",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","260","264","Recent advancements in large language models (LLMs) have spurred the development of diverse AI applications-from code generation and video editing to text generation. However, AI supply chains such as Hugging Face, which host pretrained models and their associated configuration files contributed by the public, face significant security challenges. In particular, configuration files—originally intended to set up models by specifying parameters and initial settings—can be exploited to execute unauthorized code, yet research has largely overlooked their security compared to that of the models themselves. In this work, we present the first comprehensive study of malicious configurations on Hugging Face, identifying three attack scenarios (file, website, and repository operations) that expose inherent risks. To address these threats, we introduce Configscan, an LLM-based tool that analyzes configuration files in the context of their associated runtime code and critical libraries, effectively detecting suspicious elements with low false positive rates and high accuracy. Our extensive evaluation uncovers thousands of suspicious repositories and configuration files, underscoring the urgent need for enhanced security validation in AI model hosting platforms.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050786","AI Supply Chain;LLM;Configuration","Privacy;Codes;Runtime;Accuracy;Large language models;Supply chains;Libraries;Security;Artificial intelligence;Faces","","","","18","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Research on Technical Route of AI Large Models for Electric Power Knowledge Services","S. Peng; J. Xiao; W. Zhang; Y. Zuo; S. Liu; Y. Long; Z. Huang; S. Wu","Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China; Hunan Province Engineering Technology Research Center of Electric Power Multimodal Perception and Edge Intelligence, State Grid Hunan Electric Power Company Limited Research Institute, Changsha, China",2024 IEEE 8th Conference on Energy Internet and Energy System Integration (EI2),"15 May 2025","2024","","","203","208","Artificial intelligence (AI) large language models have shown great potential and value in various vertical fields. In response to the demand for the intelligent development of new power systems, this paper summarizes the difficulties faced in the application of AI large language models in the field of power such as large language model illusions. To address these difficulties, starting from the two dimensions of large language model response enhancement and knowledge enhancement, combined with technologies such as fine-tuning, prompt engineering, and retrieval-enhanced generation, this paper proposes an engineering framework for the implementation of AI large models for electric power knowledge services, providing support for empowering the construction of new power systems in China with AI large models. Finally, this paper gives the corresponding solutions to the challenges faced in building large language models for power systems, including difficulties in data acquisition, data security, low interpretability, and high research and development cost.","","979-8-3315-2352-7","10.1109/EI264398.2024.10990616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990616","electric power knowledge service;knowledge enhancement;artificial intelligence;large model;knowledge graph","Knowledge engineering;Large language models;Computational modeling;Data security;Data acquisition;Data models;Power systems;Prompt engineering;Research and development;Context modeling","","","","27","IEEE","15 May 2025","","","IEEE","IEEE Conferences"
"MACE: Mass Concept Erasure in Diffusion Models","S. Lu; Z. Wang; L. Li; Y. Liu; A. W. -K. Kong","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research (IR) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","6430","6440","The rapid expansion of large-scale text-to-image diffusion models has raised growing concerns regarding their potential misuse in creating harmful or misleading content. In this paper, we introduce MACE, a finetuning framework for the task of MAss Concept Erasure. This task aims to prevent models from generating images that embody unwanted concepts when prompted. Existing concept erasure methods are typically restricted to handling fewer than five concepts simultaneously and struggle to find a balance between erasing concept synonyms (generality) and maintaining unrelated concepts (specificity). In contrast, MACE differs by successfully scaling the erasure scope up to 100 concepts and by achieving an effective balance between generality and specificity. This is achieved by leveraging closed-form cross-attention refinement along with LoRA finetuning, collectively eliminating the information of undesirable concepts. Furthermore, MACE integrates multiple LoRAs without mutual interference. We conduct extensive evaluations of MACE against prior methods across four different tasks: object erasure, celebrity erasure, explicit content erasure, and artistic style erasure. Our results reveal that MACE surpasses prior methods in all evaluated tasks. Code is available at https://github.com/Shilin-LU/MACE.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.00615","National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657770","Generative AI;AI security;diffusion model;concept editing","Computer vision;Codes;Text to image;Interference;Diffusion models;Pattern recognition","","8","","77","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"SCOUT: Surveillance and Cyber harassment Observation of Unseen Threats","S. Biswal","MS/ECY, Bosch Global Software Technologies (BGSW), Bosch, Bengaluru, India","2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)","9 Jan 2025","2024","","","1","6","Cyberbullying and cyber harassment pose significant challenges to mental health, with traditional detection methods often falling short, particularly in identifying subtle and passive-aggressive behaviors in textual communication. This research addresses these gaps by developing a Generative Artificial Intelligence (AI)-driven solution that enhances detection capabilities and captures the nuanced nature of cyber harassment across various platforms. Utilizing explainable AI techniques, this approach not only improves detection accuracy but also educates users on behavioral implications, supporting victims and legal authorities. The solution integrates with existing anti-harassment policies in academic institutions, workplaces, and social media environments to provide proactive and tailored interventions. To counter the potential misuse by abusers refining their harassment methods, the solution incorporates adaptive learning algorithms that continuously improve based on new data and detected evasion tactics. Regular audits and updates ensure the system evolves with emerging threats and remains resilient against misuse. This comprehensive approach aims to create safer online and offline spaces by addressing both unresolved and emerging issues in cyberbullying detection.","","979-8-3503-5348-8","10.1109/ICAMAC62387.2024.10828792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828792","Cybercrime Investigation;Behavioral Information Security;Adaptive learning algorithms;Generative AI;Human Rights;Passive Aggression","Training;Accuracy;Metaverse;Law;Surveillance;Refining;Cyberbullying;Mental health;Learning (artificial intelligence);Robustness","","","","16","IEEE","9 Jan 2025","","","IEEE","IEEE Conferences"
"Membership Inference Attacks and Differential Privacy: A Study Within the Context of Generative Models","B. A. Galende; P. A. Apellániz; J. Parras; S. Zazo; S. Uribe","Information Processing and Telecommunications Center, Escuela Tecnica Superior de Ingeniería de Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Information Processing and Telecommunications Center, Escuela Tecnica Superior de Ingeniería de Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Information Processing and Telecommunications Center, Escuela Tecnica Superior de Ingeniería de Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Information Processing and Telecommunications Center, Escuela Tecnica Superior de Ingeniería de Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Escuela Técnica Superior de Ingeniería de Sistemas Informáticos, Universidad Politécnica de Madrid, Madrid, Spain",IEEE Open Journal of the Computer Society,"11 Jun 2025","2025","6","","801","811","Membership attacks pose a major issue in terms of secure machine learning, especially in cases in which real data are sensitive. Models tend to be overconfident in predicting labels from the training set. Nevertheless, its application has traditionally been limited to supervised models, while in the case of generative models we have found that there is a lack of theoretical foundations to bring this concept into the scene. Hence, this article provides the theoretical background in the context of membership inference attacks and their relationship to generative models, including the derivation of an evaluation metric. In addition, the link between these types of attack and differential privacy is shown to be a particular case. Lastly, we empirically show through simulations the intuition and application of the concepts derived.","2644-1268","","10.1109/OJCS.2025.3572244","Synthetic Generation of Hematological Data over Federated Computing Frameworks(grant numbers:101095530); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008817","Generative AI;computer security;machine learning;private machine learning;differential privacy","Mathematical models;Data models;Measurement;Training;Computational modeling;Synthetic data;Machine learning;Privacy;Differential privacy;Context modeling","","","","30","CCBY","21 May 2025","","","IEEE","IEEE Journals"
"AutoMHS-GPT: Automated Model and Hyperparameter Selection with Generative Pre-Trained Model","L. A. C. De Souza; M. Sammarco; N. Achir; M. E. M. Campista; L. H. M. K. Costa","Grupo de Teleinformática e Automação (GTA), Universidade Federal do Rio de Janeiro (UFRJ); Stellantis; Ècole Polytechnique, INRIA Saclay, France; Grupo de Teleinformática e Automação (GTA), Universidade Federal do Rio de Janeiro (UFRJ); Grupo de Teleinformática e Automação (GTA), Universidade Federal do Rio de Janeiro (UFRJ)",2024 IEEE 13th International Conference on Cloud Networking (CloudNet),"31 Dec 2024","2024","","","1","8","Automated Machine Learning emerges as a solution to reduce the instantiation time of systems that rely on Artificial Intelligence (AI) by accelerating the search process for models and hyperparameters. These techniques, however, still require high execution time. In critical applications, such as intrusion detection in vehicular networks, delays in applying countermeasures can provoke accidents. Therefore, it is essential to guarantee accurate models in the shortest possible time to detect threats effectively. This work proposes AutoMHS-GPT, a system that uses generative artificial intelligence to reduce the time it takes to define hyperparameters and models when implementing machine learning to detect threats in vehicular networks. Based on a description of the problem, the generative model returns a text containing the appropriate model with its hyperparameters for training. Results show that AutoMSH-GPT produces models with higher threat classification performance than automated machine learning approaches AutoKeras and Auto-Sklearn, increasing in the best case the recall by 9%. Furthermore, the current proposal reduces the model search and training process, carrying out the task in around 30 minutes, while the other evaluated frameworks require two to three days.","2771-5663","979-8-3503-7656-2","10.1109/CloudNet62863.2024.10815898","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES)(grant numbers:001 and 88887.954253/2024-00,CNPq (408255/2023-4 and 405940/2022-0),FAPERJ (E-26/204.122/2024)); Fundação de Desenvolvimento da Pesquisa(grant numbers:2023/00673-7,2023/00811-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10815898","Machine Learning;Generative AI;Network Security;Vehicular Networks;AutoML","Training;Accuracy;Generative AI;Intrusion detection;Automated machine learning;Delays;Proposals;Accidents","","","","27","IEEE","31 Dec 2024","","","IEEE","IEEE Conferences"
"Deciphering Empathy in Developer Responses: A Hybrid Approach Utilizing the Perception Action Model and Automated Classification","K. Devathasan; N. N. Arony; K. Gama; D. Damian","University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada; Federal University of Pernambuco (UFPE), Recife, Brazil; University of Victoria, Victoria, Canada",2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW),"21 Aug 2024","2024","","","88","94","Empathy is crucial in software engineering requirements because it enables developers to understand and anticipate the needs and challenges of users, ensuring the creation of more effective, user-friendly, and accessible solutions. While there has been research done into how to leverage empathy for more effective requirements in traditional elicitation methods such as interviews and focus groups, little is known about how to leverage empathy in crowd-based techniques. This paper investigates the presence of empathy in a large dataset of developer responses to app users by employing the Perception Action Model (PAM) for manual classification into several categories. A curated dataset of developer communications is annotated to reflect these empathetic dimensions. We then apply machine learning techniques, leveraging recent developments in large language models (LLMs), to automatically differentiate empathetic from non-empathetic text. Our findings demonstrate that, although challenging, automated systems can identify empathy in written responses with promising accuracy. We also comment on preliminary trends found in the responses, and promising directions for future work. This hybrid approach not only enhances our understanding of empathy in crowdRE but also has practical implications for improving developer-user interactions for software organizations.","2770-6834","979-8-3503-9551-8","10.1109/REW61692.2024.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628752","Crowd Requirements Engineering;Empathy","Reviews;Large language models;Organizations;Manuals;Market research;Software;Requirements engineering","","2","","45","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Federated Large Language Model: Solutions, Challenges and Future Directions","J. Hu; D. Wang; Z. Wang; X. Pang; H. Xu; J. Ren; K. Ren","State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; Hunan Normal University, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; Tsinghua University, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, China",IEEE Wireless Communications,"23 Jul 2025","2025","32","4","82","89","Large language models (LLMs) have become increasingly popular due to their exceptional performance in various artificial intelligence applications. However, their development often suffers from the scarcity of high-quality data and the extensive requirements for computing resources. These obstacles are even more severe for enterprises in vertical industries, which have limited computer resources but urgently require large-scale models for specific activities. To address these issues, LLMs call for the integration of federated learning (FL), which enables the collaborative learning of a powerful LLM using private data and computing resources from multiple entities. In this article, we present a systematic introduction to the federated large language model (Fed-LLM), a distributed learning of LLM in the FL manner. We first introduce the learning paradigm of Fed-LLM, which is called federated parameter-efficient fine-tuning (Fed-PEFT). Fed-PEFT empowers the collaborative fine-tuning of pretrained LLMs by only involving a small subset of parameters in local LLMs. Specifically, we detail the workflow of Fed-PEFT, and summarize the state-of-the-art solutions in this area. Additionally, we discuss the challenges faced in Fed-LLMs, including efficiency, privacy, and security. Finally, we introduce future directions to facilitate the research of Fed-LLMs and guide coming explorations in this nascent field.","1558-0687","","10.1109/MWC.009.2400244","National Natural Science Foundation of China(grant numbers:62122066,U20A20182,62302164); China Postdoctoral Science Foundation(grant numbers:2023M731071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10733964","","Training;LoRa;Servers;Computational modeling;Data models;Tuning;Transformers;Adaptation models;Privacy;Federated learning;Large language models","","5","","15","IEEE","23 Oct 2024","","","IEEE","IEEE Magazines"
"Depth Prompting for Sensor-Agnostic Depth Estimation","J. -H. Park; C. Jeong; J. Lee; H. -G. Jeon","AI Graduate School; AI Graduate School; GIST, School of Electrical Engineering and Computer Science, South Korea; AI Graduate School",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","9859","9869","Dense depth maps have been used as a key element of visual perception tasks. There have been tremendous efforts to enhance the depth quality, ranging from optimization-based to learning-based methods. Despite the remarkable progress for a long time, their applicability in the real world is limited due to systematic measurement biases such as density, sensing pattern, and scan range. It is well-known that the biases make it difficult for these methods to achieve their generalization. We observe that learning a joint representation for input modalities (e.g., images and depth), which most recent methods adopt, is sensitive to the biases. In this work, we disentangle those modalities to mitigate the biases with prompt engineering. For this, we design a novel depth prompt module to allow the desirable feature representation according to new depth distributions from either sensor types or scene configurations. Our depth prompt can be embedded into foundation models for monocular depth estimation. Through this embedding process, our method helps the pretrained model to be free from restraint of depth scan range and to provide absolute scale depth maps. We demonstrate the effectiveness of our method through extensive evaluations. Source code is publicly available at https://github.com/JinhwiPark/DepthPrompting.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.00941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656476","Sensor-agnostic depth estimation;;3D from single images;;foundation model;;depth completion;;prompt engineering;","Learning systems;Systematics;Source coding;Estimation;Time measurement;Stability analysis;Sensors","","","","75","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"Bridging Gaps in LLM Code Translation: Reducing Errors with Call Graphs and Bridged Debuggers","Y. Luo; R. Yu; F. Zhang; L. Liang; Y. Xiong","Microsoft Research Beijing, Beijing, China; Microsoft Beijing, Beijing, China; Microsoft Beijing, Beijing, China; Microsoft Beijing, Beijing, China; Microsoft Research Beijing, Beijing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","2448","2449","When using large language models (LLMs) for code translation of complex software, numerous compilation and runtime errors can occur due to insufficient context awareness. To address this issue, this paper presents a code translation method based on call graphs and bridged debuggers: TransGraph. TransGraph first obtains the call graph of the entire code project using the Language Server Protocol, which provides a detailed description of the function call relationships in the program. Through this structured view of the code, LLMs can more effectively handle large-scale and complex codebases, significantly reducing compilation errors. Furthermore, TransGraph, combined with bridged debuggers and dynamic test case generation, significantly reduces runtime errors, overcoming the limitations of insufficient test case coverage in traditional methods. In experiments on six datasets including CodeNet and Avatar, TransGraph outperformed existing code translation methods and LLMs in terms of translation accuracy, with improvements of up to 10.2%.CCS CONCEPTS• Software and its engineering → Source code generation; Translator writing systems and compiler generators; Parsers.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764938","code translation;large language model;call graph;bridged debugger;Language Server Protocol;runtime error;compilation error","Codes;Runtime;Protocols;Source coding;Large language models;Context awareness;Writing;Software;Generators;Servers","","1","","24","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Nl2Fix: Generating Functionally Correct Code Edits from Bug Descriptions","S. Fakhoury; S. Chakraborty; M. Musuvathi; S. K. Lahiri","Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"20 Jun 2024","2024","","","410","411","Despite the notable advancement of Large Language Models for Code Generation, there is a distinct gap in benchmark datasets and evaluation of LLMs' proficiency in generating functionally correct code edits based on natural language descriptions of intended changes. We address this void by presenting the challenge of translating natural language descriptions of code changes, particularly bug fixes outlined in Issue reports within repositories, into accurate code fixes. To tackle this issue, we introduce Defects4J-NI2fix, a dataset comprising 283 Java programs from the widely-used Defects4J dataset, augmented with high-level descriptions of bug fixes. Subsequently, we empirically evaluate three state-of-the-art LLMs on this task, exploring the impact of different prompting strategies on their ability to generate functionally correct edits. Results show varied ability across models on this novel task. Collectively, the studied LLMs are able to produce plausible fixes for 64.6% of the bugs.","2574-1934","979-8-4007-0502-1","10.1145/3639478.3643526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554944","nl2edit;nl2fix;llm4code","Java;Codes;Accuracy;Computer bugs;Natural languages;Benchmark testing;Task analysis","","","","5","","20 Jun 2024","","","IEEE","IEEE Conferences"
"YOLOv5 Algorithm Optimization: Precise Target Detection Amidst Background Interference","B. Xiong; W. Shi; Y. Fu; Z. Zhu; D. Wang; B. Jia","School of Computer Science and Technology, Xinjiang University, Urumqi, China; Key Laboratory of Big Data of Xinjiang Social Security Risk, Xinjiang Lianhaichuangzhi Information Technology Co., Ltd., Beijing, China; Beijing Academy of Science and Technology, Beijing, China; Key Laboratory of Big Data of Xinjiang Social Security Risk, Xinjiang Lianhaichuangzhi Information Technology Co., Ltd., Urumqi, China; Key Laboratory of Big Data of Xinjiang Social Security Risk, Xinjiang Lianhaichuangzhi Information Technology Co., Ltd., Urumqi, China; Key Laboratory of Big Data of Xinjiang Social Security Risk, Xinjiang Lianhaichuangzhi Information Technology Co., Ltd., Urumqi, China",2024 4th International Conference on Consumer Electronics and Computer Engineering (ICCECE),"24 Apr 2024","2024","","","129","132","This paper solves the challenge that the target is submerged in the background in the border security scenario, and proposes the enhancement of YOLOv5 algorithm. EfficientViT replaces the DarkNet backbone, leveraging Transformer models for improved feature extraction. Modifications to the Spatial Pyramid Pooling-Fast (SPPF) module enhance the algorithm's robustness to scale variations. Introducing SCYLLA-IoU (SIoU) in the loss function improves model convergence speed and accuracy. Validated on a custom border security dataset, the enhancements show an improved average precision mean (mAP) of 48.3%, a 2.2 percentage point increase over the original YOLOv5s model.","","979-8-3503-8406-2","10.1109/ICCECE61317.2024.10504220","National Key Research and Development Program(grant numbers:2018YFC0825504); National Natural Science Foundation of China(grant numbers:U20B2060); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504220","Border security;YOLOv5;Transformer;Target Detection","YOLO;Image edge detection;Interference;Feature extraction;Transformers;Robustness;Computer security","","2","","19","IEEE","24 Apr 2024","","","IEEE","IEEE Conferences"
"Secure MIMO Communication Relying on Movable Antennas","J. Tang; C. Pan; Y. Zhang; H. Ren; K. Wang","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; Department of Computer Science, Brunel University London, Uxbridge, U.K.",IEEE Transactions on Communications,"17 Apr 2025","2025","73","4","2159","2175","This paper considers a movable antenna (MA)-aided secure multiple-input multiple-output (MIMO) communication system consisting of a base station (BS), a legitimate information receiver (IR) and an eavesdropper (Eve), where the BS is equipped with MAs to enhance the system’s physical layer security (PLS). Specifically, we aim to maximize the secrecy rate (SR) by jointly optimizing the transmit precoding (TPC) matrix, the artificial noise (AN) covariance matrix and the MAs’ positions under the constraints of the maximum transmit power and the minimum spacing between MAs. To solve this non-convex problem with highly coupled optimization variables, the block coordinate descent (BCD) method is applied to alternately update the variables. Specifically, we first reformulate the SR into a tractable form, and derive the optimal TPC matrix and the AN covariance matrix with fixed MAs’ positions by applying the Lagrangian multiplier method in semi-closed forms. Then, the majorization-minimization (MM) algorithm is employed to iteratively optimize each MA’s position while keeping others fixed. We also extend this work to the more general multicast scenario. Finally, simulation results are provided to demonstrate the effectiveness of the proposed algorithms and the significant advantages of the MAs over conventional fixed position antennas (FPAs) in enhancing system’s security.","1558-0857","","10.1109/TCOMM.2024.3465369","Research Fund of National Mobile Communications Research Laboratory, Southeast University(grant numbers:2024A03); Fundamental Research Funds for the Central Universities(grant numbers:2242022k60001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684758","Movable antenna (MA);physical layer security (PLS);artificial noise (AN);antenna position optimization","Covariance matrices;MIMO communication;Antennas;Security;Optimization;Multicast algorithms;Array signal processing","","12","","52","IEEE","20 Sep 2024","","","IEEE","IEEE Journals"
"Movable-Antenna Aided Secure Transmission for RIS-ISAC Systems","Y. Ma; K. Liu; Y. Liu; L. Zhu; Z. Xiao","School of Electronics and Information Engineering, Beihang University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; China Satellite Network System Company Ltd, Beijing, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; School of Electronics and Information Engineering, Beihang University, Beijing, China",IEEE Transactions on Wireless Communications,"","2025","PP","99","1","1","Integrated sensing and communication (ISAC) systems have the issue of secrecy leakage when using the ISAC waveforms for sensing, thus posing a potential risk for eavesdropping. To address this problem, we propose to employ movable antennas (MAs) and reconfigurable intelligent surface (RIS) to enhance the physical layer security (PLS) performance of ISAC systems, where an eavesdropping target potentially wiretaps the signals transmitted by the base station (BS). To evaluate the synergistic performance gain provided by MAs and RIS, we formulate an optimization problem for maximizing the sum-rate of the users by jointly optimizing the transmit/receive beamformers of the BS, the reflection coefficients of the RIS, and the positions of MAs at communication users, subject to a minimum communication rate requirement for each user, a minimum radar sensing requirement, and a maximum secrecy leakage to the eavesdropping target. To solve this non-convex problem with highly coupled variables, a two-layer penalty-based algorithm is developed by updating the penalty parameter in the outer-layer iterations to achieve a trade-off between the optimality and feasibility of the solution. In the inner-layer iterations, the auxiliary variables are first obtained with semi-closed-form solutions using Lagrange duality. Then, the receive beamformer filter at the BS is optimized by solving a Rayleigh-quotient subproblem. Subsequently, the transmit beamformer matrix is obtained by solving a convex subproblem. Finally, the majorization-minimization (MM) algorithm is employed to optimize the RIS reflection coefficients and the positions of MAs. Extensive simulation results validate the considerable benefits of the proposed MAs-aided RIS-ISAC systems in enhancing security performance compared to traditional fixed position antenna (FPA)-based systems.","1558-2248","","10.1109/TWC.2025.3577040","National Natural Science Foundation of China(grant numbers:U2233216); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033708","Integrated sensing and communication (ISAC);movable antenna (MA);reconfigurable intelligent surface (RIS);physical-layer security (PLS)","Antennas;Reconfigurable intelligent surfaces;Eavesdropping;Integrated sensing and communication;Vectors;Radar;Signal to noise ratio;Optimization;Wireless networks;Symmetric matrices","","1","","","IEEE","12 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Evaluation of Security of ML-based Watermarking: Copy and Removal Attacks","V. Kinakh; B. Pulfer; Y. Belousov; P. Fernandez; T. Furon; S. Voloshynovskiy","Department of Computer Science, University of Geneva, Geneva, Switzerland; Department of Computer Science, University of Geneva, Geneva, Switzerland; Department of Computer Science, University of Geneva, Geneva, Switzerland; Meta, FAIR, University of Rennes, Inria, CNRS, IRISA; University of Rennes, Inria, CNRS, IRISA, Rennes, France; Department of Computer Science, University of Geneva, Geneva, Switzerland",2024 IEEE International Workshop on Information Forensics and Security (WIFS),"27 Dec 2024","2024","","","1","6","The vast amounts of digital content captured from the real world or AI-generated media necessitate methods for copyright protection, traceability, or data provenance verification. Digital watermarking serves as a crucial approach to address these challenges. Its evolution spans three generations: handcrafted, autoencoder-based, and foundation model based methods. While the robustness of these systems is well-documented, the security against adversarial attacks remains underexplored. This paper evaluates the security of foundation models’ latent space digital watermarking systems that utilize adversarial embedding techniques. A series of experiments investigate the security dimensions under copy and removal attacks, providing empirical insights into these systems’ vulnerabilities. All experimental codes and results are available in the repository.","2157-4774","979-8-3503-6442-2","10.1109/WIFS61860.2024.10810685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810685","digital watermarking;watermarking attack;self-supervised learning;latent space","Foundation models;Forensics;Conferences;Autoencoders;Watermarking;Media;Copyright protection;Distortion;Robustness;Context modeling","","1","","32","IEEE","27 Dec 2024","","","IEEE","IEEE Conferences"
"RAG with Differential Privacy","N. Grislain","Sarus Technologies, Paris, France",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","847","852","Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to provide Large Language Models (LLM) with fresh and relevant context, mitigating the risk of hallucinations and improving the overall quality of responses in environments with large and fast moving knowledge bases. However, the integration of external documents into the generation process raises significant privacy concerns. Indeed, when added to a prompt, it is not possible to guarantee a response will not inadvertently expose confidential data, leading to potential breaches of privacy and ethical dilemmas. This paper explores a practical solution to this problem suitable to general knowledge extraction from personal data. It shows differentially private token generation is a viable approach to private RAG.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050672","Artificial Intelligence;Security and Privacy Protection;Intelligent agents;Knowledge retrieval","Privacy;Ethics;Differential privacy;Large language models;Retrieval augmented generation;Knowledge based systems;Security;Intelligent agents;Protection;Electronic medical records","","","","18","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Hybrid RAG-Empowered Multimodal LLM for Secure Data Management in Internet of Medical Things: A Diffusion-Based Contract Approach","C. Su; J. Wen; J. Kang; Y. Wang; Y. Su; H. Pan; Z. Zhong; M. Shamim Hossain","School of Automation, Guangdong University of Technology, Guangzhou, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Automation, Guangdong University of Technology, Guangdong Basic Research Center of Excellence for Ecological Security and Green Development, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Guangdong Provincial Academy of Chinese Medical Sciences, State Key Laboratory of Traditional Chinese Medicine Syndrome/The Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Guangdong Provincial Hospital of Chinese Medicine, Guangzhou, China; Guangdong Provincial Academy of Chinese Medical Sciences, State Key Laboratory of Traditional Chinese Medicine Syndrome/The Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Guangdong Provincial Hospital of Chinese Medicine, Guangzhou, China; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Internet of Things Journal,"8 May 2025","2025","12","10","13428","13440","Secure data management and effective data sharing have become paramount in the rapidly evolving healthcare landscape, especially with the growing demand for the Internet of Medical Things (IoMT) integration. The advent of generative artificial intelligence (GenAI) has further elevated multimodal large language models (MLLMs) as essential tools for managing and optimizing healthcare data in IoMT. MLLMs can handle multimodal inputs and generate different kinds of data by utilizing large-scale training on massive multimodal datasets. Nevertheless, significant challenges remain in developing medical MLLMs, especially security and data freshness concerns, which impact the quality of MLLM outputs. To this end, this article proposes a hybrid Retrieval-Augmented Generation (RAG)-empowered medical MLLM framework for healthcare data management. The proposed framework enables secure data training by utilizing a hierarchical cross-chain design. Furthermore, it improves the output quality of MLLMs by using hybrid RAG that filters different unimodal RAG results using multimodal metrics and integrates these retrieval results as additional inputs for MLLMs. Furthermore, we utilize the age of information (AoI) to indirectly assess the influence of data freshness on MLLMs and apply contract theory to motivate healthcare data stakeholders to disseminate their current data, thereby alleviating information asymmetry in the data-sharing process. Finally, we employ a generative diffusion model-based deep reinforcement learning (DRL) technique to find the optimal contract for efficient data sharing. Numerical results show the effectiveness of the proposed approach in achieving secure and efficient healthcare data management.","2327-4662","","10.1109/JIOT.2024.3521425","National Natural Science Foundation of China (NSFC)(grant numbers:62102099,U22A2054,12326604); Science and Technology Research Cultivation Project of Chinese Medicine Guangdong Laboratory(grant numbers:HQL2024PZ037); Guangzhou Basic Research Program(grant numbers:2023A04J1699); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2023A1515140137); Researchers Supporting Project through King Saud University, Riyadh, Saudi Arabia(grant numbers:RSP2025R32); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812735","Contract theory;generative diffusion models (GDMs);healthcare data sharing;multimodal LLMs (MLLMs);retrieval-augmented generation (RAG)","Medical services;Contracts;Data models;Accuracy;Hospitals;Medical diagnostic imaging;Data integrity;Security;Measurement;Hybrid power systems","","3","","47","IEEE","23 Dec 2024","","","IEEE","IEEE Journals"
"GlueTest: Testing Code Translation via Language Interoperability","M. S. Abid; M. Pawagi; S. Adhikari; X. Cheng; R. Badr; M. Wahiduzzaman; V. Rathi; R. Qi; C. Li; L. Liu; R. S. Naidu; L. Lin; Q. Liu; A. Z. Palak; M. Haque; X. Chen; D. Marinov; S. Dutta","Cornell University; Indian Institute of Science; Islington College; Dickinson College; University of Illinois; BRAC University; Adlai E Stevenson High School; Wuhan University; Po Leung Kuk Ngan Po Ling College; University of Washington; University of California, Berkeley; Zhejiang University; University of Shanghai for Science and Technology; BRAC University; University of Dhaka; University of Illinois; University of Illinois; Cornell University",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","612","617","Code translation from one programming language to another has been a topic of interest for academia and industry for a long time, and has recently re-emerged with the advent of Large Language Models (LLMs). While progress has been made in translating small code snippets, tackling larger projects with intricate dependencies remains a challenging task. A significant challenge in automating such translations is validating the resulting code. Translating existing tests to the target language can introduce errors, yielding potentially misleading quality assurance even when all the translated tests pass. We propose the idea of testing the translated code using the existing, untranslated tests written in the original programming language. The key to our idea is to leverage language interoperability to run code written in two different languages together. This partial translation approach offers two main benefits: (1) the ability to leverage original tests for validating translated code, not only from the project being translated but also from the clients using this project, and (2) the continuous maintainability and testability of the project during translation. We evaluate our approach by translating from Java to Python two popular Java libraries, Apache Commons CLI and Apache Commons CSV, with 1209 lines of code (in 22 Java files) and 860 lines of code (in 10 Java files), respectively. Our implementation uses Oracle's GraalVM framework for language interoperability. We successfully validate the translation using the original Java tests, not just from the CLI and CSV libraries themselves but also from client projects of these libraries (30 for CLI and 6 for CSV). Our approach is the first to systematically and semi-automatically validate translations for such nontrivial libraries.","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00061","NSF(grant numbers:CCF-1763788,CCF-1956374); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794998","Code Translation;Software Testing;GlueTest","Industries;Java;Software maintenance;Codes;Quality assurance;Large language models;Libraries;Interoperability;Testing;Python","","1","","64","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Large Language Model Firewall for AIGC Protection with Intelligent Detection Policy","T. Huang; L. You; N. Cai; T. Huang","Shanghai Ocean University, AIEN Institute, Information Management and Information System Major, 21st Session, University of Tasmania, Shanghai, China; R&D Department of Security Application Technology, China Telecom Research Institute, Shanghai, China; R&D Department of Security Application Technology, China Telecom Research Institute, Shanghai, China; R&D Department of Security Application Technology, China Telecom Research Institute, Shanghai, China","2024 2nd International Conference On Mobile Internet, Cloud Computing and Information Security (MICCIS)","15 Aug 2024","2024","","","247","252","LLMs face content security risks such as prompt information injection, insecure output processing, sensitive information leakage, and over-dependence, etc. By constructing a firewall for LLMs with intelligent detection strategies and introducing multi-engine detection capabilities such as rule matching, semantic computing, and AI models, we can intelligently detect and dispose of inputs and outputs of the LLMs, and realize the full-time on-line security protection of LLM applications. The system is tested on open-source LLMs, and there is a significant improvement in terms of the detection rate of insecure content.","","979-8-3503-8990-6","10.1109/MICCIS63508.2024.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10625752","Large language model;content security risk;intelligent detection strategy;rule matching;semantic computing;AI models","Cloud computing;Firewalls (computing);Computational modeling;Large language models;Semantics;Information leakage;Protection","","4","","12","IEEE","15 Aug 2024","","","IEEE","IEEE Conferences"
"Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction","Y. Li; Y. Gong; C. -H. H. Yang; P. Bell; C. Lai",University of Edinburgh; MIT CSAIL; NVIDIA Research; University of Edinburgh; University of Edinburgh,"ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Annotating and recognizing speech emotion using prompt engineering has recently emerged with the advancement of Large Language Models (LLMs), yet its efficacy and reliability remain questionable. In this paper, we conduct a systematic study on this topic, beginning with the proposal of novel prompts that incorporate emotion-specific knowledge from acoustics, linguistics, and psychology. Subsequently, we examine the effectiveness of LLM-based prompting on Automatic Speech Recognition (ASR) transcription, contrasting it with ground-truth transcription. Furthermore, we propose a Revise-Reason-Recognize prompting pipeline for robust LLM-based emotion recognition from spoken language with ASR errors. Additionally, experiments on context-aware learning, in-context learning, and instruction tuning are performed to examine the usefulness of LLM training schemes in this direction. Finally, we investigate the sensitivity of LLMs to minor prompt variations. Experimental results demonstrate the efficacy of the emotion-specific prompts, ASR error correction, and LLM training schemes for LLM-based emotion recognition. Our study aims to refine the use of LLMs in emotion recognition and related domains.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10888591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888591","Emotion Recognition;LLM;ASR;Acoustics;Linguistics;Psychology","Training;Emotion recognition;Sensitivity;Systematics;Pipelines;Psychology;Linguistics;Acoustics;Error correction;Tuning","","2","","21","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Application of Large Language Model and In-Context Learning for Aviation Safety Prediction","Y. Yang; D. Shi; J. Zurada; J. Guan","School of Electronics and Information Engineering, Anhui Jianzhu University, Hefei, China; School of Electronics and Information Engineering, Anhui Jianzhu University, Hefei, China; College of Business, University of Louisville, Kentucky, USA; College of Business, University of Louisville, Kentucky, USA",2024 17th International Conference on Advanced Computer Theory and Engineering (ICACTE),"11 Feb 2025","2024","","","361","365","The analysis of aviation safety reports using natural language processing (NLP) techniques is well-explored, but leveraging large language models (LLMs) in this domain remains under investigation. Recent studies have shown that LLMs, equipped with tens of billions of parameters and pre-trained on massive and diverse datasets, have the ability for in-context learning (ICL). This capability allows them to learn from prompts consisting of specific instructions and a few labeled examples without requiring model fine-tuning. This paper explores the use of LLMs to classify aviation safety reports through a case study focusing on domain-specific data, utilizing ICL and prompt engineering. Using BM25 to select eight examples for the prompt resulted in the highest performance, with an accuracy of 80.24% and an F1-score of 84.15%, demonstrating the LLM's generalization ability on domain-specific data through an engineered prompt.","2154-7505","979-8-3315-3988-7","10.1109/ICACTE62428.2024.10871713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871713","Large Language Model;In-context Learning;Aviation Safety Reports","Accuracy;Large language models;Computational modeling;Text categorization;Focusing;Predictive models;Natural language processing;Data models;Safety;Prompt engineering","","1","","29","IEEE","11 Feb 2025","","","IEEE","IEEE Conferences"
"Revise the NLU: A Prompting Strategy for Robust Dialogue System","M. Rohmatillah; J. -T. Chien","Institute of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Institute of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","10956","10960","The advent of large language models (LLMs), such as GPT 3.5, has demonstrated significant potential, especially when paired with the prompt engineering techniques. However, while this setting excels in zero-shot or few-shot scenario, the direct utilization of LLMs in multi-domain task-oriented dialogue (TOD) systems often falls short compared to smaller task-specific models in standard evaluations. This indicates the need for further exploration on how to harness the power of LLMs effectively to multi-domain TOD systems. This paper addresses the aforementioned challenge by introducing a novel prompting strategy to enhance the robustness of the existing text-based multi-domain TOD systems. This strategy aims to revise the outputs of natural language understanding (NLU) component through a series of prompting steps. By capitalizing on NLU outputs, a simple and straightforward prompt design can be carried out. Experimental results illustrate the benefit of the proposed strategy in improving robustness of the multi-domain TOD system.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10446138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446138","Multi-domain dialogue system;multi-step prompting strategy;dialogue system robustness","Pipelines;Signal processing;Robustness;Natural language processing;Acoustics;Task analysis;Speech processing","","1","","27","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"ChatGPT: A Threat to Spam Filtering Systems","A. Utaliyeva; M. Pratiwi; H. Park; Y. -H. Choi","School of Computer Science and Engineering, Pusan National University, Busan, Republic of Korea; School of Computer Science and Engineering, Pusan National University, Busan, Republic of Korea; School of Computer Science and Engineering, Pusan National University, Busan, Republic of Korea; School of Computer Science and Engineering, Pusan National University, Busan, Republic of Korea","2023 IEEE International Conference on High Performance Computing & Communications, Data Science & Systems, Smart City & Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","25 Mar 2024","2023","","","1043","1050","ChatGPT gathered the attention of millions of users shortly after its release, leading to the popularization of generative AI technologies. This research aims to emphasize one of the potential vulnerabilities associated with commonly used generative AI models. Even though it follows strict ethical and security policies, proper prompt engineering enables malicious misuse of ChatG PT such as spam email generation. In this paper, we present various scenarios of malicious prompt engineering to encourage the chatbot for spam email generation and rewriting the existing email. Also, we present the adversarial prompt engineering examples intended to evade the detection by spam filters by means of rewriting the given email while circumventing common spam characteristics. We experimentally evaluate the practical feasibility of prompt engineering on ChatGPT by assessing the performance of six common ML-based spam filters with emails modified by ChatG PT. From the experimental results, we show that adversarial prompt engineering decreases the performance of common ML-based spam filters, while NLP-based filter is robust to such modification. We also demonstrate that including ChatG PT rewritten emails in the training set leads to more robust ML-based spam filters, while the use of available AI-text detectors does not guarantee high detection rates of emails modified by the chatbot.","","979-8-3503-3001-4","10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00150","National Research Foundation of Korea(NRF); Ministry of Education(grant numbers:2022R1I1A3055233); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10466952","spam;spam filters;ChatGPT","Training;Ethics;Generative AI;Filtering;Unsolicited e-mail;Detectors;Chatbots","","","","24","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"An Automated Medical Rdf Knowledge Graph Construction From Text Using in-Context Learning","T. Racharak; T. Wang; W. Jearanaiwongkul","School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan",2024 16th International Conference on Knowledge and System Engineering (KSE),"11 Jul 2025","2024","","","465","471","The parameterized knowledge within large language models (LLMs), like ChatGPT, offers a significant opportunity for modelling domain knowledge base from text. However, LLMs' context sensitivity can hinder obtaining precise and taskaligned outcomes, thus requiring a suitable design for leveraging prompt engineering. This study explores the efficacy of different prompting methods for RDF knowledge graph construction from medical documents as our preliminary investigation, aiming to develop an efficient pipeline for a large-scale automatic knowledge graph construction according to semantic web standards and technologies. The results show that leveraging in-context learning within LLMs is capable of extracting an array of precise RDF triples from text. We perform a qualitative analysis of the extracted triples with different prompt templates, giving insights that could guide potential development in the research field.","2694-4804","979-8-3315-0940-8","10.1109/KSE63888.2024.11063495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11063495","Generative Knowledge Graph Extraction;Resource Description Framework;OpenAI;Prompting;Few-shot","Knowledge engineering;Sensitivity;Large language models;Pipelines;Knowledge graphs;Ontologies;Systems engineering and theory;Resource description framework;Prompt engineering;Standards","","","","19","IEEE","11 Jul 2025","","","IEEE","IEEE Conferences"
