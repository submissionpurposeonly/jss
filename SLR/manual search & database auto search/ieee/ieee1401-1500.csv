"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"LLM-Aided Automatic Modeling for Security Protocol Verification","Z. Mao; J. Wang; J. Sun; S. Qin; J. Xiong","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore; Xidian University, China; East China Normal University, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","642","654","Symbolic protocol analysis serves as a pivotal technique for protocol design, security analysis, and the safeguarding of information assets. Several modern tools such as Tamarin and ProVerif have been proven successful in modeling and verifying real-world protocols, including complex protocols like TLS 1.3 and 5G AKA. However, developing formal models for protocol verification is a non-trivial task, which hinders the wide adoption of these powerful tools in practical protocol analysis. In this work, we aim to bridge the gap by developing an automatic method for generating symbolic protocol models using Large Language Models (LLMs) from protocol descriptions in natural language document. Although LLMs are powerful in various code generation tasks, it is shown to be ineffective in generating symbolic models (according to our empirical study). Therefore, rather than applying LLMs naively, we carefully decompose the symbolic protocol modeling task into several stages so that a series of formal models are incrementally developed towards generating the final correct symbolic model. Specifically, we apply LLMs for semantic parsing, enable lightweight manual interaction for disambiguation, and develop algorithms to transform the intermediate models for final symbolic model generation. To ensure the correctness of the generated symbolic model, each stage is designed based on a formal execution model and the model transformations are proven sound. To the best of our knowledge, this is the first work aiming to generate symbolic models for protocol verification from natural language documents. We also introduce a benchmark for symbolic protocol model generation, with 18 real-world security protocol's text description and their corresponding symbolic models. We then demonstrate the potential of our tool, which successfully generated correct models of moderate scale in 10 out of 18 cases. Our tool is released at [1].","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029741","Automatic modeling;Symbolic analysis;LLMs","Analytical models;Protocols;Codes;Large language models;Natural languages;Semantics;Transforms;Manuals;Security;Software engineering","","","","58","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"A Review on Multi-Agent Systems and JADE Applications in Microgrids","S. E. Eyimaya; N. Altin; A. Nasiri","Department of Electronics and Automation, TUSAS-Kazan Vocational School, GaziUniversity, Ankara, Turkey; Department of Electrical-Electronics Engineering, Faculty of Technology, Gazi University, Ankara, Turkey; Electrical Engineering Department, College of Engineering and Computing, University of South Carolina (USC), SC, USA",2024 12th International Conference on Smart Grid (icSmartGrid),"3 Jul 2024","2024","","","623","628","The microgrid systems include distributed energy resources such as photovoltaic systems, wind energy conversion systems, and synchronous generators, energy storage devices, and loads. In order to achieve a smooth operation of all these resources and energy sutainability, a proper control mechanism is needed that considers elements of the system and optimization goals. In this control mechanism, each unit’s situation is important and therefore, a communication system within the microgrid must be established. Thanks to this communication, units are aware of each other's situation and can determine actions. This communication is provided by agents assigned as message carriers between units in a microgrid. Multi-agent systems have emerged as a promising approach to realize and optimize energy management in microgrids. In this study, agent and multi-agent system structures used in microgrids are introduced and communication platforms are examined. Java Agent Development Environment (JADE), one of the platforms used to design multi-agent-based systems, is reviewed and its use in microgrids is described.","","979-8-3503-6161-2","10.1109/icSmartGrid61824.2024.10578156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578156","Agent;JADE;microgrids;multi agent system","Reviews;Decentralized control;Microgrids;Synchronous generators;Distributed power generation;Smart grids;Energy management","","1","","40","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"Goal-Guided Generative Prompt Injection Attack on Large Language Models","C. Zhang; M. Jin; Q. Yu; C. Liu; H. Xue; X. Jin",Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University,2024 IEEE International Conference on Data Mining (ICDM),"21 Feb 2025","2024","","","941","946","Current large language models (LLMs) provide a strong foundation for large-scale user-oriented natural language tasks. Numerous users can easily inject adversarial text or instructions through the user interface, thus causing LLM model security challenges. Although there is much research on prompt injection attacks, most black-box attacks use heuristic strategies. It is unclear how these heuristic strategies relate to the success rate of attacks and thus effectively improve model robustness. To solve this problem, we redefine the goal of the attack: to maximize the KL divergence between the conditional probabilities of the clean text and the adversarial text. Furthermore, we prove that maximizing the KL divergence is equivalent to maximizing the Mahalanobis distance between the embedded representation $x$ and $x^{\prime}$ of the clean text and the adversarial text when the conditional probability is a Gaussian distribution and gives a quantitative relationship on $x$ and $x^{\prime}$. Then we designed a simple and effective goal-guided generative prompt injection strategy (G2PIA) to find an injection text that satisfies specific constraints to achieve the optimal attack effect approximately. Notably, our attack method is a query-free black-box attack method with a low computational cost. Experimental results on seven LLM models and four datasets show the effectiveness of our attack method.","2374-8486","979-8-3315-0668-1","10.1109/ICDM59182.2024.00119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884369","Prompt Injection;KL-divergence;LLM;Mahalanobis Distance","Large language models;Computational modeling;Natural languages;Closed box;Gaussian distribution;User interfaces;Linear programming;Robustness;Security;Data mining","","4","","32","IEEE","21 Feb 2025","","","IEEE","IEEE Conferences"
"ConnectGPT: Connect Large Language Models with Connected and Automated Vehicles","K. Tong; S. Solmaz","Virtual Vehicle Research GmbH, Graz, Austria; Virtual Vehicle Research GmbH, Graz, Austria",2024 IEEE Intelligent Vehicles Symposium (IV),"15 Jul 2024","2024","","","581","588","This paper explores the intersection of recent AI advancements and Intelligent Transportation Systems (ITS), specifically focusing on enhancing the capabilities of Connected and Automated Vehicles (CAVs) in dynamic traffic scenarios. While combinations of vehicular sensors and AI offer promising prospects for advanced environmental perception, challenges still persist in accurately identifying dangers during the transition to automated traffic. The ESRIUM project, funded by the EU Horizon 2020 Programme, aims to address these challenges by developing digital maps representing road deterioration and employing Vehicle-to-Everything (V2X) communication to generate infrastructure-assisted routing recommendations for CAVs. While the solutions for sending standardized safety messages and controlling enabled CAVs were demonstrated in the ESRIUM project, the solution for the automatic generation of Cooperative Intelligent Transport Systems (C-ITS) safety messages was not studied. In this paper, we propose a pipeline named ""ConnectGPT"", which connects Large Language Models (LLMs) with CAVs, utilizing GPT-4, to observe traffic conditions, identify conditions that can endanger the flow of traffic, and automate the generation of the corresponding standardized C-ITS messages, such as Decentralized Environmental Notification Message (DENM) about the actual safety problem. Practical experiments with ongoing development show potential for real-world applications, which can significantly improve traffic management efficiency and enhance the security of all traffic participants, marking a crucial advancement in the integration of AI tools in ITS.","2642-7214","979-8-3503-4881-1","10.1109/IV55156.2024.10588835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10588835","","Large language models;Roads;Pipelines;Focusing;Routing;Safety;Security","","3","","25","IEEE","15 Jul 2024","","","IEEE","IEEE Conferences"
"AI-Augmented Software Development: Boosting Efficiency and Quality","S. Pangavhane; G. Raktate; P. Pariane; K. Shelar; R. Wakchaure; J. N. Kale","Department of Computer Engineering, Sanjivani College of Engineering, Pune, India; Department of Computer Engineering, Sanjivani College of Engineering, Pune, India; Department of Computer Engineering, Sanjivani College of Engineering, Pune, India; Department of Computer Engineering, Sanjivani College of Engineering, Pune, India; Department of Computer Engineering, Sanjivani College of Engineering, Pune, India; Department of Computer Engineering, Sanjivani College of Engineering, Pune, India",2024 International Conference on Decision Aid Sciences and Applications (DASA),"17 Jan 2025","2024","","","1","5","Software developer's approaches to coding, testing, and deployment are changing due to the incorporation of Artificial Intelligence (AI) into software development. AI-Augmented Software Development Tools simplify repetitive activities, boost productivity, and lessen the cognitive load on developers by utilizing machine learning, natural language processing (NLP), and other AI techniques. These tools support several development phases, including DevOps optimization, testing automation, problem discovery, and code generation. For example, AI-driven systems find flaws and inefficiencies in the code, while AI-powered code generation tools like GitHub Copilot help with code suggestion and completion. Additionally, AI automates debugging and test case creation, ensuring the scalability and dependability of software systems. Artificial intelligence (AI) improves quality assurance in complex contexts such as microservices and APIs by maximizing test coverage and identifying abnormalities. Additionally, AI-powered assistants help guide engineers through code inspections, security checks, and performance optimization. Notwithstanding these advantages, there are drawbacks to using AI tools, such as privacy issues and an excessive reliance on automation. With continued development, these tools have the potential to not only expedite development but also redirect the developer's attention towards more complex problem resolution, thereby transforming software engineering methodologies. [7]","","979-8-3503-6910-6","10.1109/DASA63652.2024.10836523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10836523","Artificial Intelligence (AI);Generative AI;Software Development;Machine Learning;Software Testing;APIs;Quality Assurance","Productivity;Codes;Automation;Software systems;Natural language processing;Encoding;Artificial intelligence;Optimization;Software development management;Software engineering","","1","","9","IEEE","17 Jan 2025","","","IEEE","IEEE Conferences"
"Effective Vulnerable Function Identification based on CVE Description Empowered by Large Language Models","Y. Wu; M. Wen; Z. Yu; X. Guo; H. Jin","National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Huazhong University of Science and Technology (HUST), Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Huazhong University of Science and Technology (HUST), Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Huazhong University of Science and Technology (HUST), Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Huazhong University of Science and Technology (HUST), Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Huazhong University of Science and Technology (HUST), Wuhan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","393","405","Open-source software (OSS) has profoundly transformed the software development paradigm by facilitating effortless code reuse. However, in recent years, there has been an alarming increase in disclosed vulnerabilities within OSS, posing significant security risks to downstream users. Therefore, analyzing existing vulnerabilities and precisely assessing their threats to downstream applications become pivotal. Plenty of efforts have been made recently towards this problem, such as vulnerability reachability analysis and vulnerability reproduction. The key to these tasks is identifying the vulnerable function (i.e., the function where the root cause of a vulnerability resides). However, public vulnerability datasets (e.g., NVD) rarely include this information as pinpointing the exact vulnerable functions remains to be a longstanding challenge.Existing methods mainly detect vulnerable functions based on vulnerability patches or Proof-of-Concept (PoC). However, such methods face significant limitations due to data availability and the requirement for extensive manual efforts, thus hindering scalability. To address this issue, we propose a novel approach VFFinder that localizes vulnerable functions based on Common Vulnerabilities and Exposures (CVE) descriptions and the corresponding source code utilizing Large Language Models (LLMs). Specifically, VFFinder adopts a customized in-context learning (ICL) approach based on CVE description patterns to enable LLM to extract key entities. It then performs priority matching with the source code to localize vulnerable functions. We assess the performance of VFFinder on 75 large open-source projects. The results demonstrate that VFFinder surpasses existing baselines significantly. Notably, the Top-1 and MRR metrics have been improved substantially, averaging 4.25X and 2.37X respectively. We also integrate VFFinder with Software Composition Analysis (SCA) tools, and the results show that our tool can reduce the false positive rates of existing SCA tools significantly.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765043","Vulnerability Analysis;Vulnerable Function;Large Language Model","Measurement;Codes;Large language models;Source coding;Scalability;Security;Reachability analysis;Open source software;Software engineering;Software development management","","1","","61","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Security Risks Concerns of Generative AI in the IoT","H. Xu; Y. Li; O. Balogun; S. Wu; Y. Wang; Z. Cai","Kennesaw State University, USA; Georgia State University, USA; Georgia State University, USA; Kennesaw State University, USA; Georgia State University, USA; Georgia State University, USA",IEEE Internet of Things Magazine,"2 May 2024","2024","7","3","62","67","In an era where the Internet of Things (IoT) intersects increasingly with generative Artificial Intelligence (AI), this article scrutinizes the emergent security risks inherent in this integration. We explore how generative AI drives innovation in IoT and we analyze the potential for data breaches when using generative AI and the misuse of generative AI technologies in IoT ecosystems. These risks not only threaten the privacy and efficiency of IoT systems but also pose broader implications for trust and safety in AI-driven environments. The discussion in this article extends to strategic approaches for mitigating these risks, including the development of robust security protocols, the multi-layered security approaches, and the adoption of AI technological solutions. Through a comprehensive analysis, this article aims to shed light on the critical balance between embracing AI advancements and ensuring stringent security in IoT, providing insights into the future direction of these intertwined technologies.","2576-3199","","10.1109/IOTM.001.2400004","National Science Foundation(grant numbers:2413622,2244219,2231209,2315596,2146497); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10517500","","Privacy;Protocols;Generative AI;Ecosystems;Transforms;Safety;Artificial intelligence;Internet of Things;Risk management","","11","","15","IEEE","2 May 2024","","","IEEE","IEEE Magazines"
"Providing security for NFC-based payment systems using a management authentication server","A. Al-Haj; M. A. Al-Tameemi","Department of Computer Engineering, King Abdullah II Faculty of Engineering Princess Sumaya University for Technology, Amman, Jordan; Department of Computer Engineering, King Abdullah II Faculty of Engineering Princess Sumaya University for Technology, Amman, Jordan",2018 4th International Conference on Information Management (ICIM),"25 Jun 2018","2018","","","184","187","Recent models of mobile phones have been designed to offer many services such as mobile e-commerce, e-ticketing, e-payment, among many other services. Of a particular importance nowadays is the NFC-enabled mobiles in which the NFC technology allowed the integration of services from various applications into one single mobile. However, the EMV protocol, which is currently used to provide the required security for NFC-based payment systems, has two serious vulnerabilities between user payment devices and the merchants' point of sales which could lead to obvious risks for users. These two security vulnerabilities must be treated to secure NFC-based mobile payment transactions. In this paper a protocol is proposed to improve the security of EMV by adding a new security layer. The security provided by the protocol to EMV has been verified against major security attacks.","","978-1-5386-6147-5","10.1109/INFOMAN.2018.8392832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392832","NFC-based payment systems;EMV protocol;mutual authentication;MAS","Protocols;Authentication;Servers;Cryptography;Mobile handsets;Banking","","5","","12","IEEE","25 Jun 2018","","","IEEE","IEEE Conferences"
"Adversarial Attacks on IoT Systems Leveraging Large Language Models","W. Shan; T. Long; Z. Zhou","School of information Engineering, China University of Geoscience (Beijing), Beijing, China; School of information Engineering, China University of Geoscience (Beijing), Beijing, China; School of information Engineering, China University of Geoscience (Beijing), Beijing, China","2024 International Conference on Identification, Information and Knowledge in the Internet of Things (IIKI)","17 Mar 2025","2024","","","154","159","Internet of Things (IoT) devices have revolutionized various sectors by providing enhanced connectivity and automated services. However, the integration of these devices into complex networks has introduced significant security challenges. Concurrently, advancements in Language Model (LLM) technologies, exemplified by large-scale models like GPT-4, have given rise to sophisticated cyber-attack strategies. With the widespread use of various large language models, these models may generate a large amount of offensive and socially detrimental content during their use. In response, the primary focus of model developers is to adjust alignment models to prevent the generation of harmful content. Meanwhile, adversarial attackers focus on achieving “jailbreaks” to bypass the alignment measures of model developers, thereby generating harmful content and testing the effectiveness of model alignment. The main attack methods currently include prompt injection, unsafe output handling, denial of service, and general adversarial attacks. We selected the Llama-2-7b large language model as the experimental test model and constructed IoT related issues to achieve the generation of harmful content and desired responses.","","979-8-3315-1063-3","10.1109/IIKI65561.2024.00035","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917640","Large Language Model;The Internet of Things;Adversarial Attacks","Large language models;Complex networks;Internet of Things;Security;Cyberattack;Testing","","","","24","IEEE","17 Mar 2025","","","IEEE","IEEE Conferences"
"GPT-2 Modelleri Kullanarak Haber Özetinden Başlık ve Başlıktan Haber Özeti Üretimi Generation of Headline from News Summary and News Summary from Headline Using GPT-2 Models","E. Egriboz; M. F. Amasyalı","BİLGEM, TÜBİTAK, Kocaeli, Türkiye; Bilgisayar Mühendisliği Bölümü, Yıldız Teknik Üniversitesi, İstanbul, Türkiye",2024 Innovations in Intelligent Systems and Applications Conference (ASYU),"28 Nov 2024","2024","","","1","6","Generative Pre-trained Transformer 2 (GPT-2) has an important role among the generative language models used for next token prediction. Studies using GPT-2 models include tasks performed with text-based generative networks, such as text summarization, question answering, feature extraction, and prompt engineering. Fundamentally, prompt engineering and fine-tuning is the continued training of pre-trained models with appropriate textual input to generate the expected textual output from a large language model and evaluating it in terms of outputs. In our study to measure the understanding, interpretation, and meaningful text generation ability of GPT-2 models, large language models were used within the framework of prompt engineering and fine-tuning for the purpose of generating a news summary when its headline was given as input, and vice versa when news summary was given as input, to generate the headline. In our experiments, four GPT-2 language models ofdifferent sizes from the Cosmos Research Group of the Computer Engineering Department of Yildiz Technical University were used in various combinations with two different news datasets, with and without fine-tuning. Our experimental results show that generative models for generating headlines from news summaries and news summaries from headlines produce promising results.","2770-7946","979-8-3503-7943-3","10.1109/ASYU62119.2024.10756989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10756989","Turkish large language model;large language model;GPT-2;text generation;news text processing;summary;headline;text summarization;headline generation;prompt engineering","Training;Technological innovation;Computational modeling;Large language models;Text summarization;Predictive models;Transformers;Question answering (information retrieval);Prompt engineering;Intelligent systems","","","","0","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Unveiling the Potential of Large Language Models in Generating Semantic and Cross-Language Clones","P. R. Roy; A. I. Alam; F. Al-omari; B. Roy; C. K. Roy; K. A. Schneider","Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada",2023 IEEE 17th International Workshop on Software Clones (IWSC),"21 Mar 2024","2023","","","22","28","Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance. In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment. We have comprised a diverse set of code fragments and assessed GPT-3's performance in generating code variants. Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones.","2572-6587","979-8-3503-4442-4","10.1109/IWSC60764.2023.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473618","Language Models;Software Clone;Semantic Clone;Cross-language Clone;GPT;Semantic-CloneBench;Software Engineering","Computer languages;Codes;Statistical analysis;Conferences;Semantics;Cloning;Linguistics","","3","","48","IEEE","21 Mar 2024","","","IEEE","IEEE Conferences"
"ScenarioFuzz-LLM: Enhancing Diversity in Autonomous Driving Scenario Fuzzing with LLMs","S. Lin; F. Chen; L. Xi; K. Xie; Y. Zheng; H. Fei; Y. Sun; H. Zhu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"23 Jun 2025","2025","","","1581","1586","As Autonomous Driving Systems (ADS) are increasingly deployed, ensuring their safety in edge cases becomes critical to preventing catastrophic failures. However, the limited ADS test scenario diversity often hinders the discovery of new defects, especially in complex and rare situations. This paper presents ScenarioFuzz- Llm,a novel method that leverages Large Language Models (LLMs) to enhance the diversity of ADS test scenarios. By incorporating LLMs into a genetic algorithm-based testing framework, ScenarioFuzz- Llmdirects the mutation to address diversity bottlenecks, thereby enabling the exploration of a broader range of edge cases. Our experiments demonstrate that ScenarioFuzz- Llmenhances the number of violation sce-narios by 10.51 % outperforming the state-of-the-art methods, and uncovers 24 unique defects in ADS, three of which are previously undiscovered. These results highlight the superiority of our approach in enhancing ADS testing through more diverse and comprehensive simulation scenarios, ultimately improving the safety of ADS.","2768-1904","979-8-3315-1305-4","10.1109/CSCWD64889.2025.11033362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033362","Automated Driving System;Search Base Testing;Testing Scenario Generation;Large Language Model;Prompt Engineering","Federated learning;Large language models;Simulation;Fuzzing;Safety;Scenario generation;Prompt engineering;Autonomous vehicles;Testing;Genetic algorithms","","","","16","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"C-LINK Agent. Connecting social media post generation with recommender systems*","K. Ordoumpozanis; G. Trichopoulos; G. Caridakis","Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece",2024 19th International Workshop on Semantic and Social Media Adaptation & Personalization (SMAP),"4 Feb 2025","2024","","","116","121","Social Media Posts are one of the main communication paths that businesses of every size utilize in order to inform their audience. Recommender systems often struggle to get real time updates from social media posts, due either to platform terms of uses, or users that are not aware of. This case study presents a theoretical workflow of building an AI ""team of experts"" type agent that acts as an intermediate between users and recommender systems. It is the first part of a study on process trying to utilize Generative Artificial Intelligence in order to automatically create social media posts for users and at the same time convert, organize and store each post on an open database able for any recommender system to access in real time. The framework is also proposed to serve as a common experimental platform for AI agent design researchers, enabling comparative studies on various aspects","","979-8-3315-0450-2","10.1109/SMAP63474.2024.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859064","Recommender systems;AI Agents;Framework;Social Media;Large Language Models","Social networking (online);Generative AI;Databases;Buildings;Real-time systems;Recommender systems;Business","","","","23","IEEE","4 Feb 2025","","","IEEE","IEEE Conferences"
"Generative AI-Enabled Vehicular Networks: Fundamentals, Framework, and Case Study","R. Zhang; K. Xiong; H. Du; D. Niyato; J. Kang; X. Shen; H. V. Poor","School of Computer Science and Technology, Beijing Jiaotong University, Beijing, China; Engineering Research Center of Network Management Technology for High Speed Railway of Ministry of Education, the School of Computer Science and Technology, the Innovation Center of Railway Traffic Safety, and the National Engineering Research Center of Advanced Network Technologies, Beijing Jiaotong University, Beijing, China; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA",IEEE Network,"17 Jul 2024","2024","38","4","259","267","Recognizing the tremendous improvements that the integration of generative artificial intelligence (AI) can bring to intelligent transportation systems, this article explores the integration of generative AI technologies in vehicular networks, focusing on their potential applications and challenges. Generative AI, with its capabilities of generating realistic data and facilitating advanced decision-making processes, enhances various applications when combined with vehicular networks, such as navigation optimization, traffic prediction, data generation, and evaluation. Despite these promising applications, the integration of generative AI with vehicular networks faces several challenges, such as real-time data processing and decision-making, adapting to dynamic and unpredictable environments, as well as privacy and security concerns. To address these challenges, we propose a multi-modality semantic-aware framework to enhance the service quality of generative AI. By leveraging multi-modal and semantic communication technologies, the framework enables the use of text and image data for creating multi-modal content, providing more reliable guidance to receiving vehicles and ultimately improving system usability and efficiency. To further improve the reliability and efficiency of information transmission and reconstruction within the framework, taking generative AI-enabled vehicle-to-vehicle (V2V) as a case study, a deep reinforcement learning (DRL)-based approach is proposed for resource allocation. Finally, we discuss potential research directions and anticipated advancements in the field of generative AI-enabled vehicular networks.","1558-156X","","10.1109/MNET.2024.3391767","National Natural Science Foundation of China(grant numbers:62071033); Fundamental Research Funds for the Central Universities(grant numbers:2022JBGP003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10506539","Vehicular networks;generative AI;multi-modal;DRL","Generative AI;Data models;Predictive models;Navigation;Accidents;Training;Reliability","","38","","15","IEEE","22 Apr 2024","","","IEEE","IEEE Magazines"
"Cultivating Software Quality Improvement in the Classroom: An Experience with ChatGPT","E. A. AlOmar; M. W. Mkaouer","Software Engineering Department, Stevens Institute of Technology, Hoboken, NJ, USA; Computer Science Department, University of Michigan-Flint, Flint, MI, USA",2024 36th International Conference on Software Engineering Education and Training (CSEE&T),"10 Sep 2024","2024","","","1","10","Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including programming, testing, code review, and program comprehension. However, their effectiveness in improving software quality in the classroom remains uncertain. In this paper, our aim is to shed light on our experience in teaching the use of Programming Mistake Detector (PMD) to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. This paper discusses the results of an experiment involving 102 submissions that carried out a code review activity of 1,230 rules. Our quantitative and qualitative analysis reveals that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. We envision our findings to enable educators to support students with code review strategies to raise students' awareness about LLMs and promote software quality in education.","2377-570X","979-8-3503-7897-9","10.1109/CSEET62301.2024.10663028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663028","large language models;education;bugfix;code quality","Codes;Reviews;Large language models;Education;Software quality;Detectors;Chatbots","","1","","25","IEEE","10 Sep 2024","","","IEEE","IEEE Conferences"
"Educational Framework for Power Side-Channel Attacks on Neural Networks in Embedded Systems","R. R. Karn; P. Basu Roy; J. Knechtel; O. Sinanoglu","Center for Cyber Security, New York University, Abu Dhabi, UAE; Center for Cyber Security, New York University, Abu Dhabi, UAE; Center for Cyber Security, New York University, Abu Dhabi, UAE; Center for Cyber Security, New York University, Abu Dhabi, UAE",2025 IEEE International Symposium on Circuits and Systems (ISCAS),"27 Jun 2025","2025","","","1","5","We present an educational framework for security analysis of neural networks using the ChipWhisperer (CW) embedded system. More specifically, our contribution is to build a simple framework capable of performing power side-channel attacks from traces directly captured by CW’s microcontroller. CW eliminates the need for expensive and complex equipment like oscilloscopes, which helps to simplify the educational mission. Our work provides a modern educational tool, enabling students to learn about the real-world resilience of neural networks end-to-end, from training to deployment to security analysis, thereby contributing to the development of more secure systems in the future. In addition, we incorporate learning of software coding on embedded systems assisted by large language models.","2158-1525","979-8-3503-5683-0","10.1109/ISCAS56072.2025.11043456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11043456","Embedded Systems;Neural Networks;Side-Channel Attacks;ChipWhisperer;Large Language Models","Training;Embedded systems;Microcontrollers;Large language models;Neural networks;Oscilloscopes;Side-channel attacks;Software;Security;Resilience","","","","34","IEEE","27 Jun 2025","","","IEEE","IEEE Conferences"
"How LLMs Support EFL Writing:A Case Study of K-12 English Learning Based on the EDIPT Model","Y. Dai; Q. Panghe; Y. Zhang; M. Zhang; X. Xu","School of Education, City University of Macau, Macau SAR, China; School of Education, City University of Macau, Macau SAR, China; Faculty of Languages and Translation, Macao Polytechnic University, Macau, SAR, China; College of Music, Guangdong Polytechnic Normal University, Guangzhou, China; Graduate School of Education, Stamford International University, Bangkok, Thailand",2024 International Conference on Intelligent Education and Intelligent Research (IEIR),"14 Apr 2025","2024","","","1","8","Large Language Model (LLMs), the most stylish pre-trained language-agency model, has recently garnered unprecedented global attention. However, the rapid growth of LLMs’ exceptional performance in understanding and comprehending human language and completing various tasks conversationally has sparked debates regarding its educational implications and applications. Notably, it serves as a language consultant, companion, and assessment expert in Chinese English education, utilizing suggestions to enhance the quality of listening, speaking, reading, and writing instruction. This study is one of the initial efforts to explore the potential contribution of LLMs to the instruction and acquisition of writing English as a Foreign Language (EFL) in K-12. As a result, the study proposes a response strategy framework that combines the EDIPT model to promote and support future English learning development in K-12 education. Additionally, applying an LLMs can improve learning efficiency, reduce the teacher’s burden, and support large-scale personalized learning, the other side also brings challenges such as weakened learning motivation, less reliability of knowledge, and privacy and security issues. To enhance the writing abilities of EFL students for K-12, it is recommended that educators work alongside LLMs to provide feedback on students' writing in a generating.","","979-8-3315-1982-7","10.1109/IEIR62538.2024.10959858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10959858","LLMs;EFL;EDIPT model;English education;teaching research","Adaptation models;Privacy;Systematics;Reviews;Large language models;Education;Taxonomy;Security;Reliability;Faces","","","","47","IEEE","14 Apr 2025","","","IEEE","IEEE Conferences"
"Leveraging LLMs to eXplain DRL Decisions for Transparent 6G Network Slicing","M. Ameur; B. Brik; A. Ksentini","EURECOM, Sophia-Antipolis, France; Computer Science Department, College of Computing and Informatics, Sharjah University, Sharjah, UAE; EURECOM, Sophia-Antipolis, France",2024 IEEE 10th International Conference on Network Softwarization (NetSoft),"10 Jul 2024","2024","","","204","212","The emergence of 6G networks heralds a transformative era in network slicing, facilitating tailored service delivery and optimal resource utilization. Despite its promise, network slice optimization heavily relies on Deep Reinforcement Learning (DRL) models, often criticized for their black-box decision-making processes. This paper introduces a novel Composable eXplainable Reinforcement Learning (XRL) framework customized for distributed systems like 6G Network Slicing. The proposed framework leverages Large Language Models (LLMs) and Prompt Engineering techniques to elucidate DRL algorithms’ decision-making mechanisms, with a specific emphasis on user profiles. The latter transforms the inherently opaque nature of DRL into an interpretable textual format accessible not only to eXplainable AI (XAI) experts but also to diverse network slice provider stakeholders, engineers, leaders, and beyond. Experimental results underscore the efficacy of the proposed Composable XRL framework, showcasing substantial improvements in transparency and comprehensibility of DRL decisions within the context of 6G network slicing.","2693-9789","979-8-3503-6958-8","10.1109/NetSoft60951.2024.10588921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10588921","Explainable Reinforcement Learning;Composable XRL;LLMs;Admission Control;6G Network Slicing","6G mobile communication;Regulators;Network slicing;Decision making;Closed box;Transforms;Stakeholders","","3","","16","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"State of the Art of the Security of Code Generated by LLMs: A Systematic Literature Review","L. C. Ramírez; X. Limón; Á. J. Sánchez-García; J. C. Pérez-Arriaga","Facultad de Estadística e Informática, Universidad Veracruzana, Xalapa, México; Facultad de Estadística e Informática, Universidad Veracruzana, Xalapa, México; Facultad de Estadística e Informática, Universidad Veracruzana, Xalapa, México; Facultad de Estadística e Informática, Universidad Veracruzana, Xalapa, México",2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT),"18 Dec 2024","2024","","","331","339","AI -assisted programming has experienced a surge in popularity over the past few years, largely thanks to advancements in Large Language Model technologies. This has led to the emergence of tools like ChatGPT and GitHub Copilot. However, the use of AI models for code generation comes with a downside: the resulting code is susceptible to vulnerabilities, thus posing new challenges in the field of secure software development. In this study, we analyze the current state of research regarding the security of LLM generated code from the Software Engineering perspective. We conducted a Systematic Literature Review following the guidelines from Kitchenham et al. The search process included five sources: IEEE Xplore, ACM, Science Direct, Springer Link and Wiley Online Library. We also included an iteration of backward and forward snowballing. We obtained 3104 peer-reviewed studies though Quasi-Gold aided automated search and selected the most relevant ones through 5 stages. The final selection includes 15 primary studies from which we extracted and synthesized data. We identified seven different kinds of security vulnerability present in LLM generated code, six different mitigation strategies and practices, and four tools recommended by authors to use in conjunction with LLM code generation. Security related issues within LLM generated code have only just begun to be explored, initial research has already emphasized the significance of considering the inclusion of AI-powered code generation in software projects, as it carries the risk of introducing vulnerabilities at a higher rate than human-generated code. The vulnerabilities, practices and tools identified in this study, can potentially help developers to use LLM programming assistants more responsibly, making informed decisions when leveraging LLM technology.","","979-8-3315-3211-6","10.1109/CONISOFT63288.2024.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795572","LLM;Code Recommenders;Secure Software Development;Systematic Literature Review","Codes;Large language models;Training data;Software;Security;Programming profession;Systematic literature review;Software development management;Guidelines;Software engineering","","","","29","IEEE","18 Dec 2024","","","IEEE","IEEE Conferences"
"A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics","J. Bode; B. Pätzold; R. Memmesheimer; S. Behnke","Autonomous Intelligent Systems group, Computer Science Institute VI – Intelligent Systems and Robotics, Lamarr Institute for Machine Learning and Artificial Intelligence, and Center for Robotics, University of Bonn, Germany; Autonomous Intelligent Systems group, Computer Science Institute VI – Intelligent Systems and Robotics, Lamarr Institute for Machine Learning and Artificial Intelligence, and Center for Robotics, University of Bonn, Germany; Autonomous Intelligent Systems group, Computer Science Institute VI – Intelligent Systems and Robotics, Lamarr Institute for Machine Learning and Artificial Intelligence, and Center for Robotics, University of Bonn, Germany; Autonomous Intelligent Systems group, Computer Science Institute VI – Intelligent Systems and Robotics, Lamarr Institute for Machine Learning and Artificial Intelligence, and Center for Robotics, University of Bonn, Germany",2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids),"3 Dec 2024","2024","","","309","314","Recent advances in Large Language Models (LLMs) have been instrumental in autonomous robot control and human-robot interaction by leveraging their vast general knowledge and capabilities to understand and reason across a wide range of tasks and scenarios. Previous works have investigated various prompt engineering techniques for improving the performance of LLMs to accomplish tasks, while others have proposed methods that utilize LLMs to plan and execute tasks based on the available functionalities of a given robot platform. In this work, we consider both lines of research by comparing prompt engineering techniques and combinations thereof within the application of high-level task planning and execution in service robotics. We define a diverse set of tasks and a simple set of functionalities in simulation, and measure task completion accuracy and execution time for several state-of-the-art models. We make our code, including all prompts, available at https://github.com/AIS-Bonn/Prompt_Engineering.","2164-0580","979-8-3503-7357-8","10.1109/Humanoids58906.2024.10769825","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10769825","","Knowledge engineering;Service robots;Large language models;Instruments;Humanoid robots;Reliability engineering;Time measurement;Planning;Prompt engineering;Tuning","","2","","20","IEEE","3 Dec 2024","","","IEEE","IEEE Conferences"
"Retracted: Visistant: A Conversational Chatbot for Natural Language to Visualizations With Gemini Large Language Models","G. K. S. Ram; V. Muthumanikandan","School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India",IEEE Access,"2 Oct 2024","2024","12","","138547","138563","The goal of the data visualization field has always been to enable the production of visualizations directly from natural language text. This paper introduces Visistant, an innovative system designed to enhance the capabilities of advanced pre-trained language models, notably Google’s Gemini. Visistant facilitates the generation of interactive visualizations from tabular datasets through the use of Plotly and supports conversational interactions in a chatbot-styled manner by employing LangChain to maintain the memory of conversations. Visistant leverages Gemini’s code generation capabilities, demonstrating how prompt engineering can effectively lead to accurate end-to-end solutions. Our focus extended to prompt refinement, aiming to optimize the input token length of prompts. Through meticulous evaluation and comparison with existing models, Visistant exhibits superior performance in terms of both accuracy and efficiency. The results indicate that Visistant’s approach to converting natural language into detailed visualizations represents a significant advancement in the field of data visualization. The significance of this study lies in its potential to revolutionize data visualization by making it more accessible and user-friendly. By enabling users to generate complex visualizations through simple conversational interactions, Visistant democratizes data analysis, making it accessible to non-experts, which not only saves time but also reduces the barrier to entry for data-driven decision-making. This research addresses a critical gap in the literature by exploring the capabilities of Gemini LLMs for visualization generation, providing a novel solution that combines cutting-edge AI with practical usability.","2169-3536","","10.1109/ACCESS.2024.3465541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685409","","","","1","","29","CCBYNCND","23 Sep 2024","","","IEEE","IEEE Journals"
"SoCureLLM: An LLM-Driven Approach for Large-Scale System-on-Chip Security Verification and Policy Generation","S. Tarek; D. Saha; S. K. Saha; M. Tehranipoor; F. Farahmandi","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",2025 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"7 Jul 2025","2025","","","335","345","Contemporary methods for hardware security verification struggle with adaptability, scalability, and availability due to the increasing complexity of the modern system-onchips (SoCs). Large language models (LLMs) have emerged as a viable approach to address these shortcomings in security verification because of their natural language understanding, advanced reasoning, and knowledge transfer capabilities. However, their application to large designs is limited by inherent token limitation and memorization constraints. In this paper, we introduce SoCureLLM, an LLM-based framework that excels in identifying security vulnerabilities within SoC designs and creating a comprehensive security policy database. Our framework is adaptable and adept at processing varied, largescale designs, overcoming the abovementioned issues of LLM. In evaluations, SoCureLLM detected 76.47% of security bugs across three vulnerable RISC-V SoCs, outperforming the state-of-the-art security verification methods. Furthermore, assessing three additional large-scale RISC-V SoC designs against various threat models led to the formulation of 84 novel security policies, enriching the security policy database. Previously requiring extensive manual effort to craft, these newly generated security policies can be used as guidelines for developing secured SoC designs.","2765-8406","979-8-3315-4198-9","10.1109/HOST64725.2025.11050068","National Science Foundation (NSF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050068","Large Language Model;Hardware Security;Verification;Security Bug Detection;Policy Generation","Threat modeling;Databases;Navigation;Hardware security;Large language models;Scalability;Computer bugs;Natural language processing;Complexity theory;System-on-chip","","","","25","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Evaluating the Ability of GPT-4o to Generate Verifiable Specifications in VeriFast","M. Rego; W. Fan; X. Hu; S. Dod; Z. Ni; D. Xie; J. DiVincenzo; L. Tan","Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; University of Michigan - Ann Arbor, Ann Arbor, MI, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA",2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge),"2 Jul 2025","2025","","","246","251","Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources. This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic. LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers. However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic. To address this gap, this paper explores OpenAI’s GPT-4o model’s effectiveness in generating specifications on C programs that are verifiable with VeriFast, a separation logic based static verifier. Our experiment employs three different types of user inputs as well as basic and Chain-of-Thought (CoT) prompting to assess GPT-4o’s capabilities. Our results indicate that the specifications generated by GPT-4o preserve functional behavior, but struggle to be verifiable. When the specifications are verifiable, they contain redundancies. Future directions are discussed to improve the performance.","","979-8-3315-0211-9","10.1109/Forge66646.2025.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052787","formal verification;large language models;prompt engineering;separation logic","Foundation models;Large language models;Redundancy;Software quality;Documentation;Logic;Prompt engineering;Test pattern generators;Software development management;Formal verification","","","","53","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Exploring the Potential of Novel Image-to-Text Generators as Prompt Engineers for CivitAI Models","S. Song; J. Song; J. Lee; Y. Kang; H. Moon","Yonsei University, Seoul, South Korea; Onoma AI, Seoul, South Korea; Onoma AI, Seoul, South Korea; Yonsei University, Seoul, South Korea; Onoma AI, Seoul, South Korea",2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI),"15 Oct 2024","2024","","","626","631","Individuals looking to utilize AI image generation technologies to aid in creative content generation, such as anime or webtoon artists, may struggle to use new state-of-the-art text-to-image generators due to the lack of familiarity of prompt engineering. This paper explores the possibility of using models that have inherent image-to-text capacities like CLIP (ViT-L), CLIP (ViT-H), DeepDanbooru, GPT-4, and Gemini 1.5 pro, to automatically generate prompts that produce high-quality single-character images, which will help to streamline the creative content process for character image production during the character ideation phase. We employed image evaluation metrics like CLIP image-to-image (CLIPI-I), CLIP text-to-image (CLIPT-I), Contrastive Character Image Pretraining (CCIP), Bilingual Evaluation Understudy Score (BLEU), and ImageReward to compute quantitative measures to compare images representing CivitAI models to images produced by prompts that were automatically generated by different image-to-text generators. We found that the image-to-text generators' CLIPI-I scores were not statistically significant from one another, which means that the images were visually similar to each other. However, from the Bleu scores we found that the textual prompts were dissimilar between image-to-text generators. This means that visually similar images can be generated by different, but semantically similar tokens. We also found that most of the existing image evaluation metrics are not satisfactory to reflect the perceived preference of humans in their subjective ratings for images.","2472-0070","979-8-3503-7790-3","10.1109/IIAI-AAI63651.2024.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707810","AI Creativity;Generative AI;prompt engineering","Measurement;Image synthesis;Text to image;Entertainment industry;Production;Streaming media;Generators;Reliability;Prompt engineering;Informatics","","","","19","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security","Q. Zhang; P. Yang; J. Yu; H. Wang; X. He; S. -M. Yiu; H. Yin","The University of Hong Kong, Hong Kong; The University of Hong Kong, Hong Kong; University of Queensland, St Lucia, QLD, Australia; University of California, Los Angeles, CA, USA; The University of Hong Kong, Hong Kong; The University of Hong Kong, Hong Kong; University of Queensland, St Lucia, QLD, Australia",IEEE Transactions on Knowledge and Data Engineering,"1 May 2025","2025","37","6","3153","3172","The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.","1558-2191","","10.1109/TKDE.2025.3551292","HKU-SCF FinTech Academy and Shenzhen-Hong Kong-Macao Science and Technology Plan Project Category C Project(grant numbers:SGDX202108,23103537030); Theme-based Research Scheme(grant numbers:T35-710/20-R); Australian Research Council; Future Fellowship(grant numbers:FT210100624); Discovery Project(grant numbers:DP240101108); Linkage Project(grant numbers:LP230200892); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10925927","Point-of-interest recommendation;recommender systems;large language models;federated learning","Security;Surveys;Recommender systems;Computer architecture;Taxonomy;Federated learning;Training;Scalability;Reviews;Large language models","","2","","175","IEEE","14 Mar 2025","","","IEEE","IEEE Journals"
"Understanding User Perception of Biometric Privacy in the Era of Generative AI","S. Srinivasan","Cambridge International AS & A level, GEMS New Millennium School- Al Khail, Dubai, United Arab Emirates","2023 4th International Conference on Communication, Computing and Industry 6.0 (C216)","19 Feb 2024","2023","","","01","06","In the dynamic world of technology, the fusion of biometrics and artificial intelligence has ushered in an unprecedented era marked by convenience, security, and cutting-edge innovation. Biometrics, the science of using unique physical or behavioral attributes for identification and authentication, has seamlessly merged into daily routines. From unlocking smartphones with a fingerprint to clearing airport security with facial recognition, biometrics has transformed the way people interact with technology and the world. Simultaneously, Generative AI, powered by machine learning models, has unlocked new frontiers in generating remarkably realistic synthetic data, including human faces, voices, and fingerprints. This convergence of biometrics and Generative AI lies at the heart of a complex and rapidly evolving landscape, giving rise to profound questions concerning individual privacy and security. This study examines the correlation between demographic factors like age, gender, educational background, technological competence, and the regularity of employing biometric authentication, and their awareness about biometric technologies. Additionally, this research explores concerns regarding the potential misuse of biometric data and the notion that organizations should seek explicit consent before collecting such data. Lastly, it assesses the awareness of potential privacy risks and the belief that individuals should receive education regarding the utilization of their biometric data in AI systems. Descriptive research design has been used in this study. The first section of the questionnaire using Microsoft Forms covers the demographic factors, technological proficiency and frequency of using biometric authentication (e.g., fingerprint, facial recognition). The next section focuses on awareness and usage of biometric technologies, biometric privacy, trust, education, awareness of biometrics, generative AI and deepfakes using the Likert Scale. 53 samples were obtained through Simple Random Sampling from UAE residents. Then, testing of hypothesis using correlation analysis was done using SPSS. The results reveal that demographic variables do not exhibit a statistically significant relationship with privacy concerns. However, there is a statistically significant correlation exists between biometric authentication and awareness & knowledge parameters.","","979-8-3503-2732-8","10.1109/C2I659362.2023.10430931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430931","Biometrics;artificial intelligence;generative AI;deepfakes;privacy concerns","Privacy;Correlation;Biometrics (access control);Generative AI;Authentication;Fingerprint recognition;Security","","2","","15","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software","J. M. Baldonado; F. Bonomo-Braberman; V. A. Braberman","ICC UBA/CONICET and DC, FCEN, Universidad de Buenos Aires, Buenos Aires, Argentina; ICC UBA/CONICET and DC, FCEN, Universidad de Buenos Aires, Buenos Aires, Argentina; ICC UBA/CONICET and DC, FCEN, Universidad de Buenos Aires, Buenos Aires, Argentina","2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","16 Apr 2025","2025","","","418","422","Ensuring the reliability and verifiability of large language model (LLM)-enabled systems remains a significant challenge in software engineering. We propose a probabilistic framework for systematically analyzing and improving these systems by modeling and refining distributions over clusters of semantically equivalent outputs. This framework facilitates the evaluation and iterative improvement of Transference Models– key software components that utilize LLMs to transform inputs into outputs for downstream tasks. To illustrate its utility, we apply the framework to the autoformalization problem, where natural language documentation is transformed into formal program specifications. Our case illustrates how distribution-aware analysis enables the identification of weaknesses and guides focused alignment improvements, resulting in more reliable and interpretable outputs. This principled approach offers a foundation for addressing critical challenges in the development of robust LLM-enabled systems.","2159-4848","979-8-3315-3467-7","10.1109/ICSTW64639.2025.10962470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962470","LLMs;prompt engineering;autoformalization","Software testing;Refining;Natural languages;Transforms;Probabilistic logic;Reliability engineering;Software;Software reliability;Prompt engineering;Software engineering","","","","21","IEEE","16 Apr 2025","","","IEEE","IEEE Conferences"
"IoV-BERT-IDS: Hybrid Network Intrusion Detection System in IoV Using Large Language Models","M. Fu; P. Wang; M. Liu; Z. Zhang; X. Zhou","School of Modern Posts, Nanjing University of Post and Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Post and Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Post and Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Post and Telecommunications, Nanjing, China; Faculty of Data Science, Shiga University, Hikone, Japan",IEEE Transactions on Vehicular Technology,"14 Feb 2025","2025","74","2","1909","1921","The traditional vehicular ad hoc network (VANET) gradually evolved into the Internet of Vehicles (IoV), which has also become a potential target for attacks and faces security challenges in an open network environment. Intrusion detection systems (IDS) based on machine learning (ML) and deep learning (DL) are introduced to mitigate security threats. However, existing ML/DL-based IDS suffer from challenges in IoV environments. First, due to the limitations of ML/DL-based methods, classification performance is unsatisfactory when they extract only unidirectional contextual features or spatial characteristics. Second, existing research on in-vehicle network IDS often limits validation and testing to a static dataset of a single vehicle model. This approach may not adequately address diverse potential attacks in a dynamic environment. Third, few studies of hybrid IDS can simultaneously implement in-vehicle and extra-vehicle network intrusion detection. Large language models (LLM) have shown outstanding applications in fields such as natural language processing (NLP) and computer vision (CV). In particular, bidirectional encoder representations from transformers (BERT) obtain new state-of-the-art results on eleven famous NLP tasks. Consequently, this paper introduces a hybrid network IDS in IoV utilising LLM, denoted as IoV-BERT-IDS. This framework encompasses four modules: semantic extractor (SE), input embedding, IoV-BERT-IDS pre-training, and IoV-BERT-IDS fine-tuning. To conform to the BERT model, the semantic extractor is introduced to transform traffic data devoid of apparent semantics into contextual semantics, comprising bidirectional and unidirectional SE. Through SE, controller area network (CAN) data is transformed into a CAN byte sentence (CBS), while extra-vehicle network traffic data is transformed into a traffic byte sentence (TBS). Additionally, two pre-training tasks, the masked byte word model (MBWM) and next byte sentence prediction (NBSP) are proposed to acquire bidirectional contextual features from contextual semantics. These features can be adapted to downstream tasks in both in-vehicle and extra-vehicle networks through fine-tuning. Experiments demonstrate that IoV-BERT-IDS outperforms in CICIDS, BoT-IoT, Car-Hacking, and In-vehicle network intrusion detection challenge (IVN-IDS) datasets and shows good generalisation capabilities to in-vehicle networks of different vehicles.","1939-9359","","10.1109/TVT.2024.3402366","Future Network Innovation Research and Application Projects(grant numbers:2021FNA02006); Development of an Ultra-large-scale Ubiquitous Network Quality Monitoring System Based on Trusted Edge Intelligence(grant numbers:SYG202311); Foundation of State Key Laboratory of Public Big Data(grant numbers:PBD2022-10); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533857","BERT;intrusion detection system;Internet of Vehicle;large language model;pre-training model","Semantics;Encoding;Bidirectional control;Task analysis;Natural language processing;Computational modeling;Telecommunication traffic","","18","","40","IEEE","17 May 2024","","","IEEE","IEEE Journals"
"Reinforcement Learning for Key Management in Distributed Systems","L. Nenov","Faculty of Computer Systems and Technologies, Technical University - Sofia, Sofia, Bulgaria",2024 32nd National Conference with International Participation (TELECOM),"26 Dec 2024","2024","","","1","5","The ever-growing paradigms of IoT networks, cloud infrastructures, and blockchain platforms raise demands for adaptive cryptographic key management. Traditional approaches, such as Public Key Infrastructure and Shamir's Secret Sharing, are mostly ineffective in dynamic and scalable scenarios. Reinforcement Learning (RL)-a subfield of AI which possesses adaptation capabilities-can come forward as a promising solution by making the key management system time-efficient against any change or threat in a network. This review covers recent applications of RL in key management, where discussions are focused on Deep RL, Multi-Agent RL, and Federated RL with respect to strengths, use cases, and limitations. We underscore features about scalability, autonomous decision-making, and resilience against key compromise that can be brought forth by RL integration. Finally, we propose a hybrid adaptive framework combining the best aspects from each of these RL approaches for robust key management in dynamic distributed environments.","2837-5246","979-8-3503-5500-0","10.1109/TELECOM63374.2024.10812245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812245","Reinforcement Learning;Cryptographic Key Management;Distributed Systems;Deep Reinforcement Learning;Multi-Agent Systems;Adaptive Security","Technological innovation;Sensitivity;Scalability;Decision making;Computational efficiency;Blockchains;Telecommunications;Time factors;Multi-agent systems;Testing","","","","7","IEEE","26 Dec 2024","","","IEEE","IEEE Conferences"
"Confidence-Based Trustscoring System for Identification of Secure Agent Platforms","A. J. John Joseph; M. P; M. Mariappan","Department of Information Technology, Sri Ramakrishna Institute of Technology, Coimbatore, India; Department of Information Technology, Anna University Regional Campus Coimbatore, Coimbatore, India; Department of Computer Science and Engineering, Government College of Engineering, Erode, Erode, India",2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI),"27 Feb 2025","2025","","","257","261","Autonomous mobile agent systems can accomplish multiple tasks in an asynchronous and dynamic manner in platforms where there is excessive network load, network interruption and in slow networks. However, the decisions and execution depend on the platforms visited by the agents. Since the platforms may influence the decisions made by the agents, it is crucial that the trustable platforms are selected. Trust score is one parameter that helps mobile agents to select the appropriate platform. This work proposes a minor modification of the existing trust score calculation which has a significant impact on the safety and performance of mobile agent systems when deployed in a conventional distributed environment or in a modern cloud environment for completion of tasks. This work introduces a confidence-based approach for the five parameters namely persistence, competence, reputation, credibility, integrity which determine the trust score. This will provide a clear decision-making environment for the mobile agents to choose an appropriate platform.","","979-8-3315-0982-8","10.1109/ICMSCI62561.2025.10894094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894094","mobile agent security;multi-agent systems;trust score;threshold mechanism;platform attacks","Mobile agents;Decision making;Safety;Collaborative intelligence","","","","11","IEEE","27 Feb 2025","","","IEEE","IEEE Conferences"
"NERD: a Network Exfiltration Rootkit Detector based on a Multi-agent Artificial Immune System","M. B. S. Terra; J. J. C. Gondim",Universidade de Brasília; Universidade de Brasília,2021 Workshop on Communication Networks and Power Systems (WCNPS),"2 Dec 2021","2021","","","1","7","The expansion of the Internet has also seen a great increase in cyber threats. Among the main threats seen in this new scenario are Advanced Persistent Threats(APT’s) characterized by slow progress, high stealthiness and high impact. One of the tools used by cyber actors to allow the extended presence necessary to APT’s campaigns are rootkits, malware designed to subvert the Operating System allowing for processes, files and network traffic to be hidden from system administrators, and to allow easy access after the initial infection, which are extremely hard to detect. Marques et al. [1] have proposed the MADEX architecture, an Artificial Immune System (AIS) for flow analysis, that detects rootkits obfuscating network traffic. This work enhances the MADEX architecture so that it could handle more load without impact to its detection capabilities. This resulted in NERD, which can handle loads above those of the original MADEX with an improved accuracy of 99.996% and false positive rates below 0.08%.","2768-0045","978-1-6654-1078-6","10.1109/WCNPS53648.2021.9626241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626241","Security;Artificial Immune Systems;Multi-Agent Systems;Flow-based Analysis;Rootkits;Malware detection","Operating systems;Telecommunication traffic;Detectors;Tools;Power systems;Internet;Security","","","","23","IEEE","2 Dec 2021","","","IEEE","IEEE Conferences"
"Defect Classification and Localization in Material Extrusion with Multi-Modal Large Language Models","G. Wu; C. -T. Cheng; T. Y. Pang","Electrical and Electronic Engineering, RMIT University, Melbourne, Australia; Manufacturing, Materials and Mechatronics Engineering, RMIT University, Melbourne, Australia; Biomedical Engineering, RMIT University, Melbourne, Australia",2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS),"17 Feb 2025","2024","","","539","544","This study explores applying multi-modal large language models (MLLMs) for defect classification and localization in material extrusion (MEX) additive manufacturing (AM), focusing on common defects such as stringing and layer misalignment. Unlike traditional machine learning methods that require extensive labelled datasets, MLLMs offer the ability to combine textual and visual data to streamline defect detection. This study evaluates the performance of two state-of-the-art MLLMs, GPT-4o and Gemini-Pro-Vision, across varying sampling temperatures and prompt engineering techniques. The experiments demonstrated that GPT-4o achieved a classification accuracy of $\mathbf{9 1. 4 2 \%}$ with refined prompts and low sampling temperature settings, significantly outperforming Gemini-ProVision. However, both models struggled with defect localization, with a maximum accuracy of only $16.27 \%$. These findings suggest that while MLLMs show potential in automated defect detection, there is a critical need for spatial reasoning and localization accuracy improvements. Future work should focus on enhancing model training and integrating advanced image processing techniques to improve the applicability of MLLMs in real-time quality control for MEX.","","979-8-3503-9121-3","10.1109/FMLDS63805.2024.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10874057","additive manufacturing;visual inspection;MLLM;defect detection;quality control","Location awareness;Accuracy;Large language models;Machine learning;Quality control;Three-dimensional printing;Real-time systems;Cognition;Manufacturing;Defect detection","","","","16","IEEE","17 Feb 2025","","","IEEE","IEEE Conferences"
"Effects of Different Prompts on the Quality of GPT-4 Responses to Dementia Care Questions","Z. Li; B. Xie; R. Hilsabeck; A. Aguirre; N. Zou; Z. Luo; D. He","School of Computing and Information, University of Pittsburgh, Pittsburgh, USA; School of Nursing and School of Information, University of Texas at Austin, Austin, USA; University of Texas Health Sciences Center at San Antonio, San Antonio, TX, USA; Dell Medical School, University of Texas at Austin, Austin, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA",2024 IEEE 12th International Conference on Healthcare Informatics (ICHI),"22 Aug 2024","2024","","","412","417","Evidence suggests that different prompts lead large language models (LLMs) to generate responses with varying quality. Yet, little is known about prompts' effects on response quality in health care domains. In this exploratory study, we address this gap, focusing on a specific healthcare domain: dementia caregiving. We first developed an innovative prompt template with three components: (1) system prompts (SPs) featuring 4 different roles; (2) an initialization prompt; and (3) task prompts (TPs) specifying different levels of details, totaling 12 prompt combinations. Next, we selected 3 social media posts containing complicated, real-world questions about dementia caregivers' challenges in 3 areas: memory loss and confusion, aggression, and driving. We then entered these posts into G PT-4, with our 12 prompts, to generate 12 responses per post, totaling 36 responses. We compared the word count of the 36 responses to explore potential differences in response length. Two experienced dementia care clinicians on our team assessed the response quality using a rating scale with 5 quality indicators: factual, interpretation, application, synthesis, and comprehensiveness (scoring range: 0-5; higher scores indicate higher quality). Both clinicians rated the responses from 3 to 5, with 75% agreement. Consensus was reached through discussion. Overall, 44% of responses (16/36) were rated as 5; another 44% (16/36), as 4; the remaining 4 (11 %), as 3. We found no interaction effect of system and task prompts or main effect of system prompts on response length. Task prompts had a statistically significant effect on response length: F(2,24) = 82.784, $p$ <.001. Post hoc analysis showed that the significant difference in responses was due to TP3, which led to significantly longer responses. There was no interaction or main effect of system and task prompts on response quality. Our clinicians' qualitative feedback provided further insight: (1) system prompts with the different professional roles (neuropsychologist and social worker) did not lead to noticeable differences in response content (that is, there were no neuropsychology- and social work-versions of GPT-4 responses); and (2) TP3, while producing longer responses statistically, might not necessarily have produced higher quality responses clinically: at times the details contained in the lengthy responses seem unnecessary from a clinical perspective. We discuss study limitations and future research directions.","2575-2634","979-8-3503-8373-7","10.1109/ICHI61247.2024.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628643","large language models;prompt engineering;dementia;informal caregiving;social media","Measurement;Systematics;Social networking (online);Large language models;Medical services;Media;Lead","","2","","27","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Large Language Model as a Catalyst: A Paradigm Shift in Base Station Siting Optimization","Y. Wang; M. M. Afzal; Z. Li; J. Zhou; C. Feng; S. Guo; T. Q. S. Quek","School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; Department of Communication Systems, EURECOM, Sophia Antipolis, France; School of Control Science and Engineering, Shandong University, Jinan, China; Singapore University of Technology and Design, Singapore, Singapore",IEEE Transactions on Cognitive Communications and Networking,"","2025","PP","99","1","1","Traditional base station siting (BSS) methods rely heavily on drive testing and user feedback, which are laborious and require extensive expertise in communication, networking, and optimization. As large language models (LLMs) and their associated technologies advance, particularly in the realms of prompt engineering and agent engineering, network optimization will witness a revolutionary approach. This approach entails the strategic use of well-crafted prompts to infuse human experience and knowledge into these sophisticated LLMs, and the deployment of autonomous agents as a communication bridge to seamlessly connect the machine language based LLMs with human users using natural language. Furthermore, our proposed framework incorporates retrieval-augmented generation (RAG) to enhance the system’s ability to acquire domain-specific knowledge and generate solutions, thereby enabling the customization and optimization of the BSS process. This integration represents the future paradigm of artificial intelligence (AI) as a service and AI for more ease. This research first develops a novel LLM-empowered BSS optimization framework, and heuristically proposes three different potential implementations: the strategies based on Prompt-optimized LLM (PoL), LLM-empowered autonomous BSS agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa). Through evaluation on real-world data, the experiments demonstrate that prompt-assisted LLMs and LLM-based agents can generate more efficient and reliable network deployments, noticeably enhancing the efficiency of BSS optimization and reducing trivial manual participation.","2332-7731","","10.1109/TCCN.2025.3548615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915543","Base station siting;large language model (LLM);prompt engineering;agent engineering;retrieval-augmented generation (RAG)","Base stations;Optimization;Artificial intelligence;Roads;Prompt engineering;Testing;Computational modeling;User experience;Urban areas;Resource management","","1","","","IEEE","6 Mar 2025","","","IEEE","IEEE Early Access Articles"
"A Comparative Analysis of OpenAI's API Performance: Insights from AI Response Statistics","N. A. Walee; A. Shalan; H. Wimmer; C. Kadlec","College of Engineering and Computing, Georgia Southern University, Statesboro, GA, USA; College of Engineering and Computing, Georgia Southern University, Statesboro, GA, USA; College of Engineering and Computing, Georgia Southern University, Statesboro, GA, USA; College of Engineering and Computing, Georgia Southern University, Statesboro, GA, USA","2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)","15 Jul 2025","2025","","","229","233","Generative AI models have the capability to produce a wide range of new content based on the data they are trained on. These models can generate not just text, but also various types of multimedia content, including images. In recent years, they have become increasingly popular due to their significant impact across multiple fields. They are used in various applications, from text and image generation to music creation, as well as in education, healthcare, robotics, finance, education, autonomous vehicles, and more. However, these models face numerous challenges, such as overfitting the outputs, inconsistency in the results, response time, and token usage. This study presents a comparative analysis of the performance of OpenAI's API, focusing on insights gleaned from AI response statistics. The evaluation encompasses various performance insights on different model approaches, such as response tokens, processing speed, and result token efficiency. Using quantitative metrics and qualitative assessments, the research identifies trends and patterns in API performance, highlighting strengths and areas for improvement. The study concludes with recommendations for optimizing API functions, contributing to the broader discourse on advancing AI integration in real-world applications.","","979-8-3315-4348-8","10.1109/AIRC64931.2025.11077529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077529","Generative AI;OpenAI Models;API Response;Prompt Engineering;Token","Education;Key performance indicator;Medical services;Market research;Time factors;Stakeholders;Prompt engineering;Robots;Optimization;Overfitting","","","","32","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"MindScape Continuum: Advancing Online Counseling with Bert-Based Strategy Classification and Professional Helping Skills","K. Yu","Changchun University of Technology, School of International Education, Changchun, China",2024 International Conference on Digital Technology and Intelligent Education (ICDTIE),"22 May 2025","2024","","","35","41","The prevalence of mental health issues has led to a surge in demand for accessible and efficient psychological support. As technology advances, there is a growing interest in using large language models (LLMs) for online counseling. However, current LLM-based conversation systems are limited to empathetic conversations and lack the depth and variety of strategies used in professional counseling practice. To address this, we introduce a dataset for Psychological Counseling with Diverse Strategies (PCDS), an extension of PsyQA, and it contains over 39,000 data points categorized into six core helping skills for specific scenarios. This paper presents MindScape Continuum, a novel framework for integrating psychological helping skills into online counseling. It utilizes BERTbased models for text categorization and end-to-end conversation generation. Our experiments demonstrate that this approach achieves high accuracy in strategy categorization, enhancing the generation of targeted and professional responses in counseling conversations. By incorporating counseling helping skills into the prompt design, increasing the relevance and coherence of the model's responses. Although challenges remain with open-ended questions and semantic ambiguity, the MindScape Continuum framework shows promise in optimizing the application of psychological knowledge in AI-assisted counseling. It represents a significant step towards developing a next-generation online counseling tool.","","979-8-3315-1232-3","10.1109/ICDTIE65977.2024.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007308","Online Psychological Counselling;Natural Language Processing;Text Categorization;Large Language Models;Counsellor Helping Skills;Prompt Engineering;End-to-End Dialogue Generation","Employee welfare;Accuracy;Large language models;Text categorization;Semantics;Oral communication;Mental health;Coherence;Prompt engineering;Surges","","","","19","IEEE","22 May 2025","","","IEEE","IEEE Conferences"
"Is This You, LLM? Recognizing AI-written Programs with Multilingual Code Stylometry","A. Gurioli; M. Gabbrielli; S. Zacchiroli","DISI, University of Bologna, Bologna, Italy; DISI, University of Bologna, Bologna, Italy; LTCI, Télécom Paris Institut Polytechnique de Paris Palaiseau, France","2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","21 May 2025","2025","","","394","405","With the increasing popularity of LLM-based code completers, like GitHub Copilot, the interest in automatically detecting AI-generated code is also increasing-in particular in contexts where the use of LLMs to program is forbidden by policy due to security, intellectual property, or ethical concerns. We introduce a novel technique for AI code stylometry, i.e., the ability to distinguish code generated by LLMs from code written by humans, based on a transformer-based encoder classifier. Differently from previous work, our classifier is capable of detecting AI-written code across 10 different programming languages with a single machine learning model, maintaining high average accuracy across all languages (84.1% ± 3.8%). Together with the classifier we also release H-AIRosettaMP, a novel open dataset for AI code stylometry tasks, consisting of 121 247 code snippets in 10 popular programming languages, labeled as either human-written or AI-generated. The experimental pipeline (dataset, training code, resulting models) is the first fully reproducible one for the AI code stylometry task. Most notably our experiments rely only on open LLMs, rather than on proprietary/closed ones like ChatGPT.","2640-7574","979-8-3315-3510-0","10.1109/SANER64311.2025.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992332","code stylometry;large language models;AI detection;code generation;data provenance;deep learning","Training;Computer languages;Codes;Translation;Source coding;Transformers;Software;Multilingual;Security;Software development management","","","","44","IEEE","21 May 2025","","","IEEE","IEEE Conferences"
"Adaptive Deception Architectures: Conceptual Foundations for LLM-Powered Honeypot Systems","M. Érsok; Á. Balogh; E. Kail; A. Bánáti","John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI),"23 Jun 2025","2025","","","01","06","Conventional honeypot systems lack the dynamic adaptability required to counter evolving cyber threats, necessitating innovative approaches to automated deception. Building on foundational research from my diploma work in adaptive defense mechanisms, this paper proposes a conceptual architecture integrating large language models with next-generation honeypot systems. The framework establishes three pillars of intelligent deception: context-aware interaction through multi-modal dialogue processing that maintains service-specific personas, dynamic environment morphing guided by real-time attacker behavior analysis, and automated artifact generation creating credible system fingerprints. Security safeguards embedded in the design include adversarial prompt hardening and operational sandboxing to mitigate model exploitation risks. Experimental evaluations show marked improvements in attacker engagement compared to conventional rule-based systems, with generated responses demonstrating high plausibility during simulated advanced threat scenarios. This architecture advances adaptive cyber deception by enabling autonomous response calibration while addressing fingerprinting vulnerabilities inherent in traditional honeypot implementations, laying groundwork for intelligent defense systems capable of organic interaction with malicious actors.","2765-818X","979-8-3315-1547-8","10.1109/SACI66288.2025.11030110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030110","large language models;LLM;honeypot;cyber deception;adaptive architectures;attacker profiling;automated defense system","Adaptive systems;Reviews;Architecture;Large language models;Buildings;Computer architecture;Fingerprint recognition;Real-time systems;Informatics;Next generation networking","","","","26","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Enhancing User Story Generation in Agile Software Development Through Open AI and Prompt Engineering","V. Ramasamy; S. Ramamoorthy; G. S. Walia; E. Kulpinski; A. Antreassian","College of Engineering and Computing, Georgia Southern University, Statesboro, USA; School of Computer Science and Engineering, Vellore Insitute of Technology, Chennai, India; Department of Computer & Cyber Sciences, Augusta University, Augusta, USA; Computer Science, University of Wisconsin-Parkside, Kenosha, USA; Computer Science, University of Wisconsin-Parkside, Kenosha, USA",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","8","This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10893343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893343","Collaboration network;complex network analysis;structured collaboration network","Technical requirements;Technological innovation;Agile software development;Collaboration;Software;Prompt engineering;Stakeholders;Usability;Software engineering;Testing","","","","31","USGov","26 Feb 2025","","","IEEE","IEEE Conferences"
"Dynamic Incentive Strategies for Smart EV Charging Stations: A LLM-Driven User Digital Twin Approach","Y. Sun; C. Cui; C. Zhang; C. Gong","Shanghai University of Electric Power, Shanghai, China; Shanghai University of Electric Power, Shanghai, China; Shanghai University of Electric Power, Shanghai, China; Shanghai University of Electric Power, Shanghai, China",2025 IEEE International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE),"7 Aug 2025","2025","","","17","21","Electric vehicles and vehicle-to-grid technology are pivotal to modern demand response systems, yet their effectiveness is hindered by uncertainties in user behavior and low participation. To address these challenges, this paper presents a collaborative multi-agent demand response framework enhanced by large language models. By constructing user digital twins that integrate multidimensional user profile features, user decision-making patterns can be accurately predicted. Furthermore, a data and knowledge dual-driven dynamic incentive mechanism is introduced, combined with a network-constrained distributed optimization model, to optimize grid-user interactions while ensuring economic efficiency and security. Simulation results indicate significant improvements in peak load mitigation and charge-discharge strategies. Experimental validation highlights the system’s advantages in load balancing, user satisfaction, and grid stability, providing policymakers with a scalable V2G management tool that fosters sustainable vehicle-grid synergy.","","979-8-3315-2181-3","10.1109/AAIEE64965.2025.11101603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101603","Electric Vehicles;Demand Response;User Digital Twin;Vehicle-to-Grid;Large Language Models","Vehicle-to-grid;Uncertainty;Large language models;Simulation;Power system stability;Demand response;Stability analysis;Digital twins;Security;Vehicle dynamics","","","","14","IEEE","7 Aug 2025","","","IEEE","IEEE Conferences"
"DialogueMLLM: Transforming Multimodal Emotion Recognition in Conversation Through Instruction-Tuned MLLM","Y. Sun; T. Zhou","Central China Normal University, Wuhan, China; Sun Yat-sen University, Shenzhen, China",IEEE Access,"4 Aug 2025","2025","13","","121048","121060","Multimodal Emotion Recognition in Conversation (MERC) is an advanced research area that integrates cross-modal understanding and contextual reasoning through text-speech-visual fusion, with applications spanning diverse scenarios including student emotion monitoring in high school classroom interactions. Although existing research has made progress in multimodal alignment and dialogue relationship modeling through architectures such as graph neural networks and pre-trained language models, challenges persist in dataset overfitting and underexplored generative approaches. In this study, a generative MERC framework based on Multimodal Large Language Models (MLLMs) is proposed, employing Video-LLaMA, an open-source and advanced tri-modal foundation model, for end-to-end multimodal emotion reasoning. Carefully crafted structured prompts are used to align emotion semantics with dataset annotations, combined with Low-Rank Adaptation (LoRA) for parameter-efficient optimization. The method achieves a state-of-the-art weighted F1-score of 68.57% on the MELD benchmark. Further, exploratory experiments on dynamic modality combinations and fine-tuning strategies offer actionable insights for MLLM-based MERC research. This work not only advances emotion understanding in dialogues but also highlights MLLMs’ potential in complex multimodal reasoning tasks.","2169-3536","","10.1109/ACCESS.2025.3591447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088104","Multimodal emotion recognition in conversation;multimodal large language models;structured prompt engineering;downstream task fine-tuning","Emotion recognition;Large language models;Cognition;Context modeling;Visualization;Transformers;Semantics;Feature extraction;Adaptation models;Tuning","","","","60","CCBY","22 Jul 2025","","","IEEE","IEEE Journals"
"Evaluating LLM-Based Communicative Agents for Verilog Design","P. Link; B. Tan","Department of Electrical and Software Engineering, Schulich School of Engineering, University of Calgary; Department of Electrical and Software Engineering, Schulich School of Engineering, University of Calgary",2025 26th International Symposium on Quality Electronic Design (ISQED),"30 May 2025","2025","","","1","8","Large language models have demonstrated their effectiveness in generating simple hardware descriptions for a variety of basic hardware design problems. One-shot generation, however, is unable to solve many problems reliably. By utilizing Communicative Agents and a compiler-in-the-loop feedback loop, the language model was shown to be more effective than in single-shot code generation. We present an experimentation framework for connecting all necessary infrastructure to track, extract, utilize, and evaluate large language models working in tandem with each other, and with tools like Icarus Verilog, to solve hardware design problems. Our results suggest that recently proposed approaches for communicative agent-based design are only marginally beneficial in a hardware design context.","1948-3295","979-8-3315-0942-2","10.1109/ISQED65160.2025.11014310","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2022-03027); Intel Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014310","ChatGPT;Verilog;SystemVerilog;hardware security;large language models;benchmarking;artificial intelligence","Feedback loop;Codes;Large language models;Hardware security;Benchmark testing;Chatbots;Reliability;Hardware design languages","","","","18","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Human and Machine: How Software Engineers Perceive and Engage with AI-Assisted Code Reviews Compared to Their Peers","A. Alami; N. Ernst","Mœrsk Mc-Kinney Møller Institute, University of Southern Denmark; Department of Computer Science, University of Victoria",2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE),"12 Jun 2025","2025","","","63","74","The integration of artificial intelligence (AI) continues to increase and evolve, including in software engineering (SE). This integration involves processes traditionally entrusted to humans, such as coding. However, the impact on sociotechnical processes like code review remains underexplored. In this interview-based study (20 interviewees), we investigate how software engineers perceive and engage with Large Language Model (LLM)-assisted code reviews compared to human peerled reviews. In this inherently human-centric process, we aim to understand how software engineers navigate the introduction of AI into collaborative workflows. We found that engagement in code review is multi-dimensional, spanning cognitive, emotional, and behavioral dimensions. The introduction of LLM-assisted review impacts some of these attributes. For example, there is less need for emotional regulation and coping mechanisms when dealing with an LLM compared to peers. However, the cognitive load sometimes is higher in dealing with LLM-generated feedback due to its excessive details. Software engineers use a similar sense-making process to evaluate and adopt feedback suggestions from their peers and the LLM. However, the LLM feedback adoption is constrained by trust and lack of context in the review. Our findings contribute to a deeper understanding of how AI tools are impacting SE socio-technical processes and provide insights into the future of AI-human collaboration in SE practices.","2574-1837","979-8-3315-3871-2","10.1109/CHASE66643.2025.00016","Aalborg University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024268","Code Review;Large Language Models;LLM-supported software engineering;Human-AI collaboration","Codes;Reviews;Navigation;Large language models;Collaboration;Cognitive load;Software;Regulation;Encoding;Software engineering","","","","82","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-Based Prompt Injection Attacks via the Fine-Tuning Interface","A. Labunets; N. V. Pandya; A. Hooda; X. Fu; E. Fernandes",UC San Diego; UC San Diego; University of Wisconsin Madison; UC San Diego; UC San Diego,2025 IEEE Symposium on Security and Privacy (SP),"16 Jun 2025","2025","","","411","429","We surface a new threat to closed-weight Large Language Models (LLMs) that enables an attacker to compute optimization-based prompt injections. Specifically, we characterize how an attacker can leverage the loss-like information returned from the remote fine-tuning interface to guide the search for adversarial prompts. The fine-tuning interface is hosted by an LLM vendor and allows developers to fine-tune LLMs for their tasks, thus providing utility, but also exposes enough information for an attacker to compute adversarial prompts. Through an experimental analysis, we characterize the loss-like values returned by the Gemini fine-tuning API and demonstrate that they provide a useful signal for discrete optimization of adversarial prompts using a greedy search algorithm. Using the PurpleLlama prompt injection benchmark, we demonstrate attack success rates between 65% and 82% on Google's Gemini family of LLMs. These attacks exploit the classic utility-security tradeoff - the fine-tuning interface provides a useful feature for developers but also exposes the LLMs to powerful attacks.","2375-1207","979-8-3315-2236-0","10.1109/SP61157.2025.00121","NSF(grant numbers:2312119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023405","machine learning;computer security;attacks","Training;Privacy;Prevention and mitigation;Large language models;Oral communication;Vectors;Internet;Security;Optimization;Faces","","","","61","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Automatic High-Level Test Case Generation using Large Language Models","N. B. Hasan; M. A. Islam; J. Y. Khan; S. Senjik; A. Iqbal",Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology,2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","674","685","We explored the challenges practitioners face in software testing and proposed automated solutions to address these obstacles. We began with a survey of local software companies and 26 practitioners, revealing that the primary challenge is not writing test scripts but aligning testing efforts with business requirements. Based on these insights, we constructed a usecase $\rightarrow$ (high-level) test-cases dataset to train/fine-tune models for generating high-level test cases. High-level test cases specify what aspects of the software’s functionality need to be tested, along with the expected outcomes. We evaluated large language models, such as GPT-4o, Gemini, LLaMA 3.1 8B, and Mistral 7B, where fine-tuning (the latter two) yields improved performance. A final (human evaluation) survey confirmed the effectiveness of these generated test cases. Our proactive approach strengthens requirement-testing alignment and facilitates early test case generation to streamline development.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025799","Test Case;Use Case;Test Case Generation;Dataset;Large Language Model","Surveys;Software testing;Large language models;Companies;Writing;Software;Data mining;Faces;Business","","","","50","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Semantically Aligned Question and Code Generation for Automated Insight Generation","A. Singha; B. Chopra; A. Khatry; S. Gulwani; A. Z. Henley; V. Le; C. Parnin; M. Singh; G. Verbruggen","Microsoft, India; Microsoft, India; Microsoft, India; Microsoft, USA; Microsoft, USA; Microsoft, USA; Microsoft, USA; Microsoft, India; Microsoft, Belgium",2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"30 Oct 2024","2024","","","127","134","Automated insight generation is a common tactic for helping knowledge workers, such as data scientists, to quickly understand the potential value of new and unfamiliar data. Unfortunately, automated insights produced by large-language models can generate code that does not correctly correspond (or align) to the insight. In this paper, we leverage the semantic knowledge of large language models to generate targeted and insightful questions about data and the corresponding code to answer those questions. Then through an empirical study on data from Open-WikiTable, we show that embeddings can be effectively used for filtering out semantically unaligned pairs of question and code. Additionally, we found that generating questions and code together yields more diverse questions.","","979-8-4007-0579-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734616","LLM;alignment;Code-generation","Codes;Costs;Filtering;Large language models;Conferences;Semantics","","","","19","","30 Oct 2024","","","IEEE","IEEE Conferences"
"LoRATEE: A Secure and Efficient Inference Framework for Multi-Tenant LoRA LLMs Based on TEE","Z. Lin; S. Zhang; X. Wang; Y. Su; Y. Wang; R. Hou; D. Meng","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Low-Rank Adaptation (LoRA) is a parameter-efficient fine-tuning approach that adaptes pre-trained Large Language Models (LLMs) to multi-tenant tasks by generating a variety of LoRA adapters. However, this approach faces significant security challenges and is particularly susceptible to malicious servers stealing model parameters and sensitive data. Existing research on addressing security risks in multi-tenant environments remains constrained and insufficient. This paper explores the security challenges and proposes the LoRATEE framework, which embeds LoRA adapters within a server-side Trusted Execution Environment (TEE) and employs a lightweight One-Time Pad (OTP) encryption mechanism to ensure secure data transmission. Additionally, we design a dynamic LoRA adapter prefetching mechanism to reduce I/O latency. Moreover, a LoRA adapter module equivalence-sharing strategy based on Parameter-Efficient Fine-Tuning (PEFT) and minimalist design principles was introduced to optimize adapters loading. Experimental results show that LoRATEE maintains inference efficiency while securing multi-tenant LoRA LLMs systems.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890445","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890445","LoRA;Security;TEE;Dynamic Prefetching;Equivalence-Sharing","Prefetching;Large language models;Data security;Loading;Intellectual property;Signal processing;Encryption;Servers;Speech processing;Faces","","","","43","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Empowering Secondary School Teachers: Creating, Executing, and Evaluating a Transformative Professional Development Course on ChatGPT","H. Reichert; B. T. Tabarsi; Z. Zang; C. Fennell; I. Bhandari; D. Robinson; M. Drayton; C. Crofton; M. Lococo; D. Xu; T. Barnes","Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Durham Public Schools, Durham, NC; Wake County Public School System, Cary, NC, USA; Durham Public Schools, Durham, NC; Charlotte-Mecklenburg Schools, Charlotte, NC, USA; Wake County Public School System, Cary, NC, USA; Greene County Schools, Snow Hill, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","9","Background and Context. This innovative practice full paper describes the development and implementation of a professional development (PD) opportunity for secondary teachers to learn about ChatGPT. Incorporating generative AI techniques from Large Language Models (LLMs) such as ChatGPT into educational environments offers unprecedented opportunities and challenges. Prior research has highlighted their potential to personalize feedback, assist in lesson planning, generate educational content, and reduce teachers' workload, alongside concerns such as academic integrity and student privacy. However, the rapid adoption of LLMs since ChatGPT's public release in late 2022 has left educators, particularly at the secondary level, with a lack of clear guidance on how LLMs work and can be effectively adopted. Objective. This study aims to introduce a comprehensive, free, and vetted ChatGPT course tailored for secondary teachers, with the objective of enhancing their technological competencies in LLMs and fostering innovative teaching practices. Method. We developed a five-session interactive course on ChatGPT capabilities, limitations, prompt-engineering techniques, ethical considerations, and strategies for incorporating ChatGPT into teaching. We introduced the course to six middle and high school teachers. Our curriculum emphasized active learning through peer discussions, hands-on activities, and project-based learning. We conducted pre- and post-course focus groups to determine the effectiveness of the course and the extent to which teachers' attitudes toward the use of LLMs in schools had changed. To identify trends in knowledge and attitudes, we asked teachers to complete feedback forms at the end of each of the five sessions. We performed a thematic analysis to classify teacher quotes from focus groups' transcripts as positive, negative, and neutral and calculated the ratio of positive to negative comments in the pre- and post-focus groups. We also analyzed their feedback on each individual session. Finally, we interviewed all participants five months after course completion to understand the longer-term impacts of the course. Findings. Our participants unanimously shared that all five of the sessions provided a deeper understanding of ChatGPT, featured enough opportunities for hands-on practice, and achieved their learning objectives. Our thematic analysis underlined that teachers gained a more positive and nuanced understanding of ChatGPT after the course. This change is evidenced quantitatively by the fact that quotes with positive connotations rose from 45% to 68% of the total number of positive and negative quotes. Participants shared that in the longer term, the course improved their professional development, understanding of ChatGPT, and teaching practices. Implications. This research underscores the effectiveness of active learning in professional development settings, particularly for technological innovations in computing like LLMs. Our findings suggest that introducing teachers to LLM tools through active learning can improve their work processes and give them a thorough and accurate understanding of how these tools work. By detailing our process and providing a model for similar initiatives, our work contributes to the broader discourse on teaching professional educators about computing and integrating emerging technologies in educational and professional development settings.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10893106","National Science Foundation(grant numbers:2055528); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893106","K-12;large language models;chatgpt;professional development;secondary education","Technological innovation;Privacy;Computational modeling;Large language models;Education;Active learning;Position measurement;Chatbots;Market research;Planning","","","","38","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Systematic Mapping Study of Security in Multi-Embedded-Agent Systems","A. Baudet; O. -E. -K. Aktouf; A. Mercier; P. Elbaz-Vincent","LCIS, Grenoble INP, Université Grenoble Alpes, Valence, France; LCIS, Grenoble INP, Université Grenoble Alpes, Valence, France; LCIS, Grenoble INP, Université Grenoble Alpes, Valence, France; Institut Fourier, CNRS, Université Grenoble Alpes, Grenoble, France",IEEE Access,"24 Nov 2021","2021","9","","154902","154913","Context: In this paper, we study distributed and decentralized systems in which each part is modeled as an agent in a multi-agent system. Those systems provide more scalable and easier ways to control complex, distributed and interconnected systems of embedded components. We are particularly interested in methods to secure these systems. Objectives: This study aims to identify the main security properties studied, the parts of a multi-agent architecture that are considered most often in security studies and the technical solutions used to secure those systems. Methods: We conducted a systematic mapping study on research works addressing the security of multi-agent systems with embedded agents. We identified which security features were addressed, and their roles in global security architecture. Results: We identified 70 papers published in journals and conferences. We classified the extracted data reporting a tendency to focus on securing the availability of systems under attack by means of trust schemes, sometimes supported by cryptographic primitives. Conclusion: The use of cryptography appears to be limited in decentralized systems. However, solutions should be provided to overcome those limits as other solutions such as trust schemes do not protect the system from the same type of attacks.","2169-3536","","10.1109/ACCESS.2021.3128287","French National Research Agency in the framework of the “Investissements d’avenir” Program(grant numbers:ANR-15-IDEX-02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615051","Decentralized security;embedded system;multi-agent system;security architecture;systematic mapping study","Security;Multi-agent systems;Systematics;Wireless sensor networks;Data models;Computer architecture;Wireless communication","","2","","35","CCBY","15 Nov 2021","","","IEEE","IEEE Journals"
"Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach","J. Wei; A. -L. Courbis; T. Lambolais; B. Xu; P. L. Bernard; G. Dray; W. Maalej","EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Montpellier, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; University of Hamburg, Hamburg, Germany",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","857","869","Over the past decade, app store (AppStore)-inspired requirements elicitation has proven to be highly beneficial. Developers often explore competitors’ apps to gather inspiration for new features. With the advance of Generative AI, recent studies have demonstrated the potential of large language model (LLM)-inspired requirements elicitation. LLMs can assist in this process by providing inspiration for new feature ideas. While both approaches are gaining popularity in practice, there is a lack of insight into their differences. We report on a comparative study between AppStore- and LLM-based approaches for refining features into sub-features. By manually analyzing 1,200 sub-features recommended from both approaches, we identified their benefits, challenges, and key differences. While both approaches recommend highly relevant sub-features with clear descriptions, LLMs seem more powerful particularly concerning novel unseen app scopes. Moreover, some recommended features are imaginary with unclear feasibility, which suggests the importance of a human-analyst in the elicitation loop.CCS CONCEPTS• Software and its engineering → Requirements analysis; • Computing methodologies → Natural language processing.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764984","Requirements Elicitation;App Store Mining;Large Language Models;Data-Centered Requirements Engineering;Creativity in SE","Surveys;Industries;Reviews;Generative AI;Large language models;Refining;Manuals;Software;Natural language processing;Software engineering","","","","57","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Predictive Risk and Complexity Score Assessment Model for Cloud Computing","K. Ayappan; J. M. Mathana; J. Thangakumar","Hindustan Institute of Technology & Science, Chennai, India; Hindustan Institute of Technology & Science, Chennai, India; Hindustan Institute of Technology & Science, Chennai, India",2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS),"23 May 2024","2024","","","1","6","With the rapid growth in information technology and being called the Digital Era, it is very evident that no one can survive without internet or ICT advancements. The day-to-day life operations and activities are dependent on these technologies. The latest technology trends in the market and industry are computing power, Smart devices, artificial intelligence, Robotic process automation, metaverse, IOT (Internet of things), cloud computing, Edge computing, Block chain and much more in the coming years. When looking at all these aspect and advancements, one common thing is cloud computing and data which must be protected and safeguarded which brings in the need for cyber/cloud security. Hence cloud security challenges have become an omnipresent concern for organizations or industries of any size where it has gone from a small incident to threat landscape. When it comes to data and cyber/ cloud security there are lots of challenges seen to safeguard these data. Towards that it is necessary that everyone must be aware of the latest technological advancements, evolving cyber threats, data as a valuable asset, Human Factor, Regulatory compliance, Cyber resilience. To handle all these challenges, security and risk prediction framework is proposed in this paper. This framework PRCSAM (Predictive Risk and Complexity Score Assessment Model) will consider factors like impact and likelihood of the main risks, threats and attacks that is foreseen in cloud security and the recommendation of the Risk management framework with automatic risk assessment and scoring option catering to Information security and privacy risks. This framework will help management and organizations in making informed decisions on the cyber security strategy as this is a data driven, dynamic & proactive approach to cyber security and its complexity calculation. This paper also discusses on the prediction techniques using Generative AI techniques.","","979-8-3503-6482-8","10.1109/ADICS58448.2024.10533467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533467","Cloud Security;Risk assessment;Cyber threats;Incidents;Cloud threats;Predictive Risk and Complexity Score Assessment Model (PRCSAM);Generative AI","Industries;Cloud computing security;Computational modeling;Organizations;Predictive models;Data models;Complexity theory","","1","","20","IEEE","23 May 2024","","","IEEE","IEEE Conferences"
"Training Autonomous Cyber Defense Agents: Challenges & Opportunities in Military Networks","J. F. Loevenich; E. Adler; A. Bécue; A. Velazquez; K. Wrona; V. Boshnakov; J. Falkcrona; N. Nordbotten; O. L. Worthington; J. Röning; R. Rigolin; F. Lopes","Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; THALES SIX GTS, Gennevilliers, France; Information Technology Division, U.S. Naval Research Laboratory, Washington, DC, USA; NATO Cyber Security Centre, The Hague, Netherlands; NATO Cyber Security Centre, The Hague, Netherlands; Cyber Defence and C2 Technology, Swedish Defence Research Agency, Linköping, Sweden; Thales Norway, Oslo, Norway; Defence Science and Technology Laboratory (Dstl), UK Ministry of Defence, London, United Kingdom; Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; NA; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany",MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM),"6 Dec 2024","2024","","","158","163","This paper addresses the development and training of robust autonomous cyber defense (ACD) agents within military networks. We propose an architecture that integrates a hybrid AI model comprising Multi-Agent Reinforcement Learning (MARL), Large Language Models (LLMs), and a rule-based system into blue and red agent teams distributed across network devices. The primary goal is to automate key cybersecurity tasks such as monitoring, detection, and mitigation, thereby augmenting the capabilities of cybersecurity professionals in protecting critical military infrastructure. This architecture is designed to operate in modern network environments characterized by segmented clouds and software-defined controllers, which facilitate the deployment of ACD agents and other cybersecurity tools. The agent teams were evaluated in an Automated Cyber Operation (ACO) gym, which simulates NATO protected core networks and enables reproducible training and testing of autonomous agents. The paper concludes with an examination of the main challenges encountered in the training of ACD agents, with a particular focus on the security of the data and the robustness of the AI models during the training/testing phase.","2155-7586","979-8-3503-7423-0","10.1109/MILCOM61039.2024.10773923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773923","Autonomous Cyber Security;Multi-Agent Reinforcement Learning;Large Language Models","Training;Measurement;Military communication;Privacy;Prevention and mitigation;Reinforcement learning;Robustness;Autonomous agents;Monitoring;Testing","","5","","17","IEEE","6 Dec 2024","","","IEEE","IEEE Conferences"
"Multi-Agent Software Architecture for Distributed Virtual Reality Systems","V. Duchenchuk; V. Boublik","Institute of Software Systems, Kyiv, Ukraine; National University Kyiv-Mohyla Academy, Kyiv, Ukraine",2020 10th International Conference on Advanced Computer Information Technologies (ACIT),"30 Sep 2020","2020","","","529","532","Interactive distributed applications with a shared virtual environment, also known as distributed virtual reality (DVR) systems, have been examined in this paper. DVR systems are efficiently used in applications for education, simulation, training, and entertainment purposes. They impose a challenge for a high level of real-time interaction between users in an efficient way in terms of network usage. The aim of this paper is the development of a special multi-agent software architecture for distributed virtual reality systems. Main components of a multi-agent system as well as communication mechanisms between the agents have been suggested and evaluated. On the base of multi-agent systems, consistent visualization of objects as well as their interactions within the system has been achieved.","","978-1-7281-6760-2","10.1109/ACIT49673.2020.9208841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208841","distributed;virtual reality;multi-agent;mobile","Software;Virtual environments;Security;Mobile agents;Multi-agent systems;Clocks","","","","10","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Resilient Privacy-Preserving Average Consensus for Multi-agent Systems under Attacks","D. Wang; N. Zheng; M. Xu; Y. Wu; Q. Hu; G. Wang","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China","2020 16th International Conference on Control, Automation, Robotics and Vision (ICARCV)","8 Jan 2021","2020","","","1399","1405","Security of consensus control is of key significance in multi-agent systems. In this paper we investigate the resilient consensus problem for multi-agent systems under the specific attack scenarios where the attacker can eavesdrop on initial information of agents among the system, and modifies the values in the communication links to interfere in the consensus process. To protect the privacy of node' value, we employ the cryptography of homomorphic encryption to encrypt initial integer state of each agent, without revealing to other agents the real value in the network. When the communication network meets the necessary connectivity, we develop a variation of so-called ratio consensus algorithm that deal with malicious attacks. The numerical example of directed network is conducted to illustrate the effectiveness of our proposed algorithm.","","978-1-7281-7709-0","10.1109/ICARCV50220.2020.9305459","National Natural Science Foundation of China(grant numbers:61803135,61702150); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305459","","Encryption;Privacy;Directed graphs;Multi-agent systems;Ciphers;Consensus algorithm;Robot sensing systems","","3","","24","IEEE","8 Jan 2021","","","IEEE","IEEE Conferences"
"An Introduction to Prompt Engineering","S. Van Laan; J. Matfess; T. Flock; A. Reid",Slalom; AvePoint; Slalom; Slalom,Microsoft 365 Copilot At Work: Using AI to Get the Most from Your Business Data and Favorite Apps,"","2025","","","27","41","Summary <p>Prompt engineering is a key skill for anyone who wants to optimize their return on investment in M365 Copilot. This chapter sets out to demystify prompt engineering. It introduces the readers to the basics of large language models (LLMs), which are used for various language tasks with M365 Copilot. LLMs can be powerful tools for any language‐related tasks, such as content creation, summarization, or information retrieval. The chapter presents three prompt mnemonics: role, task, and format. The Copilot Lab is a great resource to help the readers to learn about various prompts that they can try across the range of Microsoft 365 applications. Creating a prompt library is a useful way to save and reuse prompts. One possible development that could affect the role of prompt engineering is automatic prompt optimization.</p>","","9781394258390","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10950747.pdf&bkn=10950115&pdfType=chapter","","Artificial intelligence;Prompt engineering;Market research;Large language models;Industries;Fish;Economics;Blogs;Biological system modeling;Training","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Assessing Model Proficiency in Autonomous Agents: A Signal Processing Perspective","A. Guerra; F. Guidi; D. Dardari; P. M. Djurić","DEI, WiLab, University of Bologna, Cesena, Italy; IEIIT, WiLab, National Research Council of Italy (CNR), Bologna, Italy; DEI, WiLab, University of Bologna, Cesena, Italy; Stony Brook University, USA","2025 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)","27 May 2025","2025","","","1","5","Autonomous agents play a crucial role in applications such as emergency response and urban security, where they are often required to operate independently in critical situations without direct human supervision. A key aspect of autonomy is the agent’s ability to assess its proficiency in carrying out tasks and making decisions based on this assessment. This paper introduces a state-space model to present a novel framework for assessing the proficiency of autonomous agents. The proposed metric is based on statistical model assessment, enabling agents to evaluate their model performance in real-time. More specifically, we focus on the proficiency of the model used for measurement predictions. We validate the effectiveness of our metric through simulations with synthetic data. Future work will explore the potential of this framework to enhance decision-making accuracy and improve task performance.","","979-8-3315-1931-5","10.1109/ICASSPW65056.2025.11011249","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011249","Model proficiency assessment;state-space models;autonomous systems","Measurement;Adaptation models;Accuracy;Decision making;Signal processing;Autonomous agents;Real-time systems;State-space methods;Speech processing;Synthetic data","","","","18","IEEE","27 May 2025","","","IEEE","IEEE Conferences"
"Data Migration between on prim to Cloud using Generative AI to Reduce Costing And Overheads","P. Chavan; P. Chavan",BE Computer Science; Data Science,2024 International Conference on Innovations and Challenges in Emerging Technologies (ICICET),"6 Aug 2024","2024","","","1","7","“Cloud data migration” describes the method of transferring digital data to new cloud services or garage structures. Data have to be transferred in a way that guarantees it remains available, secure, and uncompromised. Businesses might also easily adjust to new needs and trends in era by way of transferring their statistics, apps, or workloads to the cloud. Scalability, adaptability, and optimising charges are all made feasible by this. Generative AI can help us evaluate existing applications and provide insights into how they can be optimized for the target cloud environments. In the ever-evolving world of technology, Generative AI (GenAI) has emerged as a transformative force, poised to revolutionize various industries and domains, including cloud migration. As the global landscape of migration continues to shift, GenAI is prepared to play an essential role in streamlining processes, enhancing accuracy, and improving overall migration outcomes. The review present paper investigates the utilisation of generative AI in order to facilitate the transfer of data from on-premises to the cloud. While highlighting the potential of generative AI to automate transfer operations, it tackles obstacles such as economic implications and security concerns. Migration techniques, the benefits of cloud migration, and pertinent literature are examined in this study, which also provides a summary of key findings and recommendations for future research.","","979-8-3503-1901-9","10.1109/ICICET59348.2024.10616354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10616354","Data Migration;Cloud Migration;Generative AI;Artificial Intelligence;Challenges;Applications;Techniques","Industries;Economics;Technological innovation;Generative AI;Reviews;Costing;Scalability","","","","21","IEEE","6 Aug 2024","","","IEEE","IEEE Conferences"
"Understanding Developer-Analyzer Interactions in Code Reviews","B. Cirisci; L. Luo; M. N. Mansur; M. Schäf; O. Tripp; M. B. Zafar; Q. Zhou; D. Sanchez",Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Alexa,2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1945","1955","Static code analyzers are now a common part of the code review process. These automated tools integrate into the code review process by commenting on code changes and suggesting improvements, in the same way as human reviewers. The comments made by static analyzers often trigger a conversation between developers to align on if and how the issue should be fixed. Because developers rarely give feedback directly to the tool, understanding the sentiment and intent in the conversation triggered by the tool comments can be used to measure the usefulness of the static analyzer.In this paper, we report on an experiment where we use large language models to automatically label and categorize the sentiment and intent of such conversations triggered by static analyzer comments. Our experiment demonstrates that LLMs not only classify and interpret complex developer-analyzer conversations, but can be more accurate than human experts.CCS CONCEPTS• Software and its engineering → Software testing and debugging; Software maintenance tools.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764978","static analysis;large language models;sast","Training;Software testing;Software maintenance;Codes;Accuracy;Uncertainty;Reviews;Oral communication;Software reliability;Labeling","","","","33","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering","R. S. M. Wahidur; I. Tashdeed; M. Kaur; H. -N. Lee","School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Computer Science and Engineering, Islamic University of Technology, Gazipur, Bangladesh; School of Computer Science and Artificial Intelligence, SR University, Warangal, Telangana, India; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea",IEEE Access,"22 Jan 2024","2024","12","","10146","10159","Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft’s MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google’s FLAN-T5 demonstrates consistent and reliable performance across diverse datasets.","2169-3536","","10.1109/ACCESS.2024.3350638","Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government (MSIT)(grant numbers:No.2024-2021-0-00118); Development of decentralized consensus composition technology for large-scale nodes; MSIT (Ministry of Science and Information and Communication Technology), Korea, under the ITRC (Information Technology Research Center) support program(grant numbers:IITP-2024-2021-0-01835); IITP (Institute of Information & Communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10382518","Zero-shot learning;in-context learning;supervised fine-tuning;instruction tuned;prompt engineering","Cryptocurrency;Social networking (online);Analytical models;Training;Context modeling;Sentiment analysis;Transformers;Zero-shot learning;Context modeling;Supervised learning","","11","","69","CCBYNCND","8 Jan 2024","","","IEEE","IEEE Journals"
"Generative AI and Emotional Health: Innovations with Haystack","A. Agliata; A. Pilato; S. Mariacarmen; S. Bottiglieri; E. D. Nardo; A. Ciaramella","Department of Business Science, University of Salerno Fisciano, Italy; Department of Research & Development, BC Soft, Naples, Italy; Department of Business Science, University of Salerno Fisciano, Italy; Department of Research & Development, AiReD, Naples, Italy; Department of Science and Technology, University of Naples Parthenope, Naples, Italy; Department of Science and Technology, University of Naples Parthenope, Naples, Italy",2024 IEEE Symposium on Computers and Communications (ISCC),"31 Oct 2024","2024","","","1","4","Generative artificial intelligence (AI) is poised to revolutionize the healthcare sector by enhancing research methodologies, diagnostic procedures, and treatment protocols. This paper investigates the application of key generative AI technologies, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Pre-trained Generative Transformer models, with a particular focus on their implementation in medical imaging, drug discovery, and electronic health record management. Utilizing the Haystack framework, this study integrates these technologies to optimize data access and retrieval. The research addresses the primary challenges in healthcare AI adoption, such as data quality, model interpretability, ethical considerations, and regulatory compliance. By leveraging the Haystack framework, we identify future research opportunities, emphasizing the integration of multimodal data, the personalization of treatments, and the development of transparent AI systems. The study underscores the critical role of interdisciplinary collaboration between AI researchers and healthcare professionals in maximizing the benefits of these technologies, managing their complexities, and ensuring their successful integration into healthcare systems. Our findings demonstrate the potential of generative AI to significantly improve clinical decision-making and patient care, while also highlighting the importance of ethical guidelines and robust data security measures.","2642-7389","979-8-3503-5423-2","10.1109/ISCC61673.2024.10733569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10733569","NLP;Generative Pre-trained Transformer;Emotional Well-Being;Retrieval-Augmented Generation;User-Centered AI Design","Ethics;Technological innovation;Protocols;Generative AI;Medical services;Transformers;Generative adversarial networks;Drug discovery;Electronic medical records;Guidelines","","1","","22","IEEE","31 Oct 2024","","","IEEE","IEEE Conferences"
"AI Applications in Medical Reporting and Diagnosis","M. Makram; A. Mohammcd","Department of Data Science FGSSR, Cairo University, Cairo, Egypt; Dept. of CS, FGSSR, Cairo University","2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)","16 Dec 2024","2024","","","185","192","The integration of artificial intelligence (AI) in healthcare is revolutionizing diagnosis and patient care by improving clinical documentation and the management of electronic health records that depend on medical image interpretation, increasing accuracy, and reducing time. Egypt ranks first in liver disease and second in liver cancer mortality worldwide in 2020. Large language models, a subset of AI techniques, can assist in disease diagnosis. LLM models with multimodal capabilities can classify and describe patient scan images and extract information from clinical notes. These models can extract vital diagnoses with the support of prompt engineering, as one of these models can answer questions, summarize information, and translate complex medical terminology into plain language, enabling patients to understand their medical reports and diagnoses. There are two primary approaches to achieving this. First, fine-tuning can adapt the model to medical data, which can be resource-intensive. The second approach, pre-trained LLM models can be utilized to leverage pre-trained models to perform the necessary tasks, focusing on effectively using prompts to guide the model for precise and relevant outputs. This study highlights the role of generative AI models by focusing on prompt engineering, and how carefully crafting prompts can enhance the effectiveness of LLM models in medical applications with high accuracy. It demonstrates this through experiments using pre-trained models based on semantic similarity with GPT-4o and BioGPT. Implementing a zero-shot model for liver tumor classification is one of the prompt engineering techniques. The performance metrics achieved were impressive, accuracy, precision, recall, and F1-scores are 88, 81, 88, and 83 percent, respectively.","","979-8-3503-6777-5","10.1109/MIUCC62295.2024.10783552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10783552","Generative AI;Prompt Engineering;Large Language Model (LLM);Chat-GPT;Artificial Intelligence;Medical radiology reports","Adaptation models;Accuracy;Biological system modeling;Computational modeling;Focusing;Ubiquitous computing;Prompt engineering;Data mining;Medical diagnostic imaging;Tumors","","1","","30","IEEE","16 Dec 2024","","","IEEE","IEEE Conferences"
"Automating a Complete Software Test Process Using LLMs: An Automotive Case Study","S. Wang; Y. Yu; R. Feldt; D. Parthasarathy","Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden; Volvo Group, Gothenburg, Sweden",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","373","384","Vehicle API testing verifies whether the interactions between a vehicle's internal systems and external applications meet expectations, ensuring that users can access and control various vehicle functions and data. However, this task is inherently complex, requiring the alignment and coordination of API systems, communication protocols, and even vehicle simulation systems to develop valid test cases. In practical industrial scenarios, inconsistencies, ambiguities, and interde-pendencies across various documents and system specifications pose significant challenges. This paper presents a system designed for the automated testing of in-vehicle APIs. By clearly defining and segmenting the testing process, we enable Large Language Models (LLMs) to focus on specific tasks, ensuring a stable and controlled testing workflow. Experiments conducted on over 100 APIs demonstrate that our system effectively automates vehicle API testing. The results also confirm that LLMs can efficiently handle mundane tasks requiring human judgment, making them suitable for complete automation in similar industrial contexts.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029843","software testing;vehicle API testing;test automation;large language model","Software testing;Automation;Large language models;Manuals;Transforms;Writing;Web servers;Testing;Software engineering;Automotive engineering","","","","43","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning","C. N. Hang; C. Wei Tan; P. -D. Yu","Yam Pak Charitable Foundation School of Computing and Information Sciences, Saint Francis University, Hong Kong, China; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; Department of Applied Mathematics, Chung Yuan Christian University, Taoyuan, Taiwan",IEEE Access,"29 Jul 2024","2024","12","","102261","102273","In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.","2169-3536","","10.1109/ACCESS.2024.3420709","Nanyang Technological University (NTU) startup fund; EdeX(grant numbers:03INS001595C130); NTU Centre for Teaching, Learning and Pedagogy; National Science and Technology Council of Taiwan(grant numbers:112-2115-M-033-004-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577164","Large language models;multiple-choice questions;personalized learning;prompt engineering;retrieval-augmented generation","Education;Knowledge engineering;Testing;Knowledge based systems;Task analysis;Semantics;Problem-solving;Large language models;Information retrieval;Data augmentation","","33","","31","CCBY","28 Jun 2024","","","IEEE","IEEE Journals"
"Sentiment Analysis for the Masses: How LLMs Changed the Game","M. Borg; T. Richter","CodeScene, Malmö, Sweden; Lund University, Lund, Sweden",IEEE Software,"4 Dec 2024","2025","42","1","17","21","This column presents the evolution of sentiment analysis from a requirements engineering perspective. With large language models, the technology is now accessible to all. From novices to expert users, we discuss suitable ways to get started.","1937-4194","","10.1109/MS.2024.3478474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10777893","","Training data;Sentiment analysis;Analytical models;Large language models;Game theory;Requirements engineering","","1","","5","IEEE","4 Dec 2024","","","IEEE","IEEE Magazines"
"Respond to Change With Constancy: Instruction-Tuning With LLM for Non-I.I.D. Network Traffic Classification","X. Lin; G. Xiong; G. Gou; W. Dong; J. Yu; Z. Li; W. Xia","Zhongguancun Laboratory, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Information Forensics and Security,"16 Jun 2025","2025","20","","5758","5773","Encrypted traffic classification is highly challenging in network security due to the need for extracting robust features from content-agnostic traffic data. Existing approaches face critical issues: (i) Distribution drift, caused by reliance on the closed-world assumption, limits adaptability to real-world, shifting patterns; (ii) Dependence on labeled data restricts applicability where such data is scarce or unavailable. Large language models (LLMs) have demonstrated remarkable potential in offering generalizable solutions across a wide range of tasks, achieving notable success in various specialized fields. However, their effectiveness in traffic analysis remains constrained by challenges in adapting to the unique requirements of the traffic domain. In this paper, we introduce a novel traffic representation model named Encrypted Traffic Out-of-Distribution Instruction Tuning with LLM (ETooL), which integrates LLMs with knowledge of traffic structures through a self-supervised instruction tuning paradigm. This framework establishes connections between textual information and traffic interactions. ETooL demonstrates more robust classification performance and superior generalization in both supervised and zero-shot traffic classification tasks. Notably, it achieves significant improvements in F1 scores: APP53 (I.I.D.) to 93.19%(6.62% $\uparrow $ ) and 92.11%(4.19% $\uparrow $ ), APP53 (O.O.D.) to 74.88%(18.17% $\uparrow $ ) and 72.13%(15.15% $\uparrow $ ), and ISCX-Botnet (O.O.D.) to 95.03%(9.16% $\uparrow $ ) and 81.95%(12.08% $\uparrow $ ). Additionally, we construct NETD, a traffic dataset designed to support dynamic distributional shifts, and use it to validate ETooL’s effectiveness under varying distributional conditions. Furthermore, we evaluate the efficiency gains achieved through ETooL’s instruction tuning approach.","1556-6021","","10.1109/TIFS.2025.3574971","National Key Research and Development Program of China(grant numbers:2022YFB2702404); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018090","Encrypted traffic classification;network security;out-of-distribution generalization;large language models","Cryptography;Tuning;Feature extraction;Training;Adaptation models;Telecommunication traffic;Large language models;Distributed databases;Testing;Malware","","","","50","IEEE","29 May 2025","","","IEEE","IEEE Journals"
"LLM Agentic Workflow for Automated Vulnerability Detection and Remediation in Infrastructure-as-Code","D. Toprani; V. K. Madisetti","College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; School of Cybersecurity and Privacy, Georgia Institute of Technology, Atlanta, GA, USA",IEEE Access,"25 Apr 2025","2025","13","","69175","69181","This paper presents a multi-agent, AI-driven strategy employing Large Language Models (LLMs), retrieval-augmented generation, and a continuously updated knowledge base for the detection and remediation of security vulnerabilities win cloud frameworks. By examining Infrastructure as Code (IaC) templates alongside pertinent best-practice snippets, the system discerns context-specific misconfigurations commonly overlooked by static tools, achieving a detection rate of 85% with some occurrences of false positives. Automated remediation guidance, anchored in current security standards, provides actionable solutions that seamlessly integrate into standard continuous integration/continuous development (CI/CD) workflows. Experimental results indicate the solution’s efficacy and scalability, heralding a proactive, context-aware approach to IaC security.","2169-3536","","10.1109/ACCESS.2025.3560911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10965635","Infrastructure-as-code;large language models;vulnerability detection;security automation;CI/CD;LLM workflows","Security;Retrieval augmented generation;Static analysis;Runtime;Best practices;Vectors;Scalability;Large language models;Cognition;Organizations","","","","11","CCBY","15 Apr 2025","","","IEEE","IEEE Journals"
"Optimizing Endotracheal Suctioning Classification: Leveraging Prompt Engineering in Machine Learning for Feature Selection","M. R. Islam; A. M. Ferdous; S. Hossain; M. A. Rahman Ahad; F. Alnajjar","Dept. of Electrical and Electronic Engineering, University of Dhaka, Dhaka, Bangladesh; Dept. of Electrical and Electronic Engineering, University of Dhaka, Dhaka, Bangladesh; Dept. of Computer Science and Digital Technologies, University of East London, London, UK; Dept. of Computer Science and Digital Technologies, University of East London, London, UK; Dept. of Computer Science and Software Engineering, College of Information Technology, UAE University, Al Ain, UAE",2024 International Conference on Activity and Behavior Computing (ABC),"3 Sep 2024","2024","","","1","8","In a world with an overgrowing elderly population, there exists a critical need for a greater number of skilled individuals in the nursing industry. AI-based systems can be useful, compared to traditional ones with require in-person assistance, to accurately identify nursing activities and assess the nursing trainees to help them become proficient. This paper addresses classifying activities in one such procedure, endotracheal suctioning, using skeletal keypoint data of the subject performing the procedure. A multi-step structured prompt engineering method was established and utilized on several LLMs to select or calculate key features from the data. Then the features are passed onto several tuned machine learning models to obtain results. A tuned XGBoost prevailed across all models, achieving 90% accuracy on the validation set.","","979-8-3503-7550-3","10.1109/ABC61795.2024.10652117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10652117","Human Activity Recognition;Large Language Model;Generative AI;Machine learning;Nurse-care","Training;Accuracy;Computational modeling;Machine learning;Medical services;Predictive models;Feature extraction","","","","27","IEEE","3 Sep 2024","","","IEEE","IEEE Conferences"
"Data-Centric Fine-Tuning of Small Language Models for Automatic Extraction of Technical Requirements","L. Müller; N. Schwarz; L. Böcking; A. Bereczuk; H. Stagge; W. Kratsch; N. Kühl","Information Systems and Human-Centric Artificial Intelligence, University of Bayreuth, Bayreuth, Germany; Fraunhofer FIT, Bayreuth, Germany; Information Systems and Human-Centric Artificial Intelligence, University of Bayreuth, Bayreuth, Germany; TenneT TSO GmbH, Bayreuth, Germany; TenneT TSO GmbH, Bayreuth, Germany; Fraunhofer FIT, Bayreuth, Germany; Information Systems and Human-Centric Artificial Intelligence, University of Bayreuth, Bayreuth, Germany",IEEE Access,"4 Aug 2025","2025","13","","135301","135315","Training small language models for specific tasks often encounters a significant challenge: the limited availability of high-quality labeled data, which can restrict model performance. This constraint is especially critical in organizations handling sensitive data, where large language models cannot be readily deployed due to privacy concerns, high costs, and dependency on external providers. While existing research demonstrates the effectiveness of large language models in automating text-based tasks, there is a lack of methods tailored to fine-tuning small language models for secure, domain-specific applications with minimal labeled data. To address this gap, we introduce a data-centric fine-tuning method that systematically enhances training data through prompt engineering, making small language model fine-tuning feasible and effective in data-constrained environments. This study evaluates the proposed method on a real-world use case with an industry partner, focusing on the automatic extraction of technical requirements from full-text documents and using both quantitative metrics and qualitative expert assessments. Our findings reveal that the fine-tuned small language model achieves accuracy and consistency comparable to human service providers, while outperforming baseline models, including GPT-4-turbo, on key evaluation metrics. These results underscore the potential of data-centric fine-tuning for adapting small language models to high-stakes, privacy-sensitive tasks, offering a scalable alternative to LLMs enabling their applications to real-world use cases.","2169-3536","","10.1109/ACCESS.2025.3591739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088115","Data-centric AI;fine-tuning;large language models;requirement extraction","Data models;Prompt engineering;Technical requirements;Training data;Training;Industries;Tuning;Large language models;Labeling;Standards","","","","49","CCBYNCND","22 Jul 2025","","","IEEE","IEEE Journals"
"FinRL Contest 2025 Task 1:Market-Aware In-Context Learning Framework for Proximal Policy Optimization in Stock Trading Using DeepSeek","S. Arshad; H. Ameer; N. Azhar; S. Latif","School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan",2025 IEEE 11th International Conference on Intelligent Data and Security (IDS),"19 Jun 2025","2025","","","76","78","This paper introduces a Market-Cap Stratified Subset (MCSS) strategy. It constructs a balanced, high-quality dataset from the Financial News and Stock Price Integration Dataset (FNSPID). Building on MCSS, we propose Market-Informed Sentiment for Trading (MIST). This is a two-phase framework that first generates sentiment scores through optimized prompt engineering with LLMs, then aligns market movements to deliver actionable trading signals. With a Proximal Policy Optimization (PPO)-based agent, MIST achieves better policy stability and learning efficiency than baseline methods.","","979-8-3315-9661-3","10.1109/IDS66066.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11038765","Reinforcement Learning;FinRL;Large Language Models;Automated Stock Trading;Deepseek","Large language models;Buildings;Reinforcement learning;Stability analysis;Security;Prompt engineering;Optimization","","","","5","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Out of Context: How Important is Local Context in Neural Program Repair?","J. A. Prenner; R. Robbes","Free University of Bozen/Bolzano, Bozen/Bolzano, Italy; CNRS, Univ. Bordeaux, Bordeaux INP, LaBRI, Talence, France",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1008","1020","Deep learning source code models have been applied very successfully to the problem of automated program repair. One of the standing issues is the small input window of current models which often cannot fully fit the context code required for a bug fix (e.g., method or class declarations of a project). Instead, input is often restricted to the local context, that is, the lines below and above the bug location. In this work we study the importance of this local context on repair success: how much local context is needed?; is context before or after the bug location more important? how is local context tied to the bug type? To answer these questions we train and evaluate Transformer models in many different local context configurations on three datasets and two programming languages. Our results indicate that overall repair success increases with the size of the local context (albeit not for all bug types) and confirm the common practice that roughly 50-60% of the input window should be used for context leading the bug. Our results are not only relevant for researchers working on Transformer-based APR tools but also for benchmark and dataset creators who must decide what and how much context to include in their datasets.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549171","automated program repair;data-driven software engineering","Training;Deep learning;Computer languages;Source coding;Computer bugs;Maintenance engineering;Transformers","","4","","49","","14 Jun 2024","","","IEEE","IEEE Conferences"
"LogiCode: An LLM-Driven Framework for Logical Anomaly Detection","Y. Zhang; Y. Cao; X. Xu; W. Shen","State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; Michigan Robotics, University of Michigan, Ann Arbor, MI, USA; State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Automation Science and Engineering,"21 Mar 2025","2025","22","","7712","7723","This paper presents LogiCode, a novel framework that leverages Large Language Models (LLMs) for identifying logical anomalies in industrial settings, moving beyond the traditional focus on structural inconsistencies. By harnessing LLMs for logical reasoning, LogiCode autonomously generates Python codes to pinpoint anomalies such as incorrect component quantities or missing elements, marking a significant leap forward in anomaly detection technologies. A custom dataset “LOCO-Annotations” and a benchmark “LogiBench” are introduced to evaluate the LogiCode’s performance across various metrics including binary classification accuracy, code generation success rate, and precision in reasoning. Findings demonstrate LogiCode’s enhanced interpretability, significantly improving the accuracy of logical anomaly detection and offering detailed explanations for identified anomalies. This represents a notable shift towards more intelligent, LLM-driven approaches in industrial anomaly detection, promising substantial impacts on industry-specific applications. Our code are available at https://github.com/22strongestme/LOCO-Annotations. Note to Practitioners—This work introduces LogiCode, an innovative system leveraging Large Language Models (LLMs) for logical anomaly detection in industrial settings, shifting the paradigm from traditional visual inspection methods. LogiCode autonomously generates Python codes for logical anomaly detection, enhancing interpretability and accuracy. Our novel approach, validated through the “LOCO-Annotations” dataset and LogiBench benchmark, demonstrates superior performance in identifying logical anomalies, a challenge often encountered in complex industrial components like assembly and packaging. LogiCode provides a significant advancement in addressing the nuanced requirements of detecting logical anomalies, offering a robust and interpretable solution to practitioners seeking to enhance quality control and reduce manual inspection efforts.","1558-3783","","10.1109/TASE.2024.3468464","Ministry of Industry and Information Technology, China(grant numbers:2023ZY01089); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710633","Logical anomaly detection;large language models;industrial anomaly detection;dataset annotation","Anomaly detection;Codes;Cognition;Visualization;Semantics;Logic;Image reconstruction;Automation;Accuracy;Benchmark testing","","5","","39","IEEE","9 Oct 2024","","","IEEE","IEEE Journals"
"Evaluation and Comparison of Agent-Oriented Methodologies: A Software Engineering Viewpoint","K. Slhoub; M. Carvalho; F. Nembhard","College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA; College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA; College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA",2019 IEEE International Systems Conference (SysCon),"16 Sep 2019","2019","","","1","8","Numerous agent-oriented methodologies that offer a rich pool of resources to support developers of agent-based systems have been proposed. However, the use of existing methodologies in industrial settings is still limited due to the large volume of methodologies, diversity of covered scopes, ambiguity in concepts, and lack of maturity. This makes it difficult for agent technology practitioners to choose the appropriate methodology that best fits their given development context. To eliminate such agent-based development bottleneck, it is important to introduce suitable methods for evaluating, comparing, and classifying agent-oriented methodologies in order to leverage their usage among practitioners. Having systems to evaluate methodologies can effectively help developers better understand existing methodologies, realize their benefits, outline their pros and cons, and assist practitioners with selecting the best-fit methodology for a specific agent-based project. In response, this paper proposes a novel criteria-based evaluation that is influenced by software engineering practices to assess and compare agentoriented methodologies. The proposed evaluation is derived from the software engineering body of knowledge (SWEBOK) and provides a simplified method to assess the coverage degree of an agent-oriented methodology with respect to major software knowledge areas such as the requirements and testing phases. We demonstrate the applicability of the proposed evaluation by applying it to three agent-oriented methodologies (PASSI, MaSE, and Prometheus) in the software engineering requirements and testing phases.","2472-9647","978-1-5386-8396-5","10.1109/SYSCON.2019.8836962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836962","Agent-Oriented Methodologies;AgentOriented Software Engineering;Multi-Agent Systems;Software Requirements;Software Testing;SWEBOK;AOSE","Software engineering;Software;Knowledge engineering;Software testing;Tools;Diversity methods","","3","","39","IEEE","16 Sep 2019","","","IEEE","IEEE Conferences"
"Vulnerability prediction using pre-trained models: An empirical evaluation","I. Kalouptsoglou; M. Siavvas; A. Ampatzoglou; D. Kehagias; A. Chatzigeorgiou","Centre for Research and Technology Hellas, Information Technologies Institute, Thessaloniki, Greece; Centre for Research and Technology Hellas, Information Technologies Institute, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Centre for Research and Technology Hellas, Information Technologies Institute, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece","2024 32nd International Conference on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS)","13 Dec 2024","2024","","","1","6","The rise of Large Language Models (LLMs) has provided new directions for addressing downstream text classification tasks, such as vulnerability prediction, where segments of the source code are classified as vulnerable or not. Several recent studies have employed transfer learning in order to enhance vulnerability prediction taking advantage of the prior knowledge of the pre-trained LLMs. In the current study, different Transformer-based pre-trained LLMs are examined and evaluated with respect to their capacity to predict vulnerable software components. In particular, we fine-tune BERT, GPT-2, and T5 models, as well as their code-oriented variants namely CodeBERT, CodeGPT, and CodeT5 respectively. Subsequently, we assess their performance and we conduct an empirical comparison between them to identify the models that are the most accurate ones in vulnerability prediction.","2375-0227","979-8-3315-3130-0","10.1109/MASCOTS64422.2024.10786510","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786510","Software security;Vulnerability prediction;Transfer learning;Large language models;Transformer","Text mining;Analytical models;Computational modeling;Source coding;Natural languages;Transfer learning;Bidirectional control;Predictive models;Transformers;Software","","2","","37","IEEE","13 Dec 2024","","","IEEE","IEEE Conferences"
"ChatGPT for Cybersecurity Cookbook: Learn practical generative AI recipes to supercharge your cybersecurity skills","C. Bodungen; A. Crow",NA; NA,ChatGPT for Cybersecurity Cookbook: Learn practical generative AI recipes to supercharge your cybersecurity skills,"","2024","","","","","Master ChatGPT and the OpenAI API and harness the power of cutting-edge generative AI and large language models to revolutionize the way you perform penetration testing, threat detection, and risk assessment.Key FeaturesEnhance your skills by leveraging ChatGPT to generate complex commands, write code, and create toolsAutomate penetration testing, risk assessment, and threat detection tasks using the OpenAI API and Python programmingRevolutionize your approach to cybersecurity with an AI-powered toolkitPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAre you ready to unleash the potential of AI-driven cybersecurity? This cookbook takes you on a journey toward enhancing your cybersecurity skills, whether you’re a novice or a seasoned professional. By leveraging cutting-edge generative AI and large language models such as ChatGPT, you'll gain a competitive advantage in the ever-evolving cybersecurity landscape. ChatGPT for Cybersecurity Cookbook shows you how to automate and optimize various cybersecurity tasks, including penetration testing, vulnerability assessments, risk assessment, and threat detection. Each recipe demonstrates step by step how to utilize ChatGPT and the OpenAI API to generate complex commands, write code, and even create complete tools. You’ll discover how AI-powered cybersecurity can revolutionize your approach to security, providing you with new strategies and techniques for tackling challenges. As you progress, you’ll dive into detailed recipes covering attack vector automation, vulnerability scanning, GPT-assisted code analysis, and more. By learning to harness the power of generative AI, you'll not only expand your skillset but also increase your efficiency. By the end of this cybersecurity book, you’ll have the confidence and knowledge you need to stay ahead of the curve, mastering the latest generative AI tools and techniques in cybersecurity.What you will learnMaster ChatGPT prompt engineering for complex cybersecurity tasksUse the OpenAI API to enhance and automate penetration testingImplement artificial intelligence-driven vulnerability assessments and risk analysesAutomate threat detection with the OpenAI APIDevelop custom AI-enhanced cybersecurity tools and scriptsPerform AI-powered cybersecurity training and exercisesOptimize cybersecurity workflows using generative AI-powered techniquesWho this book is forThis book is for cybersecurity professionals, IT experts, and enthusiasts looking to harness the power of ChatGPT and the OpenAI API in their cybersecurity operations. Whether you're a red teamer, blue teamer, or security researcher, this book will help you revolutionize your approach to cybersecurity with generative AI-powered techniques. A basic understanding of cybersecurity concepts along with familiarity in Python programming is expected. Experience with command-line tools and basic knowledge of networking concepts and web technologies is also required.","","9781805125112","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10522553.pdf&bkn=10522552&pdfType=book","","","","","","","","8 May 2024","","","Packt Publishing","Packt Publishing eBooks"
"Securing Substations with Trust, Risk Posture, and Multi-Agent Systems: A Comprehensive Approach","K. Boakye-Boateng; A. A. Ghorbani; A. H. Lashkari","Canadian Institute for Cybersecurity (CIC), University of New Brunswick (UNB), Fredericton, NB, Canada; Canadian Institute for Cybersecurity (CIC), University of New Brunswick (UNB), Fredericton, NB, Canada; Canadian Institute for Cybersecurity (CIC), University of New Brunswick (UNB), Fredericton, NB, Canada","2023 20th Annual International Conference on Privacy, Security and Trust (PST)","22 Nov 2023","2023","","","1","12","The Smart Grid is an IT-integrated power grid that generates, transmits, and distributes electricity to households and businesses. The substation is a crucial element of the Smart Grid’s operation, which adjusts voltages during the entire process. The integration of IT has increased in the substation’s attack surfaces. Sophisticated attacks such as the Pipeline APT contain multi-protocol modules for various devices. Performance constraints make substations a unique case; hence it is challenging to implement encryption and intrusion detection systems. We believe trust can tackle this problem. We present an improved trust model that detects protocol-based attacks toward an IED/SCADA HMI. This model is included within a multi-agent-based trust management system that computes the substation’s risk posture. Our proposed design was implemented in a Docker-based testbed environment with a SOC-influenced dashboard to provide real-time updates. The implementation was subjected to three attack scenarios: external attack, internal attack from compromised SCADA HMI, and internal attack from a compromised non-trusted IED. We observed that our model was robust against all attacks except for the baseline replay and delay response attacks. Detecting these attacks will be considered for future work as well as trust transferability. Our institute’s website provides a publicly available dataset containing captures of our MAS testbed.","2643-4202","979-8-3503-1387-1","10.1109/PST58708.2023.10320154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10320154","substation;trust;risk posture;smart grid;cybersecurity;Modbus;substation security;critical infrastructure protection;operational technology","Performance evaluation;Privacy;Substations;Computational modeling;Pipelines;Real-time systems;Smart grids","","11","","26","IEEE","22 Nov 2023","","","IEEE","IEEE Conferences"
"Test Suite Optimization Using Machine Learning Techniques: A Comprehensive Study","A. Mehmood; Q. M. Ilyas; M. Ahmad; Z. Shi","Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; Department of Information Systems, College of Computer Sciences and Information Technology, King Faisal University, Al Ahsa, Saudi Arabia; Department of Computer Science, University of Roehampton, London, U.K.; School of Software Engineering, Jiangxi University of Software Professional Technology, Nanchang, Jiangxi, China",IEEE Access,"19 Nov 2024","2024","12","","168645","168671","Software testing is an essential yet costly phase of the software development lifecycle. While machine learning-based test suite optimization techniques have shown promise in reducing testing costs and improving fault detection, a comprehensive evaluation of their effectiveness across different environments is still lacking. This paper reviews 43 studies published between 2018 and 2023, covering various test case selection, prioritization, and reduction techniques using machine learning. The findings reveal that conventional machine learning techniques, particularly supervised learning methods, have been widely adopted for test case prioritization and selection. Recent advancements, such as deep learning and hybrid models, show potential in improving fault detection rates and scalability, though challenges remain in adapting these techniques to large-scale and dynamic environments. Additionally, Generative AI and large language models (LLMs) are emerging as promising tools for automating aspects of test case generation and prioritization, offering new avenues for future research in enhancing test suite optimization. The study identifies recent trends, challenges, and opportunities for further research, with a focus on both conventional and emerging methods, including deep learning, hybrid approaches, and Generative AI models. By systematically analyzing these techniques, this work contributes to the understanding of how machine learning and Generative AI can enhance test suite optimization and highlights future directions for improving the scalability and real-world applicability of these methods.","2169-3536","","10.1109/ACCESS.2024.3490453","Dakota State University, USA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741285","Software quality;software testing;test suite optimization (TSO);machine learning in software testing;test case selection;evaluation metrics for test suite optimization","Optimization;Software testing;Testing;Software quality;Systematics;Deep learning;Reinforcement learning;Market research;Generative AI;Costs;Machine learning","","3","","63","CCBYNCND","1 Nov 2024","","","IEEE","IEEE Journals"
"A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression","Y. Zhu; Z. -Y. Khoo; J. S. Choong Low; S. Bressan","School of Computing, National University of Singapore, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore; Agency for Science, Technology and Research (ASTAR), Singapore Institute of Manufacturing Technology, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore",2024 IEEE Conference on Artificial Intelligence (CAI),"30 Jul 2024","2024","","","38","43","Interleaved practice enhances the memory and problem-solving ability of students in undergraduate courses. We introduce a personalized learning tool built on a Large Language Model (LLM) that can provide immediate and personalized attention to students as they complete homework containing problems interleaved from undergraduate physics courses. Our tool leverages the dimensional analysis method, enhancing students’ qualitative thinking and problem-solving skills for complex phenomena. Our approach combines LLMs for symbolic regression with dimensional analysis via prompt engineering and offers students a unique perspective to comprehend relationships between physics variables. This fosters a broader and more versatile understanding of physics and mathematical principles and complements a conventional undergraduate physics education that relies on interpreting and applying established equations within specific contexts. We test our personalized learning tool on the equations from Feynman’s lectures on physics. Our tool can correctly identify relationships between physics variables for most equations, underscoring its value as a complementary personalized learning tool for undergraduate physics students.","","979-8-3503-5409-6","10.1109/CAI59869.2024.00017","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605241","AI and Education;Symbolic Regression;Large Language Models;Physics Education;Prompt Engineering;Undergraduate Learning","Knowledge engineering;Systematics;Large language models;Learning (artificial intelligence);Mathematical models;Physics education;Problem-solving","","1","","43","IEEE","30 Jul 2024","","","IEEE","IEEE Conferences"
"LLM-Based Automated Generation and Tri-modal Representation of Cyber Attack Scenario","S. Roh; T. -S. Kim","Department of Convergence Security, Chungbuk National University, Cheongju, Chungbuk, Republic of Korea; Department of Management Information Systems and Cybersecurity Economics Research Institute, Chungbuk National University, Cheongju, Chungbuk, Republic of Korea",IEEE Access,"","2025","PP","99","1","1","The rapid advancement of information technology, the proliferation of artificial intelligence (AI), and the increasing reliance on digital infrastructure have significantly intensified cyber threats faced by organizations. In this evolving landscape, timely identification of threats and coordinated strategic responses have become essential. However, traditional human-centric approaches to cyber-attack scenario generation are limited in scalability, timeliness, and semantic coherence—especially across stakeholders with diverse technical backgrounds. To address these challenges, this study proposes an automated, LLM-driven framework for generating cyber-attack scenarios and converting them into three semantically aligned modalities: natural language narratives, attack graphs, and formal mathematical representations. This tri-modal approach enhances cross-role interpretability and enables consistent understanding among technical experts and non-technical decision-makers alike. The core objective of this research is to propose an automated pipeline framework that spans from scenario generation to tri-modal representation, designed to support decision-makers by ensuring semantic consistency and enhancing interpretability across stakeholder roles. The framework incorporates real-world threat intelligence, structured input parameters, and prompt engineering techniques to ensure realism and fidelity. Evaluation results using state-of-the-art LLMs—including both open-source and proprietary models—demonstrate the system’s ability to generate coherent, context-aware, and logically consistent outputs. The findings validate the feasibility of the proposed approach and underscore its potential to improve cybersecurity preparedness, training efficacy, and governance communication through structured, intelligible scenario representations.","2169-3536","","10.1109/ACCESS.2025.3597850","Information & communications Technology Planning(grant numbers:RS-2024-00438796); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11122442","attack scenario;cybersecurity;Large Language Models;prompt engineering;tri-modal representation","Cyberattack;Training;Organizations;Scenario generation;Semantics;Manuals;Stakeholders;Scalability;Risk management;Data breach","","","","","CCBY","11 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Generative AI Based Secure Wireless Sensing for ISAC Networks","J. Wang; H. Du; Y. Liu; G. Sun; D. Niyato; S. Mao; D. In Kim; X. Shen","College of Computing and Data Science, Nanyang Technological University, 50 Nanyang Ave, Singapore; Department of Electrical and Electronic Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong; College of Computing and Data Science, Nanyang Technological University, 50 Nanyang Ave, Singapore; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computing and Data Science, Nanyang Technological University, 50 Nanyang Ave, Singapore; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Information Forensics and Security,"12 Jun 2025","2025","20","","5195","5210","Integrated sensing and communications (ISAC) is one of the crucial technologies for 6G, and channel state information (CSI) based sensing serves as an essential part of ISAC. However, current research on ISAC focuses mainly on improving sensing performance, overlooking security issues, particularly the unauthorized sensing of users. Hence, this paper proposes a diffusion model based secure sensing system (DFSS). Specifically, we first propose a discrete conditional diffusion model to generate graphs with nodes and edges, which guides the ISAC system to appropriately activate wireless links and nodes, ensuring the sensing performance while minimizing the operation cost. Using the activated links and nodes, DFSS then employs the continuous conditional diffusion model to generate safeguarding signals, which are next modulated onto the pilot at the transmitter to mask fluctuations caused by user activities. As such, only authorized ISAC devices with the safeguarding signals can extract the true CSI for sensing, while unauthorized devices are unable to perform the effective sensing. Experiment results demonstrate that DFSS can reduce the activity recognition accuracy of the unauthorized devices by approximately 70%, effectively shield the user from the illegitimate surveillance.","1556-6021","","10.1109/TIFS.2025.3570202","National Research Foundation, Singapore and Infocomm Media Development Authority under its Future Communications Research and Development Program(grant numbers:FCP-NTU-RG-2022-010,FCP-ASTAR-TG-2022-003); Singapore Ministry of Education (MOE) Tier 1(grant numbers:RG87/22,RG24/24); Nanyang Technological University (NTU) Centre for Computational Technologies in Finance (NTU-CCTF); RIE2025 Industry Alignment Fund–Industry Collaboration Projects (IAF-ICP), administered by Agency for Science, Technology and Research (A*STAR)(grant numbers:I2301E0026); Alibaba Group and NTU Singapore through Alibaba-NTU Global e-Sustainability CorpLab (ANGEL); National Research Foundation of Korea (NRF); Korean Government [Ministry of Science and ICT (MSIT)](grant numbers:2021R1A2C2007638); National Natural Science Foundation of China(grant numbers:62272194,62471200); NSF(grant numbers:CCSS-2434053,CNS-2107190); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004012","Generative AI;integrated sensing and communication;wireless sensing security","Sensors;Wireless communication;Diffusion models;Wireless sensor networks;Communication system security;Performance evaluation;Security;Integrated sensing and communication;Fluctuations;Accuracy","","10","","50","IEEE","14 May 2025","","","IEEE","IEEE Journals"
"ChatGPT for Robotics: Design Principles and Model Abilities","S. H. Vemprala; R. Bonatti; A. Bucker; A. Kapoor","Scaled Foundations, Kirkland, WA, USA; Microsoft Corporation, Redmond, WA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Scaled Foundations, Kirkland, WA, USA",IEEE Access,"23 Apr 2024","2024","12","","55682","55696","This paper presents an experimental study regarding the use of OpenAI’s ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT’s ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics. Videos and blog: aka.ms/ChatGPT-Robotics PromptCraft, AirSim-ChatGPT code: https://github.com/microsoft/PromptCraft-Robotics","2169-3536","","10.1109/ACCESS.2024.3387941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10500490","Large language models;robotics;language understanding;code generation;perception","Robots;Chatbots;Task analysis;Codes;Cognition;Large language models;Open systems;Artificial intelligence","","132","","44","CCBY","15 Apr 2024","","","IEEE","IEEE Journals"
"Describing advanced persistent threats using a multi-agent system approach","S. T. Bulusu; R. Laborde; A. S. Wazan; F. Barrère; A. Benzekri","IRIT / Université Paul Sabatier 118 Route de Narbonne, Toulouse, France; IRIT / Université Paul Sabatier 118 Route de Narbonne, Toulouse, France; IRIT / Université Paul Sabatier 118 Route de Narbonne, Toulouse, France; IRIT / Université Paul Sabatier 118 Route de Narbonne, Toulouse, France; IRIT / Université Paul Sabatier 118 Route de Narbonne, Toulouse, France",2017 1st Cyber Security in Networking Conference (CSNet),"1 Jan 2018","2017","","","1","3","Advanced Persistent Threats are increasingly becoming one of the major concerns to many industries and organizations. Currently, there exists numerous articles and industrial reports describing various case studies of recent notable Advanced Persistent Threat attacks. However, these documents are expressed in natural language. This limits the efficient reusability of the threat intelligence information due to ambiguous nature of the natural language. In this article, we propose a model to formally represent Advanced Persistent Threats as multi-agent systems. Our model is inspired by the concepts of agent-oriented social modelling approaches, generally used for software security requirement analysis.","","978-1-5386-1332-0","10.1109/CSNET.2017.8241997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241997","Attack trees;Advanced Persistent Threats;multi-agent systems","Security;Analytical models;Malware;Lead;Servers;Multi-agent systems;Organizations","","3","","5","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"An Evaluation of Transformer Models for Early Intrusion Detection in Cloud Continuum","M. M. Islam; T. Ahmad; D. Truscan","Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland; Åbo Akademi University, Turku, Finland",2023 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),"25 Mar 2024","2023","","","279","284","With the increasing popularity of the cloud continuum, the security of different layers and nodes involved has become more relevant than ever. Intrusion detection systems, are one of the main tools to identify and intercept intrusion attacks. Furthermore, identifying the attacks in time, before they are completed, is necessary in order to deploy countermeasures in time and to limit the losses. In this work, we evaluate the use of transformer models for implementing early-detection signature-based detection systems targeted at Cloud Continuum. We implement the approach in the context of our tool for early detection of network intrusions and we evaluate it using the CICIDS2017 dataset and MQTT-IDS-2020. The results show that transformer models are a viable alternative for early-detection systems and this will pave the road for further research on the topic.","2380-8004","979-8-3503-3982-6","10.1109/CloudCom59040.2023.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475796","Intrusion detection systems;monitoring;deep learning;transformer-architecture","Computers;Cloud computing;Roads;Computational modeling;Intrusion detection;Computer architecture;Transformers","","2","","19","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"Optimal Allocation of Cloud Service Resources Using Multi-agent Technologies","T. N. Yelina; V. A. Mylnikov; S. V. Bezzateev","Saint-Petersburg State University of Aerospace Instrumentation, St. Petersburg, Russia; Saint-Petersburg State University of Aerospace Instrumentation, St. Petersburg, Russia; Saint-Petersburg State University of Aerospace Instrumentation, St. Petersburg, Russia",2020 Wave Electronics and its Application in Information and Telecommunication Systems (WECONF),"2 Jul 2020","2020","","","1","4","Optimal allocation of computing systems resources is an important task in the context of constantly growing needs and limited financial capabilities of users. Cloud technologies help reduce the cost of information processing and storing while keeping in mind the requirements in security and reliability. The multi-agent systems usage allows to correctly transfer the decision-making functions for a specific case from the upper level of system control to the lower levels of executive processes. This approach allows increasing the control flexibility and improving the speed of decision-making.","","978-1-7281-4944-8","10.1109/WECONF48837.2020.9131519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131519","modeling;heterogeneous data processing systems;multi-agent systems","Costs;Decision making;Process control;Control systems;Telecommunications;Resource management;Security","","1","","6","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"Agent Technology for Data Analytics of Gene Expression Data: A Literature Review","K. Santhosh; S. Ajitha","Department of Computer Science, JSS College for Women, Mysuru, Karnataka, india; Department of MCA, Ramaiah Institute of Technology, Bangalore, Karnataka, India",2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC),"23 Apr 2020","2020","","","1013","1017","Analytics of gene expression data is the prolonged research area of present situation. Analysis of gene expression data requires enormous amount of work and huge set of algorithms. Using agent computing we deal with complex systems which are discovered many opportunities for developing data mining systems in a different ways. Hence to create predictive models, there is a huge need for intelligent and autonomous software agents which can procure useful information from the large datasets of raw information. Predictive analytics models can be created from these datasets which can be further used for various applications in security, future prediction etc. This research paper gives an overall function of multi agent systems in analytics of gene expression data, in terms of characteristics, adaptability, reliability and robotics of agents. Analytics on gene expression data is one of the emerging research fields. A large set of methodology and algorithms are existing in the field but in the application of agent technology in the field of gene expression data is at the infant stage. So the aim of this review paper is to integrate agent technology in the gene expression data analytics.","","978-1-7281-4889-2","10.1109/ICCMC48092.2020.ICCMC-000189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076482","Agents;Multi-agent Systems;gene expression data;analytics;knowledge management","Data analysis;Software algorithms;Predictive models;Prediction algorithms;Software agents;Gene expression;Security","","","","19","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"SecureFalcon: Are We There Yet in Automated Software Vulnerability Detection With LLMs?","M. A. Ferrag; A. Battah; N. Tihanyi; R. Jain; D. Maimuţ; F. Alwahedi; T. Lestable; N. S. Thandi; A. Mechri; M. Debbah; L. C. Cordeiro","Guelma University, Guelma, Algeria; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; University of Manchester, Manchester, U.K.",IEEE Transactions on Software Engineering,"17 Apr 2025","2025","51","4","1248","1265","Software vulnerabilities can cause numerous problems, including crashes, data loss, and security breaches. These issues greatly compromise quality and can negatively impact the market adoption of software applications and systems. Traditional bug-fixing methods, such as static analysis, often produce false positives. While bounded model checking, a form of Formal Verification (FV), can provide more accurate outcomes compared to static analyzers, it demands substantial resources and significantly hinders developer productivity. Can Machine Learning (ML) achieve accuracy comparable to FV methods and be used in popular instant code completion frameworks in near real-time? In this paper, we introduce SecureFalcon, an innovative model architecture with only 121 million parameters derived from the Falcon-40B model and explicitly tailored for classifying software vulnerabilities. To achieve the best performance, we trained our model using two datasets, namely the FormAI dataset and the FalconVulnDB. The FalconVulnDB is a combination of recent public datasets, namely the SySeVR framework, Draper VDISC, Bigvul, Diversevul, SARD Juliet, and ReVeal datasets. These datasets contain the top 25 most dangerous software weaknesses, such as CWE-119, CWE-120, CWE-476, CWE-122, CWE-190, CWE-121, CWE-78, CWE-787, CWE-20, and CWE-762. SecureFalcon achieves 94% accuracy in binary classification and up to 92% in multiclassification, with instant CPU inference times. It outperforms existing models such as BERT, RoBERTa, CodeBERT, and traditional ML algorithms, promising to push the boundaries of software vulnerability detection and instant code completion frameworks.","1939-3520","","10.1109/TSE.2025.3548168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910240","FalconLLM;large language model;software security;security;generative pre-trained transformers","Codes;Software;Accuracy;Security;Training;Formal verification;Real-time systems;Model checking;Software reliability;Software development management","","5","","64","IEEE","5 Mar 2025","","","IEEE","IEEE Journals"
"An Adaptive Intelligent Tutoring System Powered by Generative AI","H. Almetnawy; A. Orabi; A. R. Alneyadi; T. Ahmed; A. Lakas","College of Information Technology, UAE University, Al Ain, United Arab Emirates; College of Information Technology, UAE University, Al Ain, United Arab Emirates; College of Information Technology, UAE University, Al Ain, United Arab Emirates; College of Information Technology, UAE University, Al Ain, United Arab Emirates; College of Information Technology, UAE University, Al Ain, United Arab Emirates",2025 IEEE Global Engineering Education Conference (EDUCON),"3 Jun 2025","2025","","","1","10","The emerging technology of Generative AI (GenAI) and its applications in various fields have opened new possibilities for educational technology, particularly in the development of advanced Intelligent Tutoring Systems (ITSs) as there is an increasing need for systems that can provide personalized learning experiences. Despite significant advancements in the development of ITSs, many proposed solutions struggle to effectively adapt to diverse learner profiles, creating barriers to personalized and adaptive learning experiences. This paper explores the transformative potential of GenAI in developing ITSs and proposes a novel ITS powered by a Generative Pre-trained Transformer (GPT), which leverages advanced Large Language Models (LLMs) to deliver contextually relevant tutoring sessions tailored to individual learning styles and proficiency levels. Key aspects of the methodology used in this study is prompt engineering and Multi-Agent Systems (MAS). This approach involves crafting specific prompts that elicit tailored responses, enhancing the overall learning experience. To maintain student engagement and motivation, the system incorporates educational techniques such as gamification, interactive simulations, and adaptive feedback mechanisms. Furthermore, the ITS is designed to recognize cues for fatigue and distraction by analyzing patterns in student interactions, such as response times and engagement levels. The effectiveness of the system is validated through extensive testing with AI-simulated students of varying proficiency levels, providing valuable data for refining prompts and improving personalization. Overall, the paper demonstrates how integrating GenAI technology can create more efficient and flexible educational environments, addressing the diverse needs of learners and redefining the landscape of personalized education.","2165-9567","979-8-3315-3949-8","10.1109/EDUCON62633.2025.11016362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016362","GPT;Intelligent Tutoring System;Large Language Model","Adaptation models;Adaptive learning;Scalability;Refining;Educational technology;Transformers;Trajectory;Time factors;Testing;Strain","","","","28","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Drone Security in Connected Agriculture: Threats, Datasets, and AI-Driven Solutions","A. Charfi; S. Ayed; L. Chaari","University of Technology of Troyes LIST3N, Troyes, France; University of Technology of Troyes LIST3N, Troyes, France; CRNS-SM@RTS (Laboratory of Signals, systeMs, aRtificial Intelligence and neTworkS), Sfax, Tunisia","2025 12th IFIP International Conference on New Technologies, Mobility and Security (NTMS)","18 Jul 2025","2025","","","26","33","This positioning paper analyzes the security vulnerabilities in drone-based agricultural systems through the lens of threats, datasets, and AI-based solutions. The commercial drone industry, expected to expand from a value of ${\$}$38.25 billion in 2023 to ${\$}$244.95 billion in 2032 [7], makes the need for security increasingly pressing. We make four primary contributions: (1) a systematic classification of cyber threats to agricultural drone systems, segmented by target layers; (2) an assessment of current security datasets, from an agriculture-centric perspective; (3) a new categorization framework of AI-based security solutions by operational phase and technology category; and (4) identification of research gaps, particularly in reaction-phase and proximal generative AI solutions. This method also offers actionable insights into dataset selection for training purposes, attack comprehension, and AI solution design, all aimed at enhancing the security of agricultural drones.","2157-4960","979-8-3315-5276-3","10.1109/NTMS65597.2025.11076716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076716","drone security;connected agriculture;AI-based security;cyber threats;UAV security datasets","Training;Solution design;Systematics;Generative AI;Taxonomy;System integration;Turning;Agriculture;Security;Drones","","","","27","IEEE","18 Jul 2025","","","IEEE","IEEE Conferences"
"Research on the Penetration Testing Model in the Vertical Field Using Generative AI Technology","Y. Sun; C. Hou; Y. Su","State Grid Jibei Electric Power Co. Ltd., Research Institute, Beijing, China; State Grid Jibei Electric Power Co. Ltd., Research Institute, Beijing, China; State Grid Jibei Electric Power Co. Ltd., Research Institute, Beijing, China",2024 IEEE 8th Conference on Energy Internet and Energy System Integration (EI2),"15 May 2025","2024","","","2601","2606","Traditional penetration testing relies deeply on high technical requirements for testers, thus limiting the breadth of popularization. Automated pen-testing with artificial intelligence reduces the barrier. This article introduces the application of generative artificial intelligence in the field of pen-testing, introduces machine learning modeling techniques for vulnerability intelligence, constructs a large language model for experimental analysis, and looks forward to future research.","","979-8-3315-2352-7","10.1109/EI264398.2024.10990542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990542","generative artificial intelligence;penetration testing;security breaches;machine learning","Technical requirements;Machine learning algorithms;Limiting;Generative AI;Large language models;Cyberspace;Machine learning;System integration;Security;Penetration testing","","","","8","IEEE","15 May 2025","","","IEEE","IEEE Conferences"
"Enhancing Software Testing Using AI and Graph Similarity","H. G. Chintala; L. Alawneh; Z. A. Al-Sharif; S. Omari","Department of Engineering, Computing and Mathematical Sciences (ECaMS), College of Aviation, Science and Technology (CoAST), Lewis University, Romeoville, IL, USA; Department of Software Engineering Jordan University of Science and Technology (JUST), Irbid, Jordan; Department of Engineering, Computing and Mathematical Sciences (ECaMS), College of Aviation, Science and Technology (CoAST), Lewis University, Romeoville, IL, USA; Department of Engineering, Computing and Mathematical Sciences (ECaMS), College of Aviation, Science and Technology (CoAST), Lewis University, Romeoville, IL, USA",2025 16th International Conference on Information and Communication Systems (ICICS),"18 Jul 2025","2025","","","1","6","Software testing plays a vital role in the development lifecycle, ensuring the prevention of failures and the enhancement of software quality. Despite its importance, the testing phase is often resource-intensive, involving numerous test cases that can become redundant or overlapping over time-leading to increased complexity and prolonged testing durations. To address these inefficiencies, this paper proposes a novel approach that integrates graph similarity analysis with generative AI and deep learning to optimize test suites. By leveraging call graphs derived from test cases, the method identifies redundant and closely related test scenarios. A machine learning model is used to predict similarity scores between these call graphs, facilitating the classification and prioritization of test cases. Lower similarity scores correspond to test cases with more unique code coverage and are thus assigned higher priority. This prioritization enables test engineers to focus on a more diverse and effective subset of test cases, ensuring thorough code coverage while improving efficiency. The proposed framework ultimately reduces redundancy, lowers testing costs, and upholds high standards of software quality, offering a systematic solution for determining the optimal level of testing required to meet study objectives. While the current study experimentally validates the use of graph similarity metrics for test case prioritization, the application of generative AI models is proposed as part of future extensions.","2573-3346","979-8-3315-2580-4","10.1109/ICICS65354.2025.11073112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073112","Software Testing;Regression Testing;Redundant Test Cases;Call Graph;Graph Similarity;Similarity Scores;Test Case Prioritization","Software testing;Measurement;Codes;Systematics;Generative AI;Prevention and mitigation;Redundancy;Software quality;Resource management;Standards","","","","25","IEEE","18 Jul 2025","","","IEEE","IEEE Conferences"
"Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems","R. Liu; Q. Zhang; T. Han; B. Yang; W. Zhang; S. Yin; D. Zhou","Department of Automation, Shanghai Jiao Tong University, Shanghai, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Center for Energy and Environmental Policy Research, Beijing Institute of Technology, Beijing, China; Center for Advanced Control and Smart Operations, Nanjing University, Suzhou, China; School of Information and Communication Engineering, Hainan University, Haikou, China; Norwegian University of Science and Technology, Trondheim, Norway; Center for Advanced Control and Smart Operations, Nanjing University, Suzhou, China",IEEE Transactions on Industrial Cyber-Physical Systems,"23 Jul 2024","2024","2","","264","280","Industrial Cyber-Physical Systems (ICPS) integrating disciplines such as computer science, communication technology, and engineering, have become a crucial component of modern manufacturing and industry. However, ICPS faces numerous challenges during long-term operation, including equipment faults, performance degradation, and security threats, etc. To achieve efficient maintenance and management, prognostics and health management (PHM) has been widely applied in the critical tasks of ICPS such as fault prediction, health monitoring, and maintenance decision-making. The emergence of large-scale foundation models (LFMs) like BERT and GPT marks a significant advancement in artificial intelligence (AI) technology, demonstrating substantial application potential in multiple fields. The accumulation of AI technology, rapid development of LFMs, and the abundance of industrial data and industrial process knowledge provide the foundational conditions for the construction and advancement of industrial LFMs. However, there is currently a lack of consensus on applying LFMs of PHM in ICPS, necessitating a systematic review and roadmap to clarify future development directions. To bridge this gap, this survey provides a comprehensive survey and understanding of the recent advances in LFMs of PHM in ICPS. It provides valuable references for decision makers and researchers in the industry, and helps to further improve the reliability, availability and safety of ICPS.","2832-7004","","10.1109/TICPS.2024.3425326","National Science and Technology Major Project(grant numbers:2022ZD0119900); National Natural Science Foundation of China(grant numbers:62206199,U2141234); Shanghai Science and Technology Program(grant numbers:22015810300); Hainan Province Science and Technology Special Fund(grant numbers:ZDYF2024GXJS003); Young Elite Scientist Sponsorship Program(grant numbers:YESS20220409); Alexander von Humboldt-Stiftung(grant numbers:1226831); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10592003","Industrial cyber-physical systems;prognostics and health management;fault diagnosis;remaining useful life;large-scale foundation models;industrial process knowledge","Prognostics and health management;Cyber-physical systems;Maintenance engineering;Biological system modeling;Sensors;Artificial intelligence;Industrial engineering;Fault diagnosis;Life cycle assessment","","5","","126","IEEE","10 Jul 2024","","","IEEE","IEEE Journals"
"LLM-based Vulnerability Sourcing from Unstructured Data","V. Ashiwal; S. Finster; A. Dawoud","ABB Corporate Research Center, Mannheim, Germany; ABB Corporate Research Center, Mannheim, Germany; ABB Corporate Research Center, Mannheim, Germany",2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),"20 Aug 2024","2024","","","634","641","While open source software (OSS) components are integral to modern software development, they can introduce security risks due to potential unknown vulnerabilities. The shift left approach from DevSecOps recommends to inte-grate security measures from the early stages of development. However, the existing Common Vulnerabilities and Exposures (CVE) program has limitations in covering all vulnerabilities, leading to delays in their publication. Additionally, vulnerabilities are increasingly reported through unconventional channels, such as blog posts, newsletters, and emails, in unstructured formats. This poses challenges in processing and integrating vulnerability information into existing vulnerability management systems. To address this issue, we propose leveraging Large Language Models (LLMs) for extracting vulnerability in-formation from unstructured sources and converting them into a machine-readable CSAF VEX format. In this research paper, we present a prototype implementation that extracts information from supplier communication emails and gener-ates it in CSAF VEX format. It can be incorporated into the corresponding DevSecOps workflow, supporting a shift left approach. Our approach can help organizations to improve their vulnerability management practices by enabling the early detection and remediation of vulnerabilities in software supply chains.","2768-0657","979-8-3503-6729-4","10.1109/EuroSPW61312.2024.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628694","DevSecOps;Large Language Models;Software Supply chain Security;Vulnerability Management;CVE;VEX","Large language models;Supply chains;Prototypes;Organizations;Data models;Delays;Security","","4","","39","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP","R. Jin; C. -Y. Huang; C. You; X. Li",University of British Columbia; University of British Columbia; Yale University; University of British Columbia,2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML),"10 May 2024","2024","","","272","285","In recent years, foundation models (FMs) have contributed heavily to the advancements in the deep learning domain. By extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources [1]. Notably, MedCLIP [2], a vision-language contrastive learning-based medical FM, has been designed using unpaired image-text training. While the medical domain has often adopted unpaired training to amplify data [3], the exploration of potential security concerns linked to this approach hasn’t kept pace with its practical usage. Notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. In this study, we frame this label discrepancy as a backdoor attack problem. We further analyze its impact on medical FMs throughout the FM supply chain. Our evaluation primarily revolves around MedCLIP, emblematic of medical FM employing the unpaired strategy. We begin with an exploration of vulnerabilities in MedCLIP stemming from unpaired image-text matching, termed BadMatch. BadMatch is achieved using a modest set of wrongly labeled data. Subsequently, we disrupt MedCLIP’s contrastive learning through BadDist-assisted BadMatch by introducing a Bad-Distance between the embeddings of clean and poisoned data. Intriguingly, when BadMatch and BadDist are combined, a slight 0.05 percent of misaligned image-text data can yield a staggering 99 percent attack success rate, all the while maintaining MedCLIP’s efficacy on untainted data. Additionally, combined with BadMatch and BadDist, the attacking pipeline consistently fends off backdoor assaults across diverse model designs, datasets, and triggers. Also, our findings reveal that current defense strategies are insufficient in detecting these latent threats in medical FMs’ supply chains.","","979-8-3503-4950-4","10.1109/SaTML59370.2024.00020","Natural Sciences and Engineering Research Council of Canada; Public Safety Canada; Compute Canada; Microsoft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10516621","Backdoor Attack;Foundation Models;Vision-Text Models;Contrastive Learning","Training;Frequency modulation;Computational modeling;Supply chains;Pipelines;Data models;Security","","1","","37","IEEE","10 May 2024","","","IEEE","IEEE Conferences"
"Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback","A. Haag; B. Fuchs; A. Kacan; O. Lohse","Technology Department, Siemens, Munich, Germany; Technology Department, Siemens, Munich, Germany; Technology Department, Siemens, Munich, Germany; Technology Department, Siemens, Munich, Germany",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","65","71","IEC 61131-3 Structured Text (ST) is a widely used programming language for programmable logic controllers (PLCs) in automation systems. However, generating ST code with LLMs poses unique challenges due to limited data in public training datasets and the complexity of ST language syntax. This paper proposes an approach to fine-tune LLMs for the generation of ST code that leverages a preference-based learning method through an online process involving compiler feedback and evaluation from an LLM-based ST expert. In this framework, the model is iteratively refined and generates new training samples, which are subsequently evaluated by a compiler for syntactical correctness and by a specialized LLM that excels at assessing semantic accuracy, though it is not optimized for code generation itself. This approach results in marked improvements for the trained LLM, leading to higher compilation success rates and better semantic precision. As a result, the framework proves highly suitable for industrial automation applications and outperforms state-of-the-art models.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028556","IEC 61131-3;LLMs;LLM Fine-tuning;Compiler feedback","Training;Computer languages;Codes;Automation;Semantics;Programmable logic devices;Syntactics;Iterative methods;IEC Standards;Synthetic data","","","","38","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Reinforcement Learning for Hardware Security: Opportunities, Developments, and Challenges","S. Patnaik; V. Gohil; H. Guo; J. J. Rajendran","Electrical & Computer Engineering, Texas A&M University, College Station, Texas, USA; Electrical & Computer Engineering, Texas A&M University, College Station, Texas, USA; Electrical & Computer Engineering, Texas A&M University, College Station, Texas, USA; Electrical & Computer Engineering, Texas A&M University, College Station, Texas, USA",2022 19th International SoC Design Conference (ISOCC),"7 Feb 2023","2022","","","217","218","Reinforcement learning (RL) is a machine learning paradigm where an autonomous agent learns to make an optimal sequence of decisions by interacting with the underlying environment. The promise demonstrated by RL-guided workflows in unraveling electronic design automation problems has encouraged hardware security researchers to utilize autonomous RL agents in solving domain-specific problems. From the perspective of hardware security, such autonomous agents are appealing as they can generate optimal actions in an unknown adversarial environment. On the other hand, the continued globalization of the integrated circuit supply chain has forced chip fabrication to off-shore, untrustworthy entities, leading to increased concerns about the security of the hardware. Furthermore, the unknown adversarial environment and increasing design complexity make it challenging for defenders to detect subtle modifications made by attackers (a.k.a. hardware Trojans). In this brief, we outline the development of RL agents in detecting hardware Trojans, one of the most challenging hardware security problems. Additionally, we outline potential opportunities and enlist the challenges of applying RL to solve hardware security problems.","2163-9612","978-1-6654-5971-6","10.1109/ISOCC56007.2022.10031569","National Science Foundation(grant numbers:1822848,2039610); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031569","Reinforcement Learning;Hardware Security","Integrated circuits;Design automation;Supply chains;Globalization;Reinforcement learning;Hardware;Autonomous agents","","2","","22","IEEE","7 Feb 2023","","","IEEE","IEEE Conferences"
"The Role of Generative AI Tools in Application Development: A Comprehensive Review of Current Technologies and Practices","A. Donvir; S. Panyam; G. Paliwal; P. Gujar","Application Development, Wayne, NJ, USA; Cloud Computing and SaaS Platforms, Sunnyvale, United States; Product Marketing & Development, Seattle, USA; Enterprise Data Products in Digital Advertising, Saratoga, USA",2024 International Conference on Engineering Management of Communication and Technology (EMCTECH),"6 Nov 2024","2024","","","1","9","This paper provides a comprehensive review of the role of Generative AI (GenAI) tools in modern software application development. It highlights the advancements in machine learning, natural language processing, and neural network architectures that have enabled the evolution of GenAI tools from basic code generation and assistance to fully autonomous software development capabilities. Key GenAI tools like GitHub Copilot, TabNine, Cursor AI and Devin AI are examined, with a focus on their functionalities such as code generation, testing, debugging, and deployment. The paper also discusses the productivity benefits, limitations, and ethical considerations of integrating GenAI tools into the development lifecycle. The aim is to equip software developers, managers, and organizations with a deep understanding of the practical applications and future directions of GenAI in streamlining development processes.","3064-9382","979-8-3315-0790-9","10.1109/EMCTECH63049.2024.10741797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741797","Software Application Development;GenAI;SaaS;Cloud Computing;GenAI Tools;GitHub Copilot;TabNine;Cursor AI;Devin AI;Code Generation;Autonomous Software Development;Digital Product Lifecycle;Testing;CI/CD","Codes;Generative AI;Reviews;Software;Encoding;User experience;Security;Software measurement;Software development management;Testing","","1","","32","IEEE","6 Nov 2024","","","IEEE","IEEE Conferences"
"A Secure Dynamic Event-Triggered Mechanism for Resilient Control of Multi-Agent Systems Under Sensor and Actuator Attacks","Y. Yang; Y. Qian; W. Yue","College of Automation and the College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Automation and the College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Computer Science, Brunel University London, Uxbridge, U.K.",IEEE Transactions on Circuits and Systems I: Regular Papers,"24 Feb 2022","2022","69","3","1360","1371","Information exchanges among interacting agents play a significant role in guaranteeing successful completion of the desired coordinated control tasks for a multi-agent system (MAS). Furthermore, these information exchanges are often performed over some open and resource-constrained communication networks, thereby making security and resource efficiency vitally important for various multi-agent coordinated control problems. This paper addresses a secure dynamic event-trigger-based resilient consensus control problem for an MAS in the presence of both sensor and actuator attacks. First, a distributed adaptive compensator is introduced for prediction of unavailable system states. Due to the existence of sensor and actuator attack signals, a secure dynamic event-triggered mechanism is then proposed, and a resilient control strategy is further devised for the paralyzed MAS. It is theoretically proved that the controlled MAS is asymptotically stable and asymptotic consensus is eventually achieved among the coordinated agents regardless of the attacks and constrained resources. Finally, three examples are provided to illustrate the effectiveness of the proposed strategy.","1558-0806","","10.1109/TCSI.2021.3132153","National Natural Science Foundation of China(grant numbers:61873130,62103200); Natural Science Foundation of Jiangsu Province(grant numbers:BK20191377); 1311 Talent Project of Nanjing University of Posts and Telecommunications (NUPTSF); Scientific Foundation of NUPTSF(grant numbers:NY220102,NY220194); Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:KYCX20_0821); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9646260","Resilient control;consensus;dynamic event-triggered mechanism;observer","Actuators;Robot sensing systems;Robots;Robot kinematics;Task analysis;Vehicle dynamics;Security","","43","","42","IEEE","10 Dec 2021","","","IEEE","IEEE Journals"
"The Impact of Prompt Programming on Function-Level Code Generation","R. Khojah; F. G. d. O. Neto; M. Mohamad; P. Leitner","Chalmers University of Technology and University of Gothenburg, Sweden; Chalmers University of Technology and University of Gothenburg, Sweden; Chalmers University of Technology and University of Gothenburg, Sweden; Chalmers University of Technology and University of Gothenburg, Sweden",IEEE Transactions on Software Engineering,"","2025","PP","99","1","15","Large Language Models (LLMs) are increasingly used by software engineers for code generation. However, limitations of LLMs such as irrelevant or incorrect code have highlighted the need for prompt programming (or prompt engineering) where engineers apply specific prompt techniques (e.g., chain-of-thought or input-output examples) to improve the generated code. While some prompt techniques have been studied, the impact of different techniques—and their interactions— on code generation is still not fully understood. In this study, we introduce CodePromptEval, a dataset of 7072 prompts designed to evaluate five prompt techniques (few-shot, persona, chain-of-thought, function signature, list of packages) and their effect on the correctness, similarity, and quality of complete functions generated by three LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt techniques significantly influence the generated code, combining multiple techniques does not necessarily improve the outcome. Additionally, we observed a trade-off between correctness and quality when using prompt techniques. Our dataset and replication package enable future research on improving LLM-generated code and evaluating new prompt techniques.","1939-3520","","10.1109/TSE.2025.3587794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077752","","Codes;Software;Programming;Few shot learning;Benchmark testing;Accuracy;Training;Software engineering;Prompt engineering;Encoding","","1","","","CCBY","10 Jul 2025","","","IEEE","IEEE Early Access Articles"
"The Intersection of Generative AI and Wearable Health Devices: A Privacy-Focused Analysis","H. Thaker; B. Thaker","Dept of CSE, Symbiosis Inst of Technology, Pune, India; Dr.D.Y. Patil Vidyapeeth, Pune, India","2024 First International Conference on Data, Computation and Communication (ICDCC)","21 Apr 2025","2024","","","437","442","This study examines the privacy implications associated with the intersection of Gen-AI in wearable health devices. Wearables have the potential to revolutionize healthcare for predictive diagnoses. This technological intersection has privacy concerns. Generative AI is trained using a large amount of data that has ethical considerations. The objective of this research is to explore the privacy implications using Generative AI in wearable healthcare devices where consumer trust is concerned. The study is based on mixed method approach. Through a thorough review of literature and primary data collected from 90 wearable device users, the study highlights the dual nature of Gen AI, wearables of health monitoring and privacy concerns. The results indicate that there are security implications for the use of Generative AI in wearables. The study summarizes that users should be made aware of the privacy implications of their data collection when they use the devices regularly as the collected information is personal. It is suggested that companies developing wearable devices should aim to build transparent privacy policies in the context of consumer awareness of data protection for the use of data generated by smart devices. The study contributes to the literature on wearable devices and their data usage by revealing the impact of privacy concerns.","","979-8-3315-3295-6","10.1109/ICDCC62744.2024.10961527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10961527","wearable;health devices;Generative AI;privacy","Privacy;Ethics;Generative AI;Reviews;Medical services;Security;Wearable devices;Biomedical monitoring;Smart devices;Monitoring","","","","25","IEEE","21 Apr 2025","","","IEEE","IEEE Conferences"
"Building Agentic AI Systems: Create intelligent, autonomous AI agents that can reason, plan, and adapt","A. Biswas; W. Talukdar; M. R. Scott; D. A. Acero",NA; NA; NA; NA,"Building Agentic AI Systems: Create intelligent, autonomous AI agents that can reason, plan, and adapt","","2025","","","","","Master the art of building AI agents with large language models using the coordinator, worker, and delegator approach for orchestrating complex AI systemsKey FeaturesUnderstand the foundations and advanced techniques of building intelligent, autonomous AI agentsLearn advanced techniques for reflection, introspection, tool use, planning, and collaboration in agentic systemsExplore crucial aspects of trust, safety, and ethics in AI agent development and applicationsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionGain unparalleled insights into the future of AI autonomy with this comprehensive guide to designing and deploying autonomous AI agents that leverage generative AI (GenAI) to plan, reason, and act. Written by industry-leading AI architects and recognized experts shaping global AI standards and building real-world enterprise AI solutions, it explores the fundamentals of agentic systems, detailing how AI agents operate independently, make decisions, and leverage tools to accomplish complex tasks. Starting with the foundations of GenAI and agentic architectures, you’ll explore decision-making frameworks, self-improvement mechanisms, and adaptability. The book covers advanced design techniques, such as multi-step planning, tool integration, and the coordinator, worker, and delegator approach for scalable AI agents. Beyond design, it addresses critical aspects of trust, safety, and ethics, ensuring AI systems align with human values and operate transparently. Real-world applications illustrate how agentic AI transforms industries such as automation, finance, and healthcare. With deep insights into AI frameworks, prompt engineering, and multi-agent collaboration, this book equips you to build next-generation adaptive, scalable AI agents that go beyond simple task execution and act with minimal human intervention.What you will learnMaster the core principles of GenAI and agentic systemsUnderstand how AI agents operate, reason, and adapt in dynamic environmentsEnable AI agents to analyze their own actions and improviseImplement systems where AI agents can leverage external tools and plan complex tasksApply methods to enhance transparency, accountability, and reliability in AIExplore real-world implementations of AI agents across industriesWho this book is forThis book is ideal for AI developers, machine learning engineers, and software architects who want to advance their skills in building intelligent, autonomous agents. It's perfect for professionals with a strong foundation in machine learning and programming, particularly those familiar with Python and large language models. While prior experience with generative AI is beneficial, the book covers foundational concepts for those new to agentic systems.","","9781801079273","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10972218.pdf&bkn=10972217&pdfType=book","","","","","","","","22 Apr 2025","","","Packt Publishing","Packt Publishing eBooks"
"Generative AI for Healthcare: Concepts and Applications","R. R. Abdelsalam; Y. R. Abdelalim; N. I. Elgazzaz; M. M. Abdelaziz; M. K. Abdelaziz; M. El-Shinawi; M. M. Mohamed; M. A. Elaziz","Biomedical Informatics Program, Faculty of Computer Science and Engineering, Galala University, Suez, Egypt; Biomedical Informatics Program, Faculty of Computer Science and Engineering, Galala University, Suez, Egypt; Biomedical Informatics Program, Faculty of Computer Science and Engineering, Galala University, Suez, Egypt; Biomedical Informatics Program, Faculty of Computer Science and Engineering, Galala University, Suez, Egypt; Biomedical Informatics Program, Faculty of Computer Science and Engineering, Galala University, Suez, Egypt; Department of General Surgery, Faculty of Medicine, Ain Shams University, Sector of International Cooperation, Galala University, Suez, Egypt; Department of Zoology, Faculty of Science, Cairo University, Sector of International, Cooperation, Galala University, Suez, Egypt; Department of Mathematics, Faculty of Science, Zagazig University, Sector of International Cooperation, Galala University, Suez, Egypt",2024 International Conference on Smart-Digital-Green Technologies and Artificial Intelligence Sciences (CSDGAIS),"9 Jul 2025","2024","","","1","6","In the field of medicine, generative artificial intelligence (Gen-AI) is being used to generate reports in natural language for clinical documentation, as well as to create images used in medical training and validating diagnostic tools. Moreover, generative AI helps in drug discovery by forecasting possible targets for treatment and molecular structures, greatly saving a lot of time and expense involved in conventional drug development procedures. According to latest study the introduction of generative AI in health care leads to accurate diagnostic results, faster drug pipeline discovery, and improved clinical documentation efficiency. This widespread introduction of this technology requires addressing challenges related to ethics, data privacy, and verification of AI-generated results to ensure their security. This paper highlights the potential of generative AI to completely transform contemporary healthcare practices by examining its current developments and challenges in the field of medicine.","","979-8-3315-4207-8","10.1109/CSDGAIS64098.2024.11064841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064841","medical applications;generative AI;health;diagnostic","Drugs;Training;Generative AI;Pipelines;Natural languages;Medical services;Documentation;Transforms;Security;Medical diagnostic imaging","","","","27","IEEE","9 Jul 2025","","","IEEE","IEEE Conferences"
