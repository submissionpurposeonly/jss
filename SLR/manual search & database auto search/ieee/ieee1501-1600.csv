"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"An Intelligent Querying System for Educational Statistics Using Pre-trained and Large Language Models","B. He; B. Yu; L. Song; Z. Liu; S. Chen; Q. Liu","Faculty of Artificial Intelligence in Education Central China Normal University, Wuhan, China; Education Management Information Center Ministry of Education, Beijing, China; Education Management Information Center Ministry of Education, Beijing, China; Education Management Information Center Ministry of Education, Beijing, China; Faculty of Artificial Intelligence in Education Central China Normal University, Wuhan, China; Wuhan Fiberhome Technical Services Co.,Ltd, Wuhan, China",2024 International Conference on Intelligent Education and Intelligent Research (IEIR),"14 Apr 2025","2024","","","1","8","Educational statistics play a crucial role in comprehending the current state of educational development and informing decision-making processes. However, traditional data querying systems, which heavily rely on precise SQL statements, often fail to adequately support non-expert users. To address these limitations, we propose an intelligent querying system that leverages a pre-trained language model and a large language model to facilitate natural language interactions for accessing educational statistical data. Our system consists of two main components: query element parsing and SQL statement generation. During the parsing phase, a fine-tuned PLM identifies and correlates relevant tables and elements from the database schema. In the subsequent generation phase, these matched tables and elements, along with the original query, are utilized by LLMs to generate SQL statements. This methodology improves the reliability of SQL generation while mitigating the complexities associated with prompt engineering and reducing the significant costs associated with LLM fine-tuning. The proposed system has been successfully implemented within relevant business units, demonstrating its practicality and effectiveness.","","979-8-3315-1982-7","10.1109/IEIR62538.2024.10959865","National Natural Science Foundation of China; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10959865","natural language to structured query language;educational statistics;query element parsing;SQL statements generation","Structured Query Language;Adaptation models;Accuracy;Databases;Terminology;Large language models;Scalability;Semantics;Vectors;Usability","","","","32","IEEE","14 Apr 2025","","","IEEE","IEEE Conferences"
"Enhancing Diagnostic Accuracy in Bangla: LLM Approaches to Gender Based Medical Specialty Prediction","R. I. Hemel; M. Asef; T. I. Tamiti","Electrical and Computer Engineering, Rajshahi University of Engineering and Technology, Rajshahi, Bangladesh; Electrical and Computer Engineering, Auburn University, Auburn, USA; Cyber Security Engineering, George Mason University, Fairfax, USA",2024 27th International Conference on Computer and Information Technology (ICCIT),"10 Jun 2025","2024","","","873","878","Question-answering (QA) is the most important form of communication and knowledge exchange. Medical QA, the first step of diagnosis, is used by medical professionals to find diseases experienced by patients. Recently, leveraging the transformer architecture, the latest machine learning models known as Large Language Models (LLMs) achieved state-of-the-art performance in various tasks including open- and closed-domain QA. LLMs can potentially revolutionize the overstretched healthcare systems of the least developing countries such as Bangladesh. In this paper, we have used various types of prompts to use the knowledge embedded in the billions of LLM parameters to find potential doctors based on the descriptions of the patient’s uneasiness. Then the LLMs outputs are parsed to suggest the relevant categories of doctors. The performance of the LLM was heavily dependent on the prompts, the size of the LLM, and portions of the medical data in the pre-training corpus. Based on our experimentation, GPT-4-Turbo demonstrated superior performance compared to other LLMs. Among open-source LLMs, Llama3-8b excelled in zero-shot prompting, while Mistral-7b showed better results in mixed prompting scenarios. However, Llama3-8b was the largest CO 2, resulting in a significant carbon footprint. In terms of balancing performance with considerations of time and accuracy, Qwen2-7b emerged as the most optimal among open-source models.","2474-9656","979-8-3315-1909-4","10.1109/ICCIT64611.2024.11022612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022612","Medical Question-Answering (QA);LLMs;Specialist Recommendation;Prompt Engineering;Medical AI Applications","Measurement;Accuracy;Large language models;Prevention and mitigation;Medical specialties;Machine learning;Transformers;Prompt engineering;Medical diagnosis;Medical diagnostic imaging","","","","21","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"INTERTRANS: Leveraging Transitive Intermediate Translations to Enhance LLM-Based Code Translation","M. Macedo; Y. Tian; P. Nie; F. R. Cogo; B. Adams","School of Computing, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Centre for Software Excellence, Huawei Canada, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1153","1164","Code translation aims to convert a program from one programming language (PL) to another. This long-standing software engineering task is crucial for modernizing legacy systems, ensuring cross-platform compatibility, enhancing performance, and more. However, automating this process remains challenging due to many syntactic and semantic differences between PLs. Recent studies show that even advanced techniques such as large language models (LLMs), especially open-source LLMs, still struggle with the task. Currently, code LLMs are trained with source code from multiple programming languages, thus presenting multilingual capabilities. In this paper, we investigate whether such capabilities can be harnessed to enhance code translation. To achieve this goal, we introduce INTERTRANS, an LLM-based automated code translation approach that, in contrast to existing approaches, leverages intermediate translations to bridge the syntactic and semantic gaps between source and target PLs. INTERTRANS contains two stages. It first utilizes a novel Tree of Code Translation (ToCT) algorithm to plan transitive intermediate translation sequences between a given source and target PL, then validates them in a specific order. We evaluate INTERTRANS with three open LLMs on three benchmarks (i.e., CodeNet, HumanEval-X, and TransCoder) involving six PLs. Results show an absolute improvement of 18.3% to 43.3% in Computation Accuracy (CA) for INTERTRANS over Direct Translation with 10 attempts. The best-performing variant of INTERTRANS (with the Magicoder LLM) achieved an average CA of 87.3%-95.4% on three benchmarks.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00236","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2019-05071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029964","automated code translation;large language models;LLM;tree of code translation;intermediate representation","Computer languages;Translation;Codes;Accuracy;Large language models;Semantics;Benchmark testing;Syntactics;Multilingual;Software engineering","","","","39","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"An AI Multi-Model Approach to DeFi Project Trust Scoring and Security","V. Mothukuri; R. M. Parizi; J. L. Massa; A. Yazdinejad","Decentralized Science Lab, College of Computing and Software Engineering, Kennesaw State University, USA; Decentralized Science Lab, College of Computing and Software Engineering, Kennesaw State University, USA; Decentralized Science Lab, College of Computing and Software Engineering, Kennesaw State University, USA; Cyber Science Lab, School of Computer Science, University of Guelph, Ontario, Canada",2024 IEEE International Conference on Blockchain (Blockchain),"18 Sep 2024","2024","","","19","28","Rampant scams plague decentralized finance (DeFi) projects, creating a DeFi credibility problem that limits the impact of DeFi advances in the availability and variety of financial services. This paper presents a novel solution to the DeFi credibility problem by developing an AI multi-model that generates TrustScore ratings for DeFi projects and clear explanations of the scores. We generate DeFi-project TrustScore by aggregating multiple factors that provide DeFi investors with a holistic view of DeFi project trustworthiness. To rate a DeFi project with a TrustS core, we combine the output of four AI pipelines that analyze smart contract code vulnerabilities, suspicious transactions, anomalous price changes to smart contracts, and social media scam sentiment. Applying four factors exponentially improves the trust-score accuracy over the single-factor approaches done historically. Two of the factors, anomalous price change, and social media sentiment, have not been used before to detect DeFi fraud. Furthermore, we enhanced the most critical factor, smart-contract code vulnerability detection, with the latest Large Language Models (LLMs). Our overall system is a multi-model composed of a TrustS core Explainer LLM that aggregates individual pipeline results, a fine-tuned GPT model to audit smart contract code, the Prophet forecasting tool, FinBERT tailored for financial Natural Language Processing (NLP), and XGBoost for classification. The proposed approach identifies a significant proportion of known fraudulent DeFi projects and generates an accurate and explained TrustScore. Thus, we address the DeFi credibility problem so that investors can make reliable decisions about DeFi projects.","2834-9946","979-8-3503-5159-0","10.1109/Blockchain62396.2024.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664378","DeFi;Decentralized Finance;Security;Scam Detection;Rug Pull;AI;LLMs;GPT","Codes;Accuracy;Social networking (online);Smart contracts;Pipelines;Finance;Decentralized applications","","1","","59","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"A Comprehensive Analysis of Unified Approaches for Revealing Code Clone Detection","P. V. Bhaskar; Geetika","School of Computer Science and Engineering, Lovely Professional University, Phagwara, India; School of Computer Science and Engineering, Lovely Professional University, Phagwara, India",2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS),"13 Feb 2025","2024","","","946","953","Code clone detection can be crucial in software maintenance, because of clone occurrences have potential of causing errors, raise costs, or results in unsynchronized modify. Analyzing the limitation of the existing clone detection method, we found that while the token and AST thin methods have been rather successful at detecting simpler clone types, they are significantly inadequate when used for identifying Type III and Type IV clones. The latter are especially significant in cross-language cases in which mere conjunctions of syntactic predicates are insufficient. This paper introduces an enhanced method for code clone detection through combining token-based, abstract syntax tree based, program dependency graph based, and machine learning based clone detection methods in a single framework. In this paper, we developed a scalable approach using adaptive ensemble weighting and fine-tuned LLMs that improved the precision over all types of clones together with low FPs in both languages. The selective execution model of the proposed approach also improves resource utilization making it possible to work on large codebase. Experimental outcomes prove that the proposed approach has higher accuracy, precision, and less computation time compared with the state-of-the-art techniques for clone detection, which make it a valuable contribution for clone detection study.","","979-8-3315-2963-5","10.1109/ICUIS64676.2024.10866000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10866000","Code clone detection;multilayered framework;semantic clones;adaptive ensemble;large language models;cross-language detection;software maintenance","Software maintenance;Codes;Accuracy;Computational modeling;Scalability;Cloning;Syntactics;Ubiquitous computing;Real-time systems;Resource management","","","","20","IEEE","13 Feb 2025","","","IEEE","IEEE Conferences"
"Optimized Transformer Models: ℓ′ BERT with CNN-like Pruning and Quantization","M. H. Haider; S. Valarezo-Plaza; S. Muhsin; H. Zhang; S. -B. Ko",NA; NA; NA; NA; NA,2024 IEEE International Symposium on Circuits and Systems (ISCAS),"2 Jul 2024","2024","","","1","5","Optimizing techniques for neural network architectures aimed at the edge are complex and intricate, which makes them non-universal. Edge computing and artificial intelligence overlap to enhance data security by enabling data processing at the source, mitigating any risk during data transfer. As data security concerns are growing among world governments, AI on edge has become a highly relevant field of modern research. There is a strict need to harness the power of Convolutional Neural Networks (CNNs) and Transformer networks on resource-constrained edge devices. Although many pruning and quantization techniques have been proposed for CNNs, they may not be directly applied to transformers due to the different computation patterns. This paper will explore the implications of two fundamental techniques: pruning and quantization. We will conduct a comparative analysis to explore the applicability of optimization techniques in Transformers, originally designed for CNNs, for real-world edge deployment. Experimental results show that significant improvement in compression ratio can be achieved while the accuracy of the transformer models is maintained.","2158-1525","979-8-3503-3099-1","10.1109/ISCAS58744.2024.10558045","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558045","Transformers;BERT;Natural Language Processing;Optimization Techniques;Model Compression;Quantization;Pruning;Compression Methods for Deep Learning","Quantization (signal);Sensitivity;Data security;Pipelines;Neural networks;Transformers;Convolutional neural networks","","1","","26","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"Deriving Domain Models From User Stories: Human vs. Machines","M. Bragilovski; A. T. Van Can; F. Dalpiaz; A. Sturm","Ben-Gurion University of the Negev, Israel; Utrecht University, The Netherlands; Utrecht University, The Netherlands; Ben-Gurion University of the Negev, Israel",2024 IEEE 32nd International Requirements Engineering Conference (RE),"21 Aug 2024","2024","","","31","42","Domain models play a crucial role in software development, as they provide means for communication among stakeholders, for eliciting requirements, and for representing the information structure behind a database scheme or at the basis of model-driven development. However, creating such models is a tedious activity and automated support may assist in obtaining an initial domain model that can later be enriched by human analysts. In this paper, we propose an experimental comparison of the effectiveness of various approaches for deriving domain models from a given set of user stories. We contrast human derivation with machine derivation; for the latter, we compare (i) the Visual Narrator: an existing rule-based NLP approach; (ii) a machine-learning classifier that we feature engineered; and (iii) a generative AI approach that we constructed via prompt engineering. Based on a benchmark dataset that consists of nine collections of user stories and corresponding domain models, the evaluation indicates that no approach matches human performance, although a tuned version of the machine learning approach comes close. To better understand the results, we qualitatively analyze them and identify differences in the types of false positives as well as other factors that affect performance.","2332-6441","979-8-3503-9511-2","10.1109/RE59067.2024.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628499","Requirements Engineering;Domain Models;Machine Learning;Model Derivation;User Stories;Large Language Models","Analytical models;Visualization;Databases;Machine learning;Benchmark testing;Stakeholders;Requirements engineering","","1","","46","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Anaphora Resolution in Software Requirements Engineering: A Comparison of Generative NLP Pipelines and Encoder-Based Models","S. Yildirim; G. Malik; M. Cevik; A. Başar","Data Science Lab, Toronto Metropolitan University, Istanbul Bilgi University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada; Data Science Lab, Toronto Metropolitan University, Toronto, Canada",2024 34th International Conference on Collaborative Advances in Software and COmputiNg (CASCON),"17 Jan 2025","2024","","","1","6","In the field of requirements engineering (RE), anaphoric ambiguity can negatively impact the quality of requirements and could even threaten the success of a project. If different stakeholders like testers or customers interpret software requirements differently, the system might fail to pass the customer validation stage. On the other hand, a robust anaphora resolution model clarifies the writing process of requirements by accurately indicating the pronoun references. In this study, we exploited the power of generative NLP pipelines and compared their performance with the extractive Question Answering (or sequence labeling) technique. We conducted extensive numerical experiments including text-to-text pipelines and compared them with encoder-based models on two public requirements datasets. Our experiments revealed that a sufficiently large T5 model can yield better results than encoder-based models. We've utilized methods such as Lora to effectively address the complexity of training large language models. Our study indicated that the generative approach outperforms classification-based models for anaphora resolution tasks in Software Requirement texts.","","979-8-3315-0483-0","10.1109/CASCON62161.2024.10837905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837905","Requirements Engineering;Ambiguity;Anaphora resolution;Transformers","Training;Adaptation models;Large language models;Computational modeling;Pipelines;Writing;Software;Numerical models;Requirements engineering;Stakeholders","","1","","20","IEEE","17 Jan 2025","","","IEEE","IEEE Conferences"
"AutoRed: Automated Attack Scenario Generation Framework for Red Teaming of LLMs","Z. Wang; M. A. Tayebi","School of Computing Science, Simon Fraser University, Burnaby, Canada; School of Computing Science, Simon Fraser University, Burnaby, Canada",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2376","2383","Even though Large Language Models (LLMs) are highly beneficial, they pose significant security concerns, particularly in the realm of privacy protection. Sensitive information is often provided to LLMs during conversations and may be retained as in-context memory. This raises the risk of unintended data exposure. In the existing paradigm, a red team comprising human testers is tasked with generating input prompts (i.e., test cases) to provoke undesirable responses from LLMs. Yet, relying solely on human testers is both costly and time-intensive. This paper presents AutoRed, an innovative learning framework developed to automatically generate malicious attack scenarios for extracting sensitive information from LLMs. Our framework places particular emphasis on prompt injection—the process of injecting malicious prompts to extract conversation histories from LLMs to uncover private data. AutoRed comprises three key components: malicious prompt generator, sensitive information extractor, and stop point identifier. These components work together to enable prompt injection, ensuring a seamless process. Our extensive experimental evaluation, spanning diverse defense strategies and various LLMs, demonstrates the efficacy of AutoRed. This evaluation not only rigorously assesses the resilience of defense mechanisms but also measures the safety alignment of LLMs, thereby highlighting the potential of our automated framework as an efficient red teaming tool for identifying vulnerabilities and enhancing security within LLMs.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825267","Large Language Model;Red Teaming;Prompt Injection;Reinforcement Learning;Supervised Fine-tuning","Privacy;Training data;Oral communication;Robustness;Security;Data mining;Scenario generation;Standards;Testing;Resilience","","","","31","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Copilot-in-the-Loop: Fixing Code Smells in Copilot-Generated Python Code using Copilot","B. Zhang; P. Liang; Q. Feng; Y. Fu; Z. Li","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Central China Normal University, Wuhan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","2230","2234","As one of the most popular dynamic languages, Python experiences a decrease in readability and maintainability when code smells are present. Recent advancements in Large Language Models have sparked growing interest in AI-enabled tools for both code generation and refactoring. GitHub Copilot is one such tool that has gained widespread usage. Copilot Chat, released in September 2023, functions as an interactive tool aimed at facilitating natural language-powered coding. However, limited attention has been given to understanding code smells in Copilot-generated Python code and Copilot Chat’s ability to fix the code smells. To this end, we built a dataset comprising 102 code smells in Copilot-generated Python code. Our aim is to first explore the occurrence of code smells in Copilot-generated Python code and then evaluate the effectiveness of Copilot Chat in fixing these code smells employing different prompts. The results show that 8 out of 10 types of code smells can be detected in Copilot-generated Python code, among which Multiply-Nested Container is the most common one. For these code smells, Copilot Chat achieves a highest fixing rate of 87.1%, showing promise in fixing Python code smells generated by Copilot itself. In addition, the effectiveness of Copilot Chat in fixing these smells can be improved by providing more detailed prompts.CCS CONCEPTS• Software and its engineering → Software maintenance tools.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764839","Code Smell;Code Quality;Code Refactoring;GitHub Copilot","Software maintenance;Codes;Large language models;Containers;Encoding;Python;Software engineering;Software development management","","","","34","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Privacy Preserving in Federated Learning with Transformer Models","K. Sahithya; V. Bijalwan","Department of Computer Science and Artificial Intelligence, SR University, Warangal, India; Department of Computer Science and Artificial Intelligence, SR University, Warangal, India",2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE),"18 Jun 2025","2025","","","1","7","Privacy protection in federated learning (FL) is a critical challenge, especially with the integration of Transformer models for improved learning. Traditional FL methods struggle with privacy threats such as model inversion attacks and gradient leakage, relying on differential privacy and secure aggregation, which often cause accuracy loss and computational overhead. To overcome these limitations, we propose a hybrid model combining Swin Transformer and Federated Transformer to enhance privacy, efficiency, and scalability. The Swin Transformer extracts hierarchical representations from decentralized data while preserving local privacy and feature integrity, whereas the Federated Transformer ensures secure client collaboration through advanced self-attention mechanisms. We validate our approach using the CYBRIA dataset, achieving 98.5% accuracy, a 97.8% F1-score, and a 35% privacy leakage reduction. Additionally, our token-based aggregation technique decreases communication overhead by 15%. These results demonstrate the robustness, security, and effectiveness of our framework for real-world cybersecurity and healthcare applications.","","979-8-3315-3366-3","10.1109/ICDCECE65353.2025.11034907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034907","privacy-preserving;federated learning;transformer models;swin transformer;model inversion attack;self-attention mechanism","Privacy;Adaptation models;Differential privacy;Federated learning;Computational modeling;Scalability;Transformers;Feature extraction;Robustness;Integrated circuit modeling","","","","20","IEEE","18 Jun 2025","","","IEEE","IEEE Conferences"
"Simulation of Malicious Scenarios using Multi-Agent Systems","M. Umnitsyn; A. Nikishova; T. Omelchenko; N. Sadovnikova; D. Parygin; Y. Goncharenko","Department of Information Security, Volgograd State University, Volgograd, Russia; Department of Information Security, Volgograd State University, Volgograd, Russia; Department of Information Security, Volgograd State University, Volgograd, Russia; Department of Information Security, Volgograd State University, Volgograd, Russia; Department of CAD, Volgograd State Technical University, Volgograd, Russia; Department of Information Security, Sevastopol State University, Sevastopol, Russia",2018 International Conference on System Modeling & Advancement in Research Trends (SMART),"27 Jun 2019","2018","","","3","9","The problem of building malicious scenarios and their feasibility checking is considered. The approach consisting in preliminary modeling of information system and building of malicious scenarios is offered. The resulting scenarios are checked for feasibility with the developed multi-agent system. As a result of the analysis, the approach used to solve the problems of analysis of reliability and security of IS are proposed. The main problems associated with the loss of adequacy of information system models and malicious scenarios are identified. The proposed approach to modeling the scenarios using a multi-agent system is proposed.","","978-1-5386-6369-1","10.1109/SYSMART.2018.8746971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746971","Malicious Scenario;Attack Graphs;Multiagent System;Agents;Information System;Information System Security;Vulnerability;Information System Modeling","Buildings;Information security;Analytical models;Solid modeling;Information technology","","2","","25","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"Are Requirements Really All You Need? Using LLMs to Generate Configuration Code: A Case Study in Automotive Simulations","K. Lebioda; N. Petrovic; F. Pan; V. Zolfaghari; A. Schamschurko; A. Knoll","Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany; Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany; Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany; Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany; Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany; Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Chair of Robotics, Technical University of Munich (TUM), Boltzmannstraße 3, Garching bei München, Germany",IEEE Access,"","2025","PP","99","1","1","Large Language Models (LLMs) are taking many industries by storm. They possess impressive reasoning abilities and are capable of handling complex problems, as shown by their steadily improving scores on coding and mathematical benchmarks. However, questions remain about their ability to tackle domain-specific, real-world challenges, especially in highly technical fields like the automotive industry. How well can these models understand high-level, abstract instructions commonly found in automotive standards and documentation? Can they translate such specifications directly into functional code, or do they still require human guidance and post-processing? In this work, we investigate the practical capabilities of a state-of-the-art LLM in the context of autonomous driving functionalities. Specifically, we assess the model’s ability to interpret abstract textual requirements extracted from real automotive regulations and transform them into executable configuration code for CARLA, a widely used autonomous driving simulation environment. Our evaluation focuses on the accuracy, completeness, and reliability of the generated code, as well as the model’s ability to reason about domain-specific constraints. The results offer insight into both the potential and current limitations of the models in supporting LLM-based automotive development workflows.","2169-3536","","10.1109/ACCESS.2025.3597748","MANNHEIM-Central Car Server-Supercomputing f?r Automotive (CeCaS)(grant numbers:16ME0820); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11122468","LLM;requirements;AEB;automotive;code generation","Codes;Automotive engineering;Generators;Sensors;Pipelines;Translation;Regulation;Industries;Telemetry;Cognition","","","","","CCBY","11 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Are LLMs Ready for Practical Adoption for Assertion Generation?","V. Pulavarthi; D. Nandal; S. Dan; D. Pal","Electrical and Computer Engg. Dept., University of Illinois Chicago, Chicago, USA; Electrical and Computer Engg. Dept., University of Illinois Chicago, Chicago, USA; Microsoft; Electrical and Computer Engg. Dept., University of Illinois Chicago, Chicago, USA","2025 Design, Automation & Test in Europe Conference (DATE)","21 May 2025","2025","","","1","7","Assertions have been the de facto collateral for simulation-based and formal verification of hardware designs for over a decade. The quality of hardware verification, i.e., detection and diagnosis of corner-case design bugs, is critically dependent on the quality of the assertions. With the onset of generative AI such as Transformers and Large-Language Models (LLMs), there has been a renewed interest in developing novel, effective, and scalable techniques of generating functional and security assertions from design source code. While there have been recent works that use commercial-of-the-shelf (COTS) LLMs for assertion generation, there is no comprehensive study in quantifying the effectiveness of LLMs in generating syntactically and semantically correct assertions. In this paper, we first discuss AssertionBench from our prior work, a comprehensive set of designs and assertions to quantify the goodness of a broad spectrum of COTS LLMs for the task of assertion generations from hardware design source code. Our key insight was that COTS LLMs are not yet ready for prime-time adoption for assertion generation as they generate a considerable fraction of syntactically and semantically incorrect assertions. Motivated by the insight, we propose AssertionLLM, a first of its kind LLM model, specifically fine-tuned for assertion generation. Our initial experimental results show that AssertionLLM considerably improves the semantic and syntactic correctness of the generated assertions over COTS LLMs.","1558-1101","978-3-9826741-0-0","10.23919/DATE64628.2025.10992817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992817","component;formatting;style;styling;insert","Generative AI;Source coding;Semantics;Computer bugs;Europe;Syntactics;Transformers;Hardware;Security;Formal verification","","","","44","","21 May 2025","","","IEEE","IEEE Conferences"
"Empowering Software Architects with Artificial Intelligence: Analyzing GitHub Copilot's Role in Modern Architecture Design","R. Ramachandran","Independent Researcher and Solutions Architect, Hudson, US",2025 7th International Conference on Software Engineering and Computer Science (CSECS),"29 May 2025","2025","","","1","9","As artificial intelligence tools like GitHub Copilot become more integrated into software development workflows, they are transforming how architects approach modern software design. Although enterprises are exploring the potential of GenAl tools to improve developer productivity, limited research exists on their impact on the role of software architects. Traditionally, architects use various tools to create architectural blueprints, including Unified Modeling Language (UML) diagrams, class diagrams, sequence diagrams, use case diagrams, component diagrams, deployment diagrams, activity diagrams, and state diagrams, to name a few. Many of these diagrams follow repetitive patterns that could be automated with well-defined contexts. This paper examines Copilot's role in supporting architects through various stages of architectural development, evaluating how closely Copilot-generated outputs align with established architectural principles. By analyzing deviations, the study discusses how refined prompts can yield more accurate results. This research ultimately seeks to determine Copilot's potential to enhance productivity, ensure consistency, and support architectural decision-making, while offering insights into best practices for integrating AI into modern software architecture.","","979-8-3315-2221-6","10.1109/CSECS64665.2025.11009821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009821","Generative AI (GenAI);Github Copilot;Software Architecture","Productivity;Software design;Software architecture;Unified modeling language;Software;Natural language processing;Security;Prompt engineering;Artificial intelligence;Software development management","","","","20","IEEE","29 May 2025","","","IEEE","IEEE Conferences"
"AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models","H. Zhang; S. Sun; Y. Lin; R. Wang; J. Bian","School of Integrated Circuits, Peking University, Beijing, China; Microsoft Research Asia, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; Microsoft Research Asia, Beijing, China",2025 International Symposium of Electronics Design Automation (ISEDA),"8 Aug 2025","2025","","","772","777","Analog topology synthesis is one of the major challenges in analog design automation since the topology of analog circuits has a large design space and contains a lot of human expertise. Traditional methods suffer in generating high-quality topology due to the diversity of topologies and the lack of ability to understand human experience. Therefore, LLM has been adopted in recent studies to generate such topologies. However, most of the existing work utilizes ideal model-based generation or ambiguous design requirements, both of which are not in line with industrial practice and require additional effort. In this work, we propose AnalogXpert, an LLM-based agent formulating topology synthesis as subcircuit-level SPICE code generation which is more practical. AnalogXpert incorporates circuit design expertise by introducing a proofreading strategy that allows LLMs to incrementally correct the errors in the initial design. Finally, we construct a high-quality benchmark validated by both real data (30) and synthetic data (2k). AnalogXpert achieves 40% and 23% success rates on the synthetic dataset and real dataset respectively, which is markedly better than those of GPT-4o (3%,3%) and AnalogCoder (8%,6%).","","979-8-3315-3696-1","10.1109/ISEDA65950.2025.11100627","National Science and Technology Major Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100627","Analog Topology Synthesis;Design Expertise;Large Language Model","Design automation;Codes;Accuracy;Large language models;Benchmark testing;Analog circuits;SPICE;Topology;Circuit synthesis;Synthetic data","","","","24","IEEE","8 Aug 2025","","","IEEE","IEEE Conferences"
"Take Loads Off Your Developers: Automated User Story Generation using Large Language Model","T. Rahman; Y. Zhu; L. Maha; C. Roy; B. Roy; K. Schneider","dept. Computer Science, University of Saskatchewan, Saskatoon, Canada; Enterprise Data Platform Bell Mobility, Montreal, Canada; dept. Computer Science, University of Saskatchewan, Saskatoon, Canada; dept. Computer Science, University of Saskatchewan, Saskatoon, Canada; dept. Computer Science, University of Saskatchewan, Saskatoon, Canada; dept. Computer Science, University of Saskatchewan, Saskatoon, Canada",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","791","801","Software Maintenance and Evolution (SME) is moving fast with the assistance of artificial intelligence (AI), especially Large Language Models (LLM). Researchers have already started automating various activities of the SME workflow. Un-derstanding the requirements for maintenance and development work i.e. Requirements Engineering (RE) is a crucial phase that kicks off the SME workflow through multiple discussions on a proposed scope of work documented in different forms. The RE phase ends with a list of user stories for each unit task and usually created and tracked on a project management tool such as GitHub, Jira, AzurDev, etc. In this research, we collaborated with Bell Mobility to develop a tool “Geneus” (Generate UserSory) using GPT-4-turbo to automatically create user stories from software requirements documents. Requirements documents are usually long and contain complex information. Since LLMs typically suffer from hallucination when the input is too complex, this paper proposes a new prompting strategy, “Refine and Thought” (RaT), to mitigate that issue and improve the performance of the LLM in prompts with large and noisy contexts. Along with manual evaluation using RUST (Readability, Understandability, Specificity, Technical-aspects) survey questionnaire, automatic evaluation with BERTScore, and AlignScore evaluation metrics are used to evaluate the results of the “Geneus” tool. Results show that our method with RaT performs consistently better in most of the cases of interactions compared to the single-shot baseline method. However, the BERTScore and AlignScore test results are not consistent. In the median case, Geneus performs significantly better in all three interactions (requirements specifi-cation, user story details, and test case specifications) according to AlignScorebut it shows slightly low performance in requirements specifications according to BERTScore. Distilling RE documents requires significant time & effort from the senior members of the team through multiple meetings with stakeholders. We believe automating this process will certainly reduce additional loads off the software engineers and increase the ultimate productivity allowing them to utilize their time on other prioritized tasks.","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795004","LLM;Prompt Engineering;Refine and Thought;User Story;Auto Generate;Software Maintenance Tasks","Surveys;Productivity;Software maintenance;Large language models;Project management;Maintenance;Planning;Requirements engineering;Stakeholders;Testing","","1","","39","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Few-Shot Learning With Manifold-Enhanced LLM for Handling Anomalous Perception Inputs in Autonomous Driving","Y. Zou; Z. Xu; Q. Zhang; Z. Lin; T. Wang; Z. Liu; D. Li","Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China; Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China; Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China; Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China; Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China; School of Energy and Power Engineering, Huazhong University of Science and Technology, Wuhan, China; Faculty of Innovation Engineering, School of Computer Science and Engineering, Macau University of Science and Technology, Taipa, Macau, China",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","18","With the widespread adoption of advanced driving systems (ADS), these systems must cope with increasingly complex driving scenarios. However, data-driven deep learning models heavily rely on large amounts of training data and may perform inadequately when faced with novel situations. Consequently, few-shot learning has become a key topic in the field of autonomous driving. Yet, few-shot learning demands models with strong generalization and extrapolation abilities and tends to be vulnerable to anomalous inputs. The perception modules in current ADS systems are not infallible, and there remains a small chance of inaccurate information being generated, which could potentially affect the decision-making process. To address this issue, we propose an innovative few-shot learning framework based on large language models (LLMs) that can comprehend context and make correct decisions despite the presence of anomalous inputs. This framework decouples the high-dimensional textual space of LLMs into a low-dimensional space tailored for autonomous driving, enabling commonsense reasoning within this space. By integrating this space with the textual space, we create a decision manifold that enables effective reasoning and decision-making processes. The framework also maintains an external self-correction database that continually updates experiences to guide manifold construction, facilitating continual Learning. Experimental results demonstrate our framework reduces collision rates by 14% compared to GPT-Driver when tested with anomalous data. This confirms enhanced safety in complex driving environments with perceptual irregularities.","1558-0016","","10.1109/TITS.2025.3572404","Key Area Research and Development Program of Hubei Province(grant numbers:2023BIB017); Science and Technology Development Fund (FDCT) of Macau(grant numbers:0010/2024/AGJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034671","Large language models;few-shot learning;security;intelligent transportations system;decision reliability;advanced driving systems","Autonomous vehicles;Few shot learning;Decision making;Safety;Accuracy;Robustness;Large language models;Uncertainty;Manifolds;Training","","","","","IEEE","12 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Enhancing Trust and Safety in Digital Payments: An LLM-Powered Approach","D. Dahiphale; N. Madiraju; J. Lin; R. Karve; M. Agrawal; A. Modwal; R. Balakrishnan; S. Shah; G. Kaushal; P. Mandawat; P. Hariramani; A. Merchant","Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc; Google, Inc",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","4854","4863","Digital payment systems have revolutionized financial transactions, offering unparalleled convenience and accessibility to users worldwide. However, the increasing popularity of these platforms has also attracted malicious actors seeking to exploit their vulnerabilities for financial gain. To address this challenge, robust and adaptable scam detection mechanisms are crucial for maintaining the trust and safety of digital payment ecosystems. This paper presents a comprehensive approach to scam detection, focusing on the Unified Payments Interface (UPI) in India, Google Pay (GPay) as a specific use case. The approach leverages Large Language Models (LLMs) to enhance scam classification accuracy and designs a digital assistant to aid human reviewers in identifying and mitigating fraudulent activities. The results demonstrate the potential of LLMs in augmenting existing machine learning models and improving the efficiency, accuracy, quality, and consistency of scam reviews, ultimately contributing to a safer and more secure digital payment landscape. Our evaluation of the Gemini Ultra model on curated transaction data showed a 93.33% accuracy in scam classification. Furthermore, the model demonstrated 89% accuracy in generating reasoning for these classifications. A promising fact, the model identified 32% new accurate reasons for suspected scams that human reviewers had not included in the review notes.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825105","Trust and Safety;Digital payment systems;Large Language Models;Deep Learning;Payments Security;UPI;Fraud Detection;Reasoning","Accuracy;Reviews;Biological system modeling;Large language models;Computational modeling;Ecosystems;Data models;Cognition;Safety;Fraud","","","","21","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Search-Based LLMs for Code Optimization","S. Gao; C. Gao; W. Gu; M. R. Lyu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","578","590","The code written by developers usually suffers from efficiency problems and contain various performance bugs. These inefficiencies necessitate the research of automated refactoring methods for code optimization. Early research in code optimization employs rule-based methods and focuses on specific inefficiency issues, which are labor-intensive and suffer from the low coverage issue. Recent work regards the task as a sequence generation problem, and resorts to deep learning (DL) techniques such as large language models (LLMs). These methods typically prompt LLMs to directly generate optimized code. Although these methods show state-of-the-art performance, such one-step generation paradigm is hard to achieve an optimal solution. First, complex optimization methods such as combinatorial ones are hard to be captured by LLMs. Second, the one-step generation paradigm poses challenge in precisely infusing the knowledge required for effective code optimization within LLMs, resulting in under-optimized code. To address these problems, we propose to model this task from the search perspective, and propose a search-based LLMs framework named SBLLM that enables iterative refinement and discovery of improved optimization methods. SBLLM synergistically integrate LLMs with evolutionary search and consists of three key components: 1) an execution-based representative sample selection part that evaluates the fitness of each existing optimized code and prioritizes promising ones to pilot the generation of improved code; 2) an adaptive optimization pattern retrieval part that infuses targeted optimization patterns into the model for guiding LLMs towards rectifying and progressively enhancing their optimization methods; and 3) a genetic operatorinspired chain-of-thought prompting part that aids LLMs in combining different optimization methods and generating improved optimization methods. Our evaluation of SBLLM on a dataset of Python and C++ code demonstrates its effectiveness in improving code efficiency. Specifically, the results indicate that SBLLM can improve program execution efficiency by up to 209.59 % and consistently outperform all baseline methods by $8.75 \% \sim 28.06 {\%}$ and $1.15 \% \sim 9.56 {\%}$ with different LLMs in terms of top-5 speedup rate on Python and C++, respectively.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029800","","Codes;Large language models;Diversity reception;Optimization methods;C++ languages;Search problems;Genetics;Iterative methods;Python;Software engineering","","1","","56","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Efficient Verification of Multi-Agent Systems Through Parallel","Z. Yao; J. Liu; X. Chen; L. Han; H. Sun","Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China","2024 IEEE 24th International Conference on Software Quality, Reliability and Security (QRS)","26 Sep 2024","2024","","","745","756","Multi-agent systems (MASs) have garnered significant interest across various academic fields. Although MASs are widely applicable, they continue to encounter several challenges, particularly in terms of security.. Model checking, a verification technique that examines all possible system states, is employed to address these challenges. However, the state space of many practical systems can be prohibitively large, leading to exponential growth in verification time. This study introduces a new method for verifying MASs using Strategy Computation Tree Logic (SCTL) via the connective probe machine, a model of fully parallel computing. This approach is pioneering in utilizing the probe machine to speed up MAS verification, specifically allowing for the parallel resolution of SCTL formulas. Unlike conventional model checkers, our method can uncover multiple counterexamples for specified properties, facilitating the identification of various system flaws. We have developed a model checker named MC2PM based on our approach and have validated its feasibility and efficiency through experiments.","2693-9177","979-8-3503-6563-4","10.1109/QRS62785.2024.00079","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684682","model checking;probe machine;temporal logic;strategy logic;parallel computing","Fault diagnosis;Computational modeling;Software quality;Parallel processing;Model checking;Software reliability;Security","","","","35","IEEE","26 Sep 2024","","","IEEE","IEEE Conferences"
"SELLM: An Integrated Tool Leveraging Symbolic Execution and LLMS for Smart Contract Vulnerability Detection","Y. Sen; J. He","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China",2024 21st International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP),"18 Feb 2025","2024","","","1","5","The immutability of blockchain systems makes the security of smart contracts particularly critical. This study presents SELLM, a novel smart contract vulnerability detection tool that integrates symbolic execution with large language models. SELLM leverages symbolic execution to identify vulnerability-prone paths, extracting control flow data, call sequences, and variable constraints, which are then structured into optimized prompts for LLM analysis. Experimental results using the SmartBugs dataset demonstrate that SELLM substantially outperforms baseline methods in terms of precision and recall, achieving a recall of 90.5% and precision of 89.4% with GPT-4o, particularly excelling in detecting vulnerabilities like arithmetic overflow, bad randomness, and reentrancy.","2576-8964","979-8-3315-1925-4","10.1109/ICCWAMTIP64812.2024.10873603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10873603","Tracking;Smart contracts;Vulnerability detection;Large Language Model;Symbolic execution","Fault diagnosis;Large language models;Computational modeling;Smart contracts;Semantics;Information processing;Media;Data mining;Computer security;Arithmetic","","","","15","IEEE","18 Feb 2025","","","IEEE","IEEE Conferences"
"Automated Generation and Evaluation of MultipleChoice Quizzes using Langchain and Gemini LLM","P. Pawar; R. Dube; A. Joshi; Z. Gulhane; R. Patil","Department of Artificial Intelligence and Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence and Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence and Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence and Data Science, Vishwakarma Institute of Information Technology, Pune, India; Department of Artificial Intelligence and Data Science, Vishwakarma Institute of Information Technology, Pune, India",2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT),"4 Nov 2024","2024","1","","1","7","The research study investigates the use of cutting-edge technologies like Langchain and Gemini AI for the automated creation and assessment of multiple-choice questions (MCQs). Although producing multiple-choice questions (MCQs) has traditionally been done by hand and required a lot of work, advances in artificial intelligence (AI) and natural language processing (NLP) have opened up new possibilities. The creation and implementation of an MCQ generator—which uses Gemini AI to generate MCQs and Langchain for rapid engineering are covered in this paper. Customizing prompts for prompt engineering, chaining prompts with the Gemini AI model, and utilizing OpenAI's GPT-3.5 and multiple Language Learning Models (LLMs) to assess the created MCQs are the steps in the process. The study intends to assess these models' efficiency in handling intricate queries, producing appropriate answers, and examining the caliber of the MCQs that are produced.","","979-8-3503-7809-2","10.1109/ICEECT61758.2024.10739326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10739326","mcq generator;large language models;natural language processing;google gemini pro;langchain;generative ai","Measurement;Computers;Analytical models;Computational modeling;Educational technology;Natural language processing;Generators;Prompt engineering","","3","","20","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Application of Agent in Security Platform","H. Gu; S. Zhu; Y. Cui; X. Miao; H. Liu; M. Liu","College of Communications Engineering, JiLin University, Changchun, China; College of Communications Engineering, JiLin University, Changchun, China; College of Communications Engineering, JiLin University, Changchun, China; College of Communications Engineering, JiLin University, Changchun, China; College of Communications Engineering, JiLin University, Changchun, China; College of Communications Engineering, JiLin University, Changchun, China",2019 IEEE/CIC International Conference on Communications Workshops in China (ICCC Workshops),"26 Sep 2019","2019","","","233","238","Based on Belief-Desire-Intention(BDI) architecture,the Agent built in Answer set programming (ASP) is applied to a security platform.Firstly, the task planning is described in BDI models for different autonomous agents,which corresponding structure and cooperation mechanism are explained in detail; Secondly, the symbol language Lp including predicate set is created for the security task, which defines the unified abstract symbols for representation, interaction and state machine.The paper describes the system as a dynamic application program in ASP to solve multi-agents problem. In addition, the method to solve the conflict of beliefs in multi-agent collaboration process is given with a technical framework called Equibel, which shares beliefs among agents and the renewal of their own beliefs. Finally, the theoretical method is simulated and validated with the security application background.The simulation results prove the effectiveness of Agent method, which can upgrade the traditional security system conveniently.","2474-9133","978-1-7281-0738-7","10.1109/ICCChinaW.2019.8849959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8849959","Agent;Answer Set Programming;BDI;Security Platform","Planning;Security;Programming;Task analysis;Cognition;Unmanned aerial vehicles;Cloud computing","","1","","5","IEEE","26 Sep 2019","","","IEEE","IEEE Conferences"
"StegGPT: A Novel Foundation-Model-Based Character-Level Linguistic Steganography Method Utilizing Large Language Models","O. Farooq Ahmed Adeeb; S. J. Kabudian","Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran; Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran",IEEE Access,"28 May 2025","2025","13","","89915","89925","This study addresses the critical need for robust safeguarding of sensitive data stored on personal computing devices and during data transmissions, alongside the increasing need for secure digital interactions. Conventional methodologies for obfuscating data within textual covers exhibit inherent limitations and susceptibility to detection. The primary objective of this investigation is to devise an algorithm that not only ensures secure transmission of information, but also proficiently conceals it from unauthorized access and detection. Using advanced techniques in Natural Language Processing (NLP), Artificial Intelligence (AI), and deep learning within the domain of information security, this study delves into the realm of steganography, revealing the restricted embedding capabilities of conventional language-centric approaches. A comparative analysis pits the newly minted algorithm against contemporaneous approaches, notably cutting-edge neural linguistic steganography (NLS), evaluating their algorithmic capacities in terms of Bits per Word (BpW) and Bits per Character (BpC), along with gauging their security and imperceptibility through metrics like Area Under the Curve (AUC), Equal Error Rate (EER) and Difference of Mean Perplexity ( $\Delta $  MP). Findings underscore the marked superiority of the proposed steganography algorithm in embedding capacity metrics, while upholding comparable standards of security and imperceptibility compared to other AI-driven statistical (Markov chain-based) and neural (deep learning-based) techniques. Specifically, the StegGPT algorithm showcases a remarkable 44% increase in Word-level capacity criterion (from 2.97 to 4.27) and 53% increase in Character-level capacity criterion (from 0.51 to 0.78) in comparison to its closest competitor, all while maintaining consistent levels of security and imperceptibility.","2169-3536","","10.1109/ACCESS.2025.3568339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008605","Text steganography;data hiding;long short-term memory;generative pre-trained transformer (GPT);deep learning;Markov chain","Steganography;Linguistics;Artificial intelligence;Long short term memory;Social networking (online);Faces;Deep learning;Payloads;Logic gates;Information security","","","","22","CCBY","21 May 2025","","","IEEE","IEEE Journals"
"GenAI Security: Outsmarting the Bots with a Proactive Testing Framework","S. K. Jang Bahadur; G. Dhar; L. Nigam","AI & GenAI Specialist, Cloud GTM, Google, Mumbai, India; AI Engineer, AI Services, Google Cloud Consulting (GCC), Google, Mumbai, India; Developer Relations Engineer, Cloud AI and Industry Solutions, Google, Gurugram, India",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","610","612","The increasing sophistication and integration of Generative AI (GenAI) models into diverse applications introduce new security challenges that traditional methods struggle to address. This research explores the critical need for proactive security measures to mitigate the risks associated with malicious exploitation of GenAI systems. We present a framework encompassing key approaches, tools, and strategies designed to outmaneuver even advanced adversarial attacks, emphasizing the importance of securing GenAI innovation against potential liabilities. We also empirically prove the effectiveness of the said framework by testing it against the SPML Chatbot Prompt Injection Dataset. This work highlights the shift from reactive to proactive security practices essential for the safe and responsible deployment of GenAI technologies,","","979-8-3315-2400-5","10.1109/CAI64502.2025.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050591","GenAI;Security;Agents;Prompt Injection;Red Teaming;Blue Teaming;LLM","Technological innovation;Correlation;Generative AI;Prevention and mitigation;Organizations;Chatbots;Complexity theory;Security;Faces;Testing","","","","5","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Conversational AI","A. M. Buttar; F. Shahzad; U. Jamil","University of Agriculture Faisalabad, Faisalabad, Pakistan; University of Agriculture, Faisalabad, Pakistan; Government College University, Faisalabad, Pakistan",Conversational Artificial Intelligence,"","2024","","","31","58","Summary <p>Cloud computing is gaining popularity day by day due to its features like stability, ease of manageability, and flexibility, but at the same time, there are serious concerns about the security of data. It sparked the development of brand‐new IOT and AI‐based business models and hastened technology adoption. IOT devices and big data not only increased the volume of data but also enhanced the complexity, leading to being more prone to hacking and privacy compromises. More smart and intelligent models need to be introduced to handle these security issues; this is where AI comes in. Conversational AI technologies like chatbots and virtual assistants use big data, machine learning, and natural language processing to simulate human interaction. They understand speech and text inputs and translate them into several languages. Data collecting is necessary for conversational AI to reply to user inquiries. The method is prone to privacy and security breaches. Security measures are required at three levels, i.e., data storage, processing, and transmission. Traditional device centric security systems are not sufficient and need to evolve to data‐centric protection solutions, in which security aspects need to be focused at all the three levels. AI can help to automate the process of dynamic threat detection, reaction, and future avoidance. Many organizations are still resistant to adopt cloud computing due to security concerns, despite all complexities and overheads of managing on‐premises data centers. The paper discusses the available cloud models, related privacy and security issues, and barriers perceived in migrating applications to cloud and finally proposes an advanced security model for cloud‐based conversational AI applications.</p>","","9781394200795","10.1002/9781394200801.ch3","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951793.pdf&bkn=10950236&pdfType=chapter","","Cloud computing;Conversational artificial intelligence;Security;Data models;Solid modeling;Servers;Knowledge based systems;Computational modeling;Speech recognition;Biological system modeling","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"From Prompts to Performance: Leveraging LLMs for Enhanced Educational AI Interactions","V. Bhatt; Z. Yu; Y. Hou; B. Khan; K. Dajani; J. Jin","School of Computer Science and Engineering, California State University- San Bernardino, San Bernardino, USA; Department of Economics University of Toronto- St. George, Faculty of Arts and Science, Toronto, Canada; School of Computer Science and Engineering, California State University- San Bernardino, San Bernardino, USA; School of Computer Science and Engineering, California State University- San Bernardino, San Bernardino, USA; School of Computer Science and Engineering, California State University- San Bernardino, San Bernardino, USA; School of Computer Science and Engineering, California State University- San Bernardino, San Bernardino, USA",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","188","195","The rise in usage of Artificial Intelligence (AI) tools such as ChatGPT emphasizes the significance of exploring how prompt inputs influence response quality. This research analyzed 308 prompt-response pairs sourced from students taking Project-based classes like AI, machine learning, and Game design. Prompt quality was assessed based on specificity, clarity, and tone, while response quality was measured based on accuracy, relevance and complexity using a 5-point Likert scale. Our study explored correlation between various factors such as prompt specificity, response accuracy and relevance using Pearson analysis. Furthermore, we evaluated the performance of ChatGPT across each prompt type to determine which prompt class generated the best and worst results. Through the adoption of a prompt engineering approach, the paper identifies practical recommendations that students can employ to improve their interactions with ChatGPT. The research emphasizes that advanced methods such as prompt chaining and knowledge-augmented prompts are more effective than simple prompts in generating precise and comprehensive outputs successfully. This study shows ChatGPT's performance across various domains. The outcome of this study aims to help educators and learners to understand how to use generative AI effectively for programming problems and to support the development of efficient AI -enhanced learning environments.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050709","Prompt Engineering;ChatGPT;Large Language Model;Classification;Correlation;Generative Artificial Intelligence","Adaptation models;Accuracy;Correlation;Large language models;Transforms;Chatbots;Complexity theory;Prompt engineering;Problem-solving;Artificial intelligence","","","","18","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Next-Generation Phishing: How LLM Agents Empower Cyber Attackers","K. Afane; W. Wei; Y. Mao; J. Farooq; J. Chen","Department of Computer and Information Sciences, Fordham University, New York, NY, USA; Department of Computer and Information Sciences, Fordham University, New York, NY, USA; Department of Computer and Information Sciences, Fordham University, New York, NY, USA; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; Department of Computer and Information Sciences, Fordham University, New York, NY, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2558","2567","The escalating threat of phishing emails has become increasingly sophisticated with the rise of Large Language Models (LLMs). As attackers exploit LLMs to craft more convincing and evasive phishing emails, it is crucial to assess the resilience of current phishing defenses. In this study we conduct a comprehensive evaluation of traditional phishing detectors, such as Gmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine learning models like SVM, Logistic Regression, and Naive Bayes, in identifying both traditional and LLM-rephrased phishing emails. We also explore the emerging role of LLMs as phishing detection tools, a method already adopted by companies like NTT Security Holdings and JPMorgan Chase. Our results reveal notable declines in detection accuracy for rephrased emails across all detectors, highlighting critical weaknesses in current phishing defenses. As the threat landscape evolves, our findings underscore the need for stronger security controls and regulatory oversight on LLM-generated content to prevent its misuse in creating advanced phishing attacks. This study contributes to the development of more effective Cyber Threat Intelligence (CTI) by leveraging LLMs to generate diverse phishing variants that can be used for data augmentation, harnessing the power of LLMs to enhance phishing detection, and paving the way for more robust and adaptable threat detection systems.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825018","Large language models;Cybersecurity;Email phishing detection;Semantic evasion","Training;Adaptation models;Accuracy;Phishing;Unsolicited e-mail;Detectors;Machine learning;Data augmentation;Cyber threat intelligence;Security","","4","","38","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Distributed Adaptive Sampled-Data Security Tracking Control for Uncertain Heterogeneous Multi-Agents Systems Under DoS Attacks","N. Zhao; M. Shi; X. Zhao; G. Zong; H. Zhang","College of Control Science and Engineering, Bohai University, Jinzhou, China; Department of Radiology & MRI, The Avenue, Melbourne, VIC, Australia; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China; School of Control Science and Engineering, Tiangong University, Tianjin, China; National Research Base of Intelligent Manufacturing Service, Chongqing Technology and Business University, Chongqing, China",IEEE Transactions on Green Communications and Networking,"19 Nov 2024","2024","8","4","1385","1397","This paper addresses the issue of secure distributed consensus tracking control for uncertain heterogeneous multi-agent systems (MASs) under synchronous sampled communication and intermittent denial-of-service (DoS) attacks. Considering that DoS attacks intermittently block the sampled data signal, a new packet update sequence is established to describe the transmitted signal to the neighbor agents. By virtue of the leader’s dynamics, the sampled-data-based distributed observer is established to observe the leader’s information for all followers. Then, based on the estimated signals and employing neural network approximation approach, secure adaptive sampled-data control strategy is proposed to compensate for the effects of uncertainty and DoS attacks. By utilizing novel Lyapunov-Krasovskii approach, the consensus tracking errors are regulated in the neighborhood around the origin. Finally, a numerical example with the coupled pendulums is provided to substantiate the efficiency of the proposed approach to achieve tracking security performance.","2473-2400","","10.1109/TGCN.2024.3381346","National Natural Science Foundation of China(grant numbers:62203064,62303069); Humanities and Social Science Research Project of Education Department of Liaoning Province(grant numbers:LJKMZ20221485); Open Funding of Chongqing Technology and Business University(grant numbers:KFJJ2019062); Science and Technology Research Program of Chongqing Municipal Education Commission(grant numbers:KJZD-K202300807); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478713","Multi-agent systems;directed graphs;DoS attacks;sampling strategy;secure control","Observers;Security;Adaptive systems;Task analysis;State feedback;Vehicle dynamics;Multi-agent systems;Denial-of-service attack","","30","","45","IEEE","25 Mar 2024","","","IEEE","IEEE Journals"
"Full/Regular Research Paper submission to (CSCI-RTCW): Multi Class Classification of Online Radicalization Using Transformer Models","C. Sofat; S. S. Gill; D. Bansal","Cyber Security Research Centre, Punjab Engineering College, Chandigarh, India; Indraprastha Institute of Information Technology, Delhi, India; Cyber Security Research Centre, Punjab Engineering College, Chandigarh, India",2022 International Conference on Computational Science and Computational Intelligence (CSCI),"25 Aug 2023","2022","","","1034","1038","Online Radicalization is a major security threat to a nation and has the power to influence young minds through online blogs and articles present on social media. It can occur in various forms such as political, social, criminal radicalization etc depending upon the intention and target of the propagator. Each type of radicalization aims to harm a different section of society and thus, requires a different type of treatment and mitigation plan. In our paper we have proposed the use of transformer based models such as BERT etc. to identify the type of radicalization in online text. We have also presented a comparative analysis of several transformers based classifiers for multi class classification of radicalization on social media. The results show that DistilBERT outperforms the other transformer models and has achieved an accuracy of 96.3 percent in this text classification task. As per our knowledge, this is a first of its kind study where the type of radical behaviour in text is being detected.","2769-5654","979-8-3503-2028-2","10.1109/CSCI58124.2022.00183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10216426","BERT;Transformers;Radicalization detection;Social media analysis","Training;Social networking (online);Scientific computing;Computational modeling;Text categorization;Media;Transformers","","","","35","IEEE","25 Aug 2023","","","IEEE","IEEE Conferences"
"DAWN: Designing Distributed Agents in a Worldwide Network","Z. Aminiranjbar; J. Tang; Q. Wang; S. Pant; M. Viswanathan","Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA",IEEE Access,"12 Aug 2025","2025","13","","138795","138812","The rapid evolution of Large Language Models (LLMs) has transformed them from basic conversational tools into sophisticated entities capable of complex reasoning and decision-making. These advancements have led to the development of specialized LLM-based agents designed for diverse tasks such as coding and web browsing. As these agents become more capable, the need for a robust framework that facilitates global agentic communication and collaboration for building sophisticated software solutions has become increasingly important. Distributed Agents in a Worldwide Network (DAWN) addresses this need by providing an architectural framework that allows globally distributed agents of any provenance to be registered, discovered, and organized for building AI-based applications and solutions. In DAWN, a Principal Agent Service composes and oversees the execution of agentic applications. It delegates tasks to one or more Gateway Agent Services that provide for the discovery, registration, and connection of the most suitable agents to fit each application’s needs. DAWN offers three operational modes: No-LLM mode for deterministic and classical software development, Copilot for decision-making augmented using AI, and LLM Agent for autonomous operations. Last but not least, DAWN ensures the safety and security of agent collaborations globally through a dedicated safety, security, and compliance layer, protecting the network against attackers and adhering to stringent security and compliance standards. These features make DAWN a robust framework for designing, developing, and deploying agent-based applications across business and consumer applications.","2169-3536","","10.1109/ACCESS.2025.3588425","Cisco Outshift, the Innovation Engine of Cisco Systems, Inc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11078243","Large language model;AI agents;agentic software development;multi-agent systems;agentic frameworks","Logic gates;Security;Safety;Collaboration;Multi-agent systems;Software development management;Computer architecture;Cognition;Software tools;Large language models","","","","72","CCBY","11 Jul 2025","","","IEEE","IEEE Journals"
"Invited Paper: Software/Hardware Co-design for LLM and Its Application for Design Verification","L. J. Wan; Y. Huang; Y. Li; H. Ye; J. Wang; X. Zhang; D. Chen",University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign; Google; University of Illinois Urbana-Champaign,2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC),"25 Mar 2024","2024","","","435","441","The widespread adoption of Large Language Models (LLMs) is impeded by their demanding compute and memory resources. The first task of this paper is to explore optimization strategies to expedite LLMs, including quantization, pruning, and operation-level optimizations. One unique direction is to optimize LLM inference through novel software/hardware co-design methods. Given the accelerated LLMs, the second task of this paper is to study LLMs’ performance in the usage scenario of circuit design and verification. Specifically, we place a particular emphasis on functional verification. Through automated prompt engineering, we harness the capabilities of the established LLM, GPT-4, to generate High-Level Synthesis (HLS) designs with predefined errors based on 11 open-source synthesizable HLS benchmark suites. This dataset is a comprehensive collection of over 1000 function-level designs, and each of which is afflicted with up to 45 distinct combinations of defects injected into the source code. This dataset, named Chrysalis, expands upon what’s available in current HLS error models, offering a rich resource for training to improve how LLMs debug code. The dataset can be accessed at: https://github.com/UIUC-ChenLab/Chrysalis-HLS.","2153-697X","979-8-3503-9354-5","10.1109/ASP-DAC58780.2024.10473893","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473893","Large Language Models;software/hardware co-design;functional verification","Training;Quantization (signal);Design automation;Source coding;Focusing;Hardware;Software","","10","","46","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"GPT Prompt Engineering for Scheduling Appliances Usage for Energy Cost Optimization","M. Siino; I. Tinnirello","Dipartimento di Ingegneria Elettrica Elettronica e Informatica, University of Catania, Catania, Italy; Dipartimento di Ingegneria, University of Palermo, Palermo, Italy",2024 IEEE International Symposium on Measurements & Networking (M&N),"6 Aug 2024","2024","","","1","6","In this paper, we propose a novel approach that makes use of a GPT model and of prompt engineering to build a proper input to GPT, given a domestic energy dataset. Specifically, given a residential energy consumption dataset, we ask a GPT model - in order to reduce the cost of energy - for planning the timing usage of house appliances, while preserving the same utilization of each appliance on a daily basis. To the best of our knowledge, this is the first attempt to schedule appliances usage taking advantage of the planning ability of a GPT model. Thanks to this preliminary study, we highlight interesting results to be further investigated and enabling certain room for improvements in this domain.","2639-5061","979-8-3503-7053-9","10.1109/MN60932.2024.10615758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615758","GPT;energy cost;domestic appliances;LLMs;scheduling;Mistral 7B","Schedules;Energy consumption;Costs;Timing;Prompt engineering;Optimization","","4","","35","IEEE","6 Aug 2024","","","IEEE","IEEE Conferences"
"All You Need Is Context: Clinician Evaluations of various iterations of a Large Language Model-Based First Aid Decision Support Tool in Ghana","P. B. Mensah; N. S. Quao; S. Dagadu; J. K. Mensah; J. D. Darkwah; P. e. Genie Clinician","SnooCODE RED, SnooCODE, Accra, Ghana; Accident and Emergency Centre, Korle Bu Teaching Hospital SnooCODE RED, Accra, Ghana; SnooCODE RED, SnooCODE, Accra, Ghana; Hohoe, Ghana; University Hospital, Kwame Nkrumah, University of Science and Technology, Kumasi, Ghana; Evaluation Group [1], Ghana",2024 IEEE 12th International Conference on Healthcare Informatics (ICHI),"22 Aug 2024","2024","","","580","585","As advancements in research and development expand the capabilities of Large Language Models (LLMs), there is a growing focus on their applications within the healthcare sector, driven by the large volume of data generated in healthcare. There are a few medicine-oriented evaluation datasets and benchmarks for assessing the performance of various LLMs in clinical scenarios; however, there is a paucity of information on the real-world usefulness of LLMs in context-specific scenarios in resource-constrained settings. In this work, 5 iterations of a decision support tool for medical emergencies using 5 distinct generalized LLMs were constructed, alongside a combination of Prompt Engineering and Retrieval Augmented Generation techniques. 50 responses were generated from the LLMs. Quantitative and qualitative evaluations of the LLM responses were provided by 13 physicians (general practitioners) with an average of 3 years of practice experience managing medical emergencies in resource-constrained settings in Ghana. Machine evaluations of the LLM responses were also computed and compared with the expert evaluations.","2575-2634","979-8-3503-8373-7","10.1109/ICHI61247.2024.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628781","SnooCODE;Clinical Decision Support;Large Language Models;First Aid;Emergency Medical Services;Medical Emergencies;Clinical Context;Clinician Evaluation;Resource-Constrained Settings;Gemini 1.5 Pro;GPT 4;Claude Sonnet","Large language models;Computational modeling;Medical services;Benchmark testing;Prompt engineering;Informatics;Research and development","","1","","22","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Exploring the Effectiveness of LLM based Test-driven Interactive Code Generation: User Study and Empirical Evaluation","S. Fakhoury; A. Naik; G. Sakkas; S. Chakraborty; M. Musuvathi; S. K. Lahiri","Microsoft Research; University of Pennsylvania; University of California, San Diego; Microsoft Research; Microsoft Research; Microsoft Research",2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"20 Jun 2024","2024","","","390","391","We introduce a novel workflow, TICODER, designed to enhance the trust and accuracy of LLM-based code generation through interactive and guided intent formalization. TICODER partially formalizes ambiguous intent in natural language prompts by generating a set of tests to distinguish common divergent behaviours in generated code suggestions. We evaluate the code generation accuracy improvements provided by TICODER at scale across four competitive LLMs, and evaluate the cost-benefit trade off of evaluating tests surfaced by TICODER through a user study with 15 participants.","2574-1934","979-8-4007-0502-1","10.1145/3639478.3643525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554982","LLM4Code;User intent formulation;user study","Codes;Accuracy;Natural languages;Software engineering","","1","","5","","20 Jun 2024","","","IEEE","IEEE Conferences"
"Multifaceted Sentiment Analysis of Public Opinion Based on LLM Prompt Engineering","S. Ma; T. Zhao; B. Wei; Y. Wang","School of Journalism & Communication, Jinan University, Guangzhou, China; School of Journalism & Communication, Jinan University, Guangzhou, China; School of Journalism & Communication, Jinan University, Guangzhou, China; School of Journalism & Communication, Jinan University, Guangzhou, China","2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)","30 Apr 2025","2024","","","160","165","Large language models and prompt engineering provide new methods for rapid intelligent response and decision-making in public events through multifaceted sentiment analysis. This paper constructs eight dimensions of sentiment variables—comparative opinion mining, attitude orientation, social sentiment, individual emotion, hate detection, offensive detection, irony detection, and sensitivity detection—and applies these to 14 typical emergency public events (N=62,433) from 2023 to 2024. Sentiment polarity and consistency across these dimensions are calculated using large language models, followed by cross-analysis with variables such as geographic distribution and participant influence. This study compares six widely used large language models—ChatGPT-4o, ChatGPT-3.5, Claude, ChatGLM, KIMI, and Tongyi Qianwen —to assess their effectiveness in multifaceted analysis of subjective text. Experimental results show that emergency public events evoke complex negative emotions at the individual level, yet social sentiment remains neutral. Emotional disparities also emerge between local and non-local users discussions in events with ambiguous place names. This study provides a new framework for complex public sentiment analysis of emergency public events.","","979-8-3315-3403-5","10.1109/AIHCIR65563.2024.00034","National Natural Science Foundation of China(grant numbers:62206112); Ministry of Education of China(grant numbers:22YJC860037); Jinan University(grant numbers:2022LSYS003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974299","Public events;multifaceted sentiment analysis;social sentiment;large language model","Human computer interaction;Sentiment analysis;Analytical models;Sensitivity;Large language models;Decision making;Prompt engineering;Robots","","","","20","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"Generative AI for Physical Layer Communications: A Survey","N. Van Huynh; J. Wang; H. Du; D. T. Hoang; D. Niyato; D. N. Nguyen; D. I. Kim; K. B. Letaief","Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Electrical and Computer Engineering, Hong Kong University of Science and Technology, Sai Kung, Hong Kong",IEEE Transactions on Cognitive Communications and Networking,"6 Jun 2024","2024","10","3","706","728","The recent evolution of generative artificial intelligence (GAI) leads to the emergence of groundbreaking applications such as ChatGPT, which not only enhances the efficiency of digital content production, such as text, audio, video, or even network traffic data, but also enriches its diversity. Beyond digital content creation, GAI’s capability in analyzing complex data distributions offers great potential for wireless communications, particularly amidst a rapid expansion of new physical layer communication technologies. For example, the diffusion model can learn input signal distributions and use them to improve the channel estimation accuracy, while the variational autoencoder can model channel distribution and infer latent variables for blind channel equalization. Therefore, this paper presents a comprehensive investigation of GAI’s applications for communications at the physical layer, ranging from traditional issues, including signal classification, channel estimation, and equalization, to emerging topics, such as intelligent reflecting surfaces and joint source channel coding. We also compare GAI-enabled physical layer communications with those supported by traditional AI, highlighting GAI’s inherent capabilities and unique contributions in these areas. Finally, the paper discusses open issues and proposes several future research directions, laying a foundation for further exploration and advancement of GAI in physical layer communications.","2332-7731","","10.1109/TCCN.2024.3384500","National Research Foundation, Singapore, and Infocomm Media Development Authority under its Future Communications Research & Development Programme, DSO National Laboratories under the AI Singapore Programme (AISG Award No: AISG2-RP-2020-019 and FCP-ASTAR-TG-2022-003), and MOE Tier 1 (RG87/22); National Research Foundation of Korea (NRF) Grant; Korean Government (MSIT)(grant numbers:2021R1A2C2007638); MSIT under the ITRC support program (IITP-2023-RS-2023-00258639) supervised by the IITP; Australian Research Council under the DECRA project(grant numbers:DE210100651); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10490142","Generative AI;physical layer communications;channel estimation and equalization;physical layer security;IRS;beamforming;joint source channel coding","Physical layer;Artificial intelligence;Channel estimation;Surveys;Generative adversarial networks;Wireless communication;Generative AI","","37","","151","IEEE","3 Apr 2024","","","IEEE","IEEE Journals"
"Synergizing Internal and External Knowledge: Prompt Engineering for Efficient and Effective Large Language Model Reasoning","G. Lu; C. He; L. Shen","Department of Computer Science and Engineering, X-LANCE Lab, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, X-LANCE Lab, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, X-LANCE Lab, Shanghai Jiao Tong University, Shanghai, China","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","1217","1223","Large language models (LLMs), such as ChatGPT, have demonstrated remarkable capability in question answering but face challenges when it comes to knowledge-based rea-soning, such as limited training data and hallucination. To address these challenges, integrating LLMs with knowledge graphs (KGs) has emerged as a promising solution. However, the cost associated with training and inference of LLMs is high. Our method integrates the Retrieval-Augmented Generation (RAG) paradigm, incorporating relevant information from KGs alongside the question to enhance LLMs' reasoning process without training. Moreover, we propose a novel concept of self-knowledge motivation to reduce the overhead of inference, which prompts LLMs to integrate retrieved information with their internal knowledge for reasoning before seeking additional queries to KGs. Experimental results showcase improvements in answer accuracy and a reduction in LLMs' API calls compared to the latest published state-of-the-art (SOTA) method employing an identical paradigm, underscoring the efficiency and effectiveness of our method.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831420","","Training;Accuracy;Large language models;Retrieval augmented generation;Knowledge based systems;Training data;Knowledge graphs;Cognition;Question answering (information retrieval);Prompt engineering","","","","27","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Design and Optimization of Network Security Situation Awareness Algorithm for Generative Adversarial Networks Targeting Attack Data and Traffic","S. Yuan","Technology Risk Management American Airlines, Fort Worth, Texas, United States",2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE),"18 Jun 2025","2025","","","1","6","Network security situational awareness is crucial for detecting and mitigating network threats. However, the severe class imbalance in network attack data poses a significant challenge to accurate threat detection. To address this issue, this paper proposes a situational awareness algorithm based on Generative Adversarial Networks (GANs), focusing on three key aspects: attack data processing, traffic analysis, and perception platform development. Firstly, preprocess the UNSW-NB15 dataset and use conditional GAN to generate minority class samples to balance the dataset. Then, the Transformer model is used for precise attack behavior recognition, followed by hierarchical analysis for security assessment. The experimental results show that the algorithm is superior to existing oversampling methods, with an attack discrimination accuracy of 93.26% and a recall rate of 92.12%. Secondly, a security situational awareness algorithm optimized for real network traffic was introduced, which includes modules for traffic detection, data balancing, attack classification, and situational assessment. This algorithm significantly improves the accuracy of traffic analysis, with an accuracy rate of 94.65% and a recall rate of 95.01%. Finally, a network-based perception platform was developed, integrating functions such as account management, data analysis, and attack identification, providing real-time monitoring and situational analysis to improve the efficiency and reliability of network security management.","","979-8-3315-3366-3","10.1109/ICDCECE65353.2025.11035570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035570","network security situational awareness;generative adversarial networks;convolutional neural networks;transformer models","Accuracy;Network security;Predictive models;Generative adversarial networks;Transformers;Data models;Classification algorithms;Convolutional neural networks;Integrated circuit modeling;Optimization","","","","10","IEEE","18 Jun 2025","","","IEEE","IEEE Conferences"
"DroneDefGANt: A Generative AI-Based Approach for Detecting UAS Attacks and Faults","H. El alami; D. B. Rawat","Howard University, Washington, DC, USA; Howard University, Washington, DC, USA",ICC 2024 - IEEE International Conference on Communications,"20 Aug 2024","2024","","","1933","1938","Recently, Unmanned Aerial Systems (UAS) have become heavily reliant on communication, navigation, and other critical components such as sensors and actuators, which are essential for operations in both civilian and defense applications. However, this increasing reliance makes UAS more vulnerable to attacks and faults, posing rising threats. While there have been many advances in UAS security, a significant number of studies have proposed artificial intelligence (AI)-enhanced solutions to address these challenges. Yet, no research has explored the potential of generative AI (GenAI) in this domain. GenAI stands out due to its ability to detect and prevent cyberattacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we propose DroneDefGANt, a GenAI-based approach that combines the capabilities of generative adversarial networks (GAN) and transformer models. The DroneDefGANt is designed to detect both external UAS attacks like GPS spoofing and jamming, and internal attacks such as actuator faults. Through evaluations using synthetic datasets, DroneDefGANt surpassed various conventional AI models, demonstrating superior accuracy and robustness, particularly in the presence of Gaussian noise.","1938-1883","978-1-7281-9054-9","10.1109/ICC51166.2024.10622524","U.S. Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10622524","Generative AI;UAS;cybersecurity;GPS spoofing;GPS jamming;Fault detection","Actuators;Navigation;Generative adversarial networks;Transformers;Sensor systems and applications;Robustness;Security","","2","","18","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Increased Productivity and Reduced Waste with Robotic Process Automation and Generative AI-Powered IoE Services","W. Lo; C. -M. Yang; Q. Zhang; M. Li","School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China; School of Economics and Management, Dongguan University of Technology, Dongguan, Guangdong, China; School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China; School of Business Administration, Guangxi University of Finance and Economics, Nanning, Guangxi, China",Journal of Web Engineering,"2 Apr 2024","2024","23","1","53","87","The convergence of robotic process automation (RPA) and generative AI (GAI) within the context of Internet of Everything (IoE) services represents a profound paradigm shift. This fusion of technologies not only streamlines routine tasks but also catalyzes innovation while harnessing the potential of interconnected devices. Such integration empowers organizations to achieve remarkable gains in efficiency and sustainability. This paper embarks on an exploration of these transformative services, designed to elevate productivity, and curtail wasteful practices in contemporary industries. By closely examining intricate case studies, we illuminate the multifaceted advantages of this integrated approach. Our investigation demonstrates how RPA accelerates the execution of repetitive processes, substantially diminishing the margin for human error and amplifying operational efficiency. In contrast, generative AI introduces a disruptive force, generating fresh ideas, designs, and solutions, thereby elevating the quality of products and services. The infusion of these cutting-edge technologies into the fabric of IoE services paves the way for organizations to attain unprecedented levels of automation, intelligence, and connectivity. Furthermore, this paper comprehensively addresses the intricate challenges and considerations associated with the proposed implementation. We delve into ethical concerns, security implications, and the necessary workforce adaptation to offer a balanced perspective on the adoption of these technologies. Additionally, we navigate through potential limitations and constraints, underscoring the imperative need for strategic planning and robust governance.","1544-5976","","10.13052/jwe1540-9589.2313","National Natural Science Foundation of China(grant numbers:72361002); Guangxi Science and Technology Development Strategy Research(grant numbers:GUIKE ZL23014029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10488437","Robotic process automation (RPA);generative AI (GAI);Internet of Everything (IoE);industrial productivity;waste management","Productivity;Intelligent automation;Technological innovation;Ethics;Navigation;Standards organizations;Organizations","","5","","21","","2 Apr 2024","","","River Publishers","River Publishers Journals"
"Future of Entertainment: Integrating Generative AI into Free Ad-Supported Streaming Television Using the Variational Autoencoder","S. Ramagundam; N. Karne","Software Development & Engineering in Content Discovery & AI, Comcast, USA; Sr. Principal Systems Engineer in C & RS Platform services, DT Amtrak, USA",2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC),"2 Oct 2024","2024","","","1035","1042","Generative Artificial Intelligence (AI) is derived from the application of AI to produce works of original art including music, films, and images. Moreover, tailored Ads that are more suitable to specific viewers are produced using generative AI. But it is crucial to think about the moral complications of utilizing generative AI in streaming video. There are some issues that include data security, privacy, and the possibility of manipulating or misusing AI -generated information. So, we developed an effective Ad generation model using deep learning to tackle the existing challenges. Initially, the data is taken from the benchmark sources and given into the FAST process. Here, the Variational Autoencoder (VAE) model is used for the FAST process to generate Ads. The model offers the effectual outcome after completing the process. Then, the effectiveness of the developed model is compared with several existing models to showcase the superiority over other models accurately.","2996-5357","979-8-3503-7994-5","10.1109/ICESC60852.2024.10689839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689839","Free Ad-Supported Streaming Television;Generative AI;Targeted Advertisements Generation;Variational Autoencoder","Training;Support vector machines;Data privacy;TV;Generative AI;Films;Organizations;Streaming media;Motion pictures;Identification of persons","","1","","16","IEEE","2 Oct 2024","","","IEEE","IEEE Conferences"
"Exploring Teachers’ Perspectives and Strategies on Student Assessment Using Generative AI in Chinese Universities","Y. Zhang; W. Ma; M. Xiao","College of Education, Zhejiang Normal University, Jinhua, China; School of Economic, Management and Law, Jiangxi Science and Technology Normal University, Nanchang, China; School of Public Finance & Public Administration, Jiangxi University of Finance and Economics, Nanchang, China",2024 4th International Conference on Educational Technology (ICET),"6 Feb 2025","2024","","","403","407","Generative artificial intelligence (AI) provides changes to higher education, which has attracted widespread attention from researchers and educators. However, the existing research has not comprehensively examined how university teachers perceive the use of generative AI for student assessment and what strategies should be implemented when applying this technology in China. This study employed mixed-method research to explore teachers’ perceptions of student assessment using generative AI. We collected data through interviews and surveys from Chinese universities. Our findings demonstrate that a majority of teachers agreed with the power of AI tools to enhance the overall quality of the evaluation and their work efficiency, since they can alleviate the burden associated with manual grading and offer prompt feedback. University teachers expect to prepare their knowledge and skills for the usage of new technologies through training programs and professional development opportunities. Besides, this study notes some concerns like data security and privacy fairness, biases inherent in AI algorithms, overreliance on automation, and limited critical human thinking. These challenges lead to the need for further explorations to provide holistic feedback and balance the AI assessment approach with human judgment to meet reasonable standards. This study provides a general introduction to AI-assisted assessment transformation in the university setting, and more empirical inquiries on different types, phases, objectives, and strategies of assessment in practices are suggested.","","979-8-3503-7694-4","10.1109/ICET62460.2024.10868002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10868002","generative AI;student assessment;higher education;Chinese university teachers;AI- integrated assessment","Training;Surveys;Ethics;Generative AI;Digital transformation;Educational technology;Manuals;Interviews;Standards;Guidelines","","","","27","IEEE","6 Feb 2025","","","IEEE","IEEE Conferences"
"Technology Readiness for Generative AI Among Academic Researchers","H. Salman; M. Aliif; R. Ibrahim; J. Mahmood","University of Bahrain, Sakheer, Bahrain; Faculty of Computing, Universiti Teknologi Malaysia, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor, Malaysia","2024 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)","13 Jan 2025","2024","","","329","336","The use of Generative Artificial Intelligence tools in academic research has recently created a debate in the higher education sector. This study explores researchers' awareness, concerns, and usage of generative AI tools in the academic research process. In addition, the study investigates the current level of readiness among researchers to adopt these tools using the Technology Readiness Index 2.0. Results indicate a high familiarity among respondents with the applications of Generative AI tools in academic research. However, only about half of the participants (51.54%) stated that they are currently adopting these tools mainly for academic writing assistance and language support. In addition, researchers expressed significant concerns about the accuracy of the information, ethical considerations, the authenticity of work, and data privacy and security, with (58.96%) indicating that these concerns may influence their future decisions to adopt or continue adopting these tools. The findings also indicate that the overall readiness level is moderate but reflects a degree of discomfort and insecurity which can inhibit researchers' readiness for adoption. Furthermore, senior researchers tend to feel more insecure than other researcher groups, and AI literacy skills were shown to impact the innovativeness sub-scale.","2770-7466","979-8-3315-3313-7","10.1109/3ict64318.2024.10824523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824523","Generative AI;Academic Research;TRI;Adoption;Researcher;GAI","Training;Ethics;Data privacy;Technological innovation;Accuracy;Generative AI;Predictive models;Writing;Stress;Context modeling","","","","58","IEEE","13 Jan 2025","","","IEEE","IEEE Conferences"
"From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy","M. Gupta; C. Akiri; K. Aryal; E. Parker; L. Praharaj","Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA",IEEE Access,"4 Aug 2023","2023","11","","80218","80245","Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.","2169-3536","","10.1109/ACCESS.2023.3300381","National Science Foundation at Tennessee Tech University(grant numbers:2025682,2230609); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10198233","Generative AI;GenAI and cybersecurity;ChatGPT;Google bard;cyber offense;cyber defense;ethical GenAI;privacy;artificial intelligence;cybersecurity;jailbreaking","Chatbots;Artificial intelligence;Computer security;Hidden Markov models;Privacy;Ethics;Switches;Generative adversarial networks","","361","","65","CCBYNCND","1 Aug 2023","","","IEEE","IEEE Journals"
"Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers","S. Bengesi; H. El-Sayed; M. K. Sarker; Y. Houkpati; J. Irungu; T. Oladunni","Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, University of the District of Columbia, Washington, DC, USA; Department of Computer Science, Morgan State University, Baltimore, MD, USA",IEEE Access,"23 May 2024","2024","12","","69812","69837","The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.","2169-3536","","10.1109/ACCESS.2024.3397775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10521640","Generative AI;GPT;bard;ChatGPT;diffusion model;transformer;GAN;autoencoder;artificial intelligence","Decoding;Mathematical models;Task analysis;Vectors;Codes;Transformers;Neural networks;Generative AI;Generative adversarial networks;Artificial intelligence;Chatbots;Encoding","","115","","277","CCBYNCND","6 May 2024","","","IEEE","IEEE Journals"
"A Survey on Security and Privacy of Large Multimodal Deep Learning Models: Teaching and Learning Perspective","M. A. Rahman; L. Alqahtani; A. Albooq; A. Ainousah","Dept. of Cyber Security and Forensic Computing, University of Prince Mugrin, Madinah, KSA; Dept. of Cyber Security and Forensic Computing, University of Prince Mugrin, Madinah, KSA; Dept. of Cyber Security and Forensic Computing, University of Prince Mugrin, Madinah, KSA; Dept. of Cyber Security and Forensic Computing, University of Prince Mugrin, Madinah, KSA",2024 21st Learning and Technology Conference (L&T),"21 Mar 2024","2024","","","13","18","The proliferation of large language models (LLMs), epitomized by systems like ChatGPT, has catalyzed a paradigm shift in educational technologies, fostering a robust human-AI synergy. As the frontier expands, multimodal AI models have burgeoned, facilitating human interaction through varied channels, from text to imagery and audio-visual educational content. This dynamism has not only enriched educational interfaces but also transformed content generation, curation, and summarization in pedagogy, heralding an unparalleled era in education. However, the ascent of LLMs and their multimodal counterparts, Large Multimodal Models (LMMs), has not been without challenges. They are increasingly found susceptible to adversarial manipulations, potentially undermining the educational process's integrity. This paper delves deep into the security, privacy, compliance, and trustworthiness of LLMs and LMMs, offering a comprehensive survey of their vulnerabilities. We elucidate the myriad adversarial tactics targeting LLMs and proffer contemporary mitigation strategies.","","979-8-3503-9356-9","10.1109/LT60077.2024.10469434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10469434","large language model;large multimodal model;multimedia;generative AI","Surveys;Training;Privacy;Ethics;Educational technology;Chatbots;Data models","","6","","20","IEEE","21 Mar 2024","","","IEEE","IEEE Conferences"
"Resspar: AI-Driven Resume Parsing and Recruitment System using NLP and Generative AI","A. D; K. S; N. E. R; K. K; J. M. S; R. R","Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India; Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India; Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India; Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India; Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India; Department of Computer Science and Engineering, National Engineering College, Kovilpatti, India",2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI),"4 Oct 2024","2024","","","1","6","Artificial Intelligence (AI) is a highly emerging domain in the current scenario. It has numerous applications in various fields and almost every domain started integrating with AI for better and efficient working. In today's scenario resumes playa vital role as it decides the candidate's future scope. The candidate's resume must clearly contain the skills and details expected by the recruiters. Resume parser is always a demanding field for both the applicants and the recruiters. The LLM model takes in prompts or instructions and generates text that corresponds to the relevant information extracted from the resume images. This text generation capability is crucial for parsing and understanding the content of resumes in a structured manner. Generative AI is utilized through the GenAl API provided by Google. The GenAl API is used for tasks such as generating text from images of resumes, where it interprets the visual information and produces structured text output containing relevant details like names, emails, phone numbers, and skills. Resspar aims to streamline the hiring process by developing a web-based Resume Parsing System using Natural Language Processing (NLP) like Language Model (LLM), then it also uses GenAl, and Prompt Engineering Techniques with Python and Flask as the backend Framework. It provides a user-friendly platform that automates the extraction of essential information such as personal information (name, email, phone number) and professional skills from uploaded resumes. Recruitment processes often involve sifting through a large number of resumes to identify suitable candidates for specific job roles or domains. Resspar's functionality includes a user interface for uploading resumes, parsing them using advanced algorithms, storing parsed data in a SQLite database, and offering a filtering mechanism to match candidates with specific job requirements. It identifies the candidates whose skills align with the given criteria. This functionality significantly reduces the time spent manually sifting through resumes, enabling recruiters to focus on assessing the most relevant applicants.","","979-8-3315-4066-1","10.1109/ICoICI62503.2024.10696451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696451","Resume parser;Natural language Processing;Large Language Model;Prompt Engineering;GenAl;Python;Flask;SQLite;Information extraction","Visualization;Resumes;User interfaces;Streaming media;Natural language processing;Electronic mail;Data mining;Prompt engineering;Internet of Things;Recruitment","","1","","17","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
"Research on Multi-agent Path Planning Algorithm Based on Large Language Model","L. Lian; C. Peng","Operation Software and Simulation Research Institute, Dalian Naval Academy; Operation Software and Simulation Research Institute, Dalian Naval Academy","2024 10th International Symposium on System Security, Safety, and Reliability (ISSSR)","21 Jun 2024","2024","","","190","195","With the continuous development of AIGC technology, the application of multimodals in artificial intelligence has become more widespread. However, the formation of the generated results of large language models limits their further development. Currently, the framework of multi-agent established with large language models is a hot topic in the field of artificial intelligence research. This paper uses a large language model to construct multiple agents to simulate each unit in an unmanned cluster. The research on the path planning problem of unmanned clusters is conducted. Using the prompt engineering technology in large language models to define each unmanned unit, a new path planning algorithm is proposed. The paper has provided technical support for the future development of unmanned cluster technology.","2835-2823","979-8-3503-6293-0","10.1109/ISSSR61934.2024.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10562099","Large language model;Prompt engineering;Multi-agent;Path planning","Azimuth;Clustering algorithms;Reliability engineering;Path planning;Safety;Planning;Intelligent agents","","1","","8","IEEE","21 Jun 2024","","","IEEE","IEEE Conferences"
"Instructive Code Retriever: Learn from Large Language Model’s Feedback for Code Intelligence Tasks","J. Lu; H. Wang; Z. Liu; K. Liang; L. Bao; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Hangzhou City University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","191","203","Recent studies proposed to leverage large language models (LLMs) with In-Context Learning (ICL) to handle code intelligence tasks without fine-tuning. ICL employs task instructions and a set of examples as demonstrations to guide the model in generating accurate answers without updating its parameters. While ICL has proven effective for code intelligence tasks, its performance heavily relies on the selected examples. Previous work has achieved some success in using BM25 to retrieve examples for code intelligence tasks. However, existing approaches lack the ability to understand the semantic and structural information of queries, resulting in less helpful demonstrations. Moreover, they do not adapt well to the complex and dynamic nature of user queries in diverse domains. In this paper, we introduce a novel approach named Instructive Code Retriever (ICR), which is designed to retrieve examples that enhance model inference across various code intelligence tasks and datasets. We enable ICR to learn the semantic and structural information of the corpus by a tree-based loss function. To better understand the correlation between queries and examples, we incorporate the feedback from LLMs to guide the training of the retriever. Experimental results demonstrate that our retriever significantly outperforms state-of-the-art approaches. We evaluate our model’s effectiveness on various tasks, i.e., code summarization, program synthesis, and bug fixing. Compared to previous state-of-the-art algorithms, our method achieved improvements of 50.0% and 90.0% in terms of BLEU-4 for two code summarization datasets, 74.6% CodeBLEU on program synthesis dataset, and increases of 3.6 and 3.2 BLEU-4 on two bug fixing datasets.CCS CONCEPTS• Computing methodologies → Artificial intelligence; • Software and its engineering;","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764956","Software Engineering;Large Language Models;In-Context Learning","Training;Codes;Computational modeling;Large language models;Semantics;Computer bugs;Software algorithms;Learning (artificial intelligence);Software;Software engineering","","","","61","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Prescribed-Time Practical Consensus of Nonlinear Multi-Agent Systems Subject to DoS Attacks via Event-Triggered Mechanism","X. Xu; Z. Yu; H. Jiang; X. Mei","College of Mathematics and System Science, Xinjiang University, Ürümqi, China; College of Mathematics and System Science, Xinjiang University, Ürümqi, China; College of Mathematics and System Science, Xinjiang University, Ürümqi, China; College of Mathematics and System Science, Xinjiang University, Ürümqi, China",IEEE Transactions on Automation Science and Engineering,"2 May 2025","2025","22","","14525","14537","This article studies the prescribed-time practical consensus problem for nonlinear multi-agent systems (MASs) subject to denial-of-service (DoS) attacks via an intermittent-based event-triggered mechanism. To this end, we first propose a time-varying scaling function based on the intermittent period, and then use this function to derive a new practical prescribed-time stability theory. Second, this paper further designs an intermittent-based event-triggered control protocol, along with a corresponding triggered function. The main innovation of this protocol is its ability to avoid singular phenomena as time approaches the prescribed instant and to reduce communication costs among all agents. Additionally, some sufficient conditions for achieving leader-following practical consensus are deduced by the proposed prescribed-time stability theory while also excluding Zeno behavior. Finally, two examples are given to verify the effectiveness and feasibility of the theoretical results. Note to Practitioners—This paper is motivated by security consensus challenges in cyber-physical systems, with a particular focus on cost efficiency and convergence performance. Existing prescribed-time security consensus solutions often overlooked the singularity of prescribed instant. Our work addresses a critical issue in MASs vulnerable to DoS attacks. The proposed control strategy is especially relevant for systems susceptible to network attacks, such as microgrids, UAVs, and submarine systems. Preliminary experiments have demonstrated the feasibility of this approach. Future research will tackle the complete consensus problem for MASs within the prescribed-time.","1558-3783","","10.1109/TASE.2025.3561548","National Natural Science Foundation of China(grant numbers:62363033,62163035); Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2023D01C162); Tianshan Talent Training Program(grant numbers:2022TSYCLJ0004,2023TSYCCX0102); Excellent Doctor Innovation Program of Xinjiang University(grant numbers:XJU2024BS042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10966905","Prescribed-time;practical consensus;nonlinear multi-agent system;DoS attacks;intermittent-based event-triggered","Event detection;Convergence;Protocols;Topology;Security;Denial-of-service attack;Training;Multi-agent systems;Costs;Asymptotic stability","","1","","42","IEEE","16 Apr 2025","","","IEEE","IEEE Journals"
"Human-in-the-loop Formation-containment Safe Control for Multi-agent Systems via Reinforcement Learning","L. Yang; P. Chi; J. Zhao; Y. Wang","School of Artificial Intelligence, Beihang University, Beijing, China; Research of Unmanned System, Beihang University, Beijing, China; School of Automation Science, Beihang University, Beijing, China; Research of Unmanned System, Beihang University, Beijing, China",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","14","This paper designs the optimal formation containment safe tracking control protocol for nonlinear second-order multi-agent systems (MASs) with unknown dynamics. A human operator can interact with the tracking leader of MASs to improve security and communicate with other agent through the MASs network in an obstacle-laden environment. Primarily, adaptive neural networks are utilized to identify the unknown nonlinear dynamics parameter and ensure the identification state errors converge asymptotically. Additionally, the optimized safe control design incorporates an actor-critic architecture based on reinforcement learning (RL) to approximate the Hamilton-Jacobi-Bellman (HJB) equation for nonlinear MASs. This distributed security control of MASs achieves optimal tracking using only local connectivity information. Finally, the proposed optimal algorithm for MASs safe formation-containment control is verified with multiple unmanned aerial vehicle (UAV) systems in an unknown obstacle environment.","2691-4581","","10.1109/TAI.2025.3559040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962547","Human-in-the-loop;Reinforcement learning;Formation-containment tracking;Distributed safe control;Non-linear multiagent systems","Neural networks;Nonlinear dynamical systems;Reinforcement learning;Protocols;Heuristic algorithms;Laplace equations;Human in the loop;Vectors;Topology;Optimal control","","","","","IEEE","11 Apr 2025","","","IEEE","IEEE Early Access Articles"
"AIRE 2024: 11th International Workshop on Artificial Intelligence and Requirements Engineering","C. Arora; F. B. Aydemir; J. Frattini","Monash University, Melbourne, Australia; Utrecht University, Utrecht, The Netherlands; Blekinge Insitute of Technology, Karlskrona, Sweden",2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW),"21 Aug 2024","2024","","","1","2","Artificial intelligence (AI) and Requirements Engineering (RE) intersect in innovative and transformative ways, reshaping how we approach technology development today [1]. On the one hand, AI techniques, e.g., NLP, enhance RE processes by automating the extraction and analysis of requirements, increasing quality, accuracy and efficiency in translating human needs into technical specifications [2]. On the other hand, RE plays a crucial role in developing AI systems themselves; it ensures that AI technologies are designed with clear, well-defined requirements that align with ethical standards and practical user needs [1]. This symbiotic relationship not only advances the capabilities of AI but also ensures that the developed systems are human-centric, reliable and trustworthy [3]. AIRE workshop aims to explore this symbiotic relation to identify complex RE problems that could benefit from applying AI techniques and addressing RE for AI challenges. The 2024 workshop edition received 21 submissions, with each submission independently reviewed by at least three program committee members. The final program consisted of nine papers (seven regular research papers and two short papers) and one lightning talk. The workshop took place on June 25th, 2024. The workshop featured a keynote by Jan-Philipp Steghofer with the title “The proof is in the pudding-Real-world use cases for GenAI for Requirements Engineers.”, and a hands-on session on generative AI in RE. We are very grateful to the Program Committee members and authors of the submissions for their hard work and dedication in putting together this program. We thank you all for your participation in AIRE'24.","2770-6834","979-8-3503-9551-8","10.1109/REW61692.2024.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628865","n/a","Symbiosis;Ethics;Accuracy;Generative AI;Conferences;Lightning;Requirements engineering","","","","4","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Federated Discrete Prompt Tuning for Language Models Using Synthetic Examples","T. Tanimura; W. Nakano; Y. Kitagawa; M. Takase","Research and Development Group, Hitachi Ltd., Tokyo, Japan; Research and Development Group, Hitachi Ltd., Tokyo, Japan; Research and Development Group, Hitachi Ltd., Tokyo, Japan; Research and Development Group, Hitachi Ltd., Tokyo, Japan",2025 IEEE 22nd Consumer Communications & Networking Conference (CCNC),"5 May 2025","2025","","","1","4","Effective prompt tuning is critical for using generative AI models, such as large language models (LLMs) and small language models (SLMs), for domain-specific tasks. However, optimizing natural language prompts becomes challenging when the optimizer's access to training data is limited due to privacy concerns. In particular, we consider a multi-party situation where the optimizer has access to performance scores computed from the training dataset but does not have access to the dataset itself. To address this challenge, we propose a novel method for collaboratively optimizing natural language prompts in distributed, multiparty environments. Our approach extends the recent LLM-based prompt optimizer, Optimization by PROmpting (OPRO), by utilizing a synthetic dataset. Unlike existing federated learning-based prompt tuning techniques that only optimize continuous prompts as numerical vectors, our method allows multiple data owners to refine natural language prompts without exposing confidential data. Experiments on the GSM8K benchmark demonstrate task-specific performance improvements using the proposed method. This work provides a secure and practical solution for prompt tuning in privacy-sensitive, distributed settings, advancing the use of LLMs and SLMs in specialized domains.","2331-9860","979-8-3315-0805-0","10.1109/CCNC54725.2025.10975936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10975936","Machine Learning;Distributed Learning;Large Language Model;Prompt Engineering","Training;Data privacy;Large language models;Computational modeling;Natural languages;Training data;Vectors;Tuning;Optimization;Synthetic data","","","","13","IEEE","5 May 2025","","","IEEE","IEEE Conferences"
"Effectiveness of Generative Artificial Intelligence for Scientific Content Analysis","M. Platt; D. Platt","King’s College, London, UK; King’s College, London, UK",2023 IEEE 17th International Conference on Application of Information and Communication Technologies (AICT),"13 Nov 2023","2023","","","1","4","Generative artificial intelligence (GenAI) in general, and large language models (LLMs) in particular, are highly fashionable. As they have the ability to generate coherent output based on prompts in natural language, they are promoted as tools to free knowledge workers from tedious tasks such as content writing, customer support and routine computer code generation. Unsurprisingly, their application is also attractive to professionals in the research domain, where mundane and laborious tasks, such as literature screening, are commonplace. We evaluate Vertex AI ‘text-bison’, a foundational LLM model, in a real-world academic scenario by replicating parts of a popular systematic review in the information management domain. By comparing the results of a zero-shot LLM-based approach with those of the original study, we gather evidence on the suitability of state-of-the-art general-purpose LLMs for the analysis of scientific content. We show that the LLM-based approach delivers good scientific content analysis performance for a general classification problem (ACC =0.9), acceptable performance for a domain-specific classification problem (ACC =0.8) and borderline performance for a text comprehension problem (ACC ≈0.69). We conclude that some content analysis tasks with moderate accuracy requirements may be supported by current LLMs. As the technology will evolve rapidly in the foreseeable future, studies on large corpora, where some inaccuracies are tolerable, or workflows that prepare large data sets for human processing, may increasingly benefit from the capabilities of GenAI.","2472-8586","979-8-3503-0356-8","10.1109/AICT59525.2023.10313167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313167","AI-Assisted Research;Literature Screening;Content Analysis;Prompt Engineering;Classification Performance","Training;Text analysis;Systematics;Biological system modeling;Computational modeling;Natural languages;Resists","","9","","18","IEEE","13 Nov 2023","","","IEEE","IEEE Conferences"
"LLM Interpretability: Tracing How LLMs Answer Factual Queries and Math Questions","S. Agrawal; H. N. T. Li; L. Lu","Google LLC, Stanford University; Google LLC, Stanford University; Google LLC, Stanford University",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","1","6","In this paper, we study how LLMs like GPT store and retrieve facts to answer factual queries. Using a pretrained GPT-2 model, we evaluate factual accuracy on knowledge datasets, math questions, and hand-crafted prompts, employing metrics such as weighted first token accuracy, F1 score for token overlap, perplexity, and BLEU. We leverage interpretability techniques like attention visualization, logit-lens analysis, and causal tracing to identify layers responsible for knowledge retrieval. To enhance the model's factual and mathematical capabilities, we implement prompt engineering, retrieval-augmented generation (RAG), and fine-tuning, comparing their impact on accuracy and fact retrieval mechanisms.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050622","LLM;interpretability;explainability;AI","Measurement;Visualization;Accuracy;Retrieval augmented generation;Mathematical models;Prompt engineering","","","","13","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Decentralized cooperative protection strategy for smart distribution grid using Multi-Agent System","M. J. Daryani; A. E. Karkevandi","Dep. of Electrical engineering, Istanbul Technical University, Istanbul, Turkey; Dep. of Electrical engineering, Tarbiat Modares University, Tehran, Iran",2018 6th International Istanbul Smart Grids and Cities Congress and Fair (ICSG),"12 Jul 2018","2018","","","134","138","Recently, by increasing penetration of Distributed Generations (DGs) in power systems and its consequence bi-directionality of power flow and variability of fault current, the effect of DGs on conventional protection systems (with fixed setting) become a serious concern. In this study, a communication based decentralized adaptive protection system design is proposed, whereby every protection relay has sufficient intelligence to dynamically calculates and updates its settings based on online identification of prevailing network configurations. Moreover, in the proposed scheme the algorithm of the relay has been further developed to enable relay for proper operation and coordination for post-fault periods. Every relays by obtaining mapping information through real-time communication detects prevailing configuration of the network as well as, once a permanent fault occurs by obtaining fault detection signals detects mapping relationship for post-fault condition an become ready for detection of possible subsequent faults. In order to fast operation, improve reliability and selectivity of the protection scheme, proposed protection system is based on Multi-Agent System (MAS). Different parts of protection system are designed as different agents by their own intelligence, self-tuning and communication abilities.","","978-1-5386-4478-2","10.1109/SGCF.2018.8408958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408958","Adaptive Relaying;Power systems;Microgrid;Distributed Generation;Overcurrent Relays;Multi-agent Systems","Relays;Microgrids;Current measurement;Multi-agent systems;Circuit faults;Voltage measurement;Fault currents","","10","","13","IEEE","12 Jul 2018","","","IEEE","IEEE Conferences"
"Machine Learning for Healthcare-IoT Security: A Review and Risk Mitigation","M. A. Khatun; S. F. Memon; C. Eising; L. L. Dhirani","Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland",IEEE Access,"29 Dec 2023","2023","11","","145869","145896","The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported.","2169-3536","","10.1109/ACCESS.2023.3346320","Science Foundation Ireland (SFI)(grant numbers:18/CRT/6049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371310","Healthcare-IoT;generative AI;5G-IoT;security and privacy challenges;cybersecurity;attacks;anomaly detection;machine learning;deep learning;mitigation techniques;5G NR","Medical services;Internet of Things;Security;Sensors;Machine learning;Temperature sensors;Monitoring","","33","","280","CCBY","22 Dec 2023","","","IEEE","IEEE Journals"
"Generative AI-Enhanced Neuro-Symbolic Quantum Architectures for Secure Communications and Networking","S. K. Jagatheesaperumal; S. Ali; A. Alotaibi; K. Muhammad; V. H. C. De Albuquerque; M. Guizani","Department of Electronics and Communication Engineering, Mepco Schlenk Engineering College, Sivakasi, Tamil Nadu, India; Department of Applied Artificial Intelligence, School of Convergence, College of Computing and Informatics, Visual Analytics for Knowledge Laboratory (VIS2KNOW Lab), Sungkyunkwan University, Seoul, Republic of Korea; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Applied Artificial Intelligence, School of Convergence, College of Computing and Informatics, Visual Analytics for Knowledge Laboratory (VIS2KNOW Lab), Sungkyunkwan University, Seoul, Republic of Korea; Department of Teleinformatics Engineering, Federal University of Ceará, Fortaleza, Fortaleza/CE, Brazil; Machine Learning Department, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), Abu Dhabi, United Arab Emirates",IEEE Network,"","2025","PP","99","1","1","The rapid convergence of generative AI (GAI), neuro-symbolic reasoning, and quantum computing has redefined secure communication and networking. Owing to the massive amount of data, the need for extensive computing power, and the necessity to find and mitigate threats in real time, traditional security measures cannot keep up with changing cyber threats as the communication infrastructure becomes more complicated. Therefore, this paper investigates the potential of a GAI-enhanced neuro-symbolic quantum framework for building security systems that are strong, scalable, and self-sufficient. This method improves threat detection, encryption, and real-time adversarial defense by combining symbolic reasoning for logic, deep learning for pattern recognition, and quantum intelligence to accelerate computations. This work has made progress in creating the next generation of secure networks that can automatically and adaptively make security decisions in real-time, providing robust protection in communication environments that change over time.","1558-156X","","10.1109/MNET.2025.3579680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036761","Generative AI;Neuro-symbolic;Secure communications;Intelligent networks;Multi-agents;Quantum AI","Quantum computing;Artificial intelligence;Security;Cognition;Computer architecture;Real-time systems;Deep learning;Optimization;Next generation networking;Adaptive systems","","1","","","IEEE","16 Jun 2025","","","IEEE","IEEE Early Access Articles"
"An Overview of Trustworthy AI: Advances in IP Protection, Privacy-Preserving Federated Learning, Security Verification, and GAI Safety Alignment","Y. Zheng; C. -H. Chang; S. -H. Huang; P. -Y. Chen; S. Picek","School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Jurong West, Singapore; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; IBM Research, Yorktown Heights, NY, USA; Institute for Computing and Information Sciences, Radboud University, Nijmegen, The Netherlands",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"13 Dec 2024","2024","14","4","582","607","AI has undergone a remarkable evolution journey marked by groundbreaking milestones. Like any powerful tool, it can be turned into a weapon for devastation in the wrong hands. Understanding that no model is perfect, trustworthy AI is initiated with an intuitive aim to mitigate the harm it can inflict on people and society by prioritizing socially responsible AI ideation, design, development, and deployment towards effecting positive changes. The scope of trustworthy AI is encompassing, covering qualities such as safety, security, privacy, transparency, explainability, fairness, impartiality, robustness, reliability, and accountability. This overview paper anchors on recent advances in four research hotspots of trustworthy AI with compelling and challenging security, privacy, and safety issues. The topics discussed include the intellectual property protection of deep learning and generative models, the trustworthiness of federated learning, verification and testing tools of AI systems, and the safety alignment of generative AI systems. Through this comprehensive review, we aim to provide readers with an overview of the most up-to-date research problems and solutions. By presenting the rapidly evolving factors and constraints that motivate the emerging attack and defense strategies throughout the AI life-cycle, we hope to inspire more research effort into guiding AI technologies towards beneficial purposes with greater robustness against malicious use intent.","2156-3365","","10.1109/JETCAS.2024.3477348","National Natural Science Foundation of China(grant numbers:62404192); University Development Fund of The Chinese University of Hong Kong, Shenzhen(grant numbers:UDF01003337); Imperial College/Nanyang Technological University (NTU) CYber Protection for HEalthcaRe (IN-CYPHER) Program supported by the National Research Foundation, Prime Minister’s Office, Singapore, under its Campus for Research Excellence and Technological Enterprise (CREATE) Program; National Science and Technology Council (NSTC), Taiwan(grant numbers:112-2221-E-033-050-MY3,113-2640-E-008-001); Chief Digital and Artificial Intelligence Office(grant numbers:W519TC-23-9-2037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10711270","Federated learning;deep neural network;generative AI;large language model;formal verification;safety alignment;trustworthy AI;model poisoning;data poisoning;backdoor;watermarking;fingerprinting;security;privacy-preservation","Artificial intelligence;Security;Data models;Protection;Integrated circuit modeling;Training;Circuits and systems;Privacy;Training data;Mathematical models","","1","","278","CCBYNCND","9 Oct 2024","","","IEEE","IEEE Journals"
"Clozemaster: Fuzzing Rust Compiler by Harnessing Llms for Infilling Masked Real Programs","H. Gao; Y. Yang; M. Sun; J. Wu; Y. Zhou; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1422","1435","Ensuring the reliability of the Rust compiler is of paramount importance, given increasing adoption of Rust for critical systems development, due to its emphasis on memory and thread safety. However, generating valid test programs for the Rust compiler poses significant challenges, given Rust's complex syntax and strict requirements. With the growing popularity of large language models (LLMs), much research in software testing has explored using LLMs to generate test cases. Still, directly using LLMs to generate Rust programs often results in a large number of invalid test cases. Existing studies have indicated that test cases triggering historical compiler bugs can assist in software testing. Our investigation into Rust compiler bug issues supports this observation. Inspired by existing work and our empirical research, we introduce a bracket-based masking and filling strategy called clozeMask. The clozeMask strategy involves extracting test code from historical issue reports, identifying and masking code snippets with specific structures, and using an LLM to fill in the masked portions for synthesizing new test programs. This approach harnesses the generative capabilities of LLMs while retaining the ability to trigger Rust compiler bugs. It enables comprehensive testing of the compiler's behavior, particularly exploring edge cases. We implemented our approach as a prototype ClozeMaster. ClozeMaster has identified 27 confirmed bugs for rustc and mrustc, of which 10 have been fixed by developers. Furthermore, our experimental results indicate that ClozeMaster outperforms existing fuzzers in terms of code coverage and effectiveness.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029729","Rust Compiler;fuzzing;large language model;bug detection","Codes;Large language models;Instruction sets;Computer bugs;Prototypes;Fuzzing;Syntactics;Safety;Reliability;Software engineering","","1","","69","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Generative AI in Intrusion Detection Systems for Internet of Things: A Systematic Literature Review","Z. Deng; A. Torim; S. Ben Yahia; H. Bahsi","Department of Software Science, Tallinn University of Technology, Tallinn, Estonia; Department of Software Science, Tallinn University of Technology, Tallinn, Estonia; Department of Software Science, Tallinn University of Technology, Tallinn, Estonia; Department of Software Science, Tallinn University of Technology, Tallinn, Estonia",IEEE Open Journal of the Communications Society,"10 Jun 2025","2025","6","","4689","4717","The ubiquitous data streaming through the Internet of Things (IoT) creates security risks. Intrusion detection systems (IDS) based on machine learning can support user security. Generative Artificial Intelligence (GenAI) demonstrates strong capabilities in generating synthetic data based on realistic distributions and learning complex patterns from high-dimensional data. By harnessing the capabilities of generative AI, it is feasible to augment intrusion detection models, allowing for more robust and adaptive security solutions in IoT environments. This paper introduces a systematic literature review of recent GenAI applications in IoT IDS and analyzes the architectures and techniques in the models. We classify the common usages such as data augmentation and class balancing, data reconstruction, and adversarial attack generation. We outline the commonly used datasets and evaluation metrics and compare the performances of each model under these conditions. The study identifies current challenges and emerging research trends in various technologies for applying GenAI in IoT IDS.","2644-125X","","10.1109/OJCOMS.2025.3573194","Department of Software Science, Tallinn University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012727","Generative AI (GenAI);generative adversarial network (GAN);intrusion detection system (IDS);Internet of Things (IoT);systematic literature review (SLR)","Intrusion detection;Internet of Things;Generative AI;Systematic literature review;Generative adversarial networks;Security;Machine learning;Transformers;Surveys;Computer architecture","","","","146","CCBY","23 May 2025","","","IEEE","IEEE Journals"
"An Empirical Study on Commit Message Generation Using LLMs via In-Context Learning","Y. Wu; Y. Wang; Y. Li; W. Tao; S. Yu; H. Yang; W. Jiang; J. Li","Peking University, Beijing, China; Ant Group, Hangzhou, China; Peking University, Beijing, China; Fudan University, Shanghai, China; Peking University, Beijing, China; The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Ant Group, Hangzhou, China; Ant Group, Hangzhou, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","553","565","Commit messages concisely describe code changes in natural language and are important for software maintenance. Several approaches have been proposed to automatically generate commit messages, but they still suffer from critical limitations, such as time-consuming training and poor generalization ability. To tackle these limitations, we propose to borrow the weapon of large language models (LLMs) and in-context learning (ICL). Our intuition is based on the fact that the training corpora of LLMs contain extensive code changes and their pairwise commit messages, which makes LLMs capture the knowledge about commits, while ICL can exploit the knowledge hidden in the LLMs and enable them to perform downstream tasks without model tuning. However, it remains unclear how well LLMs perform on commit message generation via ICL. In this paper, we conduct an empirical study to investigate the capability of LLMs to generate commit messages via ICL. Specifically, we first explore the impact of different settings on the performance of ICL-based commit message generation. We then compare ICL-based commit message generation with state-of-the-art approaches on a popular multilingual dataset and a new dataset we created to mitigate potential data leakage. The results show that ICL-based commit message generation significantly outperforms state-of-the-art approaches on subjective evaluation and achieves better generalization ability. We further analyze the root causes for LLM's underperformance and propose several implications, which shed light on future research directions for using LLMs to generate commit messages.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029897","commit message generation;large language model;in-context learning","Training;Software maintenance;Codes;Weapons;Large language models;Natural languages;Multilingual;Tuning;Software engineering","","","","83","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Automatically Assessing Software Architecture Compliance With Green Software Patterns","N. Ahuja; Y. Feng; L. Li; A. Malik; T. Sivayoganathan; N. Balani; S. Rakhunathan; F. Sarro","University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; Accenture, Mumbai, India; Microsoft, Hyderabad, India; University College London, London, United Kingdom",2025 IEEE/ACM 9th International Workshop on Green and Sustainable Software (GREENS),"19 Jun 2025","2025","","","68","75","With increasing awareness of climate change, there is a growing emphasis on the environmental impact of digital solutions. While numerous tools are available to assess software environmental footprint post-development, few focus on sustainability during the software design phase. To address this gap, we propose EcoDocSense, a framework that supports engineers to evaluate the sustainability of a software design at design time. Using Large Language Models fine-tuned on a catalog of green software patterns, EcoDocSense analyzes software architecture documents to generate sustainability reports, assessing alignment with green software practices to minimize carbon emissions and recommending improvements. As one of the first frameworks targeting sustainability at the design stage, EcoDocSense represents a significant advancement, though opportunities remain for further enhancement. In future, we plan to extend EcoDocSense’s applicability to a variety of architectural types and documents as well as to provide the capability to estimate carbon emissions.","2473-1161","979-8-3315-3815-6","10.1109/GREENS66463.2025.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039296","Sustainable Software Architecture;Green Software Patterns;Green Software Development","Climate change;Sustainable development;Software architecture;Green computing;Software development management;Sustainable development;Ecodesign","","","","43","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring With Feedback","M. Fateen; B. Wang; T. Mine","Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",IEEE Access,"13 Dec 2024","2024","12","","185371","185385","Automatic short answer scoring (ASAS) helps reduce the grading burden on educators but often lacks detailed, explainable feedback. Existing methods in ASAS with feedback (ASAS-F) rely on fine-tuning language models with limited datasets, which is resource-intensive and struggles to generalize across contexts. Recent approaches using large language models (LLMs) have focused on scoring without extensive fine-tuning. However, they often rely heavily on prompt engineering and either fail to generate elaborated feedback or do not adequately evaluate it. In this paper, we propose a modular retrieval augmented generation (RAG) based ASAS-F system, utilizing RAG as a few-shot selection method to score answers and generate feedback in zero-shot and few-shot learning scenarios. We design our system to be adaptable without extensive prompt engineering using an automatic prompt generation framework. Results show an improvement in scoring accuracy by 9% on unseen questions compared to fine-tuning, offering a scalable and cost-effective solution.","2169-3536","","10.1109/ACCESS.2024.3508747","Japan Science and Technology Agency (JST), the Establishment of University fellowships towards the creation of Science Technology Innovation(grant numbers:JPMJFS2132); Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP21H00907,JP23H03511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771759","Automatic short answer scoring;large language models;retrieval-augmented generation","Measurement;Training data;Vectors;Prompt engineering;Optimization;Training;Solid modeling;Cognition;Chatbots;Adaptation models","","4","","40","CCBY","29 Nov 2024","","","IEEE","IEEE Journals"
"Language Models for Hierarchical Classification of Radiology Reports With Attention Mechanisms, BERT, and GPT-4","M. Olivato; L. Putelli; N. Arici; A. Emilio Gerevini; A. Lavelli; I. Serina","Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Fondazione Bruno Kessler, Trento, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy",IEEE Access,"21 May 2024","2024","12","","69710","69727","Radiology reports are a valuable source of textual information used to improve clinical care and support research. In recent years, deep learning techniques have been shown to be effective in classifying radiology reports. This article investigates the use of deep learning techniques with attention mechanisms to achieve better performance in the classification of radiology reports. We focus on various Natural Language Processing approaches, such as LSTM with Attention, BERT, and GPT-4, evaluated on a chest tomography report dataset regarding neoplastic diseases collected from an Italian hospital. In particular, we compare the results with a previous machine learning system, showing that models based on attention mechanisms can achieve higher performance. The Attention Mechanism allows us to identify the most relevant bits of text used by the model to make its predictions. We show that our model achieves state-of-the-art results on the hierarchical classification of radiology reports. Moreover, we evaluate the performance of GPT-4 on the classification of these reports in a zero-shot setup through prompt engineering, showing interesting results even with a small context and a non-English language. Our findings suggest that deep learning techniques with attention mechanisms may be successful in the classification of radiology reports even in non-English languages for which it is not possible to leverage on large text corpus.","2169-3536","","10.1109/ACCESS.2024.3402066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10531266","Attention mechanism;BERT;BioBIT;deep learning;GPT-4;large language models;natural language processing;Italian language;prompt engineering;radiology reports;Italian radiology reports;text classification","Radiology;Task analysis;Computed tomography;Biological system modeling;Training;Lung;Data models;Deep learning;Large language models","","3","","74","CCBY","16 May 2024","","","IEEE","IEEE Journals"
"Landscape and Taxonomy of Prompt Engineering Patterns in Software Engineering","Y. Sasaki; H. Washizaki; J. Li; N. Yoshioka; N. Ubayashi; Y. Fukazawa","Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan",IT Professional,"19 Feb 2025","2025","27","1","41","49","Advancements in large language models (LLMs) have enhanced their ability to handle ambiguous user instructions. However, effective prompt patterns remain crucial for usability and comprehension. This article presents a taxonomy of prompt engineering patterns for software engineering. It is based on a systematic literature review that was conducted in early 2023, when LLMs still faced significant limitations in context length and inference capabilities. Our study explores techniques that enhance the usability and reliability of LLMs, emphasizing the ongoing importance of well-designed prompts in optimizing task performance. Our findings highlight the critical role of prompt patterns in maximizing LLM’s potential, even as their capabilities continue to evolve.","1941-045X","","10.1109/MITP.2024.3525458","KAKENHI(grant numbers:21KK0179,23K18470); Japan Science and Technology Agency(grant numbers:JPMJMI20B8); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893869","","Prompt engineering;Taxonomy;Large language models;Software engineering;User-generated content;Usability;User experience;Performance evaluation;Quality assessment","","1","","15","CCBY","19 Feb 2025","","","IEEE","IEEE Magazines"
"Enhancing LLM-Generated Hardware Documentation: Post-Processing and Prompt Engineering Techniques","R. Kunzelmann; S. Fernando; W. Ecker",NA; NA; NA,MBMV 2025; 28. Workshop,"23 Jun 2025","2025","","","90","97","Adopting Large Language Models (LLMs) has recently gained prominence in various natural language processing tasks, including in the electronic design automation industry. As an inverse approach, this work considers using LLMs to process formal hardware models and generate human-readable design documentation hereof. We automatically preprocess formalized system-level hardware specifications to create prompts for LLMs. Based on these prompts, an LLM generates an extensive, human-readable explanation of the system. While this workflow has already shown to be viable as a concept, technical errors and style issues are the prevalent restrictions for wide-scale application. Addressing these issues, this paper presents a selection of advanced post-processing and prompt engineering techniques to improve the quality of the LLM-generated documentation. Applying our extended workflow to a set of hardware components demonstrates that the incorporated methods are especially effective in ensuring the documentation’s correct formatting and style conformity. Although occasional technical errors still occur, we observe a significant reduction in manual revision efforts, with 46.4% of the generated documentation not requiring any further changes.","","978-3-8007-6515-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047220","","","","","","","","23 Jun 2025","","","VDE","VDE Conferences"
"Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment","D. P. Panagoulias; F. A. Palamidas; M. Virvou; G. A. Tsihrintzis","Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Medicine, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","9","We evaluate the validity, accuracy, and usefulness of ChatGPT-returned medical diagnosis of lung disease based on symptoms described by a human. Specifically, Tuberculosis and its symptoms are selected as the test case and our evaluation follows the directions of (i) medical validity and accuracy of the returned diagnosis in terms of both context and references, (ii) its usefulness to both doctors and patients and (iii) the economic value added to the healthcare system. It is shown that ChatGPT performs well in diagnosing Tuberculosis, but its performance improves when supervised by a human medical expert. In the interest of adding reproducibility and comparability, we propose a novel general evaluation procedure for the medical domain, to be followed when interacting with Large Language Models. This procedure integrates the various steps employed in our evaluation process and encompasses the review indices utilized for quantifying the outcome.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345968","University of Piraeus Research Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345968","AI-empowered software engineering;explainability;ChatGPT;LLM;NLP;prompt-engineering","Economics;Tuberculosis;Pulmonary diseases;Biological system modeling;Chatbots;Software;Reproducibility of results","","17","","32","IEEE","15 Dec 2023","","","IEEE","IEEE Conferences"
"Leveraging ChatGPT to Predict Requirements Testability with Differential In-Context Learning","M. Dahiya; R. Gill; N. Niu; H. Gudaparthi; Z. Peng","University of Cincinnati, Cincinnati, OH, USA; University of Cincinnati, Cincinnati, OH, USA; University of Cincinnati, Cincinnati, OH, USA; Governors State University, University Park, IL, USA; University of Montana, Missoula, MT, USA",2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI),"8 Oct 2024","2024","","","170","175","Testability is a desired property of requirements, indicating how easy or difficult a requirements artifact supports its own testing. Prior work predicts natural language (NL) requirements’ testability by training a decision tree (DT) via some readability and word measures. To explore better ways of predicting requirements testability, we examine in this paper large language models-ChatGPT in particular. Our experiments on a total of 1,181 requirements from six software systems show that ChatGPT’s zero-shot learning performs worse than the DT. A main reason is due to the lack of context specific to the testability prediction task. However, applying ChatGPT’s incontext learning (ICL) reveals a limitation of skewed examples caused by the imbalanced data. Thus, we propose a novel approach, called differential ICL, to address the challenges by exploiting the DT and show quantitatively the higher accuracy achieved by differential ICL.","2835-5776","979-8-3503-5118-7","10.1109/IRI62200.2024.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703856","requirements testability;software testing;machine learning;large language models","Training;Instruments;Zero shot learning;Natural languages;Predictive models;Software systems;Particle measurements;Rough surfaces;Decision trees;Testing","","2","","34","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Boosting LLM-Based Software Generation by Aligning Code with Requirements","T. Yaacov; A. Elyasaf; G. Weiss",Ben-Gurion University of the Negev; Ben-Gurion University of the Negev; Ben-Gurion University of the Negev,2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW),"21 Aug 2024","2024","","","301","305","Emerging LLM-based code generation tools enable programmers to specify desired functionality and automatically generate code. However, these tools fall short in comparison to human ability when it comes to creating complete system models from requirements. This is because humans typically formulate a software design before implementing a system. In this paper, we propose to use the behavioral programming (BP) model-based paradigm as a general design approach that allows for the direct translation of requirements of any reactive systems into code. We demonstrate that each requirement can be automatically transformed into a dedicated code module without the need for a global view of the system. The key lies in BP's capability to enable modules to implement both scenarios and anti-scenarios separately. This means that each module can independently define behaviors that may happen, must happen, and must not happen. Subsequently, an application-agnostic execution engine interprets and interweaves these modules at runtime to generate cohesive system behavior consistent with system requirements. The fact that each requirement is translated into a small module also facilitates the verification of its implementation, thereby helping to reduce errors in LLM code generation. We present an initial evaluation of our approach and demonstrate how the characteristics of BP aid in generating aligned and correct implementations.","2770-6834","979-8-3503-9551-8","10.1109/REW61692.2024.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628724","behavioral programming;large language models;requirement engineering","Analytical models;Codes;Software design;Runtime;Programming;Software;Requirements engineering","","2","","29","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models","H. C. Indelman; E. Dahan; A. M. Perez-Agosto; C. Shiran; D. Shaked; N. Daniel","Dept. of AI/ML, Research Science & Technology Organization, GE Healthcare, Haifa, Israel; Dept. of AI/ML, Research Science & Technology Organization, GE Healthcare, Haifa, Israel; Dept. of Clinical Applications, Point of Care Ultrasound & Handheld, GE Healthcare, Texas, USA; Dept. of Clinical Applications, Point of Care Ultrasound & Handheld, GE Healthcare, Wisconsin, USA; Dept. of AI/ML, Research Science & Technology Organization, GE Healthcare, Haifa, Israel; Dept. of AI/ML, Research Science & Technology Organization, GE Healthcare, Haifa, Israel",2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"17 Dec 2024","2024","","","1","7","Despite the remarkable success of deep learning in medical imaging analysis, medical image segmentation remains challenging due to the scarcity of high-quality labeled images for supervision. Further, the significant domain gap between natural and medical images in general and ultrasound images in particular hinders fine-tuning models trained on natural images to the task at hand. In this work, we address the performance degradation of segmentation models in low-data regimes and propose a prompt-less segmentation method harnessing the ability of segmentation foundation models to segment abstract shapes. We do that via our novel prompt point generation algorithm which uses coarse semantic segmentation masks as input and a zero-shot prompt-able foundation model as an optimization target. We demonstrate our method on a segmentation findings task (pathologic anomalies) in ultrasound images. Our method’s advantages are brought to light in varying degrees of low-data regime experiments on a small-scale musculoskeletal ultrasound images dataset, yielding a larger performance gain as the training set size decreases.","2694-0604","979-8-3503-7149-9","10.1109/EMBC53108.2024.10781870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10781870","Zero-Shot Learning;Foundation Model;Semantic Segmentation;Prompt Engineering;Musculoskeletal Ultrasound;Pathology Finding","Training;Degradation;Ultrasonic imaging;Shape;Semantic segmentation;Biological system modeling;Refining;Performance gain;Robustness;Biomedical imaging","Ultrasonography;Humans;Algorithms;Semantics;Image Processing, Computer-Assisted;Deep Learning","","","36","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Experiences with Content Development and Assessment Design in the Era of GenAI","A. Sharma; S. Shailendra; R. Kadel","SITE, Melbourne Institute of Technology (MIT), Australia; SITE, Melbourne Institute of Technology (MIT), Australia; SITE, Melbourne Institute of Technology (MIT), Australia","2025 6th International Conference on Computer Science, Engineering, and Education (CSEE)","23 Jun 2025","2025","","","1","5","Generative Artificial Intelligence (GenAI) has the potential to transform higher education by generating human-like content. The advancement in GenAI has revolutionised several aspects of education, especially subject and assessment design. In this era, it is crucial to design assessments that challenge students and cannot be solved using GenAI tools. This makes it necessary to update the educational content with rapidly evolving technology. The assessment plays a significant role in ensuring the students' learning, as it encourages students to engage actively, leading to the achievement of learning outcomes. The paper intends to determine how effectively GenAI can design a subject, including lectures, labs and assessments, using prompts and custom-based training. This paper aims to elucidate the direction to educators so they can leverage GenAI to create subject content. Additionally, we provided our experiential learning for educators to develop content, highlighting the importance of prompts and fine-tuning to ensure output quality. It has also been observed that expert evaluation is essential for assessing the quality of GenAI-generated materials throughout the content generation process.","","979-8-3315-0516-5","10.1109/CSEE64583.2025.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11037857","Subject Design;Assessment Design;Generative AI (GenAI);Prompt Engineering","Training;Computer science;Reviews;Transforms;Iterative methods;Prompt engineering","","","","35","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"AI for Everyday IT: Accelerate workplace productivity","C. LeMaire; B. Abshire",Manning Publications; Manning Publications,AI for Everyday IT: Accelerate workplace productivity,"","2025","","","","","Automate and accelerate your everyday IT tasks with instant solutions! What if you never had to write another after-incident report, piece of boilerplate code, or a performance review from scratch ever again? Use AI tools like ChatGPT, Claude, Gemini, and Copilot right, and you’ll take back hours of your time—and more! AI for Everyday IT reveals how you can automate dozens of your daily IT tasks with generative AI.  In AI for Everyday IT you’ll learn how to:  Write effective prompts for common IT tasks Optimize report generation, document handling, and workplace communication Resolve IT conflicts and crises Acquire new skills and upgrade your resume AI for help desk, database administration and systems administration Incorporate AI into DevOps processes and create AI-powered applications Simplify time-consuming people management tasks  In this hands-on guide, automation experts Chrissy LeMaire and Brandon Abshire show you how AI tools like ChatGPT have made their lives a million times easier, and how they can do the same for you. You’ll find proven strategies for using AI to improve help desk support, automate sysadmin and database tasks, aid with DevOps engineering, handle managing IT teams, and dozens more time-saving and quality-improving hacks.","","9781633436428","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11079733.pdf&bkn=11079732&pdfType=book","AI for IT;AI automation;workplace productivity;generative AI;ChatGPT for IT;IT help desk AI;automate IT tasks;prompt engineering;IT conflict resolution;AI for sysadmins;database administration AI;DevOps automation;AI-powered applications","","","","","","","14 Jul 2025","","","Manning","Manning eBooks"
"Solving Situation Puzzles with Large Language Model and External Reformulation","K. Li; X. Chen; T. Song; C. Zhou; Z. Liu; Z. Zhang; J. Guo; Q. Shan","Department of Computer Science, University of Illinois Urbana-Champaign, Champaign, IL, USA; Department of Electronical and Computer Engineering, University of Illinois at Urbana Champaign, Champaign, IL, USA; Department of Computer Science, Columbia University, New York City, NY, USA; Department of Computer Science, Columbia University, New York City, USA; Information Networking Institute, Carnegie Mellon University, Pittsburgh, USA; Information Networking Institute, Carnegie Mellon University, Pittsburgh, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Engineering, Northeastern University, Seattle, WA, USA","2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)","23 Jun 2025","2025","","","2061","2065","In recent years, large language models (LLMs) have shown an impressive ability to perform arithmetic and symbolic reasoning tasks. However, we found that LLMs (e.g., ChatGPT) cannot perform well on reasoning that requires multiple rounds of dialogue, especially when solving situation puzzles. Specifically, LLMs intend to ask very detailed questions focusing on a specific aspect or same/similar questions after several rounds of Q&As. To help LLMs get out of the above dilemma, we propose a novel external reformulation methodology, where the situation puzzle will be reformulated after several rounds of Q&A or when the LLMs raise an incorrect guess. Experiments show superior performance (e.g., win rate, number of question/guess attempts) of our method than directly using LLMs for solving situation puzzles, highlighting the potential of strategic problem reformulation to enhance the reasoning capabilities of LLMs in complex interactive scenarios.","","979-8-3315-2228-5","10.1109/AINIT65432.2025.11035296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035296","Large Language Model;Situation Puzzles;Natural Language Processing;Prompt Engineering;Dialogue Management","Seminars;Systematics;Large language models;Redundancy;Cognition;Maintenance;Prompt engineering;Problem-solving;History;Information technology","","","","22","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Interpreting COVID Lateral Flow Tests’ Results with Foundation Models","S. Pandey; J. Myers-Dean; J. Reynolds; D. Gurari",University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder,2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","4935","4942","Lateral flow tests (LFTs) enable rapid, low-cost testing for health conditions including Covid, pregnancy, HIV, and malaria. Automated readers of LFT results can yield many benefits including empowering blind people to independently learn about their health and accelerating data entry for large-scale monitoring (e.g., for pandemics such as Covid) by using only a single photograph per LFT test. Accordingly, we explore the abilities of modern foundation vision language models (VLMs) in interpreting such tests. To enable this analysis, we first create a new labeled dataset with hierarchical segmentations of each LFT test and its nested test result window. We call this dataset LFT-Grounding. Next, we benchmark eight modern VLMs in zero-shot settings for analyzing these images. We demonstrate that current VLMs frequently fail to correctly identify the type of LFT test, interpret the test results, locate the nested result window of the LFT tests, and recognize LFT tests when they partially obfuscated. To facilitate community-wide progress towards automated LFT reading, we publicly release our dataset at https://iamstuti.github.io/lft_grounding_foundation_models/","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00498","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678080","Lateral Flow Test;Foundation Vision Language Models;Zero-Shot;Prompt Engineering;Accessibility","COVID-19;Pregnancy;Visualization;Image segmentation;Pandemics;Malaria;Life estimation","","","","32","IEEE","27 Sep 2024","","","IEEE","IEEE Conferences"
"Semantic Routing for Enhanced Performance of LLM-Assisted Intent-Based 5G Core Network Management and Orchestration","D. M. Manias; A. Chouman; A. Shami","The Department of Electrical and Computer Engineering, Western University; The Department of Electrical and Computer Engineering, Western University; The Department of Electrical and Computer Engineering, Western University",GLOBECOM 2024 - 2024 IEEE Global Communications Conference,"11 Mar 2025","2024","","","2924","2929","Large language models (LLMs) are rapidly emerging in Artificial Intelligence (AI) applications, especially in the fields of natural language processing and generative AI. Not limited to text generation applications, these models inherently possess the opportunity to leverage prompt engineering, where the inputs of such models can be appropriately structured to articulate a model’s purpose explicitly. A prominent example of this is intent-based networking, an emerging approach for automating and maintaining network operations and management. This paper presents semantic routing to achieve enhanced performance in LLM-assisted intent-based management and orchestration of 5G core networks. This work establishes an end-to-end intent extraction framework and presents a diverse dataset of sample user intents accompanied by a thorough analysis of the effects of encoders and quantization on overall system performance. The results show that using a semantic router improves the accuracy and efficiency of the LLM deployment compared to stand-alone LLMs with prompting architectures.","2576-6813","979-8-3503-5125-5","10.1109/GLOBECOM52923.2024.10901065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901065","Large Language Models;Semantic Routing;Intent-Based Networking;5G Core Networks;Next-Generation Networks;End-to-End Network Management","Quantization (signal);Translation;5G mobile communication;Large language models;System performance;Semantics;Retrieval augmented generation;Linguistics;Routing;Reliability","","4","","14","IEEE","11 Mar 2025","","","IEEE","IEEE Conferences"
"From Zero to Sixty at the Speed of RAG: Improving YAML Recipe Generation via Retrieval","F. Farmahinifarahani; P. Babkin; S. Alamir; X. Liu","J.P. Morgan AI Research, Palo Alto, USA; J.P. Morgan AI Research, Palo Alto, USA; J.P. Morgan AI Research, London, UK; J.P. Morgan AI Research, New York, USA",2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"12 Jun 2025","2025","","","49","56","LLMs have been shown to match or even exceed the performance of specialized Deep Learning models on code generation tasks for general purpose imperative languages, such as Python, Java, C++, and Rust. Conversely, there is only limited work investigating whether such impressive out of the box generalization transfers onto less ubiquitous domain-specific languages, which are often declarative, based on XML, JSON, or YAML. To bridge this gap, we explore the capabilities of LLMs for composing code automation recipes without resorting to any form of task-specific finetuning. We experiment with two GPT versions and CodeLlama-13b-Instruct, and in our experiments, we find that after extensive prompt engineering and chain-of-thought prompting, these models’ accuracy in recipe selection does not go beyond ≈ 30%. For parameter filling of YAML recipes, the accuracy of these models remains below 50%. However, by decomposing the task into two stages: dense retrieval and generative slot filling, and while still keeping our setup training-free, the models are able to attain an accuracy in a range of ≈ 50% to ≈ 67% in recipe selection, and ≈ 60% to ≈ 76% in parameter filling. Our study sheds light on the capabilities of LLMs in generating scripts for less widespread languages and opens up avenues for future research.","","979-8-3315-2615-3","10.1109/LLM4Code66737.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028329","code generation;code refactoring;LLM","Deep learning;Java;Codes;Accuracy;Large language models;Conferences;XML;Filling;Prompt engineering;Domain specific languages","","","","16","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"LLMUZZ: LLM-based seed optimization for black-box device fuzzing","G. Gao; S. Gan; X. Wang; S. Zhu","School of Artificial Intelligence and Computer Science, Jiangnan University, China; Labortory for Advanced Computing and Intelligence Engineering, Wuxi, China; Pengcheng Laboratory, Shenzhen, China; School of Artificial Intelligence and Computer Science, Jiangnan University, China","2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","4 Apr 2025","2024","","","1209","1216","As an increasing number of Internet of Things (IoT) devices are being deployed, the threat from vulnerabilities inside these devices is growing. Fuzzing is a primary method used for discovering vulnerabilities in IoT devices. The quality of the initial seeds and the seed mutation strategy are two crucial components of fuzzing that largely determine the effectiveness of the fuzzing process. However, owing to the diversity of IoT devices and the highly structured nature of inputs, designing universal seed generation and mutation strategies is extremely challenging. In this paper, we propose LLMUZZ, which is a large language model (LLM)-based black-box fuzzing approach for IoT devices. Specifically, we employ prompt engineering techniques in few-shot learning, using HTML form data from frontend files and an example HTTP request as inputs to LLMs to generate initial seeds. Then, we input the requests to be mutated into LLMs to identify the fields requiring mutation, thereby assisting in the seed mutation process. This approach ensures that the mutated seeds remain valid. Additionally, static analysis methods are utilized to discover hidden keywords within the firmware, thereby further expanding the initial seeds. In the experiments, we implement a prototype of LLMUZZ and evaluate it on 8 different IoT devices. A total of 16 previously unknown vulnerabilities are found, for which we have received 4 CVEs; the remaining vulnerabilities still under review, demonstrating that LLMUZZ has a strong capacity for vulnerability discovery.","2324-9013","979-8-3315-0620-9","10.1109/TrustCom63139.2024.00171","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10945143","Fuzzing;IoT Security;Large Language Models;Program Analysis","Reviews;Large language models;Closed box;Prototypes;Static analysis;Fuzzing;Internet of Things;Security;Prompt engineering;Microprogramming","","1","","31","IEEE","4 Apr 2025","","","IEEE","IEEE Conferences"
"Can GPT-O1 Kill All Bugs? An Evaluation of GPT-Family LLMs on QuixBugs","H. Hu; Y. Shang; G. Xu; C. He; Q. Zhang","Alibaba Cloud; State Key Laboratory for Novel Software Technology, Nanjing University, China; School of Computer Science and Technology, Chongqing University, China; University Sains Malaysia; State Key Laboratory for Novel Software Technology, Nanjing University, China",2025 IEEE/ACM International Workshop on Automated Program Repair (APR),"13 Jun 2025","2025","","","11","18","LLMs have long demonstrated remarkable effectiveness in automatic program repair (APR), with OpenAI's ChatGPT being one of the most widely used models in this domain. Through continuous iterations and upgrades of GPT-family models, their performance in fixing bugs has already reached state-of-the-art levels. However, there are few works comparing the effectiveness and variations of different versions of GPT-family models on APR. In this work, inspired by the recent public release of the GPT-o1 models, we conduct the first study to compare the effectiveness of different versions of the GPT-family models in APR. We evaluate the performance of the latest version of the GPT-family models (i.e., 01-preview and 01-mini), GPT-40oo, and the historical version of ChatGPT on APR. We conduct an empirical study of the four GPT-family models against other LLMs and APR techniques on the QuixBugs benchmark from multiple evaluation perspectives, including repair success rate, repair cost, response length, and behavior patterns. The results demonstrate that 01 's repair capability exceeds that of prior GPT-family models, successfully fixing all 40 bugs in the benchmark. Our work can serve as a foundation for further in-depth exploration of the applications of GPT-family models in APR.","","979-8-3315-2585-9","10.1109/APR66717.2025.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029663","","Costs;Conferences;Computer bugs;Maintenance engineering;Benchmark testing;Chatbots;Time factors","","","","48","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Transformer-Based Unit Test Generation","K. A. Rafique; P. Biradar; C. Grimm","University of Kaiserslautern-Landau (RPTU), Chair of Cyber-Physical Systems, Kaiserslautern, Germany; University of Kaiserslautern-Landau (RPTU), Chair of Cyber-Physical Systems, Kaiserslautern, Germany; University of Kaiserslautern-Landau (RPTU), Chair of Cyber-Physical Systems, Kaiserslautern, Germany",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","625","630","Automated test case generation reduces the manual effort of software testing, particularly for dynamic languages like Python. This study compares three transformer-based models-CodeT5, CodeBERT, and CodeGen. While CodeBERT and CodeGen were expected to excel due to their focus on code understanding and generation, CodeT5, a code summarization model, outperformed both, achieving higher code coverage and superior semantic and syntactic fidelity. Using a limited yet diverse dataset of Python functions with natural language descriptions and unit tests, we evaluated models with NLP metrics (BLEU, ROUGE-L) and practical measures like code coverage. CodeGen struggled with coherence under data constraints, while CodeBERT showed moderate effectiveness. Paired t-tests confirmed CodeT5's statistically significant advantage, highlighting that a well-adapted model can outperform more generalized architectures in realistic software testing scenarios.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050477","Natural Language Processing;Automatic Unit Test Generation;Large Language Models;Transformers;CodeT5;CodeBERT;CodeGen;Artificial Intelligence","Software testing;Measurement;Codes;Semantics;Computer architecture;Transformers;Natural language processing;Test pattern generators;Python;Software development management","","","","16","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Enhancing Web Security Using Hybrid Model","D. S. B; G. M; J. M; R. Keerthika","Artificial Intelligence and Data Science, Karpagam College of Engineering (Anna University), Coimbatore, Tamil Nadu; Artificial Intelligence and Data Science, Karpagam College of Engineering (Anna University), Coimbatore, Tamil Nadu; Artificial Intelligence and Data Science, Karpagam College of Engineering (Anna University), Coimbatore, Tamil Nadu; Artificial Intelligence and Data Science, Karpagam College of Engineering (Anna University), Coimbatore, Tamil Nadu",2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA),"31 Jul 2025","2025","","","1083","1089","It is increasingly getting attacked by the advanced attacks like XSS, SQL injection, and Remote Code Execution (RCE) which evolve much faster then traditional defences are able to hold up. As a result, we have developed a hybrid system which consists of Generative AI models like GCP, LSTMs and Transformers that detects and blocks malicious HTTP/HTTPS traffic in real time. By using Transformer models, we have boosted the accuracy of our solution to the level that it can now detect new and novel attack patterns such as sophisticated SQL injection and RCE attacks. It offers an adaptive, scalable protection for modern web applications to handle the high traffic load effectively minimizing the vulnerabilities, reducing the false positives and preventing the exploitation by the malicious queries or remote code execution. Additionally, our AI driving system helps to enhance web application firewall (WAF) ability with real time monitoring to mitigate XSS, injection SQL and RCE.","","979-8-3315-2142-4","10.1109/ICIRCA65293.2025.11089651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11089651","Generative AI;Deep Learning;Cyber Security;Web Application Firewall;Threat Detection","Deep learning;Adaptation models;Codes;Generative AI;Firewalls (computing);SQL injection;Transformers;Real-time systems;Security;Load modeling","","","","20","IEEE","31 Jul 2025","","","IEEE","IEEE Conferences"
"Leveraging GPT-like LLMs to Automate Issue Labeling","G. Colavito; F. Lanubile; N. Novielli; L. Quaranta","University of Bari, Italy; University of Bari, Italy; University of Bari, Italy; University of Bari, Italy",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","469","480","Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.CCS CONCEPTS• Software and its engineering → Documentation; Software evolution; Maintaining software; • Information systems → Clustering and classification;","2574-3864","979-8-4007-0587-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555675","LLM;Issue Labeling;GPT;Software Maintenance and Evolution;Labeling Unstructured Data","Annotations;Computational modeling;Scalability;Supervised learning;Manuals;Software;Data models","","4","","89","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Root Cause Analysis of Power Grid 5G Network Faults Based on Large Language Model","Z. Guo; J. Zou; P. Xin; X. Zhao; T. Hu; S. Zhuang; J. Sun; Y. Liu; W. Ma","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; State Grid Economic and Technological Research Institute Co., Ltd.; State Grid Economic and Technological Research Institute Co., Ltd.; School of Electrical and Electronics Engineering, North China Electric Power University, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"23 Jun 2025","2025","","","624","629","The growing complexity and diversity of 5G network architecture (e.g., power grid 5G network) have made security risk assessment and root cause analysis increasingly challenging. Recent advances in large language models (LLMs) have the potential to transform this landscape. However, existing LLMs-based solutions primarily focus on understanding the language of 5G telecommunications, while overlooking potential security vulnerabilities in the data flows. To facilitate LLMs' in-depth application, this paper presents RCA-LLM, a novel fault root cause analysis framework for 5G networks developed from tailored LLMs-based solutions. In explicit terms, RCA-LLM is trained by inputting processed and organized fault information for fine-tuning, and combined with retrieval-augmented generation (RAG) technology to significantly improve the accuracy of 5G fault analysis. Our experimental results indicate that RCA-LLM performs well in fault analysis, effectively supporting users in diagnosing and resolving fault issues. Model evaluation results further demonstrate that the model significantly improves fault analysis accuracy and has high practical value. In addition, RCA-LLM provides important reference value for efficient operation and maintenance management of 5G and future power grid networks, while also offering new ideas for advancing intelligent fault analysis.","2768-1904","979-8-3315-1305-4","10.1109/CSCWD64889.2025.11033346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033346","5G network;Root cause analysis;Signalling messages;Large language models","Training;Root cause analysis;Analytical models;Accuracy;5G mobile communication;Large language models;Transforms;Power grids;Telecommunications;Risk management","","","","27","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Poster: Exploring Explainability Techniques for Large Language Model Classification Predictions","S. Ayachitula","Ardsley High School, Ardsley, NY, USA",2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS),"22 Aug 2024","2024","","","1454","1455","Large Language Models (LLMs), such as OpenAl's GPT series, are fundamental tools in machine learning that excel in various tasks, including in-context learning. However, these models often operate as “black boxes,” offering limited insight into their decision-making processes. This paper addresses the challenge of explainability in LLMs through a novel approach, using simpler linear models like the Passive-Aggressive Classifier (PAC) as an initial jump-start mechanism to teach the LLM various rules using prompt engineering. We extract and analyze pertinent positives (PPs) as explainable rules and formulate Disjunctive Normal Form (DNF) rules. When taught to the LLM, these rules provide a clear and logical explanation of the decision-making process, enhancing the transparency of LLM predictions. Our methodology improves the interpretability of LLM outputs. The findings suggest that even complex LLM decisions can be distilled into understandable logic, facilitating better user comprehension and trust in classification predictions.","2575-8411","979-8-3503-8605-9","10.1109/ICDCS60910.2024.00148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10630978","LLMs;DNF;pertinent positives;explainability","Large language models;Decision making;Text categorization;Training data;Machine learning;Picture archiving and communication systems;Prompt engineering","","2","","4","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"MAS-Encryption and its Applications in Privacy-Preserving Classifiers","C. -z. Gao; J. Li; S. Xia; K. -K. R. Choo; W. Lou; C. Dong","School of Computer Science, Guangzhou University, Guangzhou, China; School of Computer Science and the Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, China; School of Computer Science, Guangzhou University, Guangzhou, China; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX, USA; Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; School of Computing Science, Newcastle University, Newcastle Upon Tyne, U.K",IEEE Transactions on Knowledge and Data Engineering,"1 Apr 2022","2022","34","5","2306","2323","Homomorphic encryption (HE) schemes, such as fully homomorphic encryption (FHE), support a number of useful computations on ciphertext in a broad range of applications, such as e-voting, private information retrieval, cloud security, and privacy protection. While FHE schemes do not require any interaction during computation, the key limitations are large ciphertext expansion and inefficiency. Thus, to overcome these limitations, we develop a novel cryptographic tool, MAS-Encryption (MASE), to support real-value input and secure computation on the multiply-add structure. The multiply-add structures exist in many important protocols, such as classifiers and outsourced protocols, and we will explain how MASE can be used to protect the privacy of these protocols, using two case study examples. Specifically, the first case study example is the privacy-preserving Naive Bayes classifier that can achieve minimal Bayes risk, and the other example is the privacy-preserving support vector machine. We prove that the constructed classifiers are secure and evaluate their performance using real-world datasets. Experiments show that our proposed MASE scheme and MASE based classifiers are efficient, in the sense that we achieve an optimal tradeoff between computation efficiency and communication interactions. Thus, we avoid the inefficiency of FHE based paradigm.","1558-2191","","10.1109/TKDE.2020.3009221","National Natural Science Foundation of China(grant numbers:U1936116,61772148,61802078); Guangxi Key Laboratory of Cryptography and Information Security(grant numbers:GCIS201807); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153744","MAS-encryption;homomorphism;privacy-preserving;classifiers","Privacy;Protocols;Support vector machines;Tools;Encryption;Training","","27","","65","IEEE","31 Jul 2020","","","IEEE","IEEE Journals"
"Prompt-to-SQL Injections in LLM-Integrated Web Applications: Risks and Defenses","R. Pedro; M. E. Coimbra; D. Castro; P. Carreira; N. Santos","INESC-ID/IST, Universidade de Lisboa, Portugal; INESC-ID/IST, Universidade de Lisboa, Portugal; INESC-ID/IST, Universidade de Lisboa, Portugal; INESC-ID/IST, Universidade de Lisboa, Portugal; INESC-ID/IST, Universidade de Lisboa, Portugal",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1768","1780","Large Language Models (LLMs) have found widespread applications in various domains, including web applications with chatbot interfaces. Aided by an LLM-integration middleware such as LangChain, user prompts are translated into SQL queries used by the LLM to provide meaningful responses to users. However, unsanitized user prompts can lead to SQL injection attacks, potentially compromising the security of the database. In this paper, we present a comprehensive examination of prompt-to-SQL ($\mathbf{P}_{2} \mathbf{S Q L}$) injections targeting web applications based on frameworks such as LangChain and LlamaIndex. We characterize $\mathrm{P}_{2} \text{SQL}$ injections, exploring their variants and impact on application security through multiple concrete examples. We evaluate seven state-of-the-art LLMs, demonstrating the risks of $P_{2}$ SQL attacks across language models. By employing both manual and automated methods, we discovered $\mathrm{P}_{2} \text{SQL}$ vulnerabilities in five real-world applications. Our findings indicate that LLMintegrated applications are highly susceptible to $\mathrm{P}_{2} \text{SQL}$ injection attacks, warranting the adoption of robust defenses. To counter these attacks, we propose four effective defense techniques that can be integrated as extensions to the LangChain framework.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00007","Fundação para a Ciência e Tecnologia(grant numbers:UIDB/50021/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029790","SQL;Prompt Injection;Large Language Models;Prompt-to-SQL","Structured Query Language;Translation;Databases;Large language models;Manuals;SQL injection;Chatbots;Security;Middleware;Software engineering","","1","","63","CCBYNCND","23 Jun 2025","","","IEEE","IEEE Conferences"
"NFV-based Security Estimation and Classification Approaches for AIGC-enabled Edge Networks","C. Wang; D. Zheng; H. Xing; W. Tang; H. Xu; Y. Zhong; X. Cao","School of Computing and Artificial Intelligence, Southwest Jiaotong University, Sichuan, China; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Sichuan, China; Department of Information Technology, Kennesaw State University, USA; School of Cyber Science and Engineering, Sichuan University, China; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Sichuan, China; Department of Computer Science, Georgia State University, GA, USA; Department of Computer Science, Georgia State University, GA, USA",IEEE Transactions on Network Science and Engineering,"","2025","PP","99","1","17","The rapid deployment of Pre-trained Foundation Models (PFMs) on edge servers has recently facilitated the efficient and scalable delivery of AI-Generated Content (AIGC) services. However, this convenience introduces a critical security problem: a compromised server can propagate malicious content across the network at scale. To mitigate such risks, service providers must integrate security-aware network functions (SNFs) within both hardware and software implementations into their infrastructure. Following this, a fundamental challenge remains: accurately estimating and categorizing security levels (SeLs) within such a framework. This work addresses the above challenge by pioneering a methodology for estimating and classifying the SeL of PFM-hosting servers. First, we introduce the security intensity identifier (SeII), a novel indicator designed to assess security strength. We then propose an innovative SeL calculation methodology that accurately estimates the SeL of PFM-hosting servers. Subsequently, we propose security level indicators (SeLIs) and classify servers with different S-NF sets into different security classes (SeCs) with distinct SeL ranges. Building upon this estimation and classification framework, we design a cost-efficient security complementation scheme for PFMhosting servers, tailored to the diverse security needs of AIGC services. Our extensive experimental results demonstrate that the proposed scheme significantly outperforms state-of-the-art benchmarks, showing an average improvement of 21.77% and 51.77% in implementation cost, respectively","2327-4697","","10.1109/TNSE.2025.3593234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098636","AI-generated content;Pre-trained foundation model;Security level estimation;Security classification","Security;Servers;Estimation;Service function chaining;Internet of Things;Optimization;Data security;Costs;Protection;Software","","","","","IEEE","28 Jul 2025","","","IEEE","IEEE Early Access Articles"
"Towards Automatic Mapping of Vulnerabilities to Attack Patterns using Large Language Models","S. S. Das; A. Dutta; S. Purohit; E. Serra; M. Halappanavar; A. Pothen","Purdue University; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory, Boise State University; Pacific Northwest National Laboratory; Purdue University",2022 IEEE International Symposium on Technologies for Homeland Security (HST),"30 Jan 2023","2022","","","1","7","Cyber-attack surface of an enterprise continuously evolves due to the advent of new devices and applications with inherent vulnerabilities, and the emergence of novel attack techniques that exploit these vulnerabilities. Therefore, security management tools must assess the cyber-risk of an enterprise at regular intervals by comprehensively identifying associations among attack techniques, weaknesses, and vulnerabilities. How-ever, existing repositories providing such associations are incomplete (i.e., missing associations), which increases the likelihood of undermining the risk of specific set of attack techniques with missing information. Further, such associations often rely on manual interpretations that are slow compared to the speed of attacks, and therefore, ineffective in combating the ever increasing list of vulnerabilities and attack actions. Therefore, developing methodologies to associate vulnerabilities to all relevant attack techniques automatically and accurately is critically important. In this paper, we present a framework - Vulnerabilities and Weakness to Common Attack Pattern Mapping (VWC-MAP) - that can automatically identify all relevant attack techniques of a vulnerability via weakness based on their text descriptions, applying natural language process (NLP) techniques. VWC-MAP is enabled by a novel two-tiered classification approach, where the first tier classifies vulnerabilities to weakness, and the second tier classifies weakness to attack techniques. In this work, we improve the scalability of the current state-of-the-art tool to significantly speedup the mapping of vulnerabilities to weaknesses. We also present two novel automated approaches for mapping weakness to attack techniques by applying Text-to-Text and link prediction techniques. Our experimental results are cross-validated by cyber-security experts and demonstrate that VWC-MAP can associate vulnerabilities to weakness-types with up to 87% accuracy, and weaknesses to new attack patterns with up to 80% accuracy.","","978-1-6654-9404-5","10.1109/HST56032.2022.10025459","U.S. Department of Energy (DOE); Higher Education Research Council(grant numbers:IGEM22-001); Pacific Northwest National Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025459","","Security management;Scalability;Natural languages;US Department of Homeland Security;Manuals;Cyberattack","","4","","15","IEEE","30 Jan 2023","","","IEEE","IEEE Conferences"
"Chat2Code: A Chatbot for Model Specification and Code Generation, The Case of Smart Contracts","I. Qasse; S. Mishra; B. þ. Jónsson; F. Khomh; M. Hamdaqa","Department of Computer Science, Reykjavik University, Reykjavik, Iceland; School of Computer and Communication Sciences, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland; Department of Computer Science, Reykjavik University, Reykjavik, Iceland; Department of Computer and Software Engineering, Polytechnique Montreal, Montreal, Canada; Department of Computer Science, Reykjavik University, Reykjavik, Iceland",2023 IEEE International Conference on Software Services Engineering (SSE),"4 Sep 2023","2023","","","50","60","The potential of automatic code generation through Model-Driven Engineering (MDE) frameworks has yet to be realized. Beyond their ability to help software professionals write more accurate, reusable code, MDE frameworks could make programming accessible for a new class of domain experts. However, domain experts have been slow to embrace these tools, as they still need to learn how to specify their applications' requirements using the concrete syntax (i.e., textual or graphical) of the new and unified domain-specific language. Conversational interfaces (chatbots) could smooth the learning process and offer a more interactive way for domain experts to specify their application requirements and generate the desired code. If integrated with MDE frameworks, chatbots may offer domain experts with richer domain vocabulary without sacrificing the power of agnosticism that unified modelling frameworks provide. In this paper, we discuss the challenges of integrating chatbots within MDE frameworks and then examine a specific application: the auto-generation of smart contract code based on conversational syntax. We demonstrate how this can be done and evaluate our approach by conducting a user experience survey to assess the usability and functionality of the chatbot framework. The paper concludes by drawing attention to the potential benefits of leveraging Language Models (LLMs) in this context.","","979-8-3503-4075-4","10.1109/SSE60056.2023.00018","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:2023–05484,218202–051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234336","Model-driven Engineering;Automatic Code Generation;Chatbots;Smart Contracts;Blockchain;Natural Language Processing","Surveys;Vocabulary;Codes;Smart contracts;Oral communication;Syntactics;Chatbots","","4","","27","IEEE","4 Sep 2023","","","IEEE","IEEE Conferences"
"Ethereum Blockchain-Based Peer-To-Peer Energy Trading Platform","A. Iskakova; H. S. V. S. Kumar Nunna; P. Siano","Department of Electrical and Computer Engineering, Nazarbayev University, Nur-Sultan, Kazakhstan; Department of Electrical and Computer Engineering, Nazarbayev University, Nur-Sultan, Kazakhstan; Department of Management and Innovation Systems, University of Salerno, Salerno, Italy",2020 IEEE International Conference on Power and Energy (PECon),"13 Jan 2021","2020","","","327","331","Blockchain is one of the emerging security technologies that have enormous potential in diverse sectors such as financial organization, academic institutions, national government, business sphere. In this paper, we focus on the application of blockchain systems in the energy industry addressing potential challenges and limitations in this area. The deployment of the proliferation of distributed energy resources requires an efficient and reliable transactive energy (TE) management system in terms of peer-to-peer energy trading. Independence of the energy management system from financial transactions can cause an insecure and vulnerable energy exchange environment. The proposed system design focuses on eliminating gaps in the security by the integration of decentralized application technology with the TE management and Multi-Agent System. The paper discusses the Ethereum blockchain-based peer-to-peer energy trading platform based on the enforced smart contract that controls both financial transactions and energy interchange operations for power trading systems.","","978-1-7281-7068-8","10.1109/PECon48942.2020.9314591","Nazarbayev University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314591","Transactive Energy Management Systems;Blockchain;Ethereum;Decentralized Application;Smart Contract;Multi-Agent Systems;JADE","Blockchain;Peer-to-peer computing;Transactive energy;Microgrids;Smart contracts;Security;Servers","","12","","27","IEEE","13 Jan 2021","","","IEEE","IEEE Conferences"
"AutoPAC: Exploring LLMs for Automating Policy to Code Conversion in Business Organizations","N. Chowdhary; T. Dutta; S. Chattopadhyay; S. Chakraborty","IIT, Kharagpur, India; IIT, Kharagpur, India; IDRBT, Hyderabad, India; IIT, Kharagpur, India",2025 17th International Conference on COMmunication Systems and NETworks (COMSNETS),"20 Feb 2025","2025","","","667","675","Managing systems and network policies for large-scale organizations is challenging for business process automation. Although Policy-as-code (PAC) platforms can ease the task of policy management by defining and executing systems and network policies in the form of programmable codes, converting existing organizational policies into PAC-compliant code is not straightforward due to the need for complex dependency resolutions across platforms and applications. On the other hand, policymakers/top management of a business prefer natural language (NL)-based policies that are easy to comprehend. This paper explores large language models (LLMs) to facilitate the automated conversion of NL-based policies to PAC-complaint code. We observe that public LLMs like ChatGPT need thorough multi-round prompt engineering to generate PAC policies. This concerns privacy and security as the organizational policies are sensitive business information. Consequently, we explore using a private and personalized setup, like private LLMs. Notably, we observe that existing personalized LLMs like PrivateGPT fail to understand the system-specific policy semantics. Consequently, we develop a framework called AutoPAC, which uses a micro-service architecture coupled with fine-tuned models to generate and validate PAC-complaint policies over a personalized LLM framework. An evaluation with more than 100 test cases indicates that the proposed framework effectively generates and validates PAC policies on the fly.","2155-2509","979-8-3315-3119-5","10.1109/COMSNETS63942.2025.10885751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885751","Policy Management;LLM;PrivateGPT;OPA","Privacy;Codes;Large language models;Semantics;Natural languages;Organizations;Picture archiving and communication systems;Security;Prompt engineering;Organizational aspects","","","","43","IEEE","20 Feb 2025","","","IEEE","IEEE Conferences"
"Generating Parathyroid Reports Using YOLO-Based Large Language Models","C. -Y. Chang; A. Khanum; C. -Y. Sun; Y. -T. Chen; Y. -C. Tsai; C. -C. Hsu","Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Yunlin, Taiwan; Intelligent Recognition Industry Service Research Center, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Diagnostic Radiology, Keelung Chang Gung Memorial Hospital, Keelung, Taiwan; Department of Nephrology, Keelung Chang Gung Memorial Hospital, Keelung, Taiwan; Department of Diagnostic Radiology, Keelung Chang Gung Memorial Hospital, Keelung, Taiwan; Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Yunlin, Taiwan",IEEE Access,"8 Aug 2025","2025","13","","137579","137591","Different tissues and structures in ultrasound produce varying sound wave reflections, resulting in black-and-white grayscale images. Radiologists review thousands of medical images daily and write detailed reports. In parathyroid ultrasound imaging, their reports must go beyond routine observations, providing a comprehensive analysis highlighting the lesion’s type, size, and exact location. This critical information forms the foundation for accurate diagnoses and personalized treatment plans, underscoring the vital role of radiologists in modern medical care. This study presents a novel system for generating automated medical reports from parathyroid ultrasound images focusing on critical diagnostic parameters such as size, type, structure, location, homogeneity, and echogenicity through effective lesion recognition and localization. The proposed system, medical report generation for parathyroid ultrasound (MrGPU-GPT), integrates advanced image processing and natural language generation to streamline clinical workflows and improve diagnostic accuracy. The MrGPU-GPT employs a modified YOLOv7-based architecture, YOLO-BiFPN, to detect and localize lesions within the ultrasound images. Subsequently, key lesion characteristics, including homogeneity and echogenicity, are extracted and utilized for prompt engineering. These prompts are then fed into a fine-tuned Vicuna language model, which generates detailed and precise medical reports. The system provides annotated ultrasound images with bounding boxes and offers comprehensive-textual descriptions in the form of medical reports, significantly reducing the reporting burden on radiologists. Combining image-based diagnostic insights with advanced natural language processing minimizes errors caused by human factors such as inexperience or fatigue, offering robust support for radiologists. The resulting system improves the efficiency and reliability of clinical workflows, delivering accurate diagnostic information while improving patient care outcomes. The experimental results show that, in classifying the lesion, detecting objects, and recognizing position markers, the system achieved a mAP of 93.32%, 91.04%, and 99.65% in the validation of the K-Fold. In medical report generation, compared to MiniGPT, our method, using cosine similarity, ROUGE, and BLEU metrics, along with physician feedback, can generate medical reports with higher similarity scores. (MrGPU-GPT) was deployed on a local computer, developing a medical report in about 3-5 seconds to identify parathyroid images and a medical report.","2169-3536","","10.1109/ACCESS.2025.3595504","“Intelligent Recognition Industry Service Center” from the Featured Areas Research Center Program within the framework of the Higher Education Sprout Project; Ministry of Education (MOE) in Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112831","Parathyroid gland;object detection;large language model;medical report;MiniGPT-4;YOLO","Lesions;Biomedical imaging;Ultrasonic imaging;Medical diagnostic imaging;Accuracy;Neck;Medical services;Large language models;Imaging;Thyroid","","","","31","CCBY","4 Aug 2025","","","IEEE","IEEE Journals"
"Fault Location and Isolation Technique in Smart Distribution Systems with Distributed Generation","A. Mohamed; B. Younes; T. Lamhamdi; H. El Moussaoui; H. El Markhi","Intelligent Systems, Georesources and Renewable Energies Laboratory, Sidi Mohamed Ben Abdellah University, FST Fez, Morocco; Intelligent Systems, Georesources and Renewable Energies Laboratory, Sidi Mohamed Ben Abdellah University, FST Fez, Morocco; Intelligent Systems, Georesources and Renewable Energies Laboratory, Sidi Mohamed Ben Abdellah University, FST Fez, Morocco; Intelligent Systems, Georesources and Renewable Energies Laboratory, Sidi Mohamed Ben Abdellah University, FST Fez, Morocco; Intelligent Systems, Georesources and Renewable Energies Laboratory, Sidi Mohamed Ben Abdellah University, FST Fez, Morocco","2020 1st International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)","14 May 2020","2020","","","1","5","This paper proposes a new multiagent system algorithm to increase the security and protection of power systems. The multi-agent system (MAS) proposed for fault location, distance estimation, and automatic power restoration in a distribution system with renewable Distributed Generation (DG). The smart agents proposed consisting of many nodes (agents) to collect the real-time data and power flow between different physical processes from power networks, for fault location and power system control. To test the multi-agent system proposed we used a part of Kenitra city distribution system in Morocco with the integration of wind power. The simulation present that the proposed approach for fault location and power restoration significantly improves the reliability of power systems.","","978-1-7281-4979-0","10.1109/IRASET48871.2020.9092095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092095","Smart grid;Renewable Distributed Generation;Multi-Agent Systems;Fault location;MACSimJX","Renewable energy sources;Simulation;Urban areas;Fault location;Wind power generation;Distributed power generation;Smart grids;Security;Reliability;Multi-agent systems","","3","","13","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Defense for Displacement Attacks on Distributed Formation Control Systems","Y. Yang; Y. Xiao; T. Li; K. Liu","School of Navigation, Wuhan University of Technology, Wuhan, China; Department of Computer Science, the University of Alabama, Tuscaloosa, AL, USA; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Navigation, Wuhan University of Technology, Wuhan, China",IEEE Transactions on Network Science and Engineering,"20 Nov 2024","2024","11","6","6560","6573","As an effective multi-agent system (MAS) control method, formation control is widely used in uncrewed systems, such as uncrewed surface/underwater/aerial vehicles and spacecrafts. However, the security issues of formation control have received little attention. Compared with traditional industry systems (such as smart grids or intelligence appliances), designing countermeasure approaches for distributed formation systems under attacks has several challenges, such as limited local information, robot mobility, and a chain reaction of attacks. In this paper, based on a classical formation control law on a group of robots, we concentrate on maintaining an acceptable formation performance under Man-in-the-Middle-based (MITM-based) displacement attacks. The MITM-based displacement attacks can utilize the property of formation maintenance and hijack the whole robot group. We propose two kinds of novel countermeasure approaches. An active approach, which is named the comparison-based identification and elimination (CIE) algorithm, can identify attack messages and calculate estimate values to replace attack messages based on local information. A passive approach can tolerate attack effects by designing a task priority adjustment (TPA) controller. The TPA controller can gradually adjust the formation maintenance priority to degrade attack effects. Simulation with several nonholonomic differentially driven mobile robots is conducted, and results show that our schemes can significantly decrease the impact of constant and time-varying attacks.","2327-4697","","10.1109/TNSE.2024.3457382","National Key Research and Development Program of China(grant numbers:2023YFB2603800); Fundamental Research Funds for the Central Universities(grant numbers:WUT: 2024IVA046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670489","Distributed formation control;multi-agent systems (MAS);man-in-the-middle attacks;cybersecurity","Robots;Formation control;Robot kinematics;Service robots;Maintenance;Industries;Wireless communication","","1","","57","IEEE","10 Sep 2024","","","IEEE","IEEE Journals"
"LeoDroid: An LLM-Based Few-Shot Multi-Label Detection for Android Malware","M. Dong; L. Liu; Q. Guo; H. Bai; R. Gong; Y. Bai; W. He; Z. Wang; G. Xu; J. Zhang","School of Software, Tiangong University, Tianjin, China; College of Computer Science and Technology, Jilin University, Jilin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; School of Software, Tiangong University, Tianjin, China; School of Software, Tiangong University, Tianjin, China; School of Artificial Intelligence, Hebei University of Technology, Tianjin, China; School of Software, Tiangong University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; University of Southern Queensland, Queensland, Australia",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","294","306","Data noise poses a fundamental challenge in Android malware detection that significantly degrades the performance of machine learning models. Traditional approaches using third-party services like VirusTotal introduce inconsistencies from malware evolution and temporal label variations, while deep learning methods struggle with noisy data due to their reliance on large clean datasets and their tendency to memorize rather than generalize from noisy labels. To address these challenges, we propose the LLM-based Few-shot Multi-Label Malware Detection (LeoDroid), a novel framework that enhances malware detection robustness in both noisy and data-scarce environments, which are enabled by Large Language Models (LLMs). Our approach employs a two-stage process that integrates a core-set strategy for selecting representative samples with a carefully designed prompt engineering methodology. The prompt design combines label descriptions, core-set examples, and chain-of-thought reasoning to guide large language models in multi-label classification tasks. Through this integration, LeoDroid effectively manages the balance between sample size and noise tolerance to maintain high detection accuracy. We evaluate our framework on three real-world datasets-anonymousCERT, Drebin, and VirusShare. The experimental results demonstrate exceptional performance with an MS-ACC above 0.93 across all datasets, surpassing traditional machine learning methods by more than three times on the anonymousCERT.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00042","National Key R&D Program of China(grant numbers:2023YFB2703800); National Natural Science Foundation of China(grant numbers:62302148,62172297,62172372); Hebei Natural Science Foundation(grant numbers:F2024202076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050827","Large Language Models;Android malware de-tection;Few-shot learning;Multi-label classification;Core-set;android malware detection","Technological innovation;Accuracy;Computer viruses;Large language models;Noise;Training data;Multi label classification;Cognition;Noise measurement;Security","","","","51","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Generative AI Meets Semantic Communications: Opportunities, Challenges and Security Risks","P. Ren; J. Wang; J. Chen; X. Hou; H. Du; C. Jiang","School of Cyber Science and Technology, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China",IEEE Network,"","2025","PP","99","1","1","Semantic communication (SC) leverages artificial intelligence (AI) to extract task-relevant semantic information based on specific requirements, enabling more efficient communication, which is regarded as one of the critical components for future 6G intelligent networks. Meanwhile, generative AI (GAI), a significant technological breakthrough in recent years, is renowned for its semantic extraction capabilities and data generation creativity. Inspired by this, in this paper, we explore the integration of GAI into SC, focusing on technological intersection and security risks. We begin with a comprehensive overview of SC and GAI, analyzing the current challenges. Subsequently, we elaborate on how GAI can optimize SC from multiple perspectives, including semantic extraction, data transmission and cloud-edge deployment. In particular, we focus on security and privacy issues within the GAI-enhanced SC architecture. Finally, we validate the feasibility of our theory through a case study and outline potential directions for future research.","1558-156X","","10.1109/MNET.2025.3579132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11031245","Generative artificial intelligence;semantic communication;6G networks;wireless communications","Semantics;Artificial intelligence;Training;Noise;Security;Receivers;Generative adversarial networks;Data mining;Probability distribution;6G mobile communication","","","","","IEEE","12 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Latency-Driven Execution of LLM-Generated Application Code on the Computing Continuum","K. Rao; G. Coviello; C. G. De Vita; G. Mellone; M. A. Khojastepour; S. Chakradhar","NEC Laboratories America, Inc., USA; NEC Laboratories America, Inc., USA; University of Naples “Parthenope”, USA; University of Naples “Parthenope”, USA; NEC Laboratories America, Inc., USA; NEC Laboratories America, Inc., USA","2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)","1 Jul 2025","2025","","","17","25","Latency-critical applications demand quick responses. Ideally, detailed insights are preferable for the best decision making and response actions. However, in situations when detailed insights cannot be provided quickly, even basic information goes a long way in tackling the situation effectively. For example, in marine security application, it is critical to immediately notify as soon as an unauthorized vessel is seen. Hence, timely response may be prioritized over the response based on entire details. To address such latency-critical situations, in this paper, we propose a novel system called DiCE-EC, which leverages LLM to generate distributed code with speculative execution on Edge (fast and simple response using resource-constrained hardware) and Cloud (detailed response using powerful hardware, but may be fast or slow depending on network conditions). DiCE-EC breaks down application into smaller components and executes them asynchronously across the edge and cloud computing continuum. As network conditions vary, we show through real-world marine security application, that DiCE-EC is effective in dynamically choosing detailed insights from cloud when received within latency-constraint, or falling back to simple response from edge to guarantee timely alert delivery. Without such dynamic selection of response from edge or cloud, existing systems either always provide simple responses or drop alerts. We perform real network measurements in the Gulf of Pozzuoli in Naples, Italy along accessible areas (inland and in a Ferry) and generate 1 million realistic measurements across four inaccessible regions, and demonstrate that DiCE-EC never misses an alert, while baseline misses up to ~4 % alerts with real data and up to ~1% (10,000 alerts) with generated data.","","979-8-3315-0938-5","10.1109/CCGridW65158.2025.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044757","Edge computing;Cloud computing;Large Language Models (LLM);Automatic code generation and execution;Dynamic control flow;Latency-critical applications","Cloud computing;Codes;Large language models;Conferences;Area measurement;Decision making;Data transfer;Hardware;Security;Edge computing","","","","29","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Leveraging LLMs for the Quality Assurance of Software Requirements","S. Lubos; A. Felfernig; T. N. T. Tran; D. Garber; M. El Mansi; S. P. Erdeniz; V. -M. Le","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria",2024 IEEE 32nd International Requirements Engineering Conference (RE),"21 Aug 2024","2024","","","389","397","Successful software projects depend on the quality of software requirements. Creating high-quality requirements is a crucial step toward successful software development. Effective support in this area can significantly reduce development costs and enhance the software quality. In this paper, we introduce and assess the capabilities of a Large Language Model (LLM) to evaluate the quality characteristics of software requirements according to the ISO 29148 standard. We aim to further improve the support of stakeholders engaged in requirements engineering (RE). We show how an LLM can assess requirements, explain its decision-making process, and examine its capacity to propose improved versions of requirements. We conduct a study with software engineers to validate our approach. Our findings emphasize the potential of LLMs for improving the quality of software requirements.","2332-6441","979-8-3503-9511-2","10.1109/RE59067.2024.00046","Austrian Research Promotion Agency (FFG)(grant numbers:886205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628462","requirements engineering;software requirements;large language model;quality assurance;quality improvement;empirical study","ISO Standards;Decision making;Software quality;Software;Software reliability;Requirements engineering;Stakeholders","","9","","30","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
