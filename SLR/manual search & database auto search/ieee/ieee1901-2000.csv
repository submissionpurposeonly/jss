"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Leveraging Few-Shot Learning in Generative AI for UPI Transaction Classification","C. Jain; N. N; D. Shah; R. Basant","School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, India",2024 5th IEEE Global Conference for Advancement in Technology (GCAT),"20 Mar 2025","2024","","","1","7","Classifying financial transactions based on individual needs is a vital and often complex task. Ranging from a college student who manages monthly expenses based on their allowance to a working professional preparing an annual income tax report, both require a tailored classification of finances to ensure smart spending and financial management. The recent invention of Unified Payments Interface (UPI) and constantly increasing UPI IDs have made classifying finances an extremely tedious and complex task, making supervised learning an impractical option. To tackle this problem, we propose a novel Few-Shot Learning architecture leveraging state-of-the-art Large Language Models (LLM), offering high accuracy in multi-class data classification. This prompt-based 3-way 4-shot learning utilizes the Llama 3.1 8 billion parameters model, which provides fast and efficient results on compact systems while ensuring privacy. Key findings include the importance of prompt engineering while highlighting the efficiency of few-shot learning in the finance sector. It also highlights the efficiency of open-source LLMs in task-focused applications without relying on resource-intensive models.","","979-8-3503-7668-5","10.1109/GCAT62922.2024.10923925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10923925","UPI;Few-Shot Learning;Large Language Model;Unsupervised Learning;Financial Transactions Classification","Technological innovation;Privacy;Large language models;Supervised learning;Finance;Distance measurement;Prompt engineering;Few shot learning;Unsupervised learning;Financial industry","","","","20","IEEE","20 Mar 2025","","","IEEE","IEEE Conferences"
"Aspect-Oriented Opinion Extraction with LoRA Fine-Tuning and Prompt","H. Yanagimoto; I. Kisaku; K. Hashimoto","Graduate School of Informatics, Osaka Metropolitan University, Osaka, Japan; School of Knowledge and Information Systems, Osaka Prefecture University, Osaka, Japan; Faculty of Information Science, Shunan University, Yamaguchi, Japan",2024 17th International Congress on Advanced Applied Informatics (IIAI-AAI-Winter),"14 Jul 2025","2024","","","65","70","This paper proposes a system for Aspect-Oriented Opinion Pair Extraction (AOPE) by fine-tuning a pre-trained large language model with LoRA and adjusting prompts. AOPE is a task that extracts users' aspects and their opinions from reviews, requiring a deep understanding of text, especially capturing the dependency structures within reviews. Pre-trained large language models have a high capability for text comprehension, so the goal is to utilize this effectively. However, adapting a pre-trained large language model to a specific task is challenging. Fine-tuning demands substantial computational resources, and generating appropriate prompts for each task is a laborious process. Our proposed method uses LoRA to reduce the computational resources needed for fine-tuning and combines prompts to improve performance. Evaluation experiments demonstrated that combining prompts with fine-tuning improved accuracy. While there are some areas where accuracy is lower than traditional methods, the efficiency in computational resources highlights the effectiveness of the proposed approach.","","979-8-3315-4380-8","10.1109/IIAI-AAI-Winter65925.2024.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071497","Large Language Model;Deep Learning;Prompt engineering;Fine-tuning;Natural language processing","Deep learning;Vocabulary;Accuracy;Reviews;Large language models;Natural language processing;Computational efficiency;Prompt engineering;Informatics;Testing","","","","25","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Deep Learning-based Code Reviews: A Paradigm Shift or a Double-Edged Sword?","R. Tufano; A. Martin-Lopez; A. Tayeb; O. Dabić; S. Haiduc; G. Bavota","Software Institute - USI Università della Svizzera italiana, Switzerland; Florida State University, United States; Florida State University, United States; Software Institute - USI Università della Svizzera italiana, Switzerland; Florida State University, United States; Software Institute - USI Università della Svizzera italiana, Switzerland",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1640","1652","Several techniques have been proposed to (partially) automate code review. Early support consisted in recommending the most suited reviewer for a given change or in prioritizing the review tasks. With the advent of deep learning in software engineering, the level of automation has been pushed to new heights, with approaches able to provide feedback on source code in natural language as a human reviewer would do. Also, recent work documented open source projects adopting Large Language Models (LLMs) as co-reviewers. Although the research in this field is very active, little is known about the actual impact of including automatically generated code reviews in the code review process. While there are many aspects worth investigating (e.g., is knowledge transfer between developers affected?), in this work we focus on three of them: (i) review quality, i.e., the reviewer's ability to identify issues in the code; (ii) review cost, i.e., the time spent reviewing the code; and (iii) reviewer's confidence, i.e., how confident is the reviewer about the provided feedback. We run a controlled experiment with 29 professional developers who reviewed different programs with/without the support of an automatically generated code review. During the experiment we monitored the reviewers' activities, for over 50 hours of recorded code reviews. We show that reviewers consider valid most of the issues automatically identified by the LLM and that the availability of an automated review as a starting point strongly influences their behavior: Reviewers tend to focus on the code locations indicated by the LLM rather than searching for additional issues in other parts of the code. The reviewers who started from an automated review identified a higher number of low-severity issues while, however, not identifying more high-severity issues as compared to a completely manual process. Finally, the automated support did not result in saved time and did not increase the reviewers' confidence.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029823","Code review;Controlled Experiment","Deep learning;Codes;Reviews;Source coding;Large language models;Natural languages;Manuals;Monitoring;Knowledge transfer;Software engineering","","","","66","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"AI-Based Attacker Models for Enhancing Multi-Stage Cyberattack Simulations in Smart Grids Using Co-Simulation Environments","Ö. Sen; C. Pohl; I. Hacker; M. Stroot; A. Ulbig","RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany",2024 IEEE International Conference on Cyber Security and Resilience (CSR),"24 Sep 2024","2024","","","68","75","The transition to smart grids has increased the vulnerability of electrical power systems to advanced cyber threats. To safeguard these systems, comprehensive security measures-including preventive, detective, and reactive strategies-are necessary. As part of the critical infrastructure, securing these systems is a major research focus, particularly against cyberattacks. Many methods are developed to detect anomalies and intrusions and assess the damage potential of attacks. However, these methods require large amounts of data, which are often limited or private due to security concerns. We propose a co-simulation framework that employs an autonomous agent to execute modular cyberattacks within a configurable environment, enabling reproducible and adaptable data generation. The impact of virtual attacks is compared to those in a physical lab targeting real smart grids. We also investigate the use of large language models for automating attack generation, though current models on consumer hardware are unreliable. Our approach offers a flexible, versatile source for data generation, aiding in faster prototyping and reducing development resources and time.","","979-8-3503-7536-7","10.1109/CSR61664.2024.10679448","BMBF(grant numbers:03SF0694A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679448","Smart Grid;Cybersecurity;Cyberattack;AI-based Attack;Large Language Models","Large language models;Noise;Virtual environments;Data models;Smart grids;Topology;Power systems","","2","","17","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"AI-Enhanced Security Architecture for 6G Networks: A Federated Learning and Multi-Agent Approach","V. V. Teresa; J. Dhanaseker; S. Arjun; R. Naveenraj; A. Antru Subil; P. Ahmed Najeeb","Department of ECE, Sri Eshwar College of Engineering, Coimbatore; Department of ECE, Sri Eshwar College of Engineering, Coimbatore; Department of ECE, Sri Eshwar College of Engineering, Coimbatore; Department of ECE, Sri Eshwar College of Engineering, Coimbatore; Department of ECE, Sri Eshwar College of Engineering, Coimbatore; Department of ECE, Sri Eshwar College of Engineering, Coimbatore",2024 International Conference on Computing and Intelligent Reality Technologies (ICCIRT),"18 Mar 2025","2024","","","303","308","The coming 6G network is expected to provide better connectivity and network performance but will generate new security challenges. In this paper, we demonstrate a novel technological solution to address the security challenges of the 6G network by combining artificial intelligence with federated learning and multi-agent systems. Federated learning enables the distributed learning of data in the network without revealing the data’s confidentiality. In the meantime, multi-agent systems use intelligent autonomous agents that are equipped to quickly identify and handle any potential threat in a variety of network environments. In combination, these technologies constitute a system-on-system (SoS) type, end-to-end security architecture that is modular, dynamic, and self-contained, consistent with ultra-reliability requirements, high device count in the terahertz regime, and wide-ranging traffic data found in 6G. Through simulations and case studies, this paper demonstrates that the proposed method significantly enhances the accuracy of threat detection and response, as well as improves the efficiency of threat mitigation and the overall security compliance of the network for a more secure and robust 6G environment.","","979-8-3315-1029-9","10.1109/ICCIRT59484.2024.10921972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921972","component;formatting;style;styling;insert (key words)","6G mobile communication;Accuracy;Federated learning;Computational modeling;Computer architecture;Threat assessment;Security;Artificial intelligence;Stress;Multi-agent systems","","","","15","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"Reducing Alert Fatigue via AI-Assisted Negotiation: A Case for Dependabot","R. G. Kula","Osaka University, Japan",2025 IEEE/ACM International Workshop on Bots in Software Engineering (BotSE),"26 Jun 2025","2025","","","11","12","The increasing complexity of software dependencies has led to the emergence of automated dependency management tools, such as Dependabot. However, these tools often overwhelm developers with a high volume of alerts and notifications, leading to alert fatigue. This paper presents a position on using Artificial Intelligence (AI) agents as dependency negotiators to reduce alert fatigue. We then examine specific use cases where AI agents can facilitate dependency negotiations, such as when working with external dependencies or managing complex, multi-component systems. Our findings highlight the need for more research on the design and evaluation of AI-driven dependency mediation mechanisms. With a focus on ensuring transparency, explainability, and human trustworthiness in these GitHub software projects, our goal is to reduce alert fatigue to an extent that maintainers no longer feel overwhelmed and welcome pull requests just like any other contribution into their projects","","979-8-3315-2708-2","10.1109/BotSE67031.2025.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050821","Generative AI;Security Supply Chain","Generative AI;Conferences;Supply chains;Fatigue;Software;Complexity theory;Security;Mediation;Software engineering;Software development management","","","","8","IEEE","26 Jun 2025","","","IEEE","IEEE Conferences"
"CLogLLM: A Large Language Model Enabled Approach to Cybersecurity Log Anomaly Analysis","H. Ren; K. Lan; Z. Sun; S. Liao","The 30th Research Institute of China Electronics, Technology Group Corporation, Chengdu, China; The 30th Research Institute of China Electronics, Technology Group Corporation, Chengdu, China; The 30th Research Institute of China Electronics, Technology Group Corporation, Chengdu, China; The 30th Research Institute of China Electronics, Technology Group Corporation, Chengdu, China",2024 4th International Conference on Electronic Information Engineering and Computer Communication (EIECC),"25 Mar 2025","2024","","","963","970","Log data is commonly used to record the status of the system and the events that occur, which are often used to assist security staff to determine whether the system is abnormal, diagnose problems, troubleshooting. However, with the increasing complexity of the system, the log data becomes more and more numerous and complex, Therefore the analysis of the log becomes extremely difficult. Not coincidentally, with the emergence of various system software updates, traditional deep learning-based anomaly detection methods, which rely on pre-existing data for training, often struggle to maintain their effectiveness. At the same time, simply detecting anomalies in significant number of complex log data is no longer meet operational needs. Therefore, LLM which is capable of realizing zero-shot learning and text generation has attracted attention. This paper proposed method which is based on the implementation of LLMs for security log detection and analysis. The approach involves fine-tuning the LLMs to improve their adaptability to complex and diverse log data. Moreover, It incorporates two advanced prompt engineering techniques, ToT and Self-Refine, while also exploring the combination of existing techniques such as CoT and In-Context prompting. These three different prompt engineering methods significantly enhance the LLMs' the accuracy in log anomaly detection and the quality in generation of log anomaly analysis.","","979-8-3315-3462-2","10.1109/EIECC64539.2024.10929078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929078","LLM;prompt engineering;log anomaly detection","Training;Accuracy;Large language models;Zero shot learning;System software;Complexity theory;Prompt engineering;Computer security;Anomaly detection","","","","20","IEEE","25 Mar 2025","","","IEEE","IEEE Conferences"
"Enhancing Email Safety: Harnessing ML, DL, and LLM Models for Spam Detection","T. Halder; A. Y. Srizon; N. T. Esha; S. M. Mahedy Hasan; M. F. Faruk; M. R. Hossain","Department of CSE, RUET, Rajshahi, Bangladesh; Department of CSE, RUET, Rajshahi, Bangladesh; Department of Statistics, University of Rajshahi, Rajshahi, Bangladesh; Department of CSE, RUET, Rajshahi, Bangladesh; Department of CSE, RUET, Rajshahi, Bangladesh; Department of CSE, RUET, Rajshahi, Bangladesh","2024 IEEE International Conference on Power, Electrical, Electronics and Industrial Applications (PEEIACON)","25 Dec 2024","2024","","","1","6","In today's digital landscape, email remains vital for communication in both personal and professional realms, yet spam continues to compromise user privacy and productivity. This paper explores an advanced approach to enhancing email security by integrating machine learning (ML), deep learning (DL), and Large Language Models (LLMs). Our solution leverages ML algorithms, such as Logistic Regression and Support Vector Machines (SVM), to classify emails by analyzing content, headers, and sender details. To adapt to evolving spam tactics, we employ deep learning models like Convolutional Neural Networks (CNNs) to capture complex patterns in email data. The paper also investigates the novel application of LLMs, which offer innovative strategies for addressing spam beyond traditional heuristic methods. This paper attempts to train these models using a dataset comprising spam and ham emails. LLMs have swiftly reshaped the landscapes of business, consumer behavior, and academia, demonstrating transformational potential for society. Using a dataset of spam and ham emails, we demonstrate that this combined approach offers a robust and adaptable framework for improving email safety, illustrating the transformative potential of LLMs in enhancing spam detection.","","979-8-3315-1798-4","10.1109/PEEIACON63629.2024.10800637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10800637","Ham;Spam;Phishing;Large Language Model(LLM);Cyber Security;Artificial Intelligence;Fine Tuning;CNN;SVM;GNB;Logistic Regression","Support vector machines;Deep learning;Training;Adaptation models;Logistic regression;Unsolicited e-mail;Large language models;Performance analysis;Convolutional neural networks;Security","","","","14","IEEE","25 Dec 2024","","","IEEE","IEEE Conferences"
"AI as a Tool of Disinformation in the International Arena","K. Grdzelidze","Caucasus Technical School (CST), Caucasus University, Tbilisi, Georgia",2024 IEEE International Workshop on Technologies for Defense and Security (TechDefense),"7 Feb 2025","2024","","","116","120","In the 21st century, information has become a strategic asset, fueling competition between governments and non-government bodies. As societies rely more on technology, manipulating information has become a weapon in international conflicts. This research will explore how Artificial Intelligence (AI), depending on its development and purpose, can be used to spread disinformation and amplify the influence of specific actors globally. The rise of hacktivist groups like Anonymous and increased utilization of the Internet and cyber resources by government agents highlight this issue. With advanced programming skills, these groups can exploit vulnerabilities in large language models (LLMs) to create and disseminate false narratives. This dual capacity for cyberattacks and disinformation campaigns magnifies their global impact. Moving beyond the debate of AI being good or evil, this article examines the real threat posed by accessible AI technologies to local and global information ecosystems. It analyzes how AI, despite its developers’ good intentions, can be misused to disrupt the flow of truthful information. The research also explores potential countermeasures and proactive approaches to mitigate AI-driven disinformation campaigns. This paper scrutinizes real-world cases and their implications to shed light on the complex interplay between AI, government, hacktivist groups, and disinformation in the international arena. This analysis will provide valuable insights for policymakers, security experts, and technologists to better prepare for and address the multifaceted challenges posed by AI as a disinformation tool.","","979-8-3315-0558-5","10.1109/TechDefense63521.2024.10863311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10863311","AI;Disinformation;LLM;Artificial Intelligence;Machine Learning;International Security;Cyber Security","Weapons;Large language models;Government;Programming;Malware;Internet;Security;Social implications of technology;Artificial intelligence;Fake news","","","","7","IEEE","7 Feb 2025","","","IEEE","IEEE Conferences"
"Introduction to Generative AI","O. Bergeret; A. Abbasi; J. Farvault",NA; NA; NA,GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS,"","2025","","","79","138","<p>Generative Artificial Intelligence (AI) can create new content and ideas, including conversations, stories, images, videos, and music. AI technologies attempt to mimic human intelligence in nontraditional computing tasks like image recognition, natural language processing, and translation. The goal of Prompt Engineering is to maximize the performance of an AI model by providing inputs that leverage its capabilities effectively. It's a skill that combines creativity with an understanding of how AI systems process information. It's particularly relevant for Generative AI models where the input directly shapes the creation of new content, whether it be writing a poem, composing music, coding a software function, or generating a visual image. Generative AI powers conversational assistants that offer tailored financial guidance to users based on their financial behavior and goals. Generative AI has had the most impact and has truly revolutionized content creation, from music to visual arts, by generating novel content that maintains brand consistency and authenticity.</p>","","9781394281305","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10982333.pdf&bkn=10964414&pdfType=chapter","","Generative AI;Data models;Artificial intelligence;Training;Recurrent neural networks;Autoencoders;Generative adversarial networks;Image reconstruction;Computer architecture;Computational modeling","","","","","","2 May 2025","","","Wiley","Wiley AI eBook Chapters"
"Generative AI for Consumer Internet of Things: Challenges and Opportunities","W. Jiang; Y. Zhang; H. Han; J. Mu","Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Zhejiang University of Technology, China",IEEE Consumer Electronics Magazine,"","2025","PP","99","1","10","Generative artificial intelligence (AI) is a transformative technology driving the realization of consumer Internet of Things (IoT) systems. This paper investigates how generative AI can be leveraged to revolutionize data processing and content generation within consumer IoT networks. The study focuses on deploying generative AI models at the network edge, examining their advantages, including reduced latency, improved bandwidth efficiency, enhanced privacy, and offline functionality. By analyzing specific applications in satellite IoT, maritime IoT, power IoT, and medical IoT, this paper highlights the lifecycle of generative AI at the edge, from pre-training and fine-tuning to inference. Additionally, the paper addresses key challenges in real-world implementation, such as quality control, security, privacy concerns, and scaling compute infrastructure. It concludes by identifying future research directions in areas like communication, sensing, computing integration, edge-cloud collaboration, and multi-modal learning, with the goal of advancing the practical application of generative AI in consumer IoT systems.","2162-2256","","10.1109/MCE.2025.3532890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850766","","Internet of Things;Generative AI;Data models;Real-time systems;Adaptation models;Artificial intelligence;Image edge detection;Computational modeling;Complexity theory;Accuracy","","6","","","IEEE","23 Jan 2025","","","IEEE","IEEE Early Access Articles"
"Navigating (in)Security of AI-Generated Code","S. H. Ambati; N. Ridley; E. Branca; N. Stakhanova","University of Saskatchewan, Saskatoon, Canada; University of Saskatchewan, Saskatoon, Canada; University of Saskatchewan, Saskatoon, Canada; University of Saskatchewan, Saskatoon, Canada",2024 IEEE International Conference on Cyber Security and Resilience (CSR),"24 Sep 2024","2024","","","1","8","The increasing use of large language models (LLMs) such as OpenAI's ChatGPT and Google's Bard in the software development industry raise questions about the security of generated code. Our research evaluates Java, C, and Python code samples that were generated by these LLMs. In our investigation, we assessed the consistency of code samples generated by each LLM, characterized the security of generated code, and asked both LLMs to evaluate and fix the weaknesses of their own generated code as well as the code of the other LLM. Using 133 unique prompts from Google Code Jam competitions, we produced 3,854 code samples across three distinct programming languages. We found that the code produced by these LLMs is frequently insecure and prone to weaknesses and vulnerabilities. This concerns human developers who must exercise caution while employing these LLMs.","","979-8-3503-7536-7","10.1109/CSR61664.2024.10679468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679468","AI-generated code;ChatGPT;Bard;vulnerabilities","Java;Codes;Navigation;Large language models;Chatbots;Internet;Security","","1","","37","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"Campus Navigator: Your Go-To Chatbot For Academic Advice And Resources","M. D. Kavana; A. Tasdeeq; D. Poshitha; R. Hemith Kumar; K. S. Dhavan","Dept. of CSE, Vidyavardhaka College of Engg., Mysore, India; Dept. of CSE, Vidyavardhaka College of Engg., Mysore, India; Dept. of Computer Science and Engineering, Vidyavardhaka College of Engg., Mysore, India; Dept. of Computer Science and Engineering, Vidyavardhaka College of Engg., Mysore, India; Dept. of Computer Science and Engineering, Vidyavardhaka College of Engg., Mysore, India",2024 International Conference on Recent Advances in Science and Engineering Technology (ICRASET),"28 Feb 2025","2024","","","1","5","The creation of an intelligent chatbot for the Educational Institute’s website is the subject of this study. Driven by conversational AI, the chatbot aims to enhance student engagement by providing accurate and timely responses. Objectives include admission guidance, course information, troubleshooting, and continuous improvement through user feedback. The systematic methodology covers project planning, data collection, chatbot development, personalization, security, and deployment. Positioned as a strategic move in response to modern challenges, the chatbot represents a $24 / 7$ accessible virtual assistant, aligning with the broader trend of digital transformation in higher education. The article provides a comprehensive approach to creating an intelligent and user-friendly chatbot that seamlessly aligns with our college’s digital presence.","","979-8-3503-8860-2","10.1109/ICRASET63057.2024.10895595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895595","Chatbot;Conversational AI;Educational technology;Natural Language Processing","Surveys;Systematics;Navigation;Virtual assistants;Data collection;Chatbots;Planning;Security;Usability;Testing","","","","16","IEEE","28 Feb 2025","","","IEEE","IEEE Conferences"
"Comparative Performance Analysis Between Agent-Based And Conventional Diaster Management System","T. Samaad; G. A. Tahir; Mansoor-ur-Rahman; M. Ashraf","National University of Sciences and Technology, Islamabad, Pakistan; Advance Robotics Lab, University Malaya, Kuala Lumphur, Malaysia; National University of Sciences and Technology, Islamabad, Pakistan; Korea Advanced Institute Of Science And Technology, Daejeon, Republic Of Korea",2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE),"18 Nov 2018","2018","","","1","6","The uncertain and devastating outcomes of natural disasters require pre-planning and timely coordination to reduce human and economic loss. While predictive capabilities remain limited - especially in the event of earthquakes, significant research efforts have been made towards increasing the efficiency and preparedness of rescue and relief operations. In this respect, different applications of agent-based modeling exhibits substantial promise for enabling humanitarian committees in terms of better planning and responsiveness in case of a disaster. While the usefulness of more conventional disaster management systems that focus primarily on communication and coordination efforts have a significant role, the ability of agent - based systems to aid decision making under unforeseen circumstances adds a new dimension to the overall effectiveness of such systems. Hence, the following study surveys conventional and agent-based disaster management systems, and aims to determine the performance of both systems.","","978-1-5386-4838-4","10.1109/ICSCEE.2018.8538363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538363","Disaster management systems;Agent based modelling;Multi-agent systems.","Disaster management;Reliability;Planning;Data models;Conferences;Decision making;Systematics","","1","","34","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"GenXSS: an AI-Driven Framework for Automated Detection of XSS Attacks in WAFs","V. Babaey; A. Ravindran","Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, Charlotte, NC, USA; Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, Charlotte, NC, USA",SoutheastCon 2025,"25 Apr 2025","2025","","","1519","1524","The increasing reliance on web services has led to a rise in cybersecurity threats, particularly Cross-Site Scripting (XSS) attacks, which target client-side layers of web applications by injecting malicious scripts. Traditional Web Application Firewalls (WAFs) struggle to detect highly obfuscated and complex attacks, as their rules require manual updates. This paper presents a novel generative AI framework that leverages Large Language Models (LLMs) to enhance XSS mitigation. The framework achieves two primary objectives: (1) generating sophisticated and syntactically validated XSS payloads using in-context learning, and (2) automating defense mechanisms by testing these attacks against a vulnerable application secured by a WAF, classifying bypassing attacks, and generating effective WAF security rules. Experimental results using GPT-4o demonstrate the framework's effectiveness generating 264 XSS payloads, 83% of which were validated, with 80% bypassing ModSecurity WAF equipped with an industry standard security rule set developed by the Open Web Application Security Project (OWASP) to protect against web vulnerabilities. Through rule generation, 86% of previously successful attacks were blocked using only 15 new rules. In comparison, Google Gemini Pro achieved a lower bypass rate of 63%, highlighting performance differences across LLMs.","1558-058X","979-8-3315-0484-7","10.1109/SoutheastCon56624.2025.10971558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10971558","XSS;generative AI;LLM;WAF;ModSecurity WAF;AWS WAF;cybersecurity","Industries;Generative AI;Web services;Cross-site scripting;Prevention and mitigation;Large language models;Manuals;Standards;Payloads;Testing","","1","","18","IEEE","25 Apr 2025","","","IEEE","IEEE Conferences"
"On the Use of GPT-4 for Creating Goal Models: An Exploratory Study","B. Chen; K. Chen; S. Hassani; Y. Yang; D. Amyot; L. Lessard; G. Mussbacher; M. Sabetzadeh; D. Varró","Electrical and Computer Engineering, McGill University, Montreal, Canada; Electrical and Computer Engineering, McGill University, Montreal, Canada; School of EECS, University of Ottawa, Ottawa, Canada; Electrical and Computer Engineering, McGill University, Montreal, Canada; School of EECS, University of Ottawa, Ottawa, Canada; Telfer School of Management, University of Ottawa, Ottawa, Canada; Electrical and Computer Engineering, McGill University, Montreal, Canada; School of EECS, University of Ottawa, Ottawa, Canada; Linköping University, Linköping, Sweden",2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),"28 Sep 2023","2023","","","262","271","The emergence of large language models and conversational front-ends such as ChatGPT is revolutionizing many software engineering activities. The extent to which such technologies can help with requirements engineering activities, especially the ones surrounding modeling, however, remains to be seen. This paper reports on early experimental results on the potential use of GPT-4 in the latter context, with a focus on the development of goal-oriented models. We first explore GPT-4's current knowledge and mastering of a specific modeling language, namely the Goal-oriented Requirement Language (GRL). We then use four combinations of prompts – with and without a proposed textual syntax, and with and without contextual domain knowledge – to guide the creation of GRL models for two case studies. The first case study focuses on a well-documented topic in the goal modeling community (Kids Help Phone), whereas the second one explores a context for which, to our knowledge, no public goal models currently exist (Social Housing). We explore the interactive construction of a goal model through specific follow-up prompts aimed to fix model issues and expand on the model content. Our results suggest that GPT-4 preserves considerable knowledge on goal modeling, and although many elements generated by GPT-4 are generic, reflecting what is already in the prompt, or even incorrect, there is value in getting exposed to the generated concepts, many of which being non-obvious to stakeholders outside the domain. Furthermore, aggregating results from multiple runs yields a far better outcome than from any individual run.","2770-6834","979-8-3503-2691-8","10.1109/REW57809.2023.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260905","Large Language Models;GPT-4;ChatGPT;Goal Modeling;Goal-oriented Requirement Language;GRL","Scalability;Conferences;Syntactics;Chatbots;Requirements engineering;Stakeholders;Task analysis","","28","","22","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"Evaluating Superhuman Models with Consistency Checks","L. Fluri; D. Paleka; F. Tramèr","Department of Computer Science, ETH Zürich, Zurich, Switzerland; Department of Computer Science, ETH Zürich, Zurich, Switzerland; Department of Computer Science, ETH Zürich, Zurich, Switzerland",2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML),"10 May 2024","2024","","","194","232","If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model’s decisions fail to satisfy certain logical, human-interpretable rules. As case studies, we instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model’s (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to semantically identical boards; GPT-4 forecasting that sports records will evolve non-monotonically over time; or an AI judge assigning bail to a defendant only after we add a felony to their criminal record.","","979-8-3503-4950-4","10.1109/SaTML59370.2024.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10516635","safety;security;trustworthy AI;evaluation;large language models;forecasting;robustness","Law;Decision making;Machine learning;Predictive models;Cognition;Task analysis;Forecasting","","4","","92","IEEE","10 May 2024","","","IEEE","IEEE Conferences"
"C/C++ Vulnerability Data Set Generation Framework using a Parser and LLM","M. D. Nguyen; M. Carlisle","Dept. of Computer Science, Texas A&M University College Station, Texas; Dept. of Computer Science, Texas A&M University College Station, Texas",2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC),"29 Jan 2025","2025","","","1","11","Open-source software can reduce the cost of code use and development; however, it can also introduce vulnerabilities. Machine learning methods show promise for finding and fixing vulnerabilities in source code, but require a large amount of labeled data for training. We provide a data set generation framework for $\mathrm{C} / \mathrm{C}++$ code that will identify code commits that patch vulnerabilities and provide the patched and unpatched function. The framework uses a large language model to determine if the commit patches a vulnerability, then a custom parser to extract the function before and after the patch. Our data set provides over 18,000 functions from 12 repositories. Random sampling and human verification estimate the accuracy at $\mathbf{8 9 \%}$.","","979-8-3315-1888-2","10.1109/ICAIC63015.2025.10848559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10848559","large language models;machine learning;software vulnerabilities;computer security","Training;Codes;Accuracy;Costs;Databases;Large language models;Source coding;Linux;Machine learning;Open source software","","","","46","IEEE","29 Jan 2025","","","IEEE","IEEE Conferences"
"Sensitivity to Emotional Exploitation in Reasoning Models: Stereotypical Analysis","O. M. Çeldİr; G. Dalkiliç","Computer Engineering Dokuz Eylül University, İzmir, Turkey; Computer Engineering Dokuz Eylül University, İzmir, Turkey","2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)","2 Jun 2025","2025","","","1","8","In this study, a survey was conducted on synthetic participants with different stereotypes based on three different moral dilemma scenarios using GPT-4o vs. o1-mini. The tests conducted show that the reasoning model tends to give utilitarian answers to questions measuring moral dilemmas. In the reasoning model, the fairness answers, which were 78.83% when no intervention was made, decreased to 5.99% in the case of an emotional distortion attack. The standard model only reduced this rate from 99.84% to 95.91%. In addition, when the stereotypical analysis of the answers was examined, it was determined that the human-like reasoning ability of reasoning models had a serious bias, especially in groups separated by gender and economic status. In reasoning models, synthetic participants with female personas gave an average of 52.78% utilitarian answers, while male participants gave 61.96% utilitarian answers.","2996-4393","979-8-3315-1088-6","10.1109/ICHORA65333.2025.11017311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017311","ArtificiaI Intelligence Bias;Large Language Models;LLM Security;Prompt Injection","Surveys;Ethics;Analytical models;Sensitivity;Particle measurements;Cognition;Security;Standards;Robots;Optimization","","","","54","IEEE","2 Jun 2025","","","IEEE","IEEE Conferences"
"Next-Generation Bug Reporting: Enhancing Development with AI Automation","A. Patil; A. Jadon","Juniper Networks Inc, Sunnyvale, USA; Juniper Networks Inc, Sunnyvale, USA",2025 10th International Conference on Signal Processing and Communication (ICSC),"24 Apr 2025","2025","","","487","493","In today's Agile and DevOps-driven software development landscape, rapid and accurate bug reporting is critical. This paper presents a next-generation automation tool powered by large language models and machine learning, innovating the bug reporting process. The tool automates various phases of bug reporting, such as failure detection, severity assessment, duplicate detection, and report generation. By addressing the limitations of manual bug reporting such as inconsistency, scalability challenges, and time inefficiencies, the proposed solution enhances the software testing workflow. Initial findings demonstrate significant time savings, reduced manual errors, and improved collaboration between testers and developers. This work establishes a foundation for fully automated bug reporting, poised to accelerate software development cycles and maintain high-quality standards.","2643-444X","979-8-3315-1189-0","10.1109/ICSC64553.2025.10968932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10968932","Automated Bug Reporting;Bug Creation;Data Collection;Duplicate Detection;Failure Detection;Large Language Models;Machine Learning;Report Formatting;Severity Assessment;Quality Metrics","Software testing;Automation;Accuracy;Large language models;Computer bugs;Machine learning;Software;Next generation networking;Standards;Software development management","","","","23","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures","T. Eisenreich; S. Speth; S. Wagner","Institute of Software Engineering, Stuttgart, Germany; Institute of Software Engineering, Stuttgart, Germany; TUM School of Computation, Information and Technology, Heilbronn, Germany",2024 IEEE/ACM International Workshop on Designing Software (Designing),"11 Sep 2024","2024","","","52","55","Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system’s quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.CCS CONCEPTS • Software and its engineering → Designing software; Software architectures; System description languages; • Computing methodologies → Artificial intelligence.","","979-8-4007-0563-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669862","Requirements;Software Architecture;Architecture Evaluation;LLM","Analytical models;Software architecture;Statistical analysis;Large language models;Fitting;Computer architecture;Quality of service","","3","","18","","11 Sep 2024","","","IEEE","IEEE Conferences"
"Transformer Models for Predicting Bank Loan Defaults a Next-Generation Risk Management","R. Kakadiya; T. Khan; A. Diwan; R. Mahadeva","CE - AI & Big Data, Marwadi University, Rajkot, India; CE - AI & Big Data, Marwadi University, Rajkot, India; Department of CE, Marwadi University, Rajkot, India; Department of CSE, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, India","2024 IEEE 6th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA)","11 Feb 2025","2024","","","26","31","Predicting bank loan defaults are crucial for the financial banking industry since it allows organizations to manage risk proactively so it make educated decision. While important, conventional method such as logistic regression and decision trees can face challenges when attempting to handle complex pattern and substantial relationships that are inherent in financial data. The Transformer design, which offers enormous promise in handling sequential data model, was made possible by recent advancement in natural language processing (NLP). In order to simplify the links between various financial variables, these work explores the use of transformers for bank loan default prediction, using its self-attention mechanisms. By paying attention to multiple input pieces at once, the Transformer model is able to catch subtleties and dependencies that are missed by traditional method. The Transformer based paradigm outperforms last approach in terms of performance and interpretability, as demonstrated by empirical finding. It offers valuable insights into how different financial factors are connected and how they influence the prediction of loan defaults. As a result, the Transformer becomes an essential tool in financial risk management and has the potential to change the way we predict loan defaults. Using this technology presents a strong and effective solution to the difficulties encountered with traditional methods, allowing for a deeper understanding of complex financial patterns that lead to more accurate predictions.","","979-8-3315-0579-0","10.1109/ICCCMLA63077.2024.10871798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871798","Banking Security;Bankruptcy Prediction Model;Loan Defaults;Risk Management;Data Analytics;Trans-former;neural networks","Analytical models;Logistic regression;Banking;Organizations;Machine learning;Predictive models;Transformers;Natural language processing;Risk management;Next generation networking","","1","","18","IEEE","11 Feb 2025","","","IEEE","IEEE Conferences"
"Reinforcement Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses","Y. Khan; A. A. Hamed","Sano Centre for Computational Medicine, Krakow, Poland; Multidisciplinary Graduate Engineering, Northeastern University, Miami, FL, USA",2024 IEEE International Conference on Medical Artificial Intelligence (MedAI),"25 Dec 2024","2024","","","392","397","Addressing the global challenge of breast cancer, this research explores the fusion of generative AI and the intricacies of breast cancer risk assessment. This study seeks to bridge the technology gap between intelligent machines and clinicians by demonstrating ChatGPT's proficiency in reasoning. The methodology employs a supervised prompt-engineering approach to enforce detailed explanations for ChatGPT's recom-mendations. Synthetic use cases, generated algorithmi-cally, serve as the testing ground for the encoded rules, evaluating the model's processing prowess. Findings highlight ChatGPT's promising capacity in processing rules comparable to Expert System Shells, with a focus on natural language reasoning. The research introduces the concept of reinforcement explainability, showcasing its potential in elucidating outcomes and facilitating user-friendly interfaces for breast cancer risk assessment.","","979-8-3503-7761-3","10.1109/MedAI62885.2024.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803468","Reinforcement Explainability;Chat-GPT;Prompt Engineering;Breast Cancer","Bridges;Generative AI;Natural languages;Chatbots;Breast cancer;Cognition;Risk management;Expert systems;Testing","","1","","25","IEEE","25 Dec 2024","","","IEEE","IEEE Conferences"
"Diagnosis of Plant Infection for Optimised Authomatic Health Monitoring System Using Vision Transformer Models","N. Thapliyal; M. Aeri; A. Satyarthi; V. Kukreja; R. Sharma","Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Artificial Intelligence & Data Science IIMT College of Engineering, Greater Noida, Uttar Pradesh, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India","2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)","8 Apr 2024","2024","5","","44","48","Mosaic Virus is highly responsible for the crop loss, especially the pepper, which is considered part of food crop, an essential aspect of world’s agriculture. This work aims at automating the classification of disease severity level-related the Pepper Leaf Mosaic Virus Disease threshold through vision transformer (ViT) model to ensure a critical job. The classification of the severity is more often accompanied by a fairly significant amount of workload and arbitrariness, resulting in equipment innovation in most of the locations. The work applies ViT-based approaches with sufficient precision to appropriately classify a dataset, which contains 10,800 meticulously selected photographs. The present model obtained a commendable average accuracy of 97.25%, which shows that the model was able to detect even smaller differences between the classes of severity. The operational criteria that include the tale of the precision, recall, and F1-score highlight the model’s ability to minimize to Feggsor false Positives with its ability to discriminate cases of viruses at different levels of the spectrum. The more advanced comparison charts made hand methodologies stand at the pinnacle in plant pathology studies. This study is not only beneficial in terms of illuminating the understanding about the Pepper Leaf Mosaic Virus but also gives farmers and researchers a transformative tool that could change the way disease control methods are used. Technologies AI that power ViT model are helping the agriculture industries throughout the world to implement sustainability and resiliency of the systems by providing responses in the right time and place in addressing viral infections.","","979-8-3503-8354-6","10.1109/IC2PCT60090.2024.10486329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486329","Pepper Leaf Mosaic Virus;Vision Transformer;Severity Classification;Plant Pathology;Agricultural Automation;Image Classification;Machine Learning;Disease Management;Crop Health;Precision Agriculture;Agricultural Technology;Artificial Intelligence;ViT Model;Automated Diagnosis;Global Food Security","Pathology;Computer viruses;Computational modeling;Crops;Transformers;Agriculture;Sustainable development","","","","16","IEEE","8 Apr 2024","","","IEEE","IEEE Conferences"
"ACFix: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts","L. Zhang; K. Li; K. Sun; D. Wu; Y. Liu; H. Tian; Y. Liu","College of Computing and Data Science, Nanyang Technological University, Singapore, Singapore; College of Computing and Data Science, Nanyang Technological University, Singapore, Singapore; College of Computing and Data Science, Nanyang Technological University, Singapore, Singapore; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Singapore Management University; University of Luxembourg; College of Computing and Data Science, Nanyang Technological University, Singapore, Singapore",IEEE Transactions on Software Engineering,"","2025","PP","99","1","21","Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. While existing research has proposed multiple detection tools, automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of repairing AC vulnerabilities lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence. In this paper, we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX. The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality. To this end, ACFIX involves offline and online phases. In the offline phase, ACFIX mines a taxonomy of common Role-based Access Control practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 unique samples. In the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch. To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them, a major improvement compared to the baseline GPT-4 at only 52.54%. We also conducted a human study to understand the value of ACFIX’s repairs and their differences from human repairs.","1939-3520","","10.1109/TSE.2025.3590108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11086587","Smart Contract;Software Security;Program Repair","Maintenance engineering;Smart contracts;Codes;Access control;Blockchains;Taxonomy;Benchmark testing;Source coding;Natural language processing;Logic","","","","","IEEE","22 Jul 2025","","","IEEE","IEEE Early Access Articles"
"Fine-Tuning Transformer LLMs for Detecting SQL Injection and XSS Vulnerabilities","T. -T. -H. Le; A. A. Adiputra; Y. Hwang; J. Son; H. Kim","Blockchain Platform Research Center, Pusan National University, Busan, South Korea; Dept. computer science and engineering, Pusan National University, Busan, South Korea; Dept. computer science and engineering, Pusan National University, Busan, South Korea; Dept. computer science and engineering, Pusan National University, Busan, South Korea; Dept. computer science and engineering, Pusan National University, Busan, South Korea",2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),"19 Mar 2025","2025","","","0946","0951","This paper introduces a method for detecting SQL Injection (SQLi), Command Injection, and Cross-Site Scripting (XSS) vulnerabilities using fine-tuned, transformer-based language models within a multilabel binary classification framework. Our approach takes advantage of three pre-trained lightweight models: DistilBERT, ALBERT, and ArmoRM-Llama3-8B. Each fine-tuned for text classification tasks on the SQLi XSS dataset. Fine-tuning involved freezing the pretrained transformer layers and updating a fully connected output layer. The primary challenge lies in generating multi-label outputs for four vulnerability classes (SQL Injection, Command Injection, XSS, and Normal traffic) with binary indicators for normal (0) or attack (1) status. Evaluation metrics, including confusion matrices, indicate that fine-tuning ArmoRM-Llama3-8B achieves slightly higher accuracy and detection rates than DistilBERT and ALBERT, particularly in identifying complex injection attacks. Furthermore, ArmoRM-Llama3-8B demonstrated the fastest testing evaluation time despite a moderately longer training period. These results highlight the feasibility and effectiveness of transformer-based language models in enhancing web security through improved vulnerability detection.","2831-6983","979-8-3315-0702-2","10.1109/ICAIIC64266.2025.10920868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10920868","ALBERT;ArmoRM-Llama3-8B;Command Injection;Cross-Site Scripting (XSS);DistilBERT;Multi-label classification;SQL Injection;Transformer language models;Vulnerability detection;Web security","Training;Measurement;Cross-site scripting;Text categorization;Confusion matrices;Multi label classification;SQL injection;Transformers;Security;Testing","","","","24","IEEE","19 Mar 2025","","","IEEE","IEEE Conferences"
"Harnessing GPT for Data Transformation Tasks","S. Ghazzai; D. Grigori; B. Benatallah; R. Rebai","LAMSADE University of Paris Dauphine, Paris, France; LAMSADE University of Paris Dauphine, Paris, France; Dublin City University, Dublin, Ireland; Air France, Paris, France",2024 IEEE International Conference on Web Services (ICWS),"15 Oct 2024","2024","","","1329","1334","In data science, a significant portion of time is dedicated to data preparation, a task often challenging for business users with limited technical skills. This research delves into using large language models (LLMs), particularly GPT (Generative Pre-trained Transformer), to streamline these data preparation processes. We study the usage of large language models in data cleaning, standardization, and transformation tasks. Our approach diverges from traditional methods by employing GPT as a direct transformation tool, utilizing its advanced reasoning capabilities through prompt engineering. This research aims to facilitate data transformation tasks, complicated by the diversity of data formats and inputs, for both technical and non-technical users, allowing them to accomplish these tasks through descriptive instructions rather than complex coding. We evaluate GPT’s effectiveness for frequent data transformation tasks and compare it against other data transformation tools on a benchmark. Our findings demonstrate the practical utility of GPT models in data transformation and propose prompt template guidelines for intricate data string transformations.","2836-3868","979-8-3503-6855-0","10.1109/ICWS62655.2024.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707551","Large language model;GPT;prompt engineering;data transformation","Accuracy;Web services;Large language models;Transforms;Transformers;Data models;Encoding;Prompt engineering;Software development management;Self-service","","","","21","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"Distributed output consensus security control of a nonlinear multi-agent system under sensor and actuator attacks","A. Wang; Y. Zhou; J. Ge; X. Hou","College Of Automation and College Of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College Of Automation and College Of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College Of Automation and College Of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; NARI Group Corporation, State Grid Electric Power Research Institute, Nanjing, China",2021 China Automation Congress (CAC),"14 Mar 2022","2021","","","2833","2838","This paper mainly studies the output consensus security control of multi-agent systems (MASs) under cyber-physical attacks. To deal with the sensor attacks, paralyzed uncertain dynamics in individual follower are separated by the separation theorem, and items associated attacks gather together. Then, estimation parameters are introduced for compensating and mitigating the influence from the sensors. The effects from the dead-zone property and actuator attack are treated as a total shift, and an upper bound, as well as its estimation, is introduced for the shift. In theory, the stability of the paralyzed closed-loop MAS is analyzed, and it has been proved that all signals are bounded in spite of nonlinear dynamics and attacks. Finally, theoretical results are verified through a rotary-wing air vehicle and a numerical case.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9728385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9728385","Sensor and actuator attack;security control","Actuators;Upper bound;Estimation;Control systems;Stability analysis;Nonlinear dynamical systems;Security","","","","20","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"Empowering Hardware Security with LLM: The Development of a Vulnerable Hardware Database","D. Saha; K. Yahyaei; S. Kumar Saha; M. Tehranipoor; F. Farahmandi","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"6 Jun 2024","2024","","","233","243","The scarcity of comprehensive databases and bench-marks in hardware design specifically tailored for security tasks is a significant challenge in the community. Such databases are crucial for developing machine learning-based methods and benchmarking, providing a foundation for evaluating and improving hardware security solutions. However, manually creating these extensive datasets is impractical due to the significant time and effort required. Given the proficiency of large language models (LLM) in natural language processing, coding, and advanced reasoning tasks, using LLM as an artificial intelligence (AI) agent presents a viable option to efficiently create such extensive datasets. In this light, this paper introduces Vul-FSM, a database of 10,000 vulnerable finite state machine (FSM) designs incorporating 16 distinct security weaknesses and vulnerabilities generated using the proposed SecRT-Llmframework. The framework combines the in-context learning capability of LLM, the guidance of developed prompting strategies, and the scrutiny of fidelity-check to not only insert but also detect hardware vulnerabilities and weaknesses. To demonstrate the efficacy of SecRT-LLM, we present an exhaustive analysis, highlighting the proficiency of GPT models in vulnerability insertion, detection, and mitigation. Our proposed SecRT-LLM framework, using gpt-3.5-turbo, demonstrates strong effectiveness, achieving macroaverage pass rates of 81.98% and 80.30% on the first attempt and 97.37% and 99.07% within five attempts for vulnerability insertion and detection, respectively.","2765-8406","979-8-3503-7394-3","10.1109/HOST55342.2024.10545393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545393","Large Language Model;ChatGPT;RTL design;Hardware Security;Vulnerability Analysis;Common Weakness Enumeration (CWE)","Learning systems;Analytical models;Databases;Hardware security;Instruments;Linguistics;Cognition","","15","","36","IEEE","6 Jun 2024","","","IEEE","IEEE Conferences"
"Security of AI Agents","Y. He; E. Wang; Y. Rong; Z. Cheng; H. Chen","University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis",2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE),"13 Jun 2025","2025","","","45","52","AI agents have been boosted by large language models. AI agents can function as intelligent assistants and complete tasks on behalf of their users with access to tools and the ability to execute commands in their environments. Through studying and experiencing the workflow of typical AI agents, we have raised several concerns regarding their security. These potential vulnerabilities are not addressed by the frameworks used to build the agents, nor by research aimed at improving the agents. In this paper, we identify and describe these vulnerabilities in detail from a system security perspective, emphasizing their causes and severe effects. Furthermore, we introduce defense mechanisms corresponding to each vulnerability with design and experiments to evaluate their viability. Altogether, this paper contextualizes the security issues in the current development of AI agents and delineates methods to make AI agents safer and more reliable.","","979-8-3315-1466-2","10.1109/RAIE66699.2025.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029384","ai agents;ai security","Systematics;Codes;Large language models;Conferences;Cognition;Planning;Security;Reliability;Artificial intelligence;Best practices","","1","","49","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Algorithm for Data Extraction from Photovoltaic Module Technical Documentation","A. Marinov; K. Solenkov","Department of Electronics and Microelectronics, Technical University of Varna, Varna, Bulgaria; Department of Electronics and Microelectronics, Technical University of Varna, Varna, Bulgaria","2025 19th Conference on Electrical Machines, Drives and Power Systems (ELMA)","22 Jul 2025","2025","","","1","5","This paper proposes an algorithm for structured data extraction from photovoltaic (PV) module technical datasheets, focusing on parameters critical for detailed electrical modeling and simulation. Driven by the increasing global adoption of renewable energy sources and the importance of efficient microinverter designs for residential photovoltaic installations, the proposed method systematically processes textual documentation to generate structured datasets. The implemented approach combines transformer-based natural language processing (NLP) using the Phi-2 language model finetuned via Low-Rank Adaptation (LoRA) techniques, advanced prompt engineering, and robust post-processing strategies for data extraction. Evaluation conducted over 400 photovoltaic datasheets demonstrates an extraction accuracy ranging from 85% to 90%, contingent upon document complexity. Identified limitations related to table complexity and document length constraints are discussed, highlighting avenues for future improvement. The resultant structured data significantly facilitate computational modeling workflows for photovoltaic system design optimization.","2997-6324","979-8-3315-2636-8","10.1109/ELMA65795.2025.11083445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11083445","Photovoltaics;Microinverters;Data Extraction;Natural Language Processing;Transformer Models;Structured Data;Technical Documentation;Renewable Energy Systems","Renewable energy sources;Computational modeling;Optical character recognition;Documentation;Transformers;Data models;Natural language processing;Data mining;Solar panels;Prompt engineering","","","","18","IEEE","22 Jul 2025","","","IEEE","IEEE Conferences"
"VulAdvisor: Natural Language Suggestion Generation for Software Vulnerability Repair","J. Zhang; C. Wang; A. Li; W. Wang; T. Li; Y. Liu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Yale University, USA; University of Alberta, Canada; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1932","1944","Software vulnerabilities pose serious threats to the security of modern software systems. Deep Learning-based Automated Vulnerability Repair (AVR) has gained attention as a potential solution to accelerate the remediation of vulnerabilities. However, recent studies indicate that existing AVR approaches often only generate patches, which may not align with developers’ current repair practices or expectations. In this paper, we introduce VulAdvisor, an automated approach that generates natural language suggestions to guide developers or AVR tools in repairing vulnerabilities. VulAdvisor comprises two main components: oracle extraction and suggestion learning. To address the challenge of limited historical data, we propose an oracle extraction method facilitating ChatGPT to construct a comprehensive and high-quality dataset. For suggestion learning, we take the supervised fine-tuning CodeT5 model as the basis, integrating local context into Multi-Head Attention and introducing a repair action loss, to improve the relevance and meaningfulness of the generated suggestions. Extensive experiments on a large-scale dataset from real-world C/C++ projects demonstrate the effectiveness of VulAdvisor, surpassing several alternatives in terms of both lexical and semantic metrics. Moreover, we show that the generated suggestions enhance the patch generation capabilities of existing AVR tools. Human evaluations further validate the quality and utility of VulAdvisor’s suggestions, confirming their potential to improve software vulnerability repair practices.CCS CONCEPTS• Software and its engineering → Software maintenance tools; Software testing and debugging.","2643-1572","979-8-4007-1248-7","","National Research Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764852","vulnerability repair;large language models;suggestion generation;program repair","Software testing;Software maintenance;Source coding;Natural languages;Semantics;Maintenance engineering;Chatbots;Software systems;Security;Software engineering","","2","","70","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Improving Automated Code Reviews: Learning from Experience","H. Y. Lin; P. Thongtanunam; C. Treude; W. Charoenwet","The University of Melbourne, Melbourne, Australia; The University of Melbourne, Melbourne, Australia; Singapore Management University, Singapore, Singapore; The University of Melbourne, Melbourne, Australia",2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR),"18 Jun 2024","2024","","","278","283","Modern code review is a critical quality assurance process that is widely adopted in both industry and open source software environments. This process can help newcomers learn from the feedback of experienced reviewers; however, it often brings a large workload and stress to reviewers. To alleviate this burden, the field of automated code reviews aims to automate the process, teaching large language models to provide reviews on submitted code, just as a human would. A recent approach pre-trained and fine-tuned the code intelligent language model on a large-scale code review corpus. However, such techniques did not fully utilise quality reviews amongst the training data. Indeed, reviewers with a higher level of experience or familiarity with the code will likely provide deeper insights than the others. In this study, we set out to investigate whether higher-quality reviews can be generated from automated code review models that are trained based on an experience-aware oversampling technique. Through our quantitative and qualitative evaluation, we find that experience-aware oversampling can increase the correctness, level of information, and meaningfulness of reviews generated by the current state-of-the-art model without introducing new data. The results suggest that a vast amount of high-quality reviews are underutilised with current training strategies. This work sheds light on resource-eﬃcient ways to boost automated code review models.CCS CONCEPTS• Software creation and management; • Machine translation;","2574-3864","979-8-4007-0587-8","","University of Melbourne; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555781","Code Review;Review Comments;Neural Machine Translation","Training;Industries;Codes;Quality assurance;Reviews;Training data;Data models","","3","","39","","18 Jun 2024","","","IEEE","IEEE Conferences"
"MID-LLM: Enhancing Medical Image Diagnostics With LLMs in a Blockchain AI Framework","R. Kumar; R. Yunbo; J. Kumar; B. M. Cobbinah; W. Ali; S. Zeng","Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, China; University of Electronic Science and Technology of China, Chengdu, China; Dalhousie University, Faculty of Computer Science, Halifax, NS, Canada; Anesthesiology, Perioperative and Pain Medicine, Stanford University, Stanford, CA, USA; Department of Computer Science, College of Science, Mathematics and Technology, Wenzhou-Kean University, Wenzhou, China; Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","The rapid growth of medical imaging data presents significant challenges in diagnostic accuracy, data privacy, and computational efficiency. Traditional centralized AI models struggle with scalability and pose risks to patient confidentiality due to data aggregation. Moreover, heterogeneous medical data across institutions complicates the development of robust diagnostic tools. To address these issues, we propose MID-LLM, a novel framework that integrates Large Language Models (LLMs) with a blockchain-based federated learning system for medical image analysis. It also ensures the security and privacy of sensitive medical data across decentralized networks. MID-LLM uses verification mechanisms to ensure the global model’s integrity. It also employs aggregation techniques to reduce bias and improve training efficiency. Experiments on the BraTS 2020 dataset show that MID-LLM outperforms traditional federated learning, achieving higher Dice scores with improved computational efficiency. These results highlight MID-LLM’s potential to enhance diagnostic accuracy while offering a scalable, secure solution for AI in healthcare.","2327-4662","","10.1109/JIOT.2025.3583408","Department of Education of Zhejiang Province(grant numbers:LY23F020025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053220","Large Language Model (LLM);Decentralized AI;Medical Image Data;Blockchain;IPFS","Medical diagnostic imaging;Blockchains;Accuracy;Federated learning;Visualization;Data privacy;Data models;Artificial intelligence;Training;Security","","","","","IEEE","27 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Edge Computing in Industrial IoT Framework for Cloud-based Manufacturing Control","S. Raileanu; T. Borangiu; O. Morariu; I. Iacob","Dept. of Automation and Industrial Informatics, Politehnica University of Bucharest, Romania; Dept. of Automation and Industrial Informatics, Politehnica University of Bucharest, Romania; Dept. of Automation and Industrial Informatics, Politehnica University of Bucharest, Romania; Dept. of Automation and Industrial Informatics, Politehnica University of Bucharest, Romania","2018 22nd International Conference on System Theory, Control and Computing (ICSTCC)","22 Nov 2018","2018","","","261","266","Edge computing is essential for the Industrial IoT as framework for data acquisition from shop floor devices; distributed intelligence will shift to the edge for speed reasons in real-time handling of big data. This research aims at developing a generic architecture for information and data collection, smart processing and aggregation at the edge of large-scale manufacturing control systems; the edge is represented by the set of shop floor entities (things) - resources and intelligent products that are agentified and communicate in multi-agent systems for decentralized MES tasks. The IIoT architecture integrates a private cloud platform with a network of IoT aggregation nodes composed of IoT gateways, sensors and PC-type workstations hosting the resource agents. Both networks form the distributed MES layer of a semi-heterarchical, cloud-based production control system. The implementing solution is given; experiments report communication with the cloud.","2372-1618","978-1-5386-4444-7","10.1109/ICSTCC.2018.8540725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540725","Agent-based Systems;Networked Control;Internet of Things;Manufacturing Systems","Cloud computing;Manufacturing;Real-time systems;Logic gates;Control systems;Intelligent sensors","","15","","18","IEEE","22 Nov 2018","","","IEEE","IEEE Conferences"
"On Cyber Resilience and Security of Visual Neural Networks","N. M. Grigorieva; A. S. Petrenko; S. A. Petrenko","Saint Petersburg Electrotechnical University “LETI”, Saint-Petersburg, Russia; St. Petersburg State University, Saint-Petersburg, Russia; Saint Petersburg Electrotechnical University “LETI”, Saint-Petersburg, Russia",2024 Conference of Young Researchers in Electrical and Electronic Engineering (ElCon),"20 Mar 2024","2024","","","162","165","At present, there is widespread utilization of not only large-language models as OpenAI GPT-3 and GPT-4, which enable to generate images from textual input, but generative visual neural networks and visual transformers based famous text-to-image models like DALL-E, Midjourney, Stable Diffusion, Kandinsky and others. As generative visual neural networks continue to elaborate, they exhibit new and increasingly prominent system properties, including controllability, cyber stability, cybersecurity, self-organization, and adaptability. The assurance of cyber stability in generative neural networks emerges as a pressing concern in the realm of information security. This article presents the outcomes of a systematic analysis addressing this issue amidst escalating security threats. Additionally, potential approaches to resolving the matter are outlined.","2376-6565","979-8-3503-6064-6","10.1109/ElCon61730.2024.10468146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10468146","artificial intelligence;generative neural networks;digital art","Visualization;Systematics;Image synthesis;Source coding;Neural networks;Transformers;Stability analysis","","","","14","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"Messaging Apps Vulnerability Assessment Using Conversational AI","T. Chen","College of Management and Design, Ming Chi University of Technology, New Taipei City, Taiwan, ROC",Conversational Artificial Intelligence,"","2024","","","495","512","Summary <p>In this day and age of smartphones and computers, the prevalence of mobile applications has skyrocketed. They have numerous applications, including but not limited to communication, social media, news, messaging, shopping, making payments, watching videos and transmissions, and engaging in online gaming. When it comes to mobile devices, Android is presently the operating system with the most users worldwide. The Android platform has emerged as the most popular mobile operating system, with an increasing number of applications developed especially for Android mobile devices. Simultaneously, there has been a rise in the number of incidents. Attackers exploit vulnerable areas in mobile apps to introduce potentially malicious code into the system and steal confidential data. When creating an app for a mobile device, it is critical to prioritize the security and protection of users’ data. Only by thoroughly understanding the various vulnerabilities that could be introduced into their code can mobile app developers successfully fight potential security threats. This manuscript provides an in‐depth study of vulnerability assessment and penetration testing in mobile applications. This manuscript also presents a mitigation plan for encountering vulnerabilities in mobile applications. A security framework is also proposed to enhance the security of mobile applications.</p>","","9781394200795","10.1002/9781394200801.ch29","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951298.pdf&bkn=10950236&pdfType=chapter","","Security;Mobile applications;Operating systems;Testing;Conversational artificial intelligence;Computers;Penetration testing;Information security;Smart phones;NIST","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"LLM Agents as 6G Orchestrator: A Paradigm for Task-Oriented Physical-Layer Automation","Z. Xiao; C. Ye; Y. Hu; H. Yuan; Y. Huang; L. Cai; J. Chang; Y. Feng","Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China; Nokia Bell Labs, China",2024 IEEE Globecom Workshops (GC Wkshps),"12 Aug 2025","2024","","","1","6","The rapid advancement in generative pre-training models is propelling a paradigm shift in technological progression from basic applications such as chatbots towards more sophisticated agent-based systems. It is with huge potential and necessity that the 6G system be combined with the copilot of large language model (LLM) agents and digital twins (DT) to manage the highly complicated communication system with new emerging features such as native AI service and sensing. With the 6G-oriented agent, the base station could understand the transmission requirements of various dynamic upper-layer tasks, automatically orchestrate the optimal system workflow. Through continuously get feedback from the 6G DT for reinforcement, the agents can finally raise the performance of practical system accordingly. Differing from existing LLM agents designed for general application, the 6G-oriented agent aims to make highly rigorous and precise planning with a vast amount of extra expert knowledge, which inevitably requires a specific system design from model training to implementation. This paper proposes a novel comprehensive approach for building task-oriented 6G LLM agents. We first propose a two-stage continual pre-training and fine-tuning scheme to build the field basic model and diversities of specialized expert models for meeting the requirements of various application scenarios. Further, a novel inference framework based on semantic retrieval for leveraging the existing communication-related functions is proposed. Experiment results of exemplary tasks, such as physical-layer task decomposition, show the proposed paradigm’s feasibility and effectiveness.","2166-0077","979-8-3315-0567-7","10.1109/GCWkshp64532.2024.11101226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101226","6G networks;AI agents;digital twins;large language models;physical layer","6G mobile communication;Training;Wireless communication;Automation;Large language models;Buildings;Semantics;Digital twins;Sensors;System analysis and design","","","","9","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Application and evaluation of RAG technology in civil aviation policy question answering","Y. Luo; W. Xu; C. Zeng; Q. Fu; Z. Xiang","Civil Aviation Flight University of China, Guanghan, China; Civil Aviation Flight University of China, Guanghan, China; Civil Aviation Flight University of China, Guanghan, China; Civil Aviation Flight University of China, Guanghan, China; Civil Aviation Flight University of China, Guanghan, China",2024 2nd International Conference on Computer Network Technology and Electronic and Information Engineering (CNTEIE),"12 May 2025","2024","","","138","142","Civil aviation policies are crucial for practitioners, but the current method of manually searching for relevant policies is cumbersome and inefficient. Existing question-answering systems based on knowledge graphs or large language models are not ideal due to the lack of high-quality policy question-answering datasets and the inability to update in real-time. To this end, this paper builds a civil aviation policy question-answering system based on Retrieval-Augmented Generation (RAG). The system obtains civil aviation policy-related knowledge from multiple data sources and segments it, uses ZhipuEmbedding-3 and Chroma to create a civil aviation policy text block vector library, combines vector retrieval technology to complete the retrieval of Query text blocks, obtains the context most relevant to the Query, and then combines the prompt word function of the large language model to integrate the Query and context information in real time to generate accurate answers. Finally, we use the Ragas evaluation framework to conduct a comprehensive evaluation of the system. The results show that Qwen-max has the best overall performance in the indicators related to Faithfulness, Answer Relevancy, and Context Recall, which are 0.89, 0.75, and 0.90, respectively. The reliability and effectiveness of the system have been verified.","","979-8-3315-2443-2","10.1109/CNTEIE66268.2024.00032","Civil Aviation Administration of China; Fundamental Research Funds for the Central Universities; Civil Aviation Administration of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988198","Retrieval-Augmented Generation;Large Language Model;LangChain;Prompt Engineering","Accuracy;Large language models;Soft sensors;Retrieval augmented generation;Knowledge graphs;Vectors;Real-time systems;Question answering (information retrieval);Reliability;Usability","","","","14","IEEE","12 May 2025","","","IEEE","IEEE Conferences"
"Augmenting Code Sequencing with Retrieval-Augmented Generation (RAG) for Context-Aware Code Synthesis","S. J. Rani; S. G. Deepika; D. Devdharshini; H. Ravindran","Department of Information Technology, Sri Ramakrishana Engineering College, Coimbatore, India; Department of Information Technology, Sri Ramakrishana Engineering College, Coimbatore, India; Department of Information Technology, Sri Ramakrishana Engineering College, Coimbatore, India; Department of Information Technology, Sri Ramakrishana Engineering College, Coimbatore, India","2024 First International Conference on Software, Systems and Information Technology (SSITCON)","20 Dec 2024","2024","","","1","7","The growing demand for efficient code generation has driven research into improving Large Language Models (LLMs). This project presents a novel system designed to enhance code generation by leveraging Retrieval-Augmented Generation (RAG), Grounding techniques, and Prompt Parameters. RAG integrates external knowledge to enrich code outputs, while Grounding methods improve the model’s ability to interpret language with real-world context. Prompt Parameters offer flexibility, enabling customized outputs based on user preferences. These methods were implemented and tested on various code generation tasks, resulting in contextually relevant and accurate outputs. The proposed system streamlines software development workflows, reduces errors, and fosters better collaboration between developers and machine-assisted coding tools. Ultimately, this approach represents a significant advancement in automating code generation from natural language descriptions.","","979-8-3503-5293-1","10.1109/SSITCON62437.2024.10796587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796587","natural language processing;language models;grounding;retrieval-augmented generation;prompt parameters;code generation","Codes;Accuracy;Grounding;Computational modeling;Large language models;Retrieval augmented generation;Natural languages;Training data;Software systems;Context modeling","","","","15","IEEE","20 Dec 2024","","","IEEE","IEEE Conferences"
"More Than Privacy: Applying Differential Privacy in Key Areas of Artificial Intelligence","T. Zhu; D. Ye; W. Wang; W. Zhou; P. S. Yu","School of Computer Science, China University of Geosciences, Wuhan, China; Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; Department of Computer Science, University of Illinois at Chicago, Chicago, IL, USA",IEEE Transactions on Knowledge and Data Engineering,"29 Apr 2022","2022","34","6","2824","2843","Artificial Intelligence (AI) has attracted a great deal of attention in recent years. However, alongside all its advancements, problems have also emerged, such as privacy violations, security issues and model fairness. Differential privacy, as a promising mathematical model, has several attractive properties that can help solve these problems, making it quite a valuable tool. For this reason, differential privacy has been broadly applied in AI but to date, no study has documented which differential privacy mechanisms can or have been leveraged to overcome its issues or the properties that make this possible. In this paper, we show that differential privacy can do more than just privacy preservation. It can also be used to improve security, stabilize learning, build fair models, and impose composition in selected areas of AI. With a focus on regular machine learning, distributed machine learning, deep learning, and multi-agent systems, the purpose of this article is to deliver a new view on many possibilities for improving AI performance with differential privacy techniques.","1558-2191","","10.1109/TKDE.2020.3014246","National Natural Science Foundation of China(grant numbers:61972366); National Science Foundation(grant numbers:III-1526499,III-1763325,III-1909323,SaTC-1930941); Australian Research Council Discovery(grant numbers:DP190100981); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158374","Differential privacy;artificial intelligence;machine learning;deep learning;multi-agent systems","Machine learning;Privacy;Multi-agent systems;Security","","120","","165","CCBY","4 Aug 2020","","","IEEE","IEEE Journals"
"A Knowledge Graph Approach to Cyber Threat Mitigation Derived from Data Flow Diagrams","A. Chiş; O. I. Stoica; A. -M. Ghiran; R. A. Buchmann","OMILAB§FSEGA, Faculty of Economics and Business Administration, Babeş-Bolyai University, Cluj-Napoca, Romania; Faculty of Economics and Business Administration, Babeş-Bolyai University, Cluj-Napoca, Romania; Faculty of Economics and Business Administration, Babeş-Bolyai University, Cluj-Napoca, Romania; Faculty of Economics and Business Administration, Babeş-Bolyai University, Cluj-Napoca, Romania","2024 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)","14 Jun 2024","2024","","","1","6","Data Flow Diagrams (DFD) have proven effective in designing and analyzing the flow of data in enterprise systems. They serve as indispensable tools for enterprises that are undergoing transition to cloud services. DFDs aid in understanding the current processes, identifying interfaces and integration points that require security measures. This paper reports a Design Science project to mitigate the cyber security threats at the design phase of a system and to perform auditing of an existing system through knowledge graphs. The proposal leverages knowledge gathered from various sources in a knowledge graph to identify semantic relationships and patterns, enabling automated inference, analysis and detection of vulnerability patterns. Furthermore, LLM-based (large language models) capabilities transform data management details captured as Data Flow Diagrams (DFD) into knowledge graphs for semantic querying and improved decision support.","1844-7872","979-8-3503-6193-3","10.1109/AQTR61889.2024.10554074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554074","knowledge graphs;security;privacy;data flow diagrams;threat modeling;LLMs","Current measurement;Semantics;Knowledge graphs;Transforms;Data models;Security;Proposals","","2","","23","IEEE","14 Jun 2024","","","IEEE","IEEE Conferences"
"Event-Triggered Data-Driven Security Formation Control for Quadrotors Under Denial-of-Service Attacks and Communication Faults","Z. Ren; H. Liu; G. Wen; J. Lü","School of Astronautics, Beihang University, Beijing, China; Institute of Artificial Intelligence, Beihang University, Beijing, China; Department of Systems Science, School of Mathematics, Southeast University, Nanjing, China; Zhongguancun Laboratory, Beijing, China",IEEE Transactions on Cybernetics,"","2024","PP","99","1","11","In this article, the security formation control problem is investigated for underactuated quadrotors involving nonlinear coupled dynamics, subject to denial-of-service (DoS) attacks and uncertain communication faults. A security formation control method is proposed, including a distributed resilient observer and a hierarchical data-driven controller. The observer with an adaptive event-triggered mechanism is developed to restrain the influence of DoS and communication faults on interaction information among quadrotors, and Zeno behavior of all observers can be avoided. The optimal control laws are learned iteratively based on observation data and system data by utilizing reinforcement learning without knowledge of system dynamics. The stability of the constructed closed-loop control system is proven, and sufficient conditions are established for the unreliable network. Simulation results demonstrate the advantages of the proposed security control method.","2168-2275","","10.1109/TCYB.2024.3467178","National Natural Science Foundation of China(grant numbers:62273015,U23B2032); Beijing Natural Science Foundation(grant numbers:4232045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703080","Denial-of-service (DoS) attacks;formation control;multiagent system (MAS);quadrotors;reinforcement learning (RL)","Quadrotors;Security;System dynamics;Formation control;Denial-of-service attack;Couplings;Uncertainty;Topology;Rotors;Optimal control","","1","","","IEEE","2 Oct 2024","","","IEEE","IEEE Early Access Articles"
"Distributed Trust-Aware Virtual Network Embedding for Industrial IoT Systems","P. Rezaeimoghaddam; I. Al-Anbagi","Faculty of Engineering and Applied Science, University of Regina, SK, Canada; Faculty of Engineering and Applied Science, University of Regina, SK, Canada",2023 IEEE 97th Vehicular Technology Conference (VTC2023-Spring),"14 Aug 2023","2023","","","1","6","Network virtualization in wireless sensor networks (WSNs) enables the utilization of shared sensing capabilities in many industrial internet of things (IIoT) applications. Efficient assignment of WSN resources can be achieved through virtual network embedding (VNE) while considering the Quality of Information (QoI) (as the accuracy of sensing), the Quality of Service (QoS) (as the reliability), and wireless interference handling constraints. The shared and complex nature of VNE exposes WSNs to security risks. In this paper, we develop a novel offline distributed trust-aware virtual wireless sensor networks (DTA-VWSN) algorithm that considers the QoI, QoS, and security, by adding required trust level constraints to virtual nodes and links and trust level constraints to the substrate counterparts. Since centralized algorithms suffer from scalability issues, this paper presents our new approach to the virtual network embedding problem in a distributed manner. We use the techniques of multi-agent systems as a well-known approach for distributed systems to scale these algorithms to network size. Our simulation results show that DTA-VWSN improves the execution time of embedding algorithms, acceptance ratio, and cost in substrate networks.","2577-2465","979-8-3503-1114-3","10.1109/VTC2023-Spring57618.2023.10200471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200471","Graph partitioning;multi-agent systems;virtual network embedding (VNE);industrial internet of things (IIoT);wireless sensor networks (WSNs);quality of information (QoI);quality of service (QoS);trustawareness","Wireless sensor networks;Machine learning algorithms;Costs;Heuristic algorithms;Quality of service;Partitioning algorithms;Sensors","","1","","24","IEEE","14 Aug 2023","","","IEEE","IEEE Conferences"
"Securing Trust-Based Resilient Algorithms Against Smart Malicious Agents","C. -Y. Kuo; B. Du; D. Sun","School of Aeronautics and Astronautics, Purdue University, West Lafayette, IN, USA; College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Aeronautics and Astronautics, Purdue University, West Lafayette, IN, USA",IEEE Control Systems Letters,"30 Jul 2025","2025","9","","1922","1927","In this letter, we study the problem of legitimate in-neighborhood learning in multi-agent systems, where stochastic observations of trust between agents are available. Unlike previous works, we consider two types of malicious agents: naive and smart. Naive malicious agents always behave maliciously, while smart malicious agents can intermittently disguise themselves as legitimate agents. We identify a security vulnerability of the standard threshold design  $\epsilon = 1/2$ , which is commonly used in trust aggregation approaches. This design fails to account for the deceptive behavior of smart malicious agents, making the approach vulnerable to their attacks. To address this, we propose a threshold design that explicitly accounts for such agents. Specifically, we provide a sufficient condition for the existence of a constant threshold that enables legitimate agents to identify their legitimate in-neighbors over time, despite the presence of smart malicious agents. In addition, we show that the proposed threshold design ensures geometrically decaying misclassification probabilities. Finally, we present numerical examples to validate our theoretical results and demonstrate how the design enhances the security of existing trust-based resilient algorithms against smart malicious agents.","2475-1456","","10.1109/LCSYS.2025.3588309","National Natural Science Foundation of China(grant numbers:62203218); Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20220884); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11078447","Multi-agent systems;resilient;malicious","Nickel;Security;Multi-agent systems;Resilience;Sufficient conditions;Standards;Distributed algorithms;Upper bound;Training;Sun","","","","15","IEEE","11 Jul 2025","","","IEEE","IEEE Journals"
"The Rise of Artificial Intelligence: Industry Insights and Applications in Security Information and Event Management (SIEM)","M. L. Ali; K. Thakur; H. Barker; M. Chan","Computer Science and Physics Rider University, New Jersey, USA; Department of Cybersecurity, University of Maryland, Adelphi, MD, USA; Department of Cybersecurity, University of Maryland, Adelphi, MD, USA; Information Systems & Statistics Baruch College, New York, NY, USA","2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","20 Nov 2024","2024","","","0477","0482","In recent years, Artificial Intelligence (AI) has become a focal point for companies, governments, and especially threat actors, all striving to improve system efficiency, efficacy, and responsiveness. By training complex systems based on the concept of a “neural network,” an artificial structure modeled after the pathways of the natural brain, machines are now capable of performing intricate tasks and automated processes independent of human control. Given this rapid development, several ethical considerations in data and cybersecurity must be managed or monitored. As laws and regulations continue to evolve, companies face critical decisions regarding how models are trained and how these models impact various stakeholders. After providing a general overview of the core functionalities and a technical description of Artificial Intelligence, machine learning, and the different types of AI, this paper delves into the current cybersecurity applications of AI, particularly focusing on its implementation in Security Information and Event Management (SIEM) systems and how this integration has revolutionized these technologies. Additionally, this paper offers an overview of various pioneering entities and their contributions to AI development, emerging AI trends, and diverse AI applications, including a range of AI leaders across different specialties, from generative AI to cybersecurity solutions.","","979-8-3315-4090-6","10.1109/UEMCON62879.2024.10754705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754705","Artificial Intelligence;SIEM;Machine Learning;Generative AI;Large Learning Module","Industries;Training;Shape;Companies;Brain modeling;Regulation;Stakeholders;Artificial intelligence;Computer security;Protection","","1","","23","IEEE","20 Nov 2024","","","IEEE","IEEE Conferences"
"Deploy, but verify: Analysing LLM Generated Code Safety","R. Krebs; S. Mazumdar","Department of Digitalization, Copenhagen Business School Solbjerg Plads 3, 2000, Frederiksberg, Denmark; Department of Digitalization, Copenhagen Business School Solbjerg Plads 3, 2000, Frederiksberg, Denmark","2025 33rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)","29 Apr 2025","2025","","","13","16","The number of large language models for code generation is rising. However, comprehensive evaluations that focus on reliability and security remain sparse. This study evaluated the Python language code quality generated by five large language models. They are GPT-4-Turbo, DeepSeek-Coder-33B-Instruct, Gemini Pro 1.0, Codex and CodeLLama70 b -Instruct. The evaluation considered three diverse application domains with varying prompt lengths for fair comparison. We found GPT-4-Turbo generated (on average) 4.5% more secure code than a Python code developer with three years of experience.","2377-5750","979-8-3315-2493-7","10.1109/PDP66500.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974840","Code;LLM;Python;Reliability;Safety;Security","Codes;Large language models;Safety;Security;Reliability","","","","11","IEEE","29 Apr 2025","","","IEEE","IEEE Conferences"
"Code Smell-Guided Prompting for LLM-Based Defect Prediction in Ansible Scripts","H. Hong; S. Lee; D. Ryu; J. Baik","Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Jeonbuk National University, Jeonju, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",Journal of Web Engineering,"10 Feb 2025","2024","23","8","1107","1126","Ensuring the reliability of infrastructure as code (IaC) scripts, like those written in Ansible, is vital for maintaining the performance and security of edge-cloud systems. However, the scale and complexity of these scripts make exhaustive testing impractical. To address this, we propose a large language model (LLM)-based software defect prediction (SDP) approach that uses code-smell-guided prompting (CSP). In some cases, CSP enhances LLM performance in defect prediction by embedding specific code smell indicators directly into the prompts. We explore various prompting strategies, including zero-shot, one-shot, and chain of thought CSP (CoT-CSP), to evaluate how code smell information can improve defect detection. Unlike traditional prompting, CSP uniquely leverages code context to guide LLMs in identifying defect-prone code segments. Experimental results reveal that while zero-shot prompting achieves high baseline performance, CSP variants provide nuanced insights into the role of code smells in improving SDP. This study represents exploration of LLMs for defect prediction in Ansible scripts, offering a new perspective on enhancing software quality in edge-cloud deployments.","1544-5976","","10.13052/jwe1540-9589.2383","MSIT (Ministry of Science and ICT), Korea(grant numbers:IITP-2024-2020-0-01795); National Research Foundation of Korea(NRF)(grant numbers:NRF-2022R1I1A3069233); Korea Agency for Infrastructure Technology Advancement (KAIA)(grant numbers:RS-2021-KA163348); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10879172","Edge-cloud;Ansible;large language models;software defect prediction","Codes;Large language models;Image edge detection;Refining;Software quality;Predictive models;Software reliability;Security;Defect detection;Testing","","","","16","","10 Feb 2025","","","River Publishers","River Publishers Journals"
"Beamforming Design for Physical Security in Movable Antenna-aided ISAC Systems: A Reinforcement Learning Approach","H. L. Hung; N. H. Huy; N. C. Luong; Q. -V. Pham; D. Niyato; N. T. Hoa","Faculty of Computer Science, Phenikaa University, Hanoi, Vietnam; School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam; Faculty of Computer Science, Phenikaa University, Hanoi, Vietnam; School of Computer Science and Statistics, Trinity College Dublin, Ireland; College of Computing and Data Science, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam",IEEE Transactions on Vehicular Technology,"","2025","PP","99","1","5","In this paper, we investigate a secure Integrated Sensing and Communication (ISAC) system aided by Movable Antennas (MAs). Therein, the positions of the MAs can be dynamically adjusted to enhance channel conditions, thereby improving communication security for legitimate users in the presence of adversaries. Additionally, we consider a realistic scenario, where the Base Station (BS) only has imperfect eavesdropper's Channel State Information (CSI). In this context, our objective is to optimize the system secrecy rate by jointly designing the BS's transmit beamforming vector and MA movement. To address the dynamics of the ISAC environments and uncertainties of the imperfect CSI scenario, as well as the complexity and non-convexity of the problem, we propose a deep reinforcement learning method to simultaneously design transmit beamforming and MA movement to against eavesdropper. The simulation results show that the use of MAs improves the secrecy rate by 40% and the proposed algorithm outperforms baseline methods in terms of adaptability and performance.","1939-9359","","10.1109/TVT.2025.3575653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11020999","Movable Antenna;Integrated Sensing and Communication;Reinforcement Learning;Physical Layer Security","Array signal processing;Integrated sensing and communication;Antennas;Optimization;Interference;Vectors;Signal to noise ratio;Vehicle dynamics;Radar tracking;Radar antennas","","","","","IEEE","2 Jun 2025","","","IEEE","IEEE Early Access Articles"
"A Low-cost Black-box Jailbreak Based on Custom Mapping Dictionary with Multi-round Induction","F. Wu; W. Wang; Y. Qu; S. Yu","School of Computer Science, University of Technology Sydney, Sydney, Australia; School of Computer Science, University of Technology Sydney, Sydney, Australia; Data61, Commonwealth Scientific and Industrial Research Organization, Burwood, Australia; School of Computer Science, University of Technology Sydney, Sydney, Australia","2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","4 Apr 2025","2024","","","888","895","Note:This paper contains many malicious contents generated by LLMs. Jailbreak can cause large language models (LLMs) to violate moral and ethical guidelines, generating harmful text and images. However, the existing jailbreaks are high-cost (e.g., fine-tuning LLMs) and underperform when facing some specific jailbreak tasks (e.g., generating pornographic and bloody texts), which has too many limitations for reflecting the threat of jailbreak on LLMs’ security. To fill this gap, in this paper, we propose a black-box jailbreak with a higher attack success rate and lower cost, called Dictionary Jailbreak with Multi-round Induction (DJMI). First, in DJMI, we create a simple custom language dictionary based on specific jailbreak tasks to be performed and send it to the LLM. Then, we use the custom language from the dictionary to construct malicious prompts, instructing the LLM to respond in the custom language as much as possible. Generally, in the first round, the LLM will provide a neutral response (such as translating the malicious prompts) or refuse to answer. To counteract this, we need to emphasize that the prompts comply with ethical guidelines and repeat the prompts using the custom language. The process can be conducted with multiple rounds to guide LLM in outputting harmful content. During the attack process, the only attack cost is the transmission cost of the prompts through the official interactive interface, without any other costs of LLM fine-tuning, algorithm design and prompt generation. Thus, DJMI is a low-cost jailbreak method. We verified DJMI on multiple mainstream LLMs across various jailbreak tasks. Experiments show that compared to existing black-box jailbreaks, DJMI achieves a higher attack success rate (> 80% on average) across specific jailbreak tasks with various risk levels. Additionally, DJMI enables the LLM to provide highly detailed execution steps for harmful behaviors within a session (such as specifying proportions of ingredients, synthetic chemical formulas, experimental conditions, and other detailed information in illicit drug production), further highlighting the severity of jailbreak attacks.","2324-9013","979-8-3315-0620-9","10.1109/TrustCom63139.2024.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10944972","jailbreak;LLMs;prompts;black-box;jailbreak tasks","Drugs;Ethics;Waste materials;Dictionaries;Costs;Translation;Large language models;Closed box;Resists;Guidelines","","","","30","IEEE","4 Apr 2025","","","IEEE","IEEE Conferences"
"Distributed Optimization Under Adversarial Nodes","S. Sundaram; B. Gharesifard","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Mathematics and Statistics, Queen's University, Kingston, ON, Canada",IEEE Transactions on Automatic Control,"27 Feb 2019","2019","64","3","1063","1076","We investigate the vulnerabilities of consensus-based distributed optimization protocols to nodes that deviate from the prescribed update rule (e.g., due to failures or adversarial attacks). We first characterize certain fundamental limitations on the performance of any distributed optimization algorithm in the presence of adversaries. We then propose a secure distributed optimization algorithm that guarantees that the nonadversarial nodes converge to the convex hull of the minimizers of their local functions under the certain conditions on the graph topology, regardless of the actions of a certain number of the adversarial nodes. In particular, we provide sufficient conditions on the graph topology to tolerate a bounded number of adversaries in the neighborhood of every nonadversarial node, and necessary and sufficient conditions to tolerate a globally bounded number of adversaries. For situations, where there are up to F adversaries in the neighborhood of every node, we use the concept of maximal F-local sets of graphs to provide lower bounds on the distance-to-optimality of achievable solutions under any algorithm. We show that finding the size of such sets is NP-hard.","1558-2523","","10.1109/TAC.2018.2836919","National Science Foundation(grant numbers:1653648); Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359183","Distributed algorithms;fault tolerance;graph theory;machine learning;multi-agent systems;network security;optimization","Optimization;Heuristic algorithms;Protocols;Topology;Safety;Stochastic processes;Linear programming","","174","","30","IEEE","15 May 2018","","","IEEE","IEEE Journals"
"Resilient Randomized Quantized Consensus","S. M. Dibaji; H. Ishii; R. Tempo","Department of Computer Science, Tokyo Institute of Technology, Yokohama, Japan; Department of Computer Science, Tokyo Institute of Technology, Yokohama, Japan; CNR-IEIIT, Politecnico di Torino, Torino, Italy",IEEE Transactions on Automatic Control,"26 Jul 2018","2018","63","8","2508","2522","We consider the problem of multiagent consensus where some agents are subject to faults/attacks and might make updates arbitrarily. The network consists of agents taking integer-valued (i.e., quantized) states under directed communication links. The goal of the healthy normal agents is to form consensus in their state values, which may be disturbed by the non-normal, malicious agents. We develop update schemes to be equipped by the normal agents whose interactions are asynchronous and subject to nonuniform and time-varying time delays. In particular, we employ a variant of the so-called mean subsequence reduced algorithms, which have been long studied in computer science, where each normal agent ignores extreme values from its neighbors. We solve the resilient quantized consensus problems in the presence of totally/locally bounded adversarial agents and provide necessary and sufficient conditions in terms of the connectivity notion of graph robustness. Furthermore, it will be shown that randomization is essential both in quantization and in the updating times when normal agents interact in an asynchronous manner. The results are examined through a numerical example.","1558-2523","","10.1109/TAC.2017.2771363","JST CREST(grant numbers:JPMJCR15K3); CNR-JST International Joint Lab COOPS; JSPS; Scientific Research(grant numbers:15H04020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100900","Asynchronous communication;cyber security;distributed algorithms;fault tolerant systems;multi-agent systems;quantization","Computer science;Delays;Robustness;Control systems;Quantization (signal);Multi-agent systems;Electronic mail","","122","","42","IEEE","9 Nov 2017","","","IEEE","IEEE Journals"
"A Highly-Secure Self-Protection Data Scheme in Clouds Using Active Data Bundles and Agent-Based Secure Multi-party Computation","A. Y. Sarhan; S. Carr","Faculty of Computing and IT, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science, Western Michigan University Kalamazoo, MI, USA",2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud),"24 Jul 2017","2017","","","228","236","Protection of data in cloud computing is a critical problem for many enterprises. We propose a solution that protects sensitive data outsourced to a cloud throughout their entire life cycle—both in the cloud as well as outside of the cloud (e.g., during transmission to or from the cloud). Our solution, known as Active Data Bundles using Secure Multi-Party Computation (ADB-SMC), uses: (i) active data bundles (ADBs)—for self-protecting data; (ii) ciphertext-policy attribute-based encryption—for fine-grained access control; and, (iii) threshold RSA—for secure key management. We describe components and design of ADB-SMC and present the pseudocode for creating ADB to outsource data to the cloud. We implemented a prototype of the solution and compared its overhead with the overhead of the approach known as Active Bundles with Trusted Third Party (ABTTP). The results of performance tests show that the execution time overhead for ADBSMC is acceptable.","","978-1-5090-6644-5","10.1109/CSCloud.2017.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987203","Active Data Bundle;Attribute-based Encryption;Cloud Computing;JADE;Multi-agent Systems;Multi-party Computation;Privacy;Security;Self-protecting Data.","Cloud computing;Metadata;Encryption;Distributed databases;Data privacy","","11","","37","IEEE","24 Jul 2017","","","IEEE","IEEE Conferences"
"Scalable Distributed Optimization of Multi-Dimensional Functions Despite Byzantine Adversaries","K. Kuwaranancharoen; L. Xin; S. Sundaram","Purdue University, West Lafayette, IN, USA; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA",IEEE Transactions on Signal and Information Processing over Networks,"9 Apr 2024","2024","10","","360","375","The problem of distributed optimization requires a group of networked agents to compute a parameter that minimizes the average of their local cost functions. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to “Byzantine” agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or assume certain statistical properties of the functions at the agents. In this paper, we provide two resilient, scalable, distributed optimization algorithms for multi-dimensional functions. Our schemes involve two filters, (1) a distance-based filter and (2) a min-max filter, which each remove neighborhood states that are extreme (defined precisely in our algorithms) at each iteration. We show that these algorithms can mitigate the impact of up to $F$ (unknown) Byzantine agents in the neighborhood of each regular agent. In particular, we show that if the network topology satisfies certain conditions, all of the regular agents' states are guaranteed to converge to a bounded region that contains the minimizer of the average of the regular agents' functions.","2373-776X","","10.1109/TSIPN.2024.3379844","National Science Foundation(grant numbers:1653648); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478151","Byzantine attacks;convex optimization;distributed algorithms;fault tolerance;graph theory;machine learning;multi-agent systems;network security","Optimization;Vectors;Information processing;Filtering algorithms;Convergence;Peer-to-peer computing;Convex functions","","2","","52","IEEE","22 Mar 2024","","","IEEE","IEEE Journals"
"Constant-Stepsize Distributed Optimization Algorithm with Malicious Nodes","S. Zhang; Z. -W. Liu; Y. Zhai; Y. Zhao; G. Wen","School of Artificial Intelligence and Automation Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation Huazhong University of Science and Technology, Wuhan, China; School of Automation Northwestern Polytechnical University, Xi'an, China; Department of Systems Science, School of Mathematics Southeast University, Nanjing, China",2021 International Conference on Neuromorphic Computing (ICNC),"29 Nov 2021","2021","","","177","182","This paper develops a consensus-based distributed (sub)gradient descent algorithm, which has a faster convergence rate in the presence of malicious nodes. To achieve this, two main methods are used in the proposed algorithm. The first is using the local filtering algorithm to counteract the attacks of malicious nodes; The second is using the constant step size in the distributed (sub)gradient descent algorithm rather than diminishing step size to accelerate the convergence rate. As a result, the proposed algorithm improves the convergence rate in the presence of malicious nodes. Finally, a numerical example is presented to verify the proposed algorithm, and the possible future research directions are given.","","978-1-6654-1287-2","10.1109/ICNC52316.2021.9609053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609053","distributed algorithms;multi-agent systems;optimization methods;robust networks;network security","Neuromorphic engineering;Optimization methods;Resists;Filtering algorithms;Security;Convergence","","1","","10","IEEE","29 Nov 2021","","","IEEE","IEEE Conferences"
"Securing Distributed Computing in the Metaverse: A Balanced TGDH Encryption Scheme","A. Bose; J. L. Nori; L. Bai","Department of Electrical Engineering, Temple University, Philadelphia, Philadelphia, PA; Department of Electrical Engineering, Temple University, Philadelphia, Philadelphia, PA; Department of Electrical Engineering, Temple University, Philadelphia, Philadelphia, PA","2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)","6 Oct 2023","2023","","","226","233","In this paper, we present a secure communication protocol based on a balanced Tree-based Group Diffie–Hellman (TGDH) key management solution for secure distributed computing in metaverse. The novelty of this work is that our modified TGDH algorithm balances the tree while preserving the distributed, secure architecture of group re-keying. The balanced tree ensures optimized computation regardless of join or leave events. This paper also presents a portable Python application programming interface (API) for the implementation of this secured group key management algorithm. This API addresses a lack of existing open-source implementations of TGDH, specifically in distributed-system architecture. From cloud based data sharing to distributed multi-agent frameworks and any secured computation application in metaverse, our algorithm can be easily and efficiently ported to any OS and used to secure group communications.","","979-8-3503-3333-6","10.1109/MetaCom57706.2023.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271893","secure group communication;group key agreement implementation;TGDH;secure multi-agent systems;security in distributed computing;secure computing in metaverse","Military communication;Protocols;Metaverse;Military computing;Entertainment industry;Computer architecture;Multimedia computing","","","","19","IEEE","6 Oct 2023","","","IEEE","IEEE Conferences"
"ROS-NetSim: A Framework for the Integration of Robotic and Network Simulators","M. Calvo-Fullana; D. Mox; A. Pyattaev; J. Fink; V. Kumar; A. Ribeiro","Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; Unit of Electrical Engineering, Tampere University, Tampere, Finland; Department of Computational and Information Sciences, U.S. Army Research Laboratory, Adelphi, MD, USA; Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA",IEEE Robotics and Automation Letters,"16 Feb 2021","2021","6","2","1120","1127","Multi-agent systems play an important role in modern robotics. Due to the nature of these systems, coordination among agents via communication is frequently necessary. Indeed, Perception-Action-Communication (PAC) loops, or Perception-Action loops closed over a communication channel, are a critical component of multi-robot systems. However, we lack appropriate tools for simulating PAC loops. To that end, in this letter, we introduce ROS-NetSim, a ROS package that acts as an interface between robotic and network simulators. With ROS-NetSim, we can attain high-fidelity representations of both robotic and network interactions by accurately simulating the PAC loop. Our proposed approach is lightweight, modular and adaptive. Furthermore, it can be used with many available network and physics simulators by making use of our proposed interface. In summary, ROS-NetSim is (i) Transparent to the ROS target application, (ii) Agnostic to the specific network and physics simulator being used, and (iii) Tunable in fidelity and complexity. As part of our contribution, we have made available an open-source implementation of ROS-NetSim to the community.","2377-3766","","10.1109/LRA.2021.3056347","ARL DCIST CRA(grant numbers:W911NF-17-2-0181); Intel Science and Technology Center for Wireless Autonomous Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345354","Multi-robot systems;networked robots;methods and tools for robot system design;software architecture for robotic and automation","Physics;Robot kinematics;Picture archiving and communication systems;Synchronization;Robot sensing systems;Communication channels;Wireless sensor networks","","32","","28","IEEE","2 Feb 2021","","","IEEE","IEEE Journals"
"AI Agent-based Adaptive Task Offloading for Autonomous Drones in Dynamic Environments","Q. Zhang; F. Machida","Department of Computer Science, University of Tsukuba, Tsukuba, Japan; Department of Computer Science, University of Tsukuba, Tsukuba, Japan",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S),"9 Jul 2025","2025","","","239","241","This study introduces an AI agent architecture using large language models (LLMs) for deciding task offloading in autonomous drones operating in dynamic environments. To overcome the inflexibility of existing offload decision methods, we aim to leverage AI agents to dynamically delegate tasks to edge servers or defer execution, ensuring reliable decision-making. The proposed AI agent system integrates real-time analysis (e.g., CPU/GPU utilization, network bandwidth, battery status), offloading decision making by LLMs, and a feedback loop to refine decision accuracy over time to balance reliability, latency, and energy efficiency. A primary LLM generates initial offloading decisions, while a secondary LLM verifies the initial decision by predefined risk constraints and makes the final decision. Preliminary experiments of each LLM on the NVIDIA Jetson Orin Nano demonstrate promising results in performance log analysis speed and resource optimization, though challenges remain in achieving consistent outputs across repeated runs and scaling to more complex tasks. This work highlights the potential of AI agent-based approach to enhance drone adaptive task offloading under varying conditions.","2833-292X","979-8-3315-1203-3","10.1109/DSN-S65789.2025.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068324","drone;offloading;LLM;AI agent","Feedback loop;Large language models;Decision making;Real-time systems;Energy efficiency;Reliability;Servers;Artificial intelligence;Optimization;Drones","","","","19","IEEE","9 Jul 2025","","","IEEE","IEEE Conferences"
"Keyword Searchable Provable Data Possession in Generative AI Enabled Intelligent Transportation Systems","Y. Cui; C. Wang; J. Shen; P. Vijayakumar; O. Alfarraj; A. Tolba","School of Information Science and Engineering (School of Cyber Science and Technology), Zhejiang Key Laboratory of Digital Fashion and Data Governance, and Zhejiang Provincial International Cooperation Base for Science and Technology on Cloud Computing Security and Data Aggregation, Zhejiang Sci-tech University, Hangzhou, China; School of Information Science and Engineering (School of Cyber Science and Technology), Zhejiang Key Laboratory of Digital Fashion and Data Governance, and Zhejiang Provincial International Cooperation Base for Science and Technology on Cloud Computing Security and Data Aggregation, Zhejiang Sci-tech University, Hangzhou, China; School of Information Science and Engineering (School of Cyber Science and Technology), Zhejiang Key Laboratory of Digital Fashion and Data Governance, and Zhejiang Provincial International Cooperation Base for Science and Technology on Cloud Computing Security and Data Aggregation, Zhejiang Sci-tech University, Hangzhou, China; Department of Information Technology, J.J. College of Engineering and Technology, Tiruchirappalli, Tamil Nadu, India; Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","10","In generative artificial intelligence (AI) enabled intelligent transportation systems (ITS), real-time interaction and analysis of massive multi-source data are the core drivers for system optimization. However, large scale outsourcing storage of data, while enhancing computational efficiency, also poses security threats such as data integrity compromise, sensitive information leakage, and malicious tampering. These issues severely impact the quality of generative AI model training and the reliability of system services. Although existing cloud provable data possession (PDP) schemes can verify data integrity, they incur high computational overhead in ITS scenarios and lack support for fine-grained data retrieval. To address the need for specific data auditing by data users in generative AI enabled ITS, we propose a keyword searchable provable data possession scheme, which integrates data integrity verification with efficient data retrieval. First, a lightweight indexing approach is integrated to optimize the keyword search process, allowing different data users to initiate keyword based targeted queries based on their specific business needs, with integrity verification performed only on matching data blocks. Second, an efficient integrity auditing scheme is designed to ensure the integrity of outsourced intelligent vehicle data. Finally, security analysis and experimental results demonstrate that the proposed scheme achieves acceptable efficiency in computation overhead compared to existing works, while improving the auditability and searchability of outsourced ITS data.","1558-0016","","10.1109/TITS.2025.3579407","National Key Research and Development Program of China(grant numbers:2023YFB2703700); National Natural Science Foundation of China(grant numbers:U21A20465,62302457,62441228); Program for Leading Innovative Research Team of Zhejiang Province(grant numbers:2023R01001); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LQ24F020008); Fundamental Research Funds of Zhejiang Sci-tech University(grant numbers:22222266-Y); “Pioneer” and “Leading Goose” Research and Development Program of Zhejiang(grant numbers:2025C02033,2023C01119); Ongoing Research Funding Program (King Saud University, Riyadh, Saudi Arabia)(grant numbers:ORF-2025-681); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048670","Intelligent transportation systems;provable data possession;generative artificial intelligence;keyword","Generative AI;Data integrity;Cloud computing;Security;Data privacy;Real-time systems;Encryption;Training;Driver behavior;Data models","","","","","IEEE","23 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Structural Segmentation and Large Language Model Make Behavior Tree More Explainable","H. Su; X. Zhao; F. Li; Z. Guo; Y. Wu; Y. Wang","Intelligent Game and Decision Lab (IGDL), Tianjin, China; Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Intelligent Game and Decision Lab (IGDL), Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Intelligent Game and Decision Lab (IGDL), Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Intelligent Game and Decision Lab (IGDL), Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China","2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)","29 Apr 2024","2023","","","305","310","Behavior trees have found extensive applications in the field of robotics due to their modular and reusable characteristics. They are employed to enable autonomous actions in robots, including control of robot motion, assessment of the robot's state, and the planning of the robot's action sequences. Behavior trees offer the advantage of effectively representing complex behaviors and adapting well to various environments and tasks. However, when reusing behavior trees constructed for prior projects, comprehension of the functional-ity of intricate behavior trees can pose a challenge for technical personnel. To expedite the comprehension of new behavior trees and enhance task development efficiency, this paper introduces a method for behavior tree explanation based on behavior tree segmentation and large language models. This method performs structural segmentation of behavior trees based on the hierarchical structure of tasks. It leverages the natural language capabilities of open-source large language models to obtain function explanations of behavior trees, thereby assisting technical personnel in understanding their functional-ity. Through experimentation, the paper initially demonstrates the feasibility of utilizing large language models to interpret behavior trees. It further validates that the superiority of the proposed methodology in terms of accuracy and stability compared to the mere utilization of the intrinsic capabilities of large language models.","","979-8-3503-6036-3","10.1109/AIHCIR61661.2023.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10505332","Behavior Tree;Explanation;LLM;Segmentation;Prompt Engineering","Robot motion;Human computer interaction;Natural languages;Manuals;Stability analysis;Planning;Personnel","","","","13","IEEE","29 Apr 2024","","","IEEE","IEEE Conferences"
"When ChatGPT Meets Vulnerability Management: The Good, the Bad, and the Ugly","K. McClanahan; S. Elder; M. L. Uwibambe; Y. Liu; R. Heng; Q. Li",University of Arkansas; University of Arkansas; University of Arkansas; University of Arkansas; University of Arkansas; University of Arkansas,"2024 International Conference on Computing, Networking and Communications (ICNC)","21 Jun 2024","2024","","","664","670","Vulnerability management is a very challenging and time-consuming task. For many organizations, security operators need to learn about the properties of vulnerabilities to prioritize and mitigate them. Due to the lack of automated tools for vulnerability assessment, operators usually manually search for and read related information from sources online. Recent advances in large language models, like ChatGPT, open up an opportunity for time savings and may prompt operators to use these models as vulnerability information sources. In this work, we evaluate the ability of ChatGPT and several of its siblings to accurately answer user questions about vulnerability properties as well as to provide information for how to mitigate a vulnerability. We also explore their summarization capabilities when multiple vulnerability advisory documents are provided. We find that the models perform poorly on information retrieval tasks, but they perform quite well on summarization.","2473-7585","979-8-3503-7099-7","10.1109/ICNC59896.2024.10555953","NSF(grant numbers:1751255); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555953","ChatGPT;Large Language Models;Vulnerability","Computational modeling;Training data;Organizations;Chatbots;Information retrieval;Vectors;Data models","","5","","34","IEEE","21 Jun 2024","","","IEEE","IEEE Conferences"
"Harnessing Open Language Models: A Systematic Literature Review Unleashing AI's Potential for a Smarter Future","I. M. García López; M. S. Ramírez Montoya; J. M. Molina Espinosa","Tecnologico de Monterrey, Escuela de Ingeniería y Ciencias, Estado de México, México; Tecnologico de Monterrey, EGADE Business School, Monterrey, México; Tecnologico de Monterrey, Instituto para el Futuro de la Educación, Ciudad de México, México",2025 Institute for the Future of Education Conference (IFE),"13 Jun 2025","2025","","","1","12","This study provides a systematic literature review (SLR) on Open Large Language Models (OLLM), which are large-scale natural language processing (NLP) models with accessible source code, configuration, and training data for the community. Recent advances in supervised and unsupervised learning techniques have improved the accuracy and contextual capabilities of OLLMs, enabling advanced applications in conversational interaction and long-text analysis. This research explored the applications and socioeconomic impacts of OLLMs in various industries, such as healthcare, education, and business management, demonstrating how these models optimize the efficiency and personalization of different processes. The study also addresses the ethical and operational challenges associated with OLLMs, such as bias management, data privacy and security, decision-making transparency, and technological dependency. Strategies are proposed to mitigate these issues, including regular ethics audits and the adoption of explainable AI frameworks. Finally, the study emphasizes the importance of maintaining a balance between OLLMs and human skills, the need for robust governance frameworks to ensure the ethical and legal operation of these models, and the promotion of continuous innovation to expand their capabilities for a positive and lasting impact on society.","","979-8-3503-5523-9","10.1109/IFE63672.2025.11024736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024736","higher education;educational innovation;open large language models;artificial intelligence","Ethics;Technological innovation;Large language models;Source coding;Education;Training data;Natural language processing;Socioeconomics;Unsupervised learning;Systematic literature review","","","","54","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"UX for Enterprise ChatGPT Solutions: A practical guide to designing enterprise-grade LLMs","R. H. Miller; J. Johnson",NA; NA,UX for Enterprise ChatGPT Solutions: A practical guide to designing enterprise-grade LLMs,"","2024","","","","","Create engaging AI experiences by mastering ChatGPT for business and leveraging user interface design practices, research methods, prompt engineering, the feeding lifecycle, and moreKey FeaturesLearn in-demand design thinking and user research techniques applicable to all conversational AI platformsMeasure the quality and evaluate ChatGPT from a customer’s perspective for optimal user experienceSet up and use your secure private data, documents, and materials to enhance your ChatGPT modelsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionMany enterprises grapple with new technology, often hopping on the bandwagon only to abandon it when challenges emerge. This book is your guide to seamlessly integrating ChatGPT into enterprise solutions with a UX-centered approach. UX for Enterprise ChatGPT Solutions empowers you to master effective use case design and adapt UX guidelines through an engaging learning experience. Discover how to prepare your content for success by tailoring interactions to match your audience’s voice, style, and tone using prompt-engineering and fine-tuning. For UX professionals, this book is the key to anchoring your expertise in this evolving field. Writers, researchers, product managers, and linguists will learn to make insightful design decisions. You’ll explore use cases like ChatGPT-powered chat and recommendation engines, while uncovering the AI magic behind the scenes. The book introduces a and feeding model, enabling you to leverage feedback and monitoring to iterate and refine any Large Language Model solution. Packed with hundreds of tips and tricks, this guide will help you build a continuous improvement cycle suited for AI solutions. By the end, you’ll know how to craft powerful, accurate, responsive, and brand-consistent generative AI experiences, revolutionizing your organization’s use of ChatGPT.What you will learnAlign with user needs by applying design thinking to tailor ChatGPT to meet customer expectationsHarness user research to enhance chatbots and recommendation enginesTrack quality metrics and learn methods to evaluate and monitor ChatGPT's quality and usabilityEstablish and maintain a uniform style and tone with prompt engineering and fine-tuningApply proven heuristics by monitoring and assessing the UX for conversational experiences with trusted methodsRefine continuously by implementing an ongoing process for chatbot and feedingWho this book is forThis book is for user experience designers, product managers, and product owners of business and enterprise ChatGPT solutions who are interested in learning how to design and implement ChatGPT-4 solutions for enterprise needs. You should have a basic-to-intermediate level of understanding in UI/UX design concepts and fundamental knowledge of ChatGPT-4 and its capabilities.","","9781835463802","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769349.pdf&bkn=10769348&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Audio Jailbreak Attacks: Exposing Vulnerabilities in SpeechGPT in a White-Box Framework","B. Ma; H. Guo; Z. J. Luo; R. Duan","Department of Computer Science, University of Missouri-Kansas City, Kansas City, United States; Department of Electrical and Computer Engineering, University of Hawai'i at Manoa, Honolulu, United States; Department of Computer Science and Physics, Rider University, Lawrenceville, United States; Department of Computer Science, University of Missouri-Kansas City, Kansas City, United States",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),"14 Jul 2025","2025","","","259","265","Recent advances in Multimodal Large Language Models (MLLMs) have significantly enhanced the naturalness and flexibility of human-computer interaction by enabling seamless understanding across text, vision, and audio modalities. Among these, voice-enabled models such as SpeechGPT have demonstrated considerable improvements in usability, offering expressive, and emotionally responsive interactions that foster deeper connections in real-world communication scenarios. However, the use of voice introduces new security risks, as attackers can exploit the unique characteristics of spoken language, such as timing, pronunciation variability, and speech-to-text translation, to craft inputs that bypass defenses in ways not seen in text-based systems. Despite substantial research on text-based jailbreaks, the voice modality remains largely underexplored in terms of both attack strategies and defense mechanisms. In this work, we present an adversarial attack targeting the speech input of aligned MLLMs in a white-box scenario. Specifically, we introduce a novel token-level attack that leverages access to the model's speech tokenization to generate adversarial token sequences. These sequences are then synthesized into audio prompts, which effectively bypass alignment safeguards and to induce prohibited outputs. Evaluated on SpeechGPT, our approach achieves up to 89 % attack success rate across multiple restricted tasks, significantly outperforming existing voice-based jailbreak methods. Our findings shed light on the vulnerabilities of voice-enabled multimodal systems and to help guide the development of more robust next-generation MLLMs. Disclaimer. This paper contains examples of harmful language. Reader discretion is recommended.","2325-6664","979-8-3315-1205-7","10.1109/DSN-W65791.2025.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071619","Audio Jailbreak Attacks;Multimodal Large Language Models","Translation;Large language models;Noise;Tokenization;Timing;Safety;Security;Usability;Glass box;Speech to text","","","","36","IEEE","14 Jul 2025","","","IEEE","IEEE Conferences"
"Vulnerability Patch Verification for Military Software Systems Through AI-Driven Code-Level Rule Generation","S. S. Antar; P. Charland; S. H. H. Ding; B. C. M. Fung","Research Assistant School of Computing, Queen's University, Kingston, ON, Canada; Defence Scientist Mission Critical Cyber Security Section Defence Research and Development Canada, Quebec, QC, Canada; School of Information Studies, McGill University, Montreal, QC, Canada; School of Information Studies, McGill University, Montreal, QC, Canada",2025 17th International Conference on Cyber Conflict: The Next Step (CyCon),"12 Aug 2025","2025","","","189","208","Patch verification is critical in military systems to ensure that known vulnerabilities are effectively addressed, preventing them from being exploited. Without proper verification, unpatched software could allow adversaries to exploit vulnerabilities, leading to unauthorized access, compromised operations, or even mission failure. In high-stakes environments such as military operations, patch verification is essential for maintaining the security, integrity, and readiness of both software and firmware, particularly in systems that manage sensitive information or control mission-critical equipment. Traditional methods that rely on version strings to verify vulnerability patching are often insufficient. For example, the Heartbleed vulnerability (CVE-2014-0160) affected OpenSSL versions 1.0.1 through 1.0.lf. A system running OpenSSL 1.0.lf might still be flagged as vulnerable, even if a custom patch was applied, in the event that the version string was not updated by the software maintainer fixing the vulnerability. This will lead to false positives in the vulnerability detection process. Conversely, a system may appear secure based on the version string, but if the patch was not correctly implemented, the vulnerability will remain, resulting in false negatives. To address these limitations, this paper presents a new scalable, artificial intelligence-based code-level verification system. By leveraging large language models to generate rules that analyze the actual executable code, this approach verifies whether vulnerabilities have been properly fixed, regardless of version metadata. Additionally, it can pinpoint the exact location of exploitable code as a more accurate and reliable method for detecting and confirming patches. Our experiment, involving 1,466 vulnerable software records with over 4,000 instances, demonstrates that the rule generation system is both accurate and robust.","2325-5374","978-9916-9789-9-3","10.23919/CyCon65856.2025.11103589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103589","patch verification;vulnerability detection;firmware analysis;artificial intelligence;large language models","Accuracy;Codes;Large language models;Mission critical systems;Syntactics;Performance gain;Software systems;Software reliability;Security;Microprogramming","","","","27","","12 Aug 2025","","","IEEE","IEEE Conferences"
"MAS-PD: Transferable Adversarial Attack Against Vision-Transformers-Based SAR Image Classification Task","B. Zheng; J. Liu; Y. Li; Y. Li; Z. Qin","School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China; Northern Institute of Electronic Equipment of China, Beijing, China",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"15 Apr 2025","2025","18","","9509","9521","Synthetic aperture radar (SAR) is widely used in civil and military fields. With advancements in vision transformer (ViT) research, these models have become increasingly important in SAR image classification due to their remarkable performance. Therefore, effectively interfering with the classification results of enemy radar systems has become a crucial factor in ensuring battlefield security. Adversarial attacks offer a potential solution, as they can significantly mislead models and cause incorrect predictions. However, recent research on adversarial examples focus on the vulnerability of convolutional neural network (CNN) models, while the attack on transformer models has not been extensively studied. Considering that ViTs differ from CNNs due to its unique multihead self-attention (MSA) mechanism and its approach of segmenting images into patches for input, this article proposes a “MAS-PD” black-box adversarial attack method targeting these two mechanisms in ViTs. First, to target the MSA mechanism, we propose the Momentum Attention Skipping attack. By skipping the attention gradient during backpropagation and using momentum to avoid local maxima during gradient ascent, our method enhances the transferability of adversarial attacks across different models. Then, we apply dropout on input patches in each iteration, achieving higher attack success rates compared to using all patches. We compare our method with four traditional adversarial attack techniques across different model architectures, including CNNs and ViTs, using the publicly available MSTAR SAR dataset. The experimental results show that our method achieves an average Attack Success Rate (ASR) of 68.82% across ViTs, while other methods achieve no more than 50% ASR on average. When applied to CNNs, our method also achieves an average ASR of 67.14%, compared to less than 40% ASR for other methods. The experiment results demonstrate that our algorithm significantly enhances transferability between ViTs and from ViTs to CNNs in SAR image classification tasks.","2151-1535","","10.1109/JSTARS.2025.3546271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10906523","Adversarial attack;black-box attack;synthetic aperture radar (SAR);vision transformers (ViTs)","Radar polarimetry;Remote sensing;Image recognition;Transformers;Radar imaging;Radar;Perturbation methods;Closed box;Neural networks;Feature extraction","","","","50","CCBY","27 Feb 2025","","","IEEE","IEEE Journals"
"Some Aspects of Artificial Intelligence Development Strategy for Mobile Technologies","V. Slyusar; Y. Kondratenko; A. Shevchenko; T. Yeroshenko","Institute of Artificial Intelligence Problems of the Ministry of Education and Science and the National Academy of Sciences of Ukraine, Kyiv, Ukraine; Institute of Artificial Intelligence Problems of the Ministry of Education and Science and the National Academy of Sciences of Ukraine, Kyiv, Ukraine; Institute of Artificial Intelligence Problems of the Ministry of Education and Science and the National Academy of Sciences of Ukraine, Kyiv, Ukraine; Institute of Artificial Intelligence Problems of the Ministry of Education and Science and the National Academy of Sciences of Ukraine, Kyiv, Ukraine",Journal of Mobile Multimedia,"22 Apr 2025","2024","20","3","525","554","The article addresses hardware-software and other key aspects of the artificial intelligence development strategy for mobile technologies. The proposed components of the strategy include a series of approaches to address issues related to the development and deployment of large language models on mobile devices, as well as suggestions for improving connectivity, memory management, and data security.","1550-4654","","10.13052/jmm1550-4646.2031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974497","Strategy;artificial intelligence;neural networks;large language models;Internet of Things;cloud computing;fog computing;quantum computing","Quantum computing;Prevention and mitigation;Large language models;Personal voice assistants;Smart homes;Multimedia computing;User experience;Regulation;Artificial intelligence;Standards","","","","42","","22 Apr 2025","","","River Publishers","River Publishers Journals"
"Application Status, Problems and Future Prospects of Generative AI in Education","H. Yu; Z. Liu; Y. Guo","Department of Education, Shaanxi Normal University, Xi'an, China; Department of Education, Shaanxi Normal University, Xi'an, China; School of Foreign Languages, Northwest University, Xi'an, China",2023 5th International Conference on Computer Science and Technologies in Education (CSTE),"29 Sep 2023","2023","","","1","7","The emergence of Chat GPT signifies another revolutionary wave of information technology brought about by generative AI. This article introduces the development and technical support of generative AI, revealing that there are four main issues regarding its application in the education field: opacity and inexplicability, data privacy and security, individualization and fairness, and effectiveness and reliability. The article then looks forward to the future trends of generative AI in the education field from four aspects: personalized education, intelligent teaching, joint education, and virtual teaching, aiming to provide important reference value for research and practice in this field.","","979-8-3503-2572-0","10.1109/CSTE59648.2023.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261631","generative artificial intelligence;educational application;countermeasure research;development prospects","Training;Learning systems;Ethics;Education;Virtual reality;Market research;Security","","8","","33","IEEE","29 Sep 2023","","","IEEE","IEEE Conferences"
"Themes of Building LLM-Based Applications for Production: A Practitioner's View","A. Mailach; S. Simon; J. Dorn; N. Siegmund","ScaDS.Ai Dresden/Leipzig, Leipzig University; Leipzig University; Leipzig University; ScaDS.Ai Dresden/Leipzig, Leipzig University",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","18","30","Background: Large language models (LLMs) have become a paramount interest of researchers and practitioners alike, yet a comprehensive overview of key considerations for those developing LLM-based systems is lacking. This study addresses this gap by collecting and mapping the topics practitioners discuss online, offering practical insights into where priorities lie in developing LLM-based applications. Method: We collected 189 videos from 2022 to 2024 by practitioners actively developing such systems and discussing various aspects they encounter during development and deployment of LLMs in production. We analyzed the transcripts using BERTopic, then manually sorted and merged the generated topics into themes, leading to a total of 20 topics in 8 themes. Results: The most prevalent topics fall within the theme Design & Architecture, with a strong focus on retrieval-augmented generation (RAG) systems. Other frequently discussed topics include model capabilities and enhancement techniques (e.g., finetuning, prompt engineering), infrastructure and tooling, and risks and ethical challenges. Implications: Our results highlight current discussions and challenges in deploying LLMs in production. This way, we provide a systematic overview of key aspects practitioners should be aware of when developing LLM-based applications. We further highlight topics of interest for academics where further research is needed.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030002","LLM in production;RAG;retrieval-augmented generation;fine-tuning;prompt engineering;agents;evaluation","Systematics;Large language models;Retrieval augmented generation;Production;Computer architecture;Manuals;Prompt engineering;Tuning;Videos;Software engineering","","","","78","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Exploring LLM Support for Generating IEC 61131-3 Graphic Language Programs","Y. Zhang; M. de Sousa","CISTER / Faculty of Engineering, University of Porto, Porto, Portugal; Faculty of Engineering, University of Porto, Porto, Portugal",2024 IEEE 22nd International Conference on Industrial Informatics (INDIN),"12 Dec 2024","2024","","","1","7","The capabilities demonstrated by Large Language Models (LLMs) inspire researchers to integrate them into industrial production and automation. In the field of Programmable Logic Controller (PLC) programming, previous researchers have focused on using LLMs to generate Structured Text (ST) language, and created automatic programming workflows based on it. The IEC 61131 graphic programming languages, which still has the most users [1], have however been overlooked. In this paper we explore using LLMs to generate graphic languages in ASCII art to provide assistance to engineers. Our series of experiments indicate that, contrary to what researchers usually think, it is possible to generate a correct Sequential Function Chart (SFC) for simple requirements when LLM is provided with several examples. On the other hand, generating a Ladder Diagram (LD) automatically remains a challenge even for very simple use cases. The automatic conversion between LD and SFC without extra information also fails when using prompt engineering alone.","2378-363X","979-8-3315-2747-1","10.1109/INDIN58382.2024.10774464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774464","Large Language Model;Prompt Engineering;Programmable Logic Controller;IEC 61131;Ladder Diagram;Sequential Function Chart","Graphics;Computer languages;Automation;Large language models;Programmable logic devices;Production;Prompt engineering;Logic;IEC Standards;Informatics","","","","17","IEEE","12 Dec 2024","","","IEEE","IEEE Conferences"
"Distributed Observer-Based Cyber-Security Control of Complex Dynamical Networks","Y. Wan; J. Cao; G. Chen; W. Huang","School of Mathematics, Southeast University, Nanjing, China; School of Mathematics and Statistics, Shandong Normal University, Ji’nan, China; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Intelligent Transportation System Research Center, Southeast University, Nanjing, China",IEEE Transactions on Circuits and Systems I: Regular Papers,"25 Oct 2017","2017","64","11","2966","2975","Distributed tracking problem for complex dynamical networks with Lipschitz-type nonlinear dynamics under the framework of cyber-physical systems is investigated. Due to practical limitations in some circumstances, the states of the agents are usually unavailable for controllers, so distributed observers used to reconstruct the states of nodes are needed, which will be first designed. Differing from other studies of observer-based control problems for complex dynamical networks and multi-agent systems, it considers here the scenario that the communication channels for controllers and observers may be subjected to frequently malicious attacks, which will destroy the communication links and result in disconnected topologies of the communication networks. It is assumed that the impacts of attacks on different communication networks are different and independent. New security control strategies are proposed and analyzed. An algorithm to properly select the feedback gain matrices and coupling strengths is presented. By utilizing the Lyapunov stability theory, sufficient conditions are derived to check whether final consensus tracking can be achieved against such attacks. Finally, a simulation example comparing the security control and uncontrolled scenarios is demonstrated to show the effectiveness of the theoretical results.","1558-0806","","10.1109/TCSI.2017.2708113","National Natural Science Foundation of China(grant numbers:61573096,61272530); 333 Engineering Foundation of Jiangsu Province of China(grant numbers:BRA2015286); JSPS Innovation Program(grant numbers:KYZZ15 0051); Scientific Research Foundation of Graduate School of Southeast University(grant numbers:YBJJ1559); Hong Kong Research Grants Council under the GRF(grant numbers:CityU11208515); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959063","Complex dynamical network;cyber-physical system;security control;distributed observer;distributed control","Observers;Security;Complex networks;Cyber-physical systems;Symmetric matrices;Multi-agent systems;Communication channels","","111","","35","IEEE","26 Jun 2017","","","IEEE","IEEE Journals"
"BDefects4NN: A Backdoor Defect Database for Controlled Localization Studies in Neural Networks","Y. Xiao; A. Liu; X. Zhang; T. Zhang; T. Li; S. Liang; X. Liu; Y. Liu; D. Tao","SKLCCSE, Beihang University, Beijing, China; SKLCCSE, Beihang University, Beijing, China; SKLCCSE, Beihang University, Beijing, China; SKLCCSE, Beihang University, Beijing, China; Nanyang Technological University, Singapore; National University of Singapore, Singapore; SKLCCSE, Beihang University, Beijing, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","3123","3135","Pre-trained large deep learning models are now serving as the dominant component for downstream middleware users and have revolutionized the learning paradigm, replacing the traditional approach of training from scratch locally. To reduce development costs, developers often integrate third-party pre-trained deep neural networks (DNNs) into their intelligent software systems. However, utilizing untrusted DNNs presents significant security risks, as these models may contain intentional backdoor defects resulting from the black-box training process. These backdoor defects can be activated by hidden triggers, allowing attackers to maliciously control the model and compromise the overall reliability of the intelligent software. To ensure the safe adoption of DNNs in critical software systems, it is crucial to establish a backdoor defect database for localization studies. This paper addresses this research gap by introducing BDefects4NN, the first backdoor defect database, which provides labeled backdoor-defected DNNs at the neuron granularity and enables controlled localization studies of defect root causes. In BDefects $4 N N$, we define three defect injection rules and employ four representative backdoor attacks across four popular network architectures and three widely adopted datasets, yielding a comprehensive database of $\mathbf{1, 6 5 4}$ backdoor-defected DNNs with four defect quantities and varying infected neurons. Based on BDefects4NN, we conduct extensive experiments on evaluating six fault localization criteria and two defect repair techniques, which show limited effectiveness for backdoor defects. Additionally, we investigate backdoor-defected models in practical scenarios, specifically in lane detection for autonomous driving and large language models (LLMs), revealing potential threats and highlighting current limitations in precise defect localization. This paper aims to raise awareness of the threats brought by backdoor defects in our community and inspire future advancements in fault localization methods.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029765","Backdoor defects;fault localization;deep learning","Location awareness;Training;Deep learning;Databases;Neurons;Maintenance engineering;Network architecture;Software systems;Software reliability;Software engineering","","","","89","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"PathOCl: Path-Based Prompt Augmentation for OCL Generation with GPT-4","S. Abukhalaf; M. Hamdaqa; F. Khomh","Software and Emerging Technologies Lab (SAET), Polytechnique Montréal, Montréal, Canada; Software and Emerging Technologies Lab (SAET), Polytechnique Montréal, Montréal, Canada; Software and Emerging Technologies Lab (SAET), Polytechnique Montréal, Montréal, Canada",2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym:,"30 Jul 2024","2024","","","108","118","The rapid progress of AI-powered programming assistants, such as GitHub Copilot, has facilitated the development of software applications. These assistants rely on large language models (LLMs), which are foundation models (FMs) that support a wide range of tasks related to understanding and generating language. LLMs have demonstrated their ability to express UML model specifications using formal languages like the Object Constraint Language (OCL). However, the context size of the prompt is limited by the number of tokens an LLM can process. This limitation becomes significant as the size of UML class models increases. In this study, we intro-duce PathOCL, a novel path-based prompt augmentation technique designed to facilitate OCL generation. PathOCL addresses the limi-tations of LLMs, specifically their token processing limit and the challenges posed by large UML class models. PathOCL is based on the concept of chunking, which selectively augments the prompts with a subset of UML classes relevant to the English specification. Our findings demonstrate that PathOCL, compared to augmenting the complete UML class model (UML-Augmentation), generates a higher number of valid and correct OCL constraints using the GPT-4 model. Moreover, the average prompt size crafted using PathOCL significantly decreases when scaling the size of the UML class models.","","979-8-4007-0536-6","10.1145/3650105.3652290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599553","Object Constraint Language (OCL);Simple Path;Prompt Engineering;Large Language Model (LLM);Generative Pre-Trained Trans-former (GPT);Foundation Model (FM)","Adaptation models;Frequency modulation;Terminology;Unified modeling language;Software;Software reliability;Task analysis","","","","29","","30 Jul 2024","","","IEEE","IEEE Conferences"
"ChatGPT and Software Testing Education: Promises & Perils","S. Jalil; S. Rafi; T. D. LaToza; K. Moran; W. Lam","Department of Computer Science, George Mason University, Fairfax, USA; Department of Computer Science, George Mason University, Fairfax, USA; Department of Computer Science, George Mason University, Fairfax, USA; Department of Computer Science, George Mason University, Fairfax, USA; Department of Computer Science, George Mason University, Fairfax, USA","2023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","29 May 2023","2023","","","4130","4137","Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose ""large language models"", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.","2159-4848","979-8-3503-3335-0","10.1109/ICSTW58534.2023.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10132255","ChatGPT;testing;education;case study","Software testing;Codes;Limiting;Conferences;Natural languages;Predictive models;Chatbots","","171","","27","IEEE","29 May 2023","","","IEEE","IEEE Conferences"
"Visualization-oriented Natural Language Interfaces for Grafana Dashboard","B. -Y. Tong; T. T. Kuo; C. -Y. Lin","Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan",2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan),"18 Sep 2024","2024","","","465","466","Real-time monitoring of individual node statuses is crucial in distributed systems to promptly identify and address anomalies and enable effective system management. Due to the less intuitive nature of traditional form-based methods for adding charts, there is a growing trend towards integrating large language models (LLMs) into visualization-oriented natural language interfaces (V-NLIs) to automate the entire front-end monitoring process. Although LLMs have advanced significantly, they still exhibit weaker capabilities in code generation, particularly when visualization platforms need LLMs to generate some specialized JSON formats for updating dashboards. To improve the code generation capability of general-purpose LLMs, we propose a system that allows users to create charts using arbitrary natural language. Additionally, concerning the limitations of LLMs in code generation, we aim to leverage the LangChain agent to develop a custom toolkit. The LangChain agent will enable language models to focus on text comprehension while our tool will handle code generation.","2575-8284","979-8-3503-8684-4","10.1109/ICCE-Taiwan62264.2024.10674281","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10674281","Visualization-oriented natural language interfaces;large language model;Grafana;LangChain","Visualization;Codes;Costs;Large language models;Natural languages;Market research;Real-time systems","","","","7","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"Pedestrian Intention Prediction via Vision-Language Foundation Models","M. Azarmi; M. Rezaei; H. Wang","Faculty of Environment, Computer Vision and Machine Learning Group, Institute for Transport Studies, University of Leeds, United Kingdom; Faculty of Environment, Computer Vision and Machine Learning Group, Institute for Transport Studies, University of Leeds, United Kingdom; Department of Computer Science, AI Centre, University College London, London, United Kingdom",2025 IEEE Intelligent Vehicles Symposium (IV),"6 Aug 2025","2025","","","1899","1904","Prediction of pedestrian crossing intention is a critical function in autonomous vehicles. Conventional vision-based methods of crossing intention prediction often struggle with generalizability, context understanding, and causal reasoning. This study explores the potential of vision-language foundation models (VLFMs) for predicting pedestrian crossing intentions by integrating multimodal data through hierarchical prompt templates. The methodology incorporates contextual information, including visual frames, physical cues observations, and ego-vehicle dynamics, into systematically refined prompts to guide VLFMs effectively in intention prediction. Experiments were conducted on three common datasets—JAAD, PIE, and FU-PIP. Results demonstrate that incorporating vehicle speed, its variations over time, and time-conscious prompts significantly enhances the prediction accuracy up to 19.8%. Additionally, optimised prompts generated via an automatic prompt engineering framework yielded 12.5% further accuracy gains. These findings highlight the superior performance of VLFMs compared to conventional vision-based models, offering enhanced generalisation and contextual understanding for autonomous driving applications.","2642-7214","979-8-3315-3803-3","10.1109/IV64158.2025.11097349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097349","","Visualization;Pedestrians;Accuracy;Systematics;Foundation models;Refining;Vehicle dynamics;Optimization;Autonomous vehicles;Context modeling","","","","36","IEEE","6 Aug 2025","","","IEEE","IEEE Conferences"
"Secure and Decentralized Swarm Behavior with Autonomous Agents for Smart Cities","R. Cooley; S. Wolf; M. Borowczak","Computer Science Department, University of Wyoming, Laramie, WY; Computer Science Department, University of Wyoming, Laramie, WY; Computer Science Department, University of Wyoming, Laramie, WY",2018 IEEE International Smart Cities Conference (ISC2),"4 Mar 2019","2018","","","1","8","Unmanned Aerial Vehicles (UAVs), referenced as drones, have advanced to consumer adoption for hobby and business use. Due to this increased availability in drone technology other sectors of the economy such as infrastructure technology, security mechanisms, and resource deliveries have begun to implement drones in their own operations. Following the consumer and private sectors demand for better iterations of the product, increasingly more complex tasks will become possible due to the advances in hardware. These tasks increase the potential impacts that drones will have on applications such as smart cities, modern cities which have fully adopted technology in order to enhance daily operations as well as the welfare of its citizens. These cities are being designed to consist of mostly static mesh networks of sensors, but can contain dynamic aspects as well, including both ground and air-based autonomous vehicles.When devising networked computation devices for use in a smart city, safety should be of paramount concern. In an attempt to meet these high standards of security, services and devices should be implemented with security protocols in mind during every stage of development. Given the large number of sensors, autonomous vehicles, and other advancements, a smart city necessitates this level of security. The SHARKS protocol (Secure, Heterogeneous, Autonomous, and Rotational Knowledge for Swarms) ensures this kind of security by allowing for new applications for UAV swarm technology. Enabling drones to circle a target without centralized control or selecting lead agents, the SHARKS protocol performs organized movement among agents without creating a central point of vulnerability. Through comparisons on the stability of the protocol in different settings, experiments demonstrate the efficiency and capacity of the SHARKS protocol as a potential solution for future smart cities.","","978-1-5386-5959-5","10.1109/ISC2.2018.8656939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8656939","","Protocols;Drones;Security;Smart cities;Task analysis;Intelligent sensors","","20","","19","IEEE","4 Mar 2019","","","IEEE","IEEE Conferences"
"Generative AI-Enabled Quantum Encryption Algorithm for Securing IoT-Based Healthcare Application Using Blockchain","S. Prajapat; P. Kumar; A. K. Das; G. Muhammad","Srinivasa Ramanujan Department of Mathematics, Central University of Himachal Pradesh, Dharamshala, India; Srinivasa Ramanujan Department of Mathematics, Central University of Himachal Pradesh, Dharamshala, India; Center for Security, Theory and Algorithmic Research, International Institute of Information Technology Hyderabad, Hyderabad, India; Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Internet of Things Journal,"20 Jun 2025","2025","12","13","24541","24551","The integration of artificial intelligence (AI) with the Internet of Things (IoT) has transformed numerous domains through the AI of Things (AIoT). Nonetheless, AIoT encounters issues related to energy usage and carbon emissions as mobile technology continues to progress. Generative AI (GAI) possesses significant potential to mitigate carbon emissions associated with AIoT, owing to its higher reasoning and generative powers. Conventional security protocols frequently encounter issues with computational efficiency, latency, and overall security comprehensiveness. Blockchain technology, characterized by its decentralized and immutable properties, is a viable approach for improving electronic healthcare data transmission and node authentication in IoT networks. This research examines secure data transmission and node encryption in IoT systems, with a particular emphasis on data management. Conventional approaches encounter constraints in computational efficiency, latency, and comprehensive security. This study presents a novel protocol that combines GAI and blockchain technology with quantum encryption to enhance authentication and ensure secure data transmission. The algorithm comprises multiple consecutive processes, including the encoding and transmission of node requests, followed by the authentication process utilizing hash functions and digital signatures. The authentication approach utilizes a challenge-response technique, guaranteeing that only nodes with authentic credentials can advance. Thereafter, a dynamic key exchange protocol and quantum encryption method provide secure data delivery. The results indicate the procedure’s effectiveness in ensuring secure and regulated access to patient data, underscoring its significance in medical facilities. The system’s functionalities are augmented by a thorough evaluation employing machine learning. The findings indicate that the system exhibits an accuracy of 99.4%, precision of 99.10%, recall of 98.66%, F1-score of 98.50%, and security of 99.2%. An extensive analysis and comparison with the state-of-the-art methods demonstrate the significant advancements of the suggested method in tackling cryptographic security challenges. The algorithm offers a thorough approach to protecting IoT applications, especially in managing healthcare data.","2327-4662","","10.1109/JIOT.2025.3555159","King Saud University, Riyadh, Saudi Arabia(grant numbers:ORF-2025-34); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938977","Blockchain;generative artificial intelligence (GAI);Internet of Things (IoT);machine learning (ML);quantum computing;quantum encryption","Internet of Things;Blockchains;Security;Artificial intelligence;Medical services;Encryption;Authentication;Protocols;Data communication;Carbon dioxide","","2","","41","IEEE","26 Mar 2025","","","IEEE","IEEE Journals"
"GalaxyGPT: A Hybrid Framework for Large Language Model Safety","H. Zhou; J. Zheng; L. Zhang","Geely Automobile Research Institute (Ningbo) Company Ltd., Ningbo, China; School of Aeronautics and Astronautics, Zhejiang University, Hangzhou, China; Geely Automobile Research Institute (Ningbo) Company Ltd., Ningbo, China",IEEE Access,"15 Jul 2024","2024","12","","94436","94451","The challenge of balancing safety and utility in Large Language Models (LLMs) requires novel solutions that go beyond conventional methods of pre- and post-processing, red-teaming, and feedback fine-tuning. In response to this, we introduce GalaxyGPT, a framework that synergizes safety moderation services of Internet vendors with LLMs to enhance safety performance. This necessity arises from the growing complexity of online interactions and the imperative to ensure that LLMs operate within safe and ethical boundaries without compromising their utility. GalaxyGPT leverages advanced algorithms and a comprehensive dataset to significantly improve safety measures, achieving notable accuracy (95.8%) and F1-score (94.5%) through evaluations of our custom dataset comprising 500 single-round safety tests, 100 multi-round dialogue tests, and 200 open-source tests. These results starkly outperform the safety metrics of APIs from six vendors (average 40.5% accuracy) and LLMs without GalaxyGPT integration (73% accuracy). Additionally, we contribute to the community by releasing an open-source test set of 600 entries and a compact classification model for security tasks, specifically designed to challenge and enhance the robustness of APIs, thereby facilitating the efficient deployment and application of GalaxyGPT in diverse environments.","2169-3536","","10.1109/ACCESS.2024.3425662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589654","Artificial intelligence;content moderation;ChatGPT;large language model;model safety;prompt engineering;supervised fine-tuning","Safety;Security;Accuracy;Reviews;Large language models;Task analysis;Social networking (online);Artificial intelligence;Content management","","","","33","CCBYNCND","9 Jul 2024","","","IEEE","IEEE Journals"
"The Effects of Depth of Knowledge of a Virtual Agent","F. -C. Yang; K. Duque; C. Mousas","Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA; Engineering and Science, Tecnológico de Monterrey, Monterrey, N.L., Mexico; Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA",IEEE Transactions on Visualization and Computer Graphics,"10 Oct 2024","2024","30","11","7140","7151","We explored the impact of depth of knowledge on conversational agents and human perceptions in a virtual reality (VR) environment. We designed experimental conditions with low, medium, and high depths of knowledge in the domain of game development and tested them among 27 game development students. We aimed to understand how the agent's predefined knowledge levels affected the participants' perceptions of the agent and its knowledge. Our findings showed that participants could distinguish between different knowledge levels of the virtual agent. Moreover, the agent's depth of knowledge significantly impacted participants' perceptions of intelligence, rapport, factuality, the uncanny valley effect, anthropomorphism, and willingness for future interaction. We also found strong correlations between perceived knowledge, perceived intelligence, factuality, and willingness for future interactions. We developed design guidelines for creating conversational agents from our data and observations. This study contributes to the human-agent interaction field in VR settings by providing empirical evidence on the importance of tailoring virtual agents' depth of knowledge to improve user experience, offering insights into designing more engaging and effective conversational agents.","1941-0506","","10.1109/TVCG.2024.3456148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670482","Virtual reality;virtual agent;conversational AI;depth of knowledge;knowledge bank;prompt engineering","Games;Knowledge engineering;Artificial intelligence;Prompt engineering;Oral communication;Medical services;Electronic mail","Humans;Virtual Reality;Female;Male;Computer Graphics;Young Adult;Adult;User-Computer Interface;Knowledge","5","","82","IEEE","10 Sep 2024","","","IEEE","IEEE Journals"
"Design and Implementation of Theft Detection Using YOLO Based Object Detection Methodology and Gen AI for Enhanced Security Solutions","K. U. K. Reddy; F. Shaik; V. Swathi; P. Sreevidhya; A. Yashaswini; J. U. Maheswari","Department of AI&DS, Annamacharya University, Rajampet, Andhra Pradesh; Department of ECE, Annamacharya University, Rajampet, Andhra Pradesh; Department of AI&DS, Annamacharya Institute of Technology and Sciences, Rajampet, Andhra Pradesh; Department of AI&DS, Annamacharya Institute of Technology and Sciences, Rajampet, Andhra Pradesh; Department of AI&DS, Annamacharya Institute of Technology and Sciences, Rajampet, Andhra Pradesh; Department of AI&DS, Annamacharya Institute of Technology and Sciences, Rajampet, Andhra Pradesh",2025 International Conference on Inventive Computation Technologies (ICICT),"23 May 2025","2025","","","583","589","This project introduces a intelligent theft detection system that utilizes the YOLOv8 (You Only Look Once v8) object detection model and generative AI along with real-time video surveillance and sound alarm functionality. The system constantly monitors video streams, identifies human occupancy in fenced or outofbounds zones, and sends immediate alerts, improving security and quick response. YOLOv8's advanced realtime processing abilities guarantee high-speed and accurate detection without sacrificing efficiency and thereby are the most suited for uses like survey line monitoring and surveillance. While in contrast to more conventional models like Faster R-CNN and SSD, which tend to sacrifice speed for accuracy or accuracy for speed, YOLOv8 manages to achieve the best of both. The system is implemented on the Streamlit platform, which offers an easy-to-use interface through which users can upload video files, modify confidence thresholds, and observe annotated results in real time. An in-built audio alert system implemented with Pygame also increases real-time responsiveness by alerting users to potential security threats. Through the integration of cutting-edge object detection with user-friendly and interactive experience, the solution provides a very effective and pragmatic solution for preventing theft with timely intervention as well as a security risk minimization. In addition, the system can be customized for multiple security purposes such as industrial monitoring, retail loss protection, and perimeter protection. Its efficiency and scalability provide it a solid solution for both large-scale and small-scale monitoring systems.","2767-7788","979-8-3315-1224-8","10.1109/ICICT64420.2025.11005144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005144","Theft detection;YOLOv8;real-time surveillance;Gen AI;object detection;video monitoring;audio alerts;security systems;live object detection","YOLO;Technological innovation;Accuracy;Computational modeling;Streaming media;Video surveillance;Real-time systems;User experience;Security;Protection","","","","10","IEEE","23 May 2025","","","IEEE","IEEE Conferences"
"Dynamic Scoring Code Token Tree: A Novel Decoding Strategy for Generating High-Performance Code","M. Qu; J. Liu; L. Kang; S. Wang; D. Ye; T. Huang","Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1308","1318","Within the realms of scientific computing, large-scale data processing, and artificial intelligence-powered computation, disparities in performance, which originate from differing code implementations, directly influence the practicality of the code. Although existing works tried to utilize code knowledge to enhance the execution performance of codes generated by large language models, they neglect code evaluation outcomes which directly refer to the code execution details, resulting in inefficient computation. To address this issue, we propose DSCT-Decode, an innovative adaptive decoding strategy for large language models, that employs a data structure named ’Code Token Tree’ (CTT), which guides token selection based on code evaluation outcomes. DSCT-Decode assesses generated code across three dimensions—correctness, performance, and similarity—and utilizes a dynamic penalty-based boundary intersection method to compute multi-objective scores, which are then used to adjust the scores of nodes in the CTT during backpropagation. By maintaining a balance between exploration, through token selection probabilities, and exploitation, through multi-objective scoring, DSCT-Decode effectively navigates the code space to swiftly identify high-performance code solutions. To substantiate our framework, we developed a new benchmark, big-DS-1000, which is an extension of DS-1000. This benchmark is the first of its kind to specifically evaluate code generation methods based on execution performance. Comparative evaluations with leading large language models, such as CodeLlama and GPT-4, show that our framework achieves an average performance enhancement of nearly 30%. Furthermore, 30% of the codes exhibited a performance improvement of more than 20%, underscoring the effectiveness and potential of our framework for practical applications.CCS CONCEPTS• Computing methodologies →Artificial intelligence; • Software and its engineering;","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764842","Code Generation;Large Language Model;Performance Optimization","Weight measurement;Codes;Scientific computing;Navigation;Large language models;Optimization methods;Benchmark testing;Software;Decoding;Software engineering","","","","33","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Multiagent System-Based Event-Triggered Hybrid Controls for High-Security Hybrid Energy Generation Systems","C. Dou; D. Yue; J. M. Guerrero","Institute of Electrical Engineering, Yanshan University, Qinhuangdao, China; Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Energy Technology, Aalborg University, Aalborg East, Denmark",IEEE Transactions on Industrial Informatics,"19 May 2017","2017","13","2","584","594","This paper proposes multiagent system-based event-triggered hybrid controls for guaranteeing energy supply of a hybrid energy generation system with high security. First, a multiagent system is constituted by an upper level central coordinated control agent combined with several lower level unit agents. Each lower level unit agent is responsible for dealing with internal switching control and distributed dynamic regulation for its unit system. The upper level agent implements coordinated switching control to guarantee the power supply of overall system with high security. The internal switching control, distributed dynamic regulation, and coordinated switching control are designed fully dependent on the hybrid behaviors of all distributed energy resources and the logical relationships between them, and interact with each other by means of the multiagent system to form hierarchical hybrid controls. Finally, the validity of the proposed hybrid controls is demonstrated by means of simulation results in different scenarios.","1941-0050","","10.1109/TII.2016.2618754","National Natural Science Foundation of China(grant numbers:61573300,61533010); Hebei Provincial Natural Science Foundation of China(grant numbers:E2016203374); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7593333","Distributed energy resource (DER);dynamic control;hybrid control;hybrid energy generation system (HEGS);multiagent system (MAS);switching control","Switches;Hybrid power systems;Security;Multi-agent systems;Energy resources;Density estimation robust algorithm","","55","","25","IEEE","19 Oct 2016","","","IEEE","IEEE Journals"
"Blockchain-Empowered Multiagent Systems: Advancing IoT Security and Transaction Efficiency","M. Wang; T. Zhu; X. Zuo; D. Ye; S. Yu; W. Zhou","Faculty of Data Science, City University of Macau, Macau, China; School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Data Science, City University of Macau, Macau, China",IEEE Internet of Things Journal,"27 Mar 2024","2024","11","7","11217","11231","The rapid growth and escalating complexity of the Internet of Things (IoT) necessitate meticulous attention to ensure efficient and secure transactions among various autonomous components. To address this critical issue, this study proposes the integration of multiagent systems (MASs) and blockchain technology within the IoT domain. Uniquely, our approach employs smart contracts to manage exchanges between autonomous entities, thereby offering enhanced security, transparency, and reliability. The study introduces a set of innovative algorithms that regulate agent activities, such as creating blocks, sharing information, and conducting rating processes. Additionally, it provides a detailed analysis of their privacy and security aspects. Compared to traditional multiagent frameworks, empirical evidence demonstrates significant improvements in efficiency, adaptability, and scalability. This scholarly effort lays a robust foundation for further investigations into applying blockchain to enhance MASs, potentially paving the way for more sophisticated and context-specific strategies across various IoT fields.","2327-4662","","10.1109/JIOT.2023.3329961","Australian Research Council, Australia, through the ARC Linkage Project(grant numbers:LP220200808); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316248","Blockchain;Internet of Things (IoT);multiagent system (MAS)","Blockchains;Internet of Things;Multi-agent systems;Security;Privacy;Decision making;Smart contracts","","2","","26","IEEE","13 Nov 2023","","","IEEE","IEEE Journals"
"Program Decomposition and Translation with Static Analysis","A. R. Ibrahimzada","University of Illinois Urbana-Champaign, Champaign, IL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"20 Jun 2024","2024","","","453","455","The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of “Can these LLMs process very large files and can we effectively perform prompt engineering?”. Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.","2574-1934","979-8-4007-0502-1","10.1145/3639478.3641226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554965","","Java;Computer languages;Codes;Source coding;Static analysis;Task analysis;Software engineering","","1","","30","","20 Jun 2024","","","IEEE","IEEE Conferences"
"Towards Robust Autonomous Cyber Defence Agents Using Hybrid AI Models","L. Holz; J. Loevenich; R. R. F. Lopes","Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany",2025 IEEE 11th International Conference on Network Softwarization (NetSoft),"21 Jul 2025","2025","","","269","272","Recent developments in Software-Defined Defence (SDD) provide the interfaces for multi-layer monitoring and control to realise Autonomous Cyber Defence (ACD) in critical network infrastructure used by the military. As a result, autonomous agents can enforce cybersecurity measures at different layers (link, IP, transport and application) using hybrid Artificial Intelligence (AI) models. For example, Multi-Agent Reinforcement Learning (MARL) can be combined with symbolic AI (knowledge graphs) and augmented/fine-tuned Large Language Models (LLMs) to detect, predict, protect, respond and recover from cyberattacks. This thesis starts from the hypothesis that the robustness of ACD agents can be formally verified, ensuring their safe development in mission critical environments. By applying Formal Verification (FV) techniques to MARL systems, the aim is to provide mathematically grounded guarantees such as correctness, safety, and adversarial resilience, thereby enabling trustworthy autonomous decision-making in SDD-enabled infrastructures.","2693-9789","979-8-3315-4345-7","10.1109/NetSoft64993.2025.11080605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11080605","Software-Defined Defence;Autonomous Cyber Defence;Multi-Agent Reinforcement Learning;Cyber Security","Large language models;Mission critical systems;Reinforcement learning;Knowledge graphs;Robustness;Mathematical models;Safety;Computer crime;Monitoring;Resilience","","","","15","IEEE","21 Jul 2025","","","IEEE","IEEE Conferences"
"Real-Time Email Phishing Detection Using a Custom DistilBERT Model","E. M. Damatie; A. Eleyan; T. Bejaoui","Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, England; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, England; Computer Engineering Department, University of Carthage, Tunisia","2024 International Symposium on Networks, Computers and Communications (ISNCC)","26 Nov 2024","2024","","","1","6","This paper presents a real-time email phishing detection system that utilizes a custom DistilBERT model. The custom DistilBERT architecture incorporates dynamic threshold adjustment and an enhanced classifier head, optimized for analyzing email content. With detection response times of under two seconds, the system delivers real-time protection. Experimental results demonstrate 99.29% accuracy in controlled tests and 95.45% in real-world tests, surpassing current state-of-the-art methods. The system maintains high performance at low false positive rates, essential for practical deployment. An adaptive daily retraining mechanism ensures continued effectiveness against evolving phishing tactics. This research advances email security and offers insights into the use of transformer-based models in real-time cybersecurity applications. By addressing the limitations of current systems through distilled transformer models, this work significantly strengthens organizational cybersecurity against advanced phishing threats.","2768-0940","979-8-3503-6491-0","10.1109/ISNCC62547.2024.10759011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759011","Email phishing detection;DistilBERT;Real-time detection;Adaptive retraining;Transformer models;False positive rate","Computers;Adaptation models;Phishing;Computational modeling;Computer architecture;Transformers;Real-time systems;Electronic mail;Time factors;Protection","","4","","14","IEEE","26 Nov 2024","","","IEEE","IEEE Conferences"
"Accelerating Complex Disease Treatment Through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer","A. A. Hamed; T. E. Fandy; X. Wu","Multidisciplinary Graduate Engineering, Northeastern University and iMol Polish Academy of Sciences, Warsaw, Poland; Dept. of Medical Education, Texas Tech University HSC, El Paso, United States; Dept. Key Lab of KEBD, Hefei University of Technology, Hefei, China",2024 IEEE International Conference on Medical Artificial Intelligence (MedAI),"25 Dec 2024","2024","","","354","359","The objective of this research is to introduce a network specialized in predicting drugs that can be repurposed by investigating real-world evidence sources, such as clinical trials and biomedical literature. Specifically, it aims to generate drug combination therapies for complex diseases (e.g., cancer, Alzheimer's). We present a multilayered network medicine approach, empowered by a highly configured ChatGPT prompt engineering system, which is constructed on the fly to extract drug mentions in clinical trials. Additionally, we introduce a novel algorithm that connects real-world evidence with disease-specific signaling pathways (e.g., KEGG database). This sheds light on the repurposability of drugs if they are found to bind with one or more protein constituents of a signaling pathway. Our network medicine framework, empowered by GenAI, shows promise in identifying drug combinations with a high degree of specificity, knowing the exact signaling pathways and proteins that serve as targets. It is noteworthy that ChatGPT successfully accelerated the process of identifying drug mentions in clinical trials, though further investigations are required to determine the relationships among the drug mentions.","","979-8-3503-7761-3","10.1109/MedAI62885.2024.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803434","Network Medicine;Drug Repurposing;Generative AI;LLMs;Multilayered Network;Signaling Pathways;Breast Cancer","Drugs;Proteins;Protein engineering;Databases;Clinical trials;Chatbots;Breast cancer;Prompt engineering;Artificial intelligence;Alzheimer's disease","","2","","34","IEEE","25 Dec 2024","","","IEEE","IEEE Conferences"
"Alchemist: LLM-Aided End-User Development of Robot Applications","U. B. Karli; J. -T. Chen; V. N. Antony; C. -M. Huang","Yale University, New Haven, CT, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA",2024 19th ACM/IEEE International Conference on Human-Robot Interaction (HRI),"10 Sep 2024","2024","","","361","370","Large Language Models (LLMs) have the potential to catalyze a paradigm shift in end-user robot programming—moving from the conventional process of user specifying programming logic to an iterative, collaborative process in which the user specifies desired program outcomes while LLM produces detailed specifications. We introduce a novel integrated development system, Alchemist, that leverages LLMs to empower end-users in creating, testing, and running robot programs using natural language inputs, aiming to reduce the required knowledge for developing robot applications. We present a detailed examination of our system design and provide an exploratory study involving true end-users to assess capabilities, usability, and limitations of our system. Through the design, development, and evaluation of our system, we derive a set of lessons learned from the use of LLMs in robot programming. We discuss how LLMs may be the next frontier for democratizing end-user development of robot applications.CCS CONCEPTS• Human-centered computing; • Computer systems organization → Robotics;","2167-2121","979-8-4007-0322-5","","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10660797","robot programming;end-user development;code generation","Large language models;Natural languages;Human-robot interaction;Organizations;Logic;Usability;Robots","","6","","59","","10 Sep 2024","","","IEEE","IEEE Conferences"
"Towards More Dependable Specifications: An Empirical Study Exploring the Synergy of Traditional and LLM-Based Repair Approaches","M. R. Hasan; M. Alhanahnah; C. Stevens; H. Bagheri","University of Nebraska-Lincoln, Lincoln, NE, USA; Chalmers/University of Gothenburg, Sweden; Iowa State University, Ames, IA, USA; University of Nebraska-Lincoln, Lincoln, NE, USA",2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),"11 Jul 2025","2025","","","88","101","Declarative specification languages like Alloy are critical for modeling and verifying complex software systems, yet repairing these specifications remains a significant challenge for ensuring software dependability. This study conducts the first comprehensive empirical evaluation comparing traditional systematic repair techniques with emerging Large Language Model (LLM)-based approaches across two established benchmarks, analyzing over 1,900 Alloy specifications. By systematically analyzing repair success rates, ground truth similarity, and repair generation strategies, we reveal nuanced performance characteristics of different repair methodologies. Our findings demonstrate that while traditional tools excel in systematic fault localization and achieving high ground truth similarity, LLM-based techniques—particularly multi-round prompting approaches—offer unique capabilities in addressing complex specification errors, with some hybrid approaches achieving repair rates of up to 85.5%. Critically, we show that integrating traditional fault localization techniques with LLM-based repair strategies can significantly enhance overall repair effectiveness and specification dependability. This research provides a large-scale empirical evaluation of how various Alloy repair techniques work in synergy, offering valuable insights that chart a promising path for future automated specification repair approaches and contribute to the development of more reliable and secure software systems.","2158-3927","979-8-3315-1201-9","10.1109/DSN64029.2025.00023","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068824","dependable specifications;automated repair;empirical study;large language models","Location awareness;Systematics;Large language models;Metals;Maintenance engineering;Benchmark testing;Software systems;Specification languages;Software reliability","","","","46","IEEE","11 Jul 2025","","","IEEE","IEEE Conferences"
"Test Agents: The Next Generation of Test Cases","E. Enoiu; M. Frasheri","Mälardalen University, Västerås, Sweden; Mälardalen University, Västerås, Sweden","2019 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","6 Jun 2019","2019","","","305","308","Growth of software size, lack of resources to perform regression testing, and failure to detect bugs faster have seen increased reliance on continuous integration and test automation. Even with greater hardware and software resources dedicated to test automation, software testing is faced with enormous challenges, resulting in increased dependence on centralized and complex mechanisms for automated test case selection as part of continuous integration. These mechanisms are currently using static entities called test cases that are concretely realized as executable scripts. Our key vision is to provide test cases with more reasoning, adaptive behavior and learning capabilities by using the concepts of software agents. We refer to such test cases as test agents. The model that underlie a test agent is capable of flexible and autonomous actions in order to meet overall testing objectives. Our goal is to increase the decentralization of regression testing by letting test agents to know for themselves when they should be executing, how they should update their purpose, and when they should interact with each other. In this paper, we envision test agents that display such adaptive autonomous behavior. Existing and emerging developments and challenges regarding the use of test agents are explored-in particular, new research that seeks to use adaptive autonomous agents in software testing.","","978-1-7281-0888-9","10.1109/ICSTW.2019.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8728945","software testing;test design;regression;agent;test automation;adaptive;autonomous","Software;Task analysis;Software testing;Automation;Adaptation models;Switches","","8","","25","IEEE","6 Jun 2019","","","IEEE","IEEE Conferences"
"Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices","K. K. Phokela; S. Sikand; K. Singi; K. Dey; V. S. Sharma; V. Kaulgud","Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture Labs, India",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","1846","1848","Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions. and basic control and data flow are met.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298429","Prompt Engineering;Artificial Intelligence;Deep Learning;LLM;Ontology","Visualization;Codes;Costs;Semantics;Time to market;Natural language processing;Task analysis","","3","","8","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Rapid and Flexible Yield Analysis Powered by Large-Scale Language Model","Y. Sawai; S. Okuyama; Y. Ono; M. Omori; Y. Ueda","Power Devices Business Unit, ROHM Co., Ltd., Fukuoka, Japan; Power Devices Business Unit, ROHM Co., Ltd., Kyoto, Japan; Power Devices Business Unit, ROHM Co., Ltd., Fukuoka, Japan; GenerativeX Co., Ltd., Tokyo, Japan; GenerativeX Co., Ltd., Tokyo, Japan",2024 International Symposium on Semiconductor Manufacturing (ISSM),"14 Feb 2025","2024","","","1","4","Semiconductor device manufacturing involves numerous processes, making it challenging for even experienced engineers to comprehensively analyze yield issues. This study introduces a novel framework for identifying and addressing factors influencing specific characteristics based on simplified production descriptions, such as ""a specific product's characteristic deteriorated during a defined period."" The framework consists of four layers: input, selection, analysis, and interpretation, with significant innovations in the selection and interpretation layers. In the selection layer, large language models (LLM) utilize metadata from analytical tables to infer column attributes, facilitating the precise determination of columns for row filtration and target variable identification. In the interpretation layer, process information and correlation analysis results are synthesized to propose actionable process improvements or assess risks, grounded in semiconductor engineering principles. The proposed approach highlights the potential of integrating LLM with domain-specific methodologies to efficiently support yield improvement analysis and accurately interpret production data.","2996-1904","979-8-3315-1058-9","10.1109/ISSM64832.2024.10874915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10874915","Yield analysis;large language model;prompt engineering;machine learning","Semiconductor device modeling;Analytical models;Technological innovation;Correlation;Filtration;Large language models;Production;Semiconductor device manufacture;Metadata;Manufacturing","","","","2","IEEE","14 Feb 2025","","","IEEE","IEEE Conferences"
"Supporting Software Maintenance with Dynamically Generated Document Hierarchies","K. R. Dearstyne; A. D. Rodriguez; J. Cleland-Huang","Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","426","437","Software documentation supports a broad set of software maintenance tasks; however, creating and maintaining high-quality, multi-level software documentation can be incredibly time-consuming and therefore many code bases suffer from a lack of adequate documentation. We address this problem through presenting HGEN, a fully automated pipeline that leverages LLMs to transform source code through a series of six stages into a well-organized hierarchy of formatted documents. We evaluate HGEN both quantitatively and qualitatively. First, we use it to generate documentation for three diverse projects, and engage key developers in comparing the quality of the generated documentation against their own previously produced manually-crafted documentation. We then pilot HGEN in nine different industrial projects using diverse datasets provided by each project. We collect feedback from project stakeholders, and analyze it using an inductive approach to identify recurring themes. Results show that HGEN produces artifact hierarchies similar in quality to manually constructed documentation, with much higher coverage of the core concepts than the baseline approach. Stakeholder feedback highlights HGEN's commercial impact potential as a tool for accelerating code comprehension and maintenance tasks. Results and associated supplemental materials can be found at https://zenodo.org/records/11403244","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795041","documentation;hierarchy;requirements;llm","Software maintenance;Codes;Source coding;Pipelines;Documentation;Transforms;Manuals;Maintenance;Stakeholders;Requirements engineering","","","","63","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"A Quantitative Analysis of Quality and Consistency in AI-generated Code","A. Clark; D. Igbokwe; S. Ross; M. F. Zibran","Department of Computer Science, Idaho State University, Pocatello, ID, USA; Department of Computer Science, Idaho State University, Pocatello, ID, USA; Department of Computer Science, Idaho State University, Pocatello, ID, USA; Department of Computer Science, Idaho State University, Pocatello, ID, USA",2024 7th International Conference on Software and System Engineering (ICoSSE),"29 Jul 2024","2024","","","37","41","With the recent emergence of generative AI (Artificial intelligence), Large Language Model (LLM) based tools such as ChatGPT have become popular assistants to humans in diverse tasks. ChatGPT has also been widely adopted for solving programming problems and for generating source code in software development. This research investigates both the code quality and the consistency of code quality over iterative prompts in 625 ChatGPT-generated Python code samples in the DevGPT dataset and the corresponding code snippets regenerated by manually prompting ChatGPT. Code samples are measured in terms of seven Halstead complexity metrics. We also assess how consistent they are across code snippets generated by different versions of ChatGPT. It was found that while ChatGPT generates good quality code across iterative prompts, it does generate semifrequent bugs, similar to how humans do, necessitating code review before integration. These traits also remain consistent across code snippets generated by subsequent releases of ChatGPT. These results suggest using AI-generated source code in software development will not hinder the process.","","979-8-3503-8659-2","10.1109/ICoSSE62619.2024.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608315","ChatGPT;Generative AI;Code;Quality;Complexity;Consistency;Python;Program;Analysis","Measurement;Codes;Statistical analysis;Source coding;Computer bugs;Chatbots;Complexity theory","","5","","24","IEEE","29 Jul 2024","","","IEEE","IEEE Conferences"
"A Systematic Literature Review of Deepfake Literacy, Societal Impacts, and AI-Driven Prevention Strategies for Platform-Specific Vulnerabilities","T. Wikum; J. Wijayanayake","Department of Industrial Management, University of Kelaniya, Sri Lanka; Department of Industrial Management, University of Kelaniya, Sri Lanka",2024 International Conference on Advances in Technology and Computing (ICATC),"9 Jun 2025","2024","","","1","6","Deepfake technology has rapidly evolved from a niche novelty into a significant threat to digital security, media integrity, and societal trust. This systematic review aims to analyze the progression of deepfake technology, its increasing societal impact, and how generative AI models can be leveraged for developing personalized, platform-specific prevention strategies. The review begins by exploring the foundational work on deepfakes, focusing on the technological advancements of Generative Adversarial Networks (GANs) that make the creation of hyper-realistic manipulated content possible. Then it examines the social implications of deepfakes, including their role in misinformation campaigns, political manipulation, and privacy violations. As deepfakes become more prevalent across social media platforms like Facebook, Instagram, and YouTube, the challenges in detecting and mitigating their impact are increasing. The review highlights the limitations of current detection tools and the urgent need for user education and technological interventions. Generative AI models such as ChatGPT, Google Bard, and Meta’s LLaMA are analyzed for their potential to provide tailored deepfake prevention strategies that enhance user awareness and digital literacy. The study compares the ability of these models to offer personalized recommendations, focusing on the superior adaptability and user-friendliness of ChatGPT. By addressing the gaps in deepfake literacy and platform-specific vulnerabilities, this review aims to present a comprehensive framework for mitigating the risks associated with deepfakes and empowering users with AI-driven solutions.","","979-8-3315-1821-9","10.1109/ICATC64549.2024.11025231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025231","deepfake prevention;generative AI;digital security;media literacy;social media platforms;customized recommendations","Deepfakes;Social networking (online);Generative AI;Prevention and mitigation;Chatbots;Generative adversarial networks;Real-time systems;Web sites;Security;Systematic literature review","","","","19","IEEE","9 Jun 2025","","","IEEE","IEEE Conferences"
"Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates","Z. Sun; Y. Wan; J. Li; H. Zhang; Z. Jin; G. Li; C. Lyu","Shandong Normal University, Jinan, China; Huazhong University of Science and Technology, Wuhan, China; MOE; SCS, Beijing, China; Chongqing University, Chongqing, China; Key Lab of HCST (PKU), MOE; SCS, Beijing, China; Key Lab of HCST (PKU), MOE; SCS, Beijing, China; Shandong Normal University, Jinan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","229","241","Large Language Models (LLMs), such as GPT-4, StarCoder, and Code Llama, are transforming the way developers approach programming by automatically generating code based on given contexts, such as natural language descriptions or incomplete surrounding code. Despite advancements, generating syntactically and semantically correct code remains challenging, especially for complex programming tasks. Existing approaches typically generate multiple candidate solutions using LLMs to increase the likelihood of producing correct code. However, selecting the correct code from these candidates — a process known as code ranking — remains a major challenge. Current research on code ranking can be cate-gorized into execution-based and non-execution-based methods. Execution-based methods, although effective, encounter notable limitations, such as scarcity of quality unit tests and security risks. Non-execution-based methods like CodeRanker, which rely solely on classification labels to train a code ranker, struggle to capture subtle errors and provide detailed error insights. Recognizing the strengths and limitations of both approaches, we propose a new method that integrates the advantages of execution-based and non-execution-based techniques. The key insight of our work is that an effective code ranker is expected to truly comprehend the underlying causes of erroneous code, as relying solely on classification labels is insufficient. Inspired by this, this paper puts forward RankEF, an innovative approach for code ranking that leverages execution feedback. RankEF employs multi-task learning to integrate code classification with execution feedback generation. This approach enables the model to understand the reasons behind incorrect code, distinguishing between correct and incorrect solutions without the need to execute the code during the ranking phase. Experiments on three code generation benchmarks—APPS, MBPP, and HumanEval—demonstrate that RankEF significantly outperforms the state-of-the-art CodeRanker, achieving relative improvements of +30.97%, +31.43%, and +19.51% in Pass@1, Pass@2, and Pass@5 on APPS test, respectively.CCS CONCEPTS• Software and its engineering → Automatic programming.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765015","Code Generation;Code Ranking;Execution Feedback","Codes;Source coding;Large language models;Natural languages;Cause effect analysis;Benchmark testing;Multitasking;Software;Security;Software engineering","","","","50","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Can ChatGPT Pass Classical Control Theory Exam?","I. Ogo; M. Koga","Department of Intelligent and Control Systems, Kyushu Institute of Technology, Fukuoka, Japan; Department of Intelligent and Control Systems, Kyushu Institute of Technology, Fukuoka, Japan",2024 SICE Festival with Annual Conference (SICE FES),"24 Dec 2024","2024","","","318","322","With the advancement of AI technology, generative AI has made remarkable progress in its ability to process multiple languages and adapt to creative tasks. It has also demonstrated its strength in academic fields, such as passing the national medical examinations. In this study, we tested the extent to which ChatGPT (GPT-4) can accurately answer classical control theory questions offered in undergraduate courses. The experimental results showed that GPT-4 showed a correct response rate of under 70% for quiz exercises in classical control theory, and that the correct response rate was lower for problems whose solutions were specific or required step-by-step thinking. In addition, since GPT-4 is a Transformer-based model, and the answers are based on mere prediction, it may give incorrect answers for problems that require complex calculations. In this study, we proposed a method to improve the response accuracy by developing a customized GPT specialized for classical control theory and using prompt engineering. The proposed method was applied to a university undergraduate final exam in undergraduate course, and the results showed that the correct response rate was improved and a passing score (60% or higher) was obtained.","","978-4-9077-6483-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804888","ChatGPT;Generative AI;Classical Control Theory;GPTs;GPT-4","Robust control;Accuracy;Training data;Predictive models;Chatbots;Transformers;Iron;Control theory;Prompt engineering","","","","12","","24 Dec 2024","","","IEEE","IEEE Conferences"
"Plug'n Play Task-Level Autonomy for Robotics Using POMDPs and Probabilistic Programs","O. Wertheim; D. R. Suissa; R. I. Brafman","Department of Computer Science, Ben-Gurion University of the Negev, Be'er Sheva, Israel; Department of Computer Science, Ben-Gurion University of the Negev, Be'er Sheva, Israel; Department of Computer Science, Ben-Gurion University of the Negev, Be'er Sheva, Israel",IEEE Robotics and Automation Letters,"29 Nov 2023","2024","9","1","587","594","We describe AOS, the first general-purpose system for model-based control of autonomous robots using AI planning that fully supports partial observability and noisy sensing. The AOS provides a code-based language for specifying a generative model of the system, making model specification easier and model sampling efficient. It provides a language for specifying the relation between the model and the code, using which it auto-generates all required integration code. This allows Plug'n Play behavior, which facilitates incremental and modular system design. Extensive experiments on real and simulated robotic platforms demonstrate these advantages.","2377-3766","","10.1109/LRA.2023.3334682","ISF(grant numbers:1651/19); Leona M. and Harry B. Helmsley Charitable Trust; Agricultural, Biological and Cognitive Robotics Initiative; Marcus Endowment Fund; Lynn and William Frankel Center for Computer Science at Ben-Gurion University of the Negev; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323164","AI-enabled robotics;autonomous agents;integrated planning and control;planning under uncertainty;software architecture for robotic and automation","Robot sensing systems;Codes;Sensors;Planning;Noise measurement;Artificial intelligence;Autonomous agents;Motion control;Centralized control","","","","24","IEEE","20 Nov 2023","","","IEEE","IEEE Journals"
"Monitoring and Control for Hundreds Megawatt Scale Battery Energy Storage Station Based on Multi-Agent: Methodology and System Design","Y. Li; X. Li; X. Jia; R. Ma; D. Hui","De artment of Electric En ineerin, North China Electric Power University, Beijing, China; State Key Laboratory of Control and Operation of Renewable Energy and Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Control and Operation of Renewable Energy and Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Control and Operation of Renewable Energy and Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Control and Operation of Renewable Energy and Storage Systems, China Electric Power Research Institute, Beijing, China",2018 IEEE International Conference of Safety Produce Informatization (IICSPI),"14 Apr 2019","2018","","","765","769","In this paper, a multi-agent system (MAS) -based hundreds megawatt-scale battery energy storage station monitoring system is proposed, which adopts the monitoring method of multi-agent zoning and hierarchical control to establish a multi-agent system at terminal level, local level and equipment level. Each energy storage converter of energy storage plant is controlled by a virtual synchronous machine, and the specific functions of each Agent and its coordination strategy are discussed to realize the real-time monitoring and operation control of the ultra-large-scale battery energy storage station in order to keep hundreds of megawatt-scale battery storage power station efficient and stable operations.","","978-1-5386-5514-6","10.1109/IICSPI.2018.8690406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8690406","Battery Energy Storage Station;Virtual Synchronous Generator;Multi-Agent System;SOC","Monitoring;Batteries;Power generation;State of charge;Frequency control;Mathematical model","","4","","11","IEEE","14 Apr 2019","","","IEEE","IEEE Conferences"
