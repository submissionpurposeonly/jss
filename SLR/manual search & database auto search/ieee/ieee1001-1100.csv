"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Using LLMs for Security Advisory Investigations: How Far are We?","B. F. Abdullah; Y. S. Nugroho; B. Reid; R. G. Kula; K. Shimari; K. Matsumoto","Informatics Engineering, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Informatics Engineering, Universitas Muhammadiyah Surakarta, Surakarta, Indonesia; Information Science, Nara Institute of Science and Technology, Nara, Japan; Graduate School of IST, University of Osaka, Osaka, Japan; Information Science, Nara Institute of Science and Technology, Nara, Japan; Information Science, Nara Institute of Science and Technology, Nara, Japan","2025 International Conference on Smart Computing, IoT and Machine Learning (SIML)","22 Jul 2025","2025","","","1","6","Large Language Models (LLMs) are increasingly used in software security, but their trustworthiness in generating accurate vulnerability advisories remains uncertain. This study investigates the ability of ChatGPT to (1) generate plausible security advisories from CVE-IDs, (2) differentiate real from fake CVE-IDs, and (3) extract CVE-IDs from advisory descriptions. Using a curated dataset of 100 real and 100 fake CVE-IDs, we manually analyzed the credibility and consistency of the model's outputs. The results show that ChatGPT generated plausible security advisories for 96 % of given input real CVE-IDs and $\mathbf{9 7 \%}$ of given input fake CVE-IDs, demonstrating a limitation in differentiating between real and fake IDs. Furthermore, when these generated advisories were reintroduced to ChatGPT to identify their original CVE-ID, the model produced a fake CVEID in 6% of cases from real advisories. These findings highlight both the strengths and limitations of ChatGPT in cybersecurity applications. While the model demonstrates potential for automating advisory generation, its inability to reliably authenticate CVE-IDs or maintain consistency upon re-evaluation underscores the risks associated with its deployment in critical security tasks. Our study emphasizes the importance of using LLMs with caution in cybersecurity workflows and suggests the need for further improvements in their design to improve reliability and applicability in security advisory generation.","","979-8-3315-2278-0","10.1109/SIML65326.2025.11080876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11080876","advisory;chatgpt;cve id;security;vulnerability","Training;Accuracy;Large language models;Refining;Machine learning;Chatbots;Reliability engineering;Software;Prompt engineering;Computer security","","","","25","IEEE","22 Jul 2025","","","IEEE","IEEE Conferences"
"On the Quest for Foundation Generative-AI Models for Anomaly Detection in Time-Series Data","G. G. González; P. Casas; E. Martínez; A. Fernández","IIE-FING, Universidad de la República, Montevideo, Uruguay; AIT - Austrian Institute of Technology, Vienna, Austria; IIE-FING, Universidad de la República, Montevideo, Uruguay; IIE-FING, Universidad de la República, Montevideo, Uruguay",2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),"20 Aug 2024","2024","","","252","260","Network security data generally consists of hundreds of counters periodically collected in the form of time-series, resulting in a complex-to-analyze multivariate time-series (MTS) process. We investigate a novel approach to time-series modeling, inspired by the successes of large pre-trained foundation models. We introduce FAE (Foundation Auto-Encoders), a foundation generative-AI model for anomaly detection in time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we mean a model pre-trained on massive amounts of time-series data which can learn complex temporal patterns useful for accurate modeling, forecasting, and detection of anomalies on previously unseen datasets. Based on the DC-VAE architecture originally designed for multivariate anomaly detection, FAE leverages VAEs and Dilated Convolutional Neural Networks (DCNNs) to build a generic model for univariate time-series modeling, which could eventually perform properly in out-of-the-box, zero-shot anomaly detection applications. We introduce the main concepts and ideas of this foundation model, and present some preliminary results in a multi-dimensional network monitoring dataset, collected from an operational mobile Internet Service Provider (ISP). This work represents a significant step forward in the development of foundation generative-AI models for anomaly detection in time-series analysis, with applications spanning cybersecurity, network management, and beyond.","2768-0657","979-8-3503-6729-4","10.1109/EuroSPW61312.2024.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628756","Multivariate Time-Series Data;Anomaly Detection;Generative AI;VAE;Foundation Models","Web and internet services;Time series analysis;Predictive models;Network security;Data models;Convolutional neural networks;Forecasting","","","","44","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"ChemAI: Empowering Robots to Automate Chemical Experiments with Large Language Models","Y. Lin; Z. Wang; L. Zhang; C. Zhang; X. Hei","School of Elec. Info. & Comm., Huazhong University of Science and Technology; School of Elec. Info. & Comm., Huazhong University of Science and Technology; School of Elec. Info. & Comm., Huazhong University of Science and Technology; School of Elec. Info. & Comm., Huazhong University of Science and Technology; School of Elec. Info. & Comm., Huazhong University of Science and Technology",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","369","373","Chemical experimentation remains fundamental to material discovery and compound synthesis, yet conventional methods face critical limitations. Manual laboratory workflows require repetitive operations that prolong research timelines, while robotic automation platforms inadvertently shift the burden to chemists through complex programming requirements. Existing systems also struggle to adapt to novel experimental designs, constraining scientific innovation. To bridge these gaps, we present a large language model (LLM)-driven robotic framework that redefines automated experimentation. Our system interprets natural language instructions through advanced LLM processing, dynamically integrates real-time environmental data, and autonomously generates executable code utilizing a modular action library. A self-correcting validation mechanism ensures operational precision, systematically resolving execution errors through iterative feedback. Empirical validation across two benchmark experiments including the iodine clock reaction kinetics and the salt purification demonstrates transformative advantages: 1) intuitive interaction; 2) extended workflow handling efficiency gain in multi-step protocols; 3) adaptive code generation. This paradigm shift may enable chemists to focus on hypothesis-driven research rather than procedural implementation, establishing a scalable infrastructure for next-generation autonomous laboratories.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00064","Huazhong University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106165","Chemical Experimentation;Robotic Automation;Large Language Model;ChemAI;ChemAPI","Technological innovation;Salt;Codes;Automation;Large language models;Natural languages;Libraries;Compounds;Chemicals;Robots","","","","6","IEEE","11 Aug 2025","","","IEEE","IEEE Conferences"
"Identifying and Mitigating the Security Risks of Generative AI","C. Barrett; B. Boyd; E. Bursztein; N. Carlini; B. Chen; J. Choi; A. Roy Chowdhury; M. Christodorescu; A. Datta; S. Feizi; K. Fisher; T. Hashimoto; D. Hendrycks; S. Jha; D. Kang; F. Kerschbaum; E. Mitchell; J. Mitchell; Z. Ramzan; K. Shams; D. Song; A. Taly; D. Yang",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,Identifying and Mitigating the Security Risks of Generative AI,"","2024","","","","","Every major technical invention resurfaces the dual-use dilemma — the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks. This monograph reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This work is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. Short-term and long-term goals for the community on this topic are discussed. This work should provide both a launching point for a discussion on this important topic, as well as interesting problems that the research community can work to address.","","9781638283133","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10410240.pdf&bkn=10410239&pdfType=book","Privacy and Security","","","","","","","22 Jan 2024","","","now","Now Foundations and Trends Books"
"Developing a User-Friendly Conversational AI Assistant for University Using Ollama and LLama3","J. Gohil; H. L.Shifare; M. Shukla","Faculty of Computer Applications, Marwadi University, Rajkot, India; Department of AI, ML and DS Marwadi University, Rajkot, India; Department of AI, ML and DS Marwadi University, Rajkot, India","2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)","29 May 2025","2025","","","1","5","This paper presents the development and implementation of an AI-driven chatbot for a university, designed to assist students and parents by providing accurate and instant information about the university. The chatbot leverages advanced LLM technologies, specifically LLama3, integrated with Ollama, to ensure high-quality natural language processing. Using LangChain, the system processes user queries by combining them with a structured prompt template, generating precise responses, and storing interactions in a database for future reference. The architecture includes modules like login, signup, and chat, ensuring a user-friendly interface. The chatbot's capability to reliably give precise responses was evaluated both manually and with volunteers in actual situations. This project showcases the uniqueness of utilizing Ollama and LLama3, which distinguishes it from conventional solutions by providing incredibly trustworthy and relevant replies. The chatbot enhances the user experience and acts as an efficient virtual assistant for the university by bridging the gap between user inquiries and institutional resources.","","979-8-3315-3755-5","10.1109/ICDSAAI65575.2025.11011878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011878","Chatbot;Prompt Engineering;Ollama;University Chatbot;Large Language Model","Accuracy;Databases;Virtual assistants;Large language models;Chatbots;User experience;Reliability;Prompt engineering","","","","10","IEEE","29 May 2025","","","IEEE","IEEE Conferences"
"DynaMentA: Dynamic Prompt Engineering and Weighted Transformer Architecture for Mental Health Classification Using Social Media Data","A. Kumar; A. Sharma; S. R. Sangwan","School of Computing, Goldsmiths, London, U.K.; Department of Computer Science and Engineering, Punjab, India; Department of Computer Science and Engineering, Artificial Intelligence and Machine Learning, Greater Noida, Uttar Pradesh, India",IEEE Transactions on Computational Social Systems,"","2025","PP","99","1","11","Mental health classification is inherently challenging, requiring models to capture complex emotional and linguistic patterns. Although large language models (LLMs) such as ChatGPT, Mental-Alpaca, and MentaLLaMA show promise, they are not trained on clinically grounded data and often overlook subtle psychological cues. Their predictions tend to overemphasize emotional intensity, while failing to capture contextually relevant indicators that are critical for accurate mental health assessment. This article introduces dynamic prompt engineering and weighted transformer architecture dynamic prompt engineering and weighted transformer architecture for mental health classification (DynaMentA), a novel dual-layer transformer framework that integrates the strengths of BioGPT and decoding-enhanced BERT with disentangled attention (DeBERTa) to address these challenges. BioGPT captures fine-grained biomedical indicators, while DeBERTa provides context-aware disambiguation. The ensemble mechanism dynamically weights their outputs, guided by a simulated feedback loop that refines the predictions during training. Unlike previous studies that treat classification statically, DynaMentA incorporates dynamic prompt engineering to better align with evolving linguistic and emotional signals. Evaluated on three benchmark datasets, DepSeverity, suicide versus depression classification natural language (SDCNL), and Dreaddit, DynaMentA achieves precision of 92.6%, 91.9% F1-score, and 0.94 AUC-ROC, consistently outperforming the existing benchmark, including general-purpose LLMs and domain-specific mental health models. This scalable and interpretable framework establishes a state-of-the-art methodology for computational mental health analysis in high-stakes applications, such as suicide risk assessment and crisis intervention and early detection of severe depressive episodes.","2329-924X","","10.1109/TCSS.2025.3569400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024027","Artificial intelligence (AI) in mental health;deep learning for social systems;mental health classification;social media data analysis;weighted transformer models","Mental health;Transformers;Biological system modeling;Linguistics;Prompt engineering;Computer architecture;Adaptation models;Depression;Computational modeling;Social networking (online)","","","","","IEEE","4 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Exploring Testing Methods for Large Language Models","T. Elvira; T. T. Procko; L. Vonderhaar; O. Ochoa","Department of Electrical Engineering & Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, Florida; Department of Electrical Engineering & Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, Florida; Department of Electrical Engineering & Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, Florida; Department of Electrical Engineering & Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, Florida",2024 International Conference on Machine Learning and Applications (ICMLA),"4 Mar 2025","2024","","","1152","1157","Large Language Models (LLMs) are extensive aggregations of human language, designed to understand and generate sophisticated text. LLMs are becoming ubiquitous in a range of applications, from social media to code generation. With their immense size, LLMs face scalability challenges, making testing methods particularly difficult to implement effectively. Traditional machine learning and software testing methods, derived and adapted for LLMs, test these models to a point; however, they still struggle to accurately capture the full complexity of model behavior. This paper aims to capture the current efforts and techniques in testing LLMs, specifically focusing on stress testing, mutation testing, regression testing, metamorphic testing, and adversarial testing. This survey focuses on how traditional testing methods must be adapted to fit the needs of LLMs. Furthermore, while this area is fairly novel, there are still gaps in the literature that have been identified for future research.","1946-0759","979-8-3503-7488-9","10.1109/ICMLA61862.2024.00177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903339","Large Language Model;Testing;Stress testing;Mutation testing;Regression testing;Metamorphic testing;Penetration testing","Surveys;Software testing;Adaptation models;Social networking (online);Large language models;Machine learning;Complexity theory;Stress;Testing;Systematic literature review","","","","39","IEEE","4 Mar 2025","","","IEEE","IEEE Conferences"
"Performance Analysis and Impacts of NLP and Chatbot Systems","G. N. Bikir; M. Ak; H. T. Ünal; Ö. U. Vurgun; A. F. Mendi; M. A. Nacar","Ürün Mühendisi HAVELSAN, Ankara, Türkiye; Ürün Müdürü HAVELSAN, Ankara, Türkiye; Mühendis HAVELSAN, Ankara, Türkiye; HAVELSAN, Ankara, Türkiye; HAVELSAN, Ankara, Türkiye; Genel Müdür HAVELSAN, Ankara, Türkiye","2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)","2 Jun 2025","2025","","","1","6","The integration of artificial intelligence (AI) technologies into digital transformation processes in Turkey plays a significant role in the dissemination of high-tech products. Large Language Models (LLMs) and Natural Language Processing (NLP) techniques are supported by innovative solutions developed by HAVELSAN. During this process, Turkey's AI development capacity is increasing, and its competitiveness is being strengthened. HAVELSAN addresses public and private sector demands by developing national products, aiming for an 18.79% resource saving in enterprise content management and a 34.46% reduction in information access time through digital assistants. The solutions safeguard user data in compliance with international ISO 27001 and GDPR standards. The proliferation of high-tech products has increased the number of AI-based solutions by 48.27%, and patented solutions have boosted the success rate of technological projects by 40.12%. National AI products have expanded their domestic market share by 30%, revitalizing the local ecosystem while playing a significant role in entering international markets. These advancements strengthen Turkey's position as a regional leader in artificial intelligence and facilitate the achievement of its future technological goals.","2996-4393","979-8-3315-1088-6","10.1109/ICHORA65333.2025.11017071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017071","Artificial Intelligence;Large Language Models;Natural Language Processing;Enterprise Management;Data Security","Content management;Large language models;ISO Standards;Digital transformation;Data security;Ecosystems;Performance analysis;Standards;Robots;Optimization","","","","0","IEEE","2 Jun 2025","","","IEEE","IEEE Conferences"
"Evaluation of Static Analysis and Transformer-Based LLMs for IoT Firmware Security","A. Al-Zuraiqi; D. Greer","Queen's University Belfast, Belfast, United Kingdom; Queen's University Belfast, Belfast, United Kingdom",2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT),"5 Aug 2025","2025","","","389","396","The widespread adoption of Internet of Things (IoT) devices has heightened the need for robust firmware security measures. Static analysis tools, such as the Firmware Analysis and Comparison Tool (FACT), automatically detect vulnerabilities using predefined rules and signatures. However, these rules must be manually updated over time to remain effective. In parallel, transformer-based Large Language Models (LLMs) can capture contextual relationships within code and metadata, enabling the detection of novel threats without predefined signatures. This paper presents a comprehensive comparison of these two approaches by detailing independent research environments, curated datasets, and performance metrics including detection accuracy, scalability, energy consumption, and environmental impact. FACT achieved a detection accuracy of 93%, effectively identifying well-documented vulnerabilities, while LLMs demonstrated a slightly higher accuracy of 96%, leveraging contextual reasoning to uncover novel threats. Additionally, the energy consumption analysis revealed that FACT operates with lower power requirements, whereas LLMs, despite higher energy usage, can be powered entirely by renewable energy sources. The ease of deployment and maintenance for both systems was evaluated, highlighting FACT's straightforward setup versus LLMs' more complex infrastructure needs. The results underscore the complementary roles of static analysis and LLMs in addressing both well-documented and emerging IoT vulnerabilities, providing valuable insights for practitioners seeking to secure diverse firmware ecosystems sustainably and efficiently.","2325-2944","979-8-3315-4372-3","10.1109/DCOSS-IoT65416.2025.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096232","IoT Firmware Security;Static Analysis;Transformer-Based Models;Vulnerability Detection;Energy Efficiency","Energy consumption;Renewable energy sources;Accuracy;Scalability;Static analysis;Transformers;Smart systems;Internet of Things;Security;Microprogramming","","","","33","IEEE","5 Aug 2025","","","IEEE","IEEE Conferences"
"Harnessing the Power of LLMs in Source Code Vulnerability Detection","A. A. Mahyari",AIVault Inc. IHMC,MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM),"6 Dec 2024","2024","","","251","256","Software vulnerabilities, caused by unintentional flaws in source code, are a primary root cause of cyberattacks. Static analysis of source code has been widely used to detect these unintentional defects introduced by software developers. Large Language Models (LLMs) have demonstrated human-like conversational abilities due to their capacity to capture complex patterns in sequential data, such as natural languages. In this paper, we harness LLMs’ capabilities to analyze source code and detect known vulnerabilities. To ensure the proposed vulnerability detection method is universal across multiple programming languages, we convert source code to LLVM IR and train LLMs on these intermediate representations. We conduct extensive experiments on various LLM architectures and compare their accuracy. Our comprehensive experiments on real-world and synthetic codes from NVD and SARD demonstrate high accuracy in identifying source code vulnerabilities.","2155-7586","979-8-3503-7423-0","10.1109/MILCOM61039.2024.10774025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774025","vulnerability detection;source code;security;program analysis;deep learning","Military communication;Computer languages;Vocabulary;Accuracy;Source coding;Large language models;Natural languages;Computer architecture;Static analysis;Software","","5","","25","IEEE","6 Dec 2024","","","IEEE","IEEE Conferences"
"Static Analysis of IoT Firmware: Identifying Systemic Vulnerabilities with RMMIDL","A. Al-Zuraiqi; D. Greer","Queen's University Belfast, Belfast, United Kingdom; Queen's University Belfast, Belfast, United Kingdom",2025 IEEE/ACM 6th International Workshop on Engineering and Cybersecurity of Critical Systems (EnCyCriS),"13 Jun 2025","2025","","","7","14","The unprecedented surge in Internet of Things (IoT) device deployment has brought forth significant security challenges, primarily arising from vulnerabilities within firmware that facilitate unauthorized access, data exfiltration, and network exploitation. This study undertakes a comprehensive static analysis of 1,520 IoT firmware samples using the Firmware Analysis and Comparison Tool (FACT) alongside metadata from the WikiDevi archive to systematically identify inherent security flaws. Among the key vulnerabilities discovered are improper handling of format strings (CWE-134, 10.07%), memory mismanagement issues (CWE-416, 10.06 %; CWE-415, 10.03 %), and the presence of exposed debugging interfaces (CWE-782, 10.07%). These results highlight enduring risks in critical domains such as healthcare and industrial IoT, often magnified by insecure coding practices and reliance on outdated software components. To address these systemic shortcomings, this study proposes the Risk Mitigation Modeling for IoT Development Lifecycle (RMMIDL), a secure-by-design framework that embeds proactive security measures throughout each phase of IoT development. RMMIDL offers a systematic and well-defined framework for addressing pervasive risks, enhancing the resilience of IoT ecosystems, and promoting the implementation of robust security measures. Furthermore, this study outlines prospective research directions, emphasizing the potential of integrating large language models (LLMs), broadening the scope of firmware datasets, and fostering industry-wide collaboration to drive advancements in IoT security.","","979-8-3315-3810-1","10.1109/EnCyCriS66464.2025.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029551","Internet of Things (IoT);Secure-by-Design;Vulnerable-by-Design;IoT Firmware Security;Firmware Analysis;Systemic Vulnerabilities;Risk Mitigation Modeling (RMMIDL);Large Language Models (LLMs)","Large language models;Ecosystems;Static analysis;Debugging;Internet of Things;Security;Object recognition;Microprogramming;Risk mitigation;Resilience","","1","","27","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"An Exploratory Study on Architectural Smell Refactoring Using Large Languages Models","G. Pandini; A. Martini; A. N. Videsjorden; F. A. Fontana","Dept. of Computer Science, University of Milano Bicocca, Milano, Italy; Dept. of Informatics, University of Oslo, Oslo, Norway; Sustainable Communication Technologies, SINTEF Digital, Oslo, Norway; Dept. of Computer Science, University of Milano Bicocca, Milano, Italy",2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C),"30 May 2025","2025","","","462","471","Architectural smells are abundant in codebases and regularly hinder the development of stable and maintainable code. Understanding and removing these elements can consume a huge amount of developers' time, who often need to prioritize implementing new features. This causes a substantial increase in Technical Debt, compromising the scalability and maintainability of the codebases, at time bringing the development to a standstill. Meanwhile, the use of Large Language Models for small error correction is constantly growing, bringing the attention of an ever-wider audience to these technologies. This study explores a first approach to use Large Language Models to suggest refactoring for architectural smells, with a focus on Cyclic Dependencies smells. We study the use of detailed prompt and Retrieval-Augmented Generation (RAG) to enhance LLMs, and we study local vs cloud LLMs. The results are promising, also validated with a series of interviews with students and developers, and highlight how additional and precise context is key to enhance the use of LLMs to propose refactoring suggestions. A multi-agent approach seems to be more suited when increasing the complexity of the smells.","2768-4288","979-8-3315-3336-6","10.1109/ICSA-C65153.2025.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015021","Architectural Smell;Refactoring;LLM;RAG","Codes;Software architecture;Large language models;Scalability;Retrieval augmented generation;Error correction;Complexity theory;Interviews","","1","","33","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Gemini-GraphQA: Integrating Language Models and Graph Encoders for Executable Graph Reasoning","X. Luo; E. Wang; Y. Guo","Uppsala University, Uppsala, Sweden; Rice University, Dallas, USA; Dalhousie University, Halifax, Canada",2025 Information Science Frontier Forum and the Academic Conference on Information Security and Intelligent Control (ISF),"1 Jul 2025","2025","","","70","74","Graph-structured data presents challenges for natural language question answering due to its non-Euclidean topology and task-specific requirements. To solve this, we propose Gemini-GraphQA, a new graph question answering framework that combines a large language model (Gemini) with graph neural networks and retrieval-augmented generation strategies. Unlike traditional models that use shallow feature mapping or isolated code synthesis, Gemini-GraphQA uses a graph encoder to capture structural semantics, a graph solver network to translate natural language into executable graph code, and a retrieval module to add external knowledge to the reasoning process. An execution correctness loss is added to ensure the generated code is both syntactically and functionally correct, allowing the framework to outperform existing graph-based QA systems and pretrained code generation models. This design improves the model's ability to reason across various graph-related tasks and enables its deployment in fields requiring structured data understanding.","","979-8-3315-1035-0","10.1109/ISF65011.2025.11047460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047460","Graph Question Answering;Large Language Models;Graph Neural Networks;Code Generation;Execution Supervision","Representation learning;Codes;Translation;Large language models;Semantics;Retrieval augmented generation;Question answering (information retrieval);Graph neural networks;Cognition;Topology","","","","10","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"Exploring Security Vulnerabilities in ChatGPT Through Multi-Technique Evaluation of Resilience to Jailbreak Prompts and Defensive Measures","H. Strohmier; Y. Dasri; D. Murzello","Computer Science, Engineering and Mathematics, University of South Carolina Aiken, Aiken, SC, USA; Computer Science, Engineering and Mathematics, University of South Carolina Aiken, Aiken, SC, USA; Computer Science, Engineering and Mathematics, University of South Carolina Aiken, Aiken, SC, USA",2024 International Conference on Computer and Applications (ICCA),"26 Mar 2025","2024","","","1","12","Large Language Models (LLMs), such as GPT-3.5, GPT-4, Bard, and LLaMa, have demonstrated remarkable pro-ficiency in natural language processing, exhibiting human-like fluency and understanding across multiple languages. However, recent incidents have underscored concerns regarding their potential misuse, including dissemination of misinformation, hate speech, conspiracy theories, and even exploitation as hacking tools. Central to these security concerns is the concept of jailbreaking, which involves circumventing the predefined security measures of LLMs to manipulate their output. Various techniques, such as Adversarial attacks, cross-language attacks, and the novel method DeepInception, exploit vulnerabilities in LLMs to induce them into generating harmful content. These methods highlight the need for robust defenses against malicious exploitation of language models. In this paper, we present an experimental study aimed at evaluating the effectiveness of jailbreak prompts in bypassing content restrictions across various forbidden scenarios. Our methodology involves assessing the success rate of jailbreak prompts in breaching content restrictions and analyzing the sentiment of generated responses. Through this experiment, we aim to quantify the efficacy of jailbreak prompts in circumventing security measures, thereby providing insights into the risks associated with misusing LLMs. We acknowledge potential limitations, including prompt effectiveness, model biases, and ethical considerations, and discuss implications for the ethical usage of AI language models. Our study encompasses a range of jailbreak prompts, including the DAN prompt, Deep Inception, AIM prompt, Tom and Jerry Prompt, and Hypothetical Response Prompt, each offering unique insights into the challenges and opportunities in securing LLMs against malicious exploitation.","","979-8-3503-6756-0","10.1109/ICCA62237.2024.10928071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10928071","Artificial intelligence;machine learning;cyber-security;ChatGPT;jailbreaking;open AI;vulnerabilities;prompts;prompt engineering","Ethics;Large language models;Hate speech;Machine learning;Chatbots;Security;Prompt engineering;Fake news;Testing;Resilience","","","","20","IEEE","26 Mar 2025","","","IEEE","IEEE Conferences"
"Agentic AI for Autonomous Cyber Threat Hunting and Adaptive Defense in Dynamic Security Environments","A. Sheth; A. Patel; C. Upadhyay; H. Ragothaman; B. Patil; S. K. Udayakumar","Microsoft Corporation; NA; NA; Advanced Micro Devices (AMD); NA; Salesforce, Inc.",2025 IEEE International Conference on Electro Information Technology (eIT),"12 Aug 2025","2025","","","316","321","Evolution of cyber threats have led to limitations in the efficiency of traditional rule-based cybersecurity approaches. These traditional interventions have remained to have a resource intensive and reaction approach, prompting the creation of new steps that can help in handling cyber threats through AI. This study develops an AI driven system for autonomous cyber threat hunting, through leveraging Machine Learning (ML), Deep Reinforcement Learning (RDL) and using AI analytics to ensure a proactive detection, resolution and management of threats. The study uses datasets such as DARPA and CIDS ensuring that they can work on an AI intervention. The use of ML models such as CNN and RNN ensure analysis of the network traffic, behavioral indicators and system logs. Using DRL enables the system to have an autonomous adaptation to threats such as zero day exploits, reducing the instances of false positives and false negatives. Results from this study indicates that using AI driven threat detection leads to an accuracy rate of 98.2%, F1 score of 97.1% while reducing both MTTD and MTTR by an estimated 99%. The findings depict the ability of the system to have an operational framework demanding minimal human intervention. Thus, the cybersecurity operations can be advanced to have an increasingly transformative engagement, working on proactive threat detection and reducing operational costs. Considerably, future research should focus on enhancing Explainability in AI, addressing ethical issues and countering growing adversarial attacks on the AI system.","2154-0373","979-8-3315-3233-8","10.1109/eIT64391.2025.11103697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103697","Machine Learning;Cybersecurity Automation;Agentic AI;Real Time Threat Detection;Deep Reinforcement Learning;Autonomous Threat Hunting","Ethics;Analytical models;Costs;Automation;Telecommunication traffic;Deep reinforcement learning;Threat assessment;Real-time systems;Computer security;Information technology","","","","18","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Towards a Predictive Model of Speech Signatures: Insights from Spectral Analysis and Generative AI Models","S. Regondi; R. Pugliese; A. Mahroo","Nemo Lab; Nemo Lab; Institute of Intelligent Industrial, Technologies and Systems for Advanced Manufacturing (STIIMA), National Research Council of Italy, (CNR)","2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)","24 Dec 2024","2024","","","782","786","This study delves into a comprehensive analysis and identification of potential vocal cues influencing the perception of authenticity versus artificiality in speech. Our primary aim is to pinpoint the pivotal parameters distinguishing genuine voices from artificially synthesized ones. Employing a multifaceted approach, we leverage advanced methodologies encompassing spectral analysis of speech signals, discernment of prosodic patterns, and the application of cutting-edge machine learning techniques such as Hifi-GAN and generative AI. By examining voice data sourced from diverse origins, our aim is to uncover pivotal markers that impact the perception of truthfulness or artificiality in voices, ultimately constructing a predictive model capable of reliably distinguishing between authentic and artificially crafted voices across both pathological and non-pathological conditions. The culmination of this research holds significant implications not only for advancing the scientific and technological understanding of human voice distinctiveness but also for practical applications in healthcare and security domains. Indeed, in the healthcare field the ability to discern authentic voices from artificial ones could facilitate more accurate diagnosis and monitoring of conditions affecting speech, such as neurodegenerative diseases or vocal cord disorders. Additionally, in security contexts, this research could enhance the reliability of voice-based authentication systems, thereby bolstering the integrity of sensitive communications and data transmission. This could pave the way for advancements in security protocols, healthcare applications, and bolstering the reliability of voice-based technologies.","","979-8-3503-7800-9","10.1109/MetroXRAINE62247.2024.10795959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795959","Speech analysis;Prosodic patterns;Machine learning;Hifi-GAN;Generative AI;Healthcare applications;Voice-based authentication","Generative AI;Statistical analysis;Authentication;Medical services;Predictive models;Speech enhancement;Recording;Security;Reliability;Spectral analysis","","","","16","IEEE","24 Dec 2024","","","IEEE","IEEE Conferences"
"Cyber secure consensus of discrete-time fractional-order multi-agent systems with distributed delayed control against attacks","G. Narayanan; M. S. Ali; S. Ahamad","Department of Mathematics, Thiruvalluvar University, Vellore, Tamilnadu, India; Department of Mathematics, Thiruvalluvar University, Vellore, Tamilnadu, India; College of Computer Science and Engineering, University of Hail, Hail City, Saudi Arabia","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","2191","2196","In this paper, the leader-following cyber secure consensus problem for discrete-time fractional-order multi-agent systems (DFOMASs) in the present of denial-of-service attacks by means of distributed delayed control strategy is investigated. As MASs work in networked environments, their security control becomes critically desirable in response to various cyberattacks, such as denial of service (DoS). The resulting topologies caused by DoS attacks may destabilize the consensus performance of MASs. Especially under connectivity-broken attacks, the connectivity between agents is destroyed. To deal with these difficulties, a novel defense strategy consisting of distributed delayed consensus control is proposed. To guarantee cyber secure consensus of the addressed systems to determine the stability of the resulting error system, sufficient criteria including the condition in terms of LMI are derived on the basis of the Caputo fractional difference operator, by employing the Lyapunov function approach, algebraic graph theory and average dwell time (ADT). At last, the effectiveness of the obtained results is demonstrated by performing simulations on the proposed systems.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658921","Caputo fractional difference;Multiagent systems;Distributed delayed control;Dos attacks","Protocols;Network topology;Stability criteria;Denial-of-service attack;Graph theory;Topology;Security","","2","","21","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Encrypted Data-driven Control on Networked Multi-agent Systems","K. Nagao; N. Kawaguchi; T. Sato","Graduate School of Engineering, University of Hyogo, Hyogo, Japan; Graduate School of Engineering, University of Hyogo, Hyogo, Japan; Graduate School of Engineering, University of Hyogo, Hyogo, Japan","2023 International Conference on Networking, Sensing and Control (ICNSC)","20 Nov 2023","2023","1","","1","5","A data-driven design method is proposed for multi-agent systems that communicate with each other via a network. In such a networked control system, even if the controlled process itself is secure, information about the process can be leaked through eavesdropping because the control data is transferred over the network. In particular, in data-driven systems, process data transferred over a network drives the controller design as well as process control. Therefore, the security of data transferred over a network is critical to the safe operation of the system. To this end, this study examines a data-driven design using encrypted data. In the proposed method, both process control and controller design are performed with encrypted data instead of unencrypted data. Therefore, both eavesdropping of control data and leakage of the designed controller are prevented.","2766-8665","979-8-3503-6950-2","10.1109/ICNSC58704.2023.10319012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319012","","Networked control systems;Design methodology;Process control;Sensors;Cryptography;Multi-agent systems;Eavesdropping","","","","16","IEEE","20 Nov 2023","","","IEEE","IEEE Conferences"
"Agentic AI for Pathogen-Based Plant Disease Detection","A. R. K. P; G. S","Department of Computer Science and Engineering, Dr. Ambedkar Institute of Technology, Bengaluru, Karnataka, India; Department of Computer Science and Engineering, Dr. Ambedkar Institute of Technology, Bengaluru, Karnataka, India","2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)","15 Jul 2025","2025","","","323","328","Plant disease detection is crucial for ensuring global food security and sustainable agriculture. Traditional methods rely on manual inspection, which is time consuming, error prone and requires expert knowledge. AI-driven approaches, particularly deep learning models have significantly improved disease classification and early detection. However existing AI models suffer from key limitations, including the need for large, annotated datasets, poor generalization across different crop varieties and environmental conditions, and limited adaptability to real-time dynamic scenarios. To address these challenges, we propose an Agentic AI framework for plant disease detection that goes beyond passive classification. Our approach integrates autonomous decision making, continuous learning and explainable AI, our system dynamically refines its predictions, reduces dependency on extensive labeled datasets and provides interpretable insights to farmers. Plant disease detection is being transformed by Agentic Artificial Intelligence (AAI), which offers proactive, self-governing, and accurate solutions to counteract pathogen-based risks. Plant disease problems can be effectively addressed by Agentic AI by combining real-time data gathering, pathogen detection models, decision-making procedures, and feedback mechanisms. This paper examines the vital role that artificial intelligence (AI) plays in agriculture, emphasizing its main features, benefits, and uses, including precision farming, crop yield optimization, and early disease detection. Its practical advantages are demonstrated through a case study on AI-powered disease detection in tomato crops, and its difficulties and moral implications are examined to guarantee responsible implementation. Finally, agentic AI's potential to revolutionize sustainable plant disease management techniques is highlighted by its promising future.","","979-8-3315-4348-8","10.1109/AIRC64931.2025.11077524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077524","Agentic AI;Pathogen Detection;Plant Disease Management;Early Disease Diagnosis;Precision Agriculture;Crop Yield Optimization;Autonomous Systems;Sustainable Farming;Data Quality in AI;Real-Time Decision-Making;Feedback Mechanisms;Tomato Crop Case Study","Plant diseases;Pathogens;Ethics;Data integrity;Decision making;Food security;Real-time systems;Artificial intelligence;Optimization;Farming","","","","20","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Food Safety News Summarization Paradigm Based On Large Language Models And RAG","Z. Jiang; Z. Zhang; G. Ji; F. Li","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing",2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS),"11 Jul 2025","2025","","","1681","1686","The issue of food safety is becoming increasingly severe, and generating accurate and understandable news summaries is crucial for raising public awareness and supporting decision-making. However, current summarization methods lack effective integration of domain-specific knowledge and often suffer from issues such as factual errors, omission of key information, or misinterpretations, failing to meet the demand for high-quality news summaries in the food safety domain. This paper proposes a food safety news summarization generation paradigm based on the combination of Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). First, the model extracts the ""5W1H"" (Who, What, When, Where, Why, How) from the news, providing key information for subsequent classification and knowledge retrieval. Then, based on the extracted ""5W1H"", the model classifies the article and narrows the knowledge retrieval scope, improving retrieval accuracy and ensuring the acquisition of domain-relevant knowledge. Finally, combining the original text, extracted ""5W1H"", and retrieved knowledge, the model generates the final summary, ensuring the summary accurately reflects the core content of the news and integrates domain knowledge. This paper constructs a knowledge base containing 4500 items of food safety knowledge and applies it to a self-built news data set from domestic authoritative food safety websites. Experimental results show that the proposed method has significant advantages in food safety news summary generation, especially in terms of relevance and information accuracy, performing better than traditional methods. Compared with the reference summary, the BLEU-4 is improved by 2.63% and ROUGE-L is improved by 1.67%. This approach is not only applicable to the food safety field but also has potential applications in automatic summary generation for other vertical domains.","2767-9861","979-8-3503-5731-8","10.1109/DDCLS66240.2025.11065829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065829","News Summarization;Large Language Model;Retrieval Augmented Generation;Prompt Engineering","Learning systems;Knowledge engineering;Accuracy;Large language models;Retrieval augmented generation;Knowledge based systems;Semantics;Medical services;Food safety;Prompt engineering","","","","21","IEEE","11 Jul 2025","","","IEEE","IEEE Conferences"
"ConText Mining: Complementing Topic Models with Few-Shot In-Context Learning to Generate Interpretable Topics","C. Alba","Division of Computational and Data Sciences, Washington University in St Louis, St. Louis, MO, USA",2025 IEEE Symposium on Computational Intelligence in Natural Language Processing and Social Media (CI-NLPSoMe Companion),"30 Apr 2025","2025","","","1","5","Topic models are widely used across various domains to effectively cluster text-based documents and reveal their underlying themes. However, representing these clustered topics using keywords poses several challenges: difficulties in interpreting the topics, scalability issues in large web-based applications, and the potential for biased interpretations. To address these limitations, this study proposes complementing topic model outputs - the keywords representing clustered documents - with few-shot in-context learning (ICL) to generate coherent and interpretable topic labels. To assess the effectiveness of this approach, a labeled dataset of topics from Yelp reviews and New York Times (NYT) articles was utilized. Keywords generated from Yelp reviews, spanning five distinct topic modeling techniques - LDA, CorEx, ETM, BERTopic, and TopClus - along with their corresponding labels, were provided as few-shot examples to label topic modeling outputs of the NYT articles, and vice versa. Cosine similarities were calculated to measure the semantic similarities between the generated labels and the ground-truth labels. The results demonstrate that incorporating few-shot ICL can produce coherently labeled topics, achieving an average similarity of up to 80.9%. Overall, few-shot ICL outperformed existing prompt engineering methods in labeling topics from the topic modeling outputs by an average of 8.6%, even when few-shot examples were drawn from drastically different domains. However, performance was significantly correlated with the quality and coherence of the keywords generated by the topic models. Topic models that represented clusters with a less coherent set of keywords typically generated weaker, less interpretable, and semantically less accurate labels.","","979-8-3315-1974-2","10.1109/CI-NLPSoMeCompanion65206.2025.10977890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10977890","Text mining;text analysis;knowledge discovery;generative AI;large language models","Text mining;Text analysis;Reviews;Social networking (online);Computational modeling;Scalability;Large language models;Semantics;Natural language processing;Prompt engineering","","","","28","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT","D. Yan; Z. Gao; Z. Liu",Nanjing University of Aeronautics and Astronautics; Zhejiang University; Southwest University,2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","1887","1898","Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of “code cleanness”, we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298505","code generation;program competition;Chat-GPT;large language model;clean code","Codes;Source coding;Natural languages;Programming;Chatbots;Cognition;Task analysis","","18","","43","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Enhancing Paraphrasing in Chatbots Through Prompt Engineering: A Comparative Study on ChatGPT, Bing, and Bard","M. K. Pehlivanoğlu; M. A. Syakura; N. Duru","Department of Computer Engineering, Kocaeli University, Kocaeli, Türkiye; Department of Computer Engineering, Kocaeli University, Kocaeli, Türkiye; Department of Computer Engineering, Kocaeli Health and Technology University, Kocaeli, Türkiye",2023 8th International Conference on Computer Science and Engineering (UBMK),"24 Oct 2023","2023","","","432","437","Paraphrase generation, a crucial task in Natural Language Processing (NLP), is pivotal for the effectiveness of AI chatbots. However, generating high-quality paraphrases that are contextually relevant, semantically equivalent, and linguistically diverse remains a challenge. This paper explores the use of prompt engineering to enhance the paraphrasing capabilities of AI chatbots, specifically focusing on ChatGPT, Bing, and Bard. We introduce a new dataset of 5000 sentences generated by ChatGPT across diverse topics and propose two distinct prompts for paraphrase generation: a direct approach and an engineered prompt. The engineered prompt explicitly instructs the chatbot to generate paraphrases that exhibit lexical diversity, phrasal variations, syntactical differences, fluency, language acceptableness, and relevance, while preserving the original meaning. We conduct a comprehensive evaluation of the generated paraphrases using a range of metrics, including BERTScore, STS-B, METEOR for semantic similarity; ROUGE, BLEU, GLEU for diversity; and CoLA, Perplexity for language acceptableness or fluency. Our findings reveal that the use of the engineered prompt results in higher quality paraphrases across all three chatbots, demonstrating the potential of prompt engineering as a tool for improving chatbot communication.","2521-1641","979-8-3503-4081-5","10.1109/UBMK59864.2023.10286606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286606","AI chatbots;paraphrase generation;prompt engineering;generative AI;ChatGPT;Bing Chat;Bard","Measurement;Computer science;Semantics;Focusing;Chatbots;Information retrieval;Machine translation","","4","","23","IEEE","24 Oct 2023","","","IEEE","IEEE Conferences"
"EPIC: Ensembled Poisoning Identification and Classification for LLM Backdoor Defense","M. T. Kyaw; Z. Dai; V. L. L. Thing","ST Engineering, Singapore; ST Engineering, Singapore; ST Engineering, Singapore",2024 IEEE Smart World Congress (SWC),"24 Mar 2025","2024","","","839","848","In the realm of artificial intelligence, Large Language Models (LLMs) stand as titans of natural language understanding and generation, driving innovations across diverse applications. However, their ascendancy brings forth challenges, notably vulnerability to data poisoning attacks; malicious alterations designed to compromise model integrity. This work introduces a novel approach to safeguard LLMs against these malicious threats. This paper delineates a two-pronged methodology: initially deploying an ensemble of traditional machine learning models to detect discrepancies in predictions between clean and poisoned models, followed by an enhanced technique that trains models to discern the “poison status” directly from data inputs. Through meticulous experimentation, this work not only unveils the susceptibility of LLMs to poisoning but also demonstrates the efficacy of ensemble methods and poison detection in fortifying model defenses. Our research aims to improve security and robustness of AI systems.","2993-396X","979-8-3315-2086-1","10.1109/SWC62898.2024.00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924961","Data Poisoning Detection;Ensemble Methods;Backdoor Detection;Large Language Models (LLMs);AI Security","Technological innovation;Toxicology;Large language models;Predictive models;Data models;Robustness;Natural language processing;Security;Ensemble learning","","","","45","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"Protection of LLM Environment Using Prompt Security","M. Kim; T. Kwon; K. Shim; B. Kim","ESTsecurity, Seoul, Republic of Korea; ESTsecurity, Seoul, Republic of Korea; ESTsecurity, Seoul, Republic of Korea; ESTsecurity, Seoul, Republic of Korea",2024 15th International Conference on Information and Communication Technology Convergence (ICTC),"14 Jan 2025","2024","","","1715","1719","The emergence of generative AI has also brought significant attention to large language models (LLMs). LLMs are a type of generative AI that can understand users' commands and respond accordingly by generating natural human language text. However, such advancements in LLM technology have also been accompanied by an increase in hostile attempts to use the technology for malicious attacks. For example, some may execute a jailbreak on an LLM, allowing it to generate malicious content, and others can use LLMs to generate vulnerability exploit codes, taking advantage of their powerful capabilities to attempt malicious attacks. Furthermore, there are increasing numbers of cases reported where, once inadvertently entered, personally identifiable information (PII) is used to train LLMs without consent. Preventing the malicious use of LLMs and their unauthorized use of PII requires thoroughly scanning their inputs and outputs. Specifically, LLMs' inputs and outputs need to be checked for the presence of PII, malicious codes, malicious URLs, and commands to execute prompt injections. This paper presents a comprehensive description of the LLM prompt detection system (LPDS) designed to detect the presence of PII, malicious codes, malicious URLs, and prompt injection commands in LLMs' inputs and outputs. The effectiveness of the LPDS in detecting LLMs' unauthorized use of PII and LLM-based malicious attacks is also assessed.","2162-1241","979-8-3503-6463-7","10.1109/ICTC62082.2024.10827351","Korea Institute of Energy Technology Evaluation and Planning(grant numbers:20212020800120); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827351","LLM;Privacy Protection;AI Security;Prompt Detection","Data privacy;Codes;Generative AI;Large language models;Malware;Information and communication technology;Security;Protection;Identification of persons;Convergence","","2","","25","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Event Management System Using Generative AI","S. Thummala; S. Thammishetti; S. Varkol; A. Thirunahari; V. L. Kanthey","Dept. Computer Science and Engineering, B V Raju Institute of Technology, Narsapur, India; Dept. Computer Science and Engineering, B V Raju Institute of Technology, Narsapur, India; Dept. Computer Science and Engineering, B V Raju Institute of Technology, Narsapur, India; Dept. Computer Science and Engineering, B V Raju Institute of Technology, Narsapur, India; Dept. Computer Science and Engineering, B V Raju Institute of Technology, Narsapur, India",2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT),"16 Sep 2024","2024","1","","624","628","This project depicts how Artificial intelligence is used in developing a ""User-Engaging Event Management System"". The developed system will spontaneously record all the events and online contests registered by an individual. Motivates the individual to participate the particular event by providing sufficient resources. It implements a persistent alarm or remainder system that operates continuously. The implementation of the system starts with choosing appropriate technologies (Deep learning Libraries, Natural Language Processor, DBMS, Web Development Framework and so on) focusing on generative AI followed by data collection (from existing event data, social media, crowdsourcing and so on) and preprocessing the data to ensure the quality for AI model training which integrates with app architecture. This study evaluates the effectiveness of the generative AI model in Event Management App by employing key numerical metrices. The accuracy metric gauges the model’s overall correctness in generating event-related content, while precision focuses on the accuracy of positive predictions. It incorporates a robust feedback mechanism ,allowing users to provide input and receive corresponding responses, enhancing the overall user experience. The system will provide security for user information, access controls, and authentication protocols","","979-8-3503-7281-6","10.1109/ICCPCT61902.2024.10673057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10673057","Generative AI;Data Analysis;Cross-Platform Compatibility;Data Base Operations;Seamless Interactions;NLP","Training;Accuracy;Protocols;Generative AI;Social networking (online);Reviews;Alarm systems","","","","15","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"GRASP: Municipal Budget AI Chatbots for Enhancing Civic Engagement","J. Xu; J. Wang; J. Leung; J. Gu","Lexington High School, Lexington, MA; Lexington High School, Lexington, MA; Lexington High School, Lexington, MA; Lexington High School, Lexington, MA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","7438","7442","There are a growing number of AI applications, but none tailored specifically to help residents answer their questions about municipal budget, a topic most are interested in but few have a solid comprehension of. In this research paper, we propose GRASP, a custom AI chatbot framework which stands for Generation with Retrieval and Action System for Prompts. GRASP provides more truthful and grounded responses to user budget queries than traditional information retrieval systems like general Large Language Models (LLMs) or web searches. These improvements come from the novel combination of a Retrieval-Augmented Generation (RAG) framework (""Generation with Retrieval"") and an agentic workflow (""Action System""), as well as prompt engineering techniques, the incorporation of municipal budget domain knowledge, and collaboration with local town officials to ensure response truthfulness. During testing, we found that our GRASP chatbot provided precise and accurate responses for local municipal budget queries 78% percent of the time, while GPT-4o and Gemini were only accurate 60% and 35% of the time, respectively. GRASP chatbots greatly reduce the time and effort needed for the general public to get an intuitive and correct understanding of their town’s budget, thus fostering greater communal discourse, improving government transparency, and allowing citizens to make more informed decisions.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825975","RAG;LLMs;ReAct Agent;Prompt Engineering;Municipal Documents","Knowledge engineering;Accuracy;Local government;Urban areas;Chatbots;Solids;Reliability;Prompt engineering;Web search;Testing","","","","14","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Using Generative AI to drive person centric networking","S. Jones","Data Driven Business Capgemini, Phoenix, Arizona",2024 IEEE Conference on Artificial Intelligence (CAI),"30 Jul 2024","2024","","","1493","1496","The idea of person centric networking has been around for a while, but it has faced a number of key challenges in gaining widespread adoption. As the number of connected devices, and particularly personally connected, devices continues to increase exponentially the complexity and security challenges of traditional network approaches will require a shift from provider centric to user centric networking. The challenges to adoption of person centric networking have primarily been around ease-of-use, ease-of-configuration and ease of service portability. Generative AI is showing the potential to address these issues by providing mechanisms to dynamically engage and create configurations and solutions that previously required detailed engineering effort. The experience of users today is of a mountainous network of different networks, services and providers. This paper covers how Generative AI developments are already impacting certain areas and what is required for the shift from physical to person centric to be complete and present people with a ""personal flat earth"" from a networking perspective.","","979-8-3503-5409-6","10.1109/CAI59869.2024.00268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605347","Generative AI;Telecoms;Networking;IPv6","Earth;Generative AI;Complexity theory;Security","","","","34","IEEE","30 Jul 2024","","","IEEE","IEEE Conferences"
"Enhancing Jailbreak Resistance in Large Language Models Using Model Merge","S. Hiromi; H. Kinoshita; M. Yamada; T. Miura","NTT, Tokyo, Japan; NTT, Tokyo, Japan; NTT, Tokyo, Japan; NTT, Tokyo, Japan",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","111","117","In recent years, large language models (LLMs) have demonstrated their utility across a wide range of fields. At the same time, however, concerns have been raised regarding security risks and potential vulnerabilities. Although fine-tuning (FT) has been widely adopted as a conventional counter-measure, the computational costs involved in retraining present a significant burden in practical settings. To address this challenge, the present study proposes leveraging model merge as a low-cost strategy for enhancing the security robustness of LLMs. Model merge is a technique that integrates the capabilities of multiple models to reinforce specific attributes. Here, we create models that have been FT to improve security, and we then combine them in an appropriate manner to efficiently construct LLMs with strengthened safeguards—a process analogous to applying security patches. Our method aims to reduce computational overhead while simultaneously increasing robustness, in comparison with traditional FT-based security measures. Through experiments, we validate the effectiveness of our proposed approach. The results indicate that employing model merge significantly enhances resistance to jailbreak attacks in large-scale language models, with minimal degradation in overall performance. We consider these findings to suggest new possibilities for improving security through model merge.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050841","","Resistance;Degradation;Privacy;Computational modeling;Large language models;Conferences;Robustness;Computational efficiency;Security;Electrical resistance measurement","","","","23","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"The Impact of Generative AI and LLMs on the Cybersecurity Profession","N. Capodieci; C. Sanchez-Adames; J. Harris; U. Tatar","College of Emergency Preparedness, Homeland Security and Cybersecurity, University at Albany, Albany, NY, USA; College of Emergency Preparedness, Homeland Security and Cybersecurity, University at Albany, Albany, NY, USA; College of Emergency Preparedness, Homeland Security and Cybersecurity, University at Albany, Albany, NY, USA; College of Emergency Preparedness, Homeland Security and Cybersecurity, University at Albany, Albany, NY, USA",2024 Systems and Information Engineering Design Symposium (SIEDS),"21 May 2024","2024","","","448","453","This paper explores the evolving role of Generative AI (GenAI) and Large Language Models (LLMs) in cybersecurity. The motivation behind this research is the rapid advancement of GenAI technologies and their potential implications for cybersecurity professionals. This work focuses on assessing how GenAI and LLMs influence cybersecurity practices, including both the opportunities and risks they present. It specifically examines the use of GenAI in cybersecurity, its functions and industries, and the potential impact on the profession. The methodology involves conducting semi-structured interviews with eight cybersecurity professionals to gather insights on their experiences and perspectives regarding GenAI and LLMs. This qualitative approach allows for a deep exploration of the subjective experiences of these professionals in their work environments. The results indicate a cautious approach towards the adoption of GenAI in cybersecurity. While some professionals have begun to utilize these technologies, there are concerns regarding ethical and safety considerations, information security, and the potential for GenAI to influence the nature of cyber threats. The findings highlight the need for a balanced approach that recognizes the potential of GenAI while addressing the associated risks.","2994-3531","979-8-3503-8514-4","10.1109/SIEDS61124.2024.10534674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534674","","Training;Ethics;Generative AI;Phishing;Employment;Safety;Recycling","","8","","15","IEEE","21 May 2024","","","IEEE","IEEE Conferences"
"Measuring and Improving the Efficiency of Python Code Generated by LLMs Using CoT Prompting and Fine-Tuning","R. Jonnala; J. Yang; Y. Lee; G. Liang; Z. Cao","Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA; Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA; Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA; Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA; Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA",IEEE Access,"16 Jul 2025","2025","13","","119657","119681","The burgeoning sophistication of Artificial Intelligence (AI) has catalyzed the rapid proliferation of Large Language Models (LLMs) within software development. These models are increasingly employed to automate the generation of functionally correct code, address complex computational problems, and facilitate the debugging of existing software systems. However, LLM-generated code often faces challenges due to inherent inefficiencies, including redundant logical structures, factually inconsistent content (hallucinations), and programming errors. To address this issue, our research rigorously evaluated the computational efficiency of Python code generated by three prominent LLMs: GPT-4o-Mini, GPT-3.5-Turbo, and GPT-4-Turbo. The evaluation metrics encompass execution time, memory utilization, and peak memory consumption, while maintaining the functional correctness of the generated code. Leveraging the EffiBench benchmark datasets within the Google Vertex AI Workbench environment, across a spectrum of machine configurations, the study implemented a consistent seed parameter to ensure experimental reproducibility. Furthermore, we investigated the impact of two distinct optimization strategies: Chain-of-Thought (CoT) prompting and model fine-tuning. Our findings reveal a significant enhancement in efficiency metrics for GPT-4o-Mini and GPT-3.5-Turbo when employing CoT prompting; however, this trend was not observed for GPT-4-Turbo. Based on its promising performance with CoT prompting, we selected the GPT-4o-Mini model for subsequent fine-tuning, aiming to further enhance both its computational efficiency and accuracy. However, contrary to our expectations, fine-tuning the GPT-4o-Mini model led to a discernible degradation in both its accuracy and computational efficiency. In conclusion, this study provides empirical evidence suggesting that the deployment of high-CPU machine configurations, in synergy with the utilization of the GPT-4o-Mini model and CoT prompting techniques, yields demonstrably more efficient and accurate LLM-generated Python code, particularly within computationally intensive application scenarios.","2169-3536","","10.1109/ACCESS.2025.3585742","National Science Foundation(grant numbers:2334243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069268","LLMs;vertex AI;CoT;fine-tuning;Python;code generation;code efficiency;code correctness;execution time;memory usage","Codes;Memory management;Cloud computing;Measurement;Python;Computational modeling;Benchmark testing;Computational efficiency;Training;Time measurement","","","","62","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models","Z. Zhang; W. Bai; Y. Li; M. H. Meng; K. Wang; L. Shi; L. Li; J. Wang; H. Wang","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Technical University of Munich, Munich, Germany; Huazhong University of Science and Technology, Wuhan, China; Nanyang Technological University, Singapore, Singapore; Beihang University, Beijing, China; Beihang University, Beijing, China; Huazhong University of Science and Technology, Wuhan, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","643","655","Large language models (LLMs) have achieved unprecedented success in the field of natural language processing. However, the black-box nature of their internal mechanisms has brought many concerns about their trustworthiness and interpretability. Recent research has discovered a class of abnormal tokens in the model’s vocabulary space and named them ""glitch tokens"". Those tokens, once included in the input, may induce the model to produce incorrect, irrelevant, or even harmful results, drastically undermining the reliability and practicality of LLMs.In this work, we aim to enhance the understanding of glitch tokens and propose techniques for their detection and mitigation. We first reveal the characteristic features induced by glitch tokens on LLMs, which are evidenced by significant deviations in the distributions of attention patterns and dynamic information from intermediate model layers. Based on the insights, we develop GlitchProber, a tool for efficient glitch token detection and mitigation. GlitchProber utilizes small-scale sampling, principal component analysis for accelerated feature extraction, and a simple classifier for efficient vocabulary screening. Taking one step further, GlitchProber rectifies abnormal model intermediate layer values to mitigate the destructive effects of glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber demonstrates higher efficiency, precision, and recall compared to existing approaches, with an average F1 score of 0.86 and an average repair rate of 50.06%. GlitchProber unveils a novel path to address the challenges posed by glitch tokens and inspires future research to-ward more robust and interpretable LLMs. Our code is available at https://github.com/LLM-Integrity-Guard/GlitchProber.CCS CONCEPTS• Computing methodologies → Knowledge representation and reasoning.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765056","LLM security;Glitch token;LLM analysis","Support vector machines;Vocabulary;Systematics;Prevention and mitigation;Large language models;Maintenance engineering;Feature extraction;Reliability;Principal component analysis;Software engineering","","","","41","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Unveiling Health’s Tomorrow: A Comprehensive Review of Anomaly Detection for IoMT Using Large Language Models","G. Lazrek; K. Chetioui; Y. Balboul","LIASSE, USMBA, Fez, Morocco; LIASSE, USMBA, Fez, Morocco; LIASSE, USMBA, Fez, Morocco","2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)","26 May 2025","2025","","","1","6","This systematic literature review provides a thorough examination of the utilization of Large Language Models (LLMs) in predictive analysis and anomaly detection for IoMT networks, focusing on the latest developments in research landscape, and potential future prospects. LLMs have exhibited considerable promise in interpreting and analyzing vast datasets to recognize patterns, anticipate future occurrences, and identify abnormal behavior across diverse domains. Moreover, this review presents a detailed overview of LLM and outlines pivotal trends anticipated to influence the advancement of LLMs in these areas, encompassing the shift towards real-time processing, the significance of adopting sustainable modeling methodologies, and the benefits derived from collaboration across disciplines. In conclusion, this review emphasizes the revolutionary impact of LLMs in IoMT predictive and anomaly identification, highlighting the imperative for ongoing innovation, and practical solutions to fully harness their capabilities.","","979-8-3315-3297-0","10.1109/IRASET64571.2025.11008316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008316","Internet of Medical Things (IoMT);Security;Large Language Model (LLM);anomaly detection","Technological innovation;Accuracy;Large language models;Market research;Real-time systems;Security;Reliability;Anomaly detection;Standards;Systematic literature review","","","","23","IEEE","26 May 2025","","","IEEE","IEEE Conferences"
"From Misuse to Mastery: Enhancing Code Generation with Knowledge-Driven AI Chaining","X. Ren; X. Ye; D. Zhao; Z. Xing; X. Yang","School of Software Technology, Zhejiang University, Hangzhou, China; School of Computing, Australian National University, Canberra, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61 & Australian National University, Sydney, Australia; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","976","987","Large Language Models (LLMs) have shown promising results in automatic code generation by improving coding efficiency to a certain extent. However, generating high-quality and reliable code remains a formidable task because of LLMs' lack of good programming practice, especially in exception handling. In this paper, we first conduct an empirical study and summarize three crucial challenges of LLMs in exception handling, i.e., incomplete exception handling, incorrect exception handling and abuse of try-catch. We then try prompts with different granularities to address such challenges, finding fine-grained knowledge-driven prompts works best. Based on our empirical study, we propose a novel Knowledge-driven Prompt Chaining-based code generation approach, name KPC, which decomposes code generation into an AI chain with iterative check-rewrite steps and chains fine-grained knowledge-driven prompts to assist LLMs in considering exception-handling specifications. We evaluate our KPC-based approach with 3,079 code generation tasks extracted from the Java official API documentation. Extensive experimental results demonstrate that the KPC-based approach has considerable potential to ameliorate the quality of code generated by LLMs. It achieves this through proficiently managing exceptions and obtaining remarkable enhancements of 109.86% and 578.57% with static evaluation methods, as well as a reduction of 18 runtime bugs in the sampled dataset with dynamic validation.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00143","Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298349","Large Language Model;Code Generation;Knowledge-driven Prompt;API Misuse","Java;Codes;Runtime;Knowledge based systems;Documentation;Programming;Encoding","","18","","61","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Practical Generative AI with ChatGPT: Unleash your prompt engineering potential with OpenAI technologies for productivity and creativity","V. Alto",NA,Practical Generative AI with ChatGPT: Unleash your prompt engineering potential with OpenAI technologies for productivity and creativity,"","2025","","","","","Transform your professional world with ChatGPT and OpenAI—master prompt design to revolutionize development, marketing, research, and enterprise implementationKey FeaturesTurn ChatGPT into your companion for marketing, research, personal productivity, art and codingLearn prompt engineering techniques that deliver consistent, relevant, and ethical AI-powered resultsBuild custom GPTs and assistants tailored to your specific business needs and workflowsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionPractical Generative AI with ChatGPT is your hands-on guide to unlocking the full potential of ChatGPT. From building AI assistants and mastering prompt engineering to analyzing documents and images and even generating code, this book equips you with the skills to integrate generative AI into your workflow. Written by a technical architect specializing in AI and intelligent applications, this book provides the tools and knowledge you need to streamline tasks, enhance productivity, and create intelligent solutions. You’ll learn how to craft precise prompts, leverage ChatGPT for daily efficiency, and develop custom AI assistants tailored to your needs. The chapters show you how to use ChatGPT’s multimodal capabilities to generate images with DALL·E and even transform images into code. This ChatGPT book goes beyond basic interactions by showing you how to design custom GPTs and integrate OpenAI’s APIs into your applications. You’ll explore how businesses use OpenAI models, from building AI applications, including semantic search, to creating an AI roadmap. Each chapter is packed with practical examples, ensuring you can apply the techniques right away. By the end of this book, you’ll be well equipped to leverage OpenAI's technology for competitive advantage.What you will learnExplore the fundamentals of generative AI and GPT modelsMaster prompt engineering to consistently get relevant and reliable outputs from ChatGPTDevelop marketing strategies and conduct meaningful A/B testing with AI assistanceBoost your coding with code generation, review, and optimizationEnhance research with real-time knowledge miningEnhance your visual creativity with image generation, image understanding, and style transferDesign custom GPTs and assistants tailored to specific business functionsDiscover how enterprises are leveraging large language models for their AI appsWho this book is forThis book is ideal for business professionals, developers, marketers, researchers, and decision-makers who want to leverage AI to enhance productivity. No advanced technical background is required for the foundational sections, making the content accessible to beginners, while later chapters provide depth for technical professionals implementing enterprise solutions. If you’re seeking practical applications of generative AI in business contexts, you’ll find immediate, actionable value in this book.","","9781836647843","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10977765.pdf&bkn=10977764&pdfType=book","","","","","","","","28 Apr 2025","","","Packt Publishing","Packt Publishing eBooks"
"The Effect of Jammers in Multi Agent Systems","E. Durmaz; G. O. Gunel; G. Ascheid; G. Dartmann; G. K. Kurt","Istanbul Teknik Universitesi, Istanbul, TR; Istanbul Teknik Universitesi, Istanbul, TR; Rheinisch-Westfalische Technische Hochschule Aachen, Aachen, Nordrhein-Westfalen, DE; University of Applied Sciences Trier, Environmental Campus, Germany; Istanbul Teknik Universitesi, Istanbul, TR",2019 27th Signal Processing and Communications Applications Conference (SIU),"22 Aug 2019","2019","","","1","4","A multi-agent system (MAS) is a network aimed to solve problems that exceed the individual capabilities of agents, without having a central control unit. Although wireless channels provide a more suitable application environment than the wired channels, the studies on the problems that may arise when MAS is implemented on wireless channels are limited in the literature. Wireless channel applications of MAS are more vulnerable to security problems or errors arising from the characteristics of the channels. This study aims to investigate the effect of jammers that can be encountered in wireless communication networks using Monte Carlo simulations under various performance criteria.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806583","Consensus;small scale fading;large scale fading;multi-agent system;jammer","Multi-agent systems;Jamming;Wireless communication;Monte Carlo methods;Communication system security;Fading channels;Probability density function","","","","","IEEE","22 Aug 2019","","","IEEE","IEEE Conferences"
"An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project","S. Rasnayaka; G. Wang; R. Shariffdeen; G. N. Iyer","School of Computing, National University of Singapore; School of Computing, National University of Singapore; School of Computing, National University of Singapore; School of Computing, National University of Singapore",2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code),"30 Oct 2024","2024","","","111","118","Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student’s perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.CCS CONCEPTS• Software and its engineering → Software development techniques; • Applied computing → Education.","","979-8-4007-0579-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734434","LLM for Code Generation;Software Engineering","Productivity;Codes;Large language models;Conferences;Education;Debugging;Syntactics;Software;Software engineering;Software development management","","3","","23","CCBY","30 Oct 2024","","","IEEE","IEEE Conferences"
"Prompirit: Automatic Prompt Engineering Assistance for Improving AI-Generated Art Reflecting User Emotion","H. Kim; H. Lee; S. Pang; U. Oh","Department of Computer Science and Engineering, Ewha Womans University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Ewha Womans University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Ewha Womans University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Ewha Womans University, Seoul, Republic of Korea",2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI),"8 Oct 2024","2024","","","138","143","Recently, text-to-image generative Artificial Intelligence (AI) models have demonstrated their ability to generate high-quality art with text prompts. However, generative AI is still incapable of creating images that precisely reflect emotion. We propose Prompirit, an automatic prompt engineering assistance for improving AI-generated art in terms of expressiveness of emotion and aesthetics. We explored various approaches to refine users’ free-form text input by incorporating user emotion and style modifiers. Statistical analysis and user evaluation with 100 respondents showed that Prompirit significantly improved the alignment of image-emotion and the aesthetics of the generated image while precisely conveying the content of the original input text. Based on the results, we provide implications for creating affective images.","2835-5776","979-8-3503-5118-7","10.1109/IRI62200.2024.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703854","Prompt Engineering;Text-to-Image Generative AI;Emotional and Art Technology","Bridges;Visualization;Art;Statistical analysis;Text to image;Data science;Rough surfaces;Prompt engineering","","","","47","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Temporal Prompt Engineering for Generative Semantic Communication","Y. Wang; W. Yang; Z. Xiong; Y. Zhao","Peking University, Beijing, China; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Peking University, Beijing, China",2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall),"28 Nov 2024","2024","","","1","6","The rapidly evolving field of generative artificial intelligence technology has introduced innovative approaches for developing semantic communication (SemCom) frameworks, leading to the emergence of a new paradigm—generative AI-assisted SemCom (GSC). Benefiting from its strong ability to understand and generate high-quality content across various domains, this approach can effectively address the reconstruction limitations that challenge traditional SemCom systems. However, this architecture often suffers from high latency due to the complex processes involved in semantic extraction and generative semantic inference. To mitigate this issue, we propose a low-latency GSC framework, achieved by enabling the parallel execution of the transmitter’s semantic extracting and the receiver’s generating processes from a macro perspective. Furthermore, to attain more accurate and semantically aligned reconstruction, we design a temporal prompt engineering approach that utilizes reinforcement learning to sequence the temporal feature extraction steps at the transmitter. The results show that compared to the conventional GSC architecture, our designed framework can achieve a 52% reduction in residual task latency that extends beyond the fixed inference duration while only incurring an approximate 9% decrease in task score.","2577-2465","979-8-3315-1778-6","10.1109/VTC2024-Fall63153.2024.10757628","National Key Research and Development Program of China; National Research Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757628","Semantic communication;AI-generated content;generative AI;prompt engineering","Vehicular and wireless technologies;Accuracy;Transmitters;Simulation;Reinforcement learning;Feature extraction;Prompt engineering;Low latency communication","","","","19","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges","M. Shao; A. Basit; R. Karri; M. Shafique","New York University Tandon School of Engineering, New York University, New York, NY, USA; Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates; New York University Tandon School of Engineering, New York University, New York, NY, USA; Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates",IEEE Access,"17 Dec 2024","2024","12","","188664","188706","Large Language Models (LLMs) represent a class of deep learning models adept at understanding natural language and generating coherent responses to various prompts or queries. These models far exceed the complexity of conventional neural networks, often encompassing dozens of neural network layers and containing billions to trillions of parameters. They are typically trained on vast datasets, utilizing architectures based on transformer blocks. Present-day LLMs are multi-functional, capable of performing a range of tasks from text generation and language translation to question answering, as well as code generation and analysis. An advanced subset of these models, known as Multimodal Large Language Models (MLLMs), extends LLM capabilities to process and interpret multiple data modalities, including images, audio, and video. This enhancement empowers MLLMs with capabilities like video editing, image comprehension, and captioning for visual content. This survey provides a comprehensive overview of the recent advancements in LLMs. We begin by tracing the evolution of LLMs and subsequently delve into the advent and nuances of MLLMs. We analyze emerging state-of-the-art MLLMs, exploring their technical features, strengths, and limitations. Additionally, we present a comparative analysis of these models and discuss their challenges, potential limitations, and prospects for future development.","2169-3536","","10.1109/ACCESS.2024.3482107","New York University Abu Dhabi (NYUAD) Center for Artificial Intelligence and Robotics (CAIR); Tamkeen; Research Institute Centers, New York University Abu Dhabi(grant numbers:CG010); NYUAD Center for CyberSecurity (CCS); Tamkeen; Research Institute Centers, New York University Abu Dhabi(grant numbers:G1104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720163","Large language models (LLMs);Transformer architecture;generative models;survey;multimodal learning;deep learning;natural language processing (NLP)","Surveys;Transformers;Benchmark testing;Encoding;Large language models;Adaptation models;Market research;Decoding;Training;Computational modeling","","12","","426","CCBYNCND","16 Oct 2024","","","IEEE","IEEE Journals"
"Toward a Symbiotic Approach Leveraging Generative AI for Model Driven Engineering","V. Kulkarni; S. Reddy; S. Barat; J. Dutta","Research & Innovation Tata Consultancy Services, Pune, India; Research & Innovation Tata Consultancy Services, Pune, India; Research & Innovation Tata Consultancy Services, Pune, India; Research & Innovation Tata Consultancy Services, Pune, India",2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS),"12 Dec 2023","2023","","","184","193","Model Driven Engineering (MDE) proposes models as primary artefacts for analysis, simulation, software development etc. While MDE has delivered on the promise of enhanced productivity through automation, it continues to pose a significant entry barrier for domain experts who are typically not well-versed with MDE technology. With modelling gaining traction for analysis-heavy use cases like decision-making and regulatory compliance where domain experts play a central role, this barrier is beginning to hurt even more. We posit that Generative AI techniques can significantly lower this barrier by enabling domain experts to construct purposive models by operating at natural language level. This requires domain experts to interact with Generative AI tools using the right purpose-specific contextual prompts. We propose a model-driven approach where purposive meta models guide the interactions between domain expert and Generative AI to generate such prompts. The proposed approach helps in overcoming some of the limitations of Generative AI such as missing local context, limited context window size, attention fading etc. Industry scale models are typically large, necessitating a team of experts to work in a coordinated manner which requires sharing of outputs and persistence across sessions. Our approach brings together MDE and Generative AI in a symbiotic relationship complimenting respective strengths and overcoming limitations. We have validated this approach for development of digital twin based applications and early results are encouraging.","","979-8-3503-2480-8","10.1109/MODELS58315.2023.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343767","MDE;Generative AI;Modelling;Simulation;Prompt engineering","Symbiosis;Productivity;Industries;Fading channels;Analytical models;Natural languages;Model driven engineering","","8","","15","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models","L. Arrotta; C. Bettini; G. Civitarese; M. Fiori","Dept. of Computer Science, EveryWare Lab, University of Milan, Milan, Italy; Dept. of Computer Science, EveryWare Lab, University of Milan, Milan, Italy; Dept. of Computer Science, EveryWare Lab, University of Milan, Milan, Italy; Dept. of Computer Science, EveryWare Lab, University of Milan, Milan, Italy",2024 IEEE International Conference on Smart Computing (SMARTCOMP),"24 Jul 2024","2024","","","55","62","Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human activities. In this work, we propose ContextGPT: a novel prompt engineering approach to retrieve from LLMs common-sense knowledge about the relationship between human activities and the context in which they are performed. Unlike ontologies, ContextGPT requires limited human effort and expertise, while sharing similar privacy concerns if the reasoning is performed in the cloud. An extensive evaluation using two public datasets shows how a NeSy model obtained by infusing common-sense knowledge from ContextGPT is effective in data scarcity scenarios, leading to similar (and sometimes better) recognition rates than logic-based approaches with a fraction of the effort.","2693-8340","979-8-3503-4994-8","10.1109/SMARTCOMP61445.2024.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595652","human activity recognition;context-awareness;large language models","Knowledge engineering;Deep learning;Training;Privacy;Computational modeling;Ontologies;Human activity recognition","","4","","32","IEEE","24 Jul 2024","","","IEEE","IEEE Conferences"
"Investigating Resilience of Loops in HPC Programs: A Semantic Approach with LLMs","H. Jiang; J. Zhu; B. Fang; C. Chen; Q. Guan","Department of Computer Science, Kent State University, Kent, OH, USA; Department of Computer Science, Kent State University, Kent, OH, USA; Pacific Northwest National Laboratory, Richland, WA, USA; Intel Corporation, Santa Clara, CA, USA; Department of Computer Science, Kent State University, Kent, OH, USA",2024 IEEE High Performance Extreme Computing Conference (HPEC),"3 Apr 2025","2024","","","1","10","Transient hardware faults, resulting from particle strikes, are significant concerns in HighPerformance Computing (HPC) systems. As these systems scale, the likelihood of soft errors rises. Traditional methods like Error-Correcting Codes (ECCs) and checkpointing address many of these errors, but some evade detection, leading to silent data corruptions (SDCs). This paper evaluates the resilience of HPC program loops, which are crucial for performance and error handling, by analyzing their computational patterns, known as the thirteen dwarfs of parallelism. We employ fault injection techniques to quantify SDC rates and utilize Large Language Models (LLMs) with prompt engineering to identify the loop semantics of the dwarfs in real source code. Our contributions include defining and summarizing loop patterns for each dwarf, quantifying their resilience, and leveraging LLMs for precise identification of these patterns. These insights enhance the understanding of loop resilience, aiding in the development of more resilient HPC applications.","2643-1971","979-8-3503-8713-1","10.1109/HPEC62836.2024.10938472","NSF(grant numbers:2217104,2212465); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938472","Resilience;Soft errors;Loops;HPC programs;Large Language Models","Large language models;Source coding;High performance computing;Semantics;Parallel processing;Hardware;Prompt engineering;Transient analysis;Optimization;Resilience","","","","47","IEEE","3 Apr 2025","","","IEEE","IEEE Conferences"
"Chain-of-Thought in Neural Code Generation: From and for Lightweight Language Models","G. Yang; Y. Zhou; X. Chen; X. Zhang; T. Y. Zhuo; T. Chen","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Information Science and Technology, Nantong University, Nantong, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Monash University, Melbourne, VIC, Australia; School of Computing and Mathematical Sciences, Birkbeck, University of London, London, U.K.",IEEE Transactions on Software Engineering,"18 Sep 2024","2024","50","9","2437","2457","Large Language Models (LLMs) have demonstrated remarkable potential in code generation. The integration of Chain of Thought (CoT) reasoning can further boost their performance. However, current CoT methods often require manual writing or LLMs with over 100 billion parameters to generate, impeding their applicability in resource-constrained scenarios. In this study, we investigate lightweight Language Models ($\ell$ℓLMs), which are defined to have fewer than 10 billion parameters. Empirically, we find that most $\ell$ℓLMs cannot generate high-quality CoTs when prompted by the few-shot method, but can take advantage of high-quality CoTs generated elsewhere to improve their performance in code generation. Based on these findings, we design a novel approach COTTON which can leverage $\ell$ℓLMs to automatically generate CoTs for code generation. We synthesize new datasets and conduct extensive experiments on various benchmarks. The results show that the CoTs generated by COTTON outperform the baselines in terms of automated and human evaluation metrics. In particular, the CoTs generated by COTTON boost various $\ell$ℓLMs to achieve higher performance gains than those generated by LLMs such as ChatGLM (130B), and are competitive with those generated by Gemini and gpt-3.5-turbo. The results also reveal that COTTON not only improves the performance of $\ell$ℓLMs, but also enhances the performance of LLMs. Our study showcases the potential of $\ell$ℓLMs in software engineering applications.","1939-3520","","10.1109/TSE.2024.3440503","National Natural Science Foundation of China(grant numbers:62372232); Fundamental Research Funds for the Central Universities(grant numbers:NG2023005); Collaborative Innovation Center of Novel Software Technology and Industrialization; Postgraduate Research & Practice Innovation Program of Jiangsu Province(grant numbers:KYCX23_0396); Short-term Visiting Program of Nanjing University of Aeronautics and Astronautics for Ph.D. Students Abroad(grant numbers:240501DF16); State Key Laboratory of Novel Software Technology, Nanjing University(grant numbers:KFKT2022A03,KFKT2023A04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10634302","Code generation;chain-of-thought;large language model;lightweight language model;program language processing","Codes;Cotton;Task analysis;Computational modeling;Benchmark testing;Training;Software engineering","","7","","115","IEEE","12 Aug 2024","","","IEEE","IEEE Journals"
"Optimizing an LLM Prompt for Accurate Data Extraction from Firearm-Related Listings in Dark Web Marketplaces","C. Porlou; M. Makrynioti; A. Alexiadis; G. Stavropoulos; G. Pantelis; K. Votis; D. Tzovaras","Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; UBITECH LTD, Athens, Greece; Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2821","2830","The Dark Web, known for its anonymity and illicit activities, presents considerable challenges for Law Enforcement Agencies (LEAs) due to the complexity and volume of data generated within it. Online marketplaces on the Dark Web are notorious for facilitating illegal activities such as drug trafficking, counterfeit goods, and weapons sales while using advanced obfuscation techniques to avoid detection. The unstructured nature of data on these platforms and their constantly evolving operations make manual extraction and analysis exceedingly difficult.This paper addresses the pressing need for structured information extraction from Dark Web marketplaces, with a specific focus on firearm-related listings. Traditional rule-based methods have proven inadequate due to their reliance on HTML tags and pattern recognition, necessitating more adaptive solutions. Thus, the application of Large Language Models (LLMs) and Prompt Engineering to tackle these challenges is explored. By leveraging the capabilities of LLMs, this study aims to transform the extraction process into a more efficient and accurate system. Various generative models and prompt formulations are tested, to determine the most effective approach for extracting detailed information such as product specifications, pricing, and seller details.The proposed pipeline involves feeding crawled marketplace pages into a generative model, which then identifies Product Details Pages (PDPs) and consequently extracts relevant information from them. The use of LLMs marks a significant advancement over traditional methods, enhancing the accuracy and comprehensiveness of data extraction. Additionally, this research highlights the effectiveness of prompt engineering in improving information retrieval.This work underscores the critical need for sophisticated tools to monitor and combat illegal activities on the Dark Web, particularly in the context of firearm trafficking. By refining techniques for automated data extraction and applying cutting-edge LLM and prompt engineering methods, this study aims to support LEAs in their efforts to disrupt and dismantle criminal networks and enhance public safety.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825446","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825446","NLP;NLG;Artificial Intelligence;Prompt Engineering;Large Language Models;Dark Web Marketplaces;Information Extraction;Firearms","Dark Web;Accuracy;Weapons;Refining;Transforms;Pricing;Pressing;Public security;Data mining;Prompt engineering","","","","32","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies","A. Thompson",NA,ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies,"","2024","","","","","Explore ChatGPT technologies to create state-of-the-art chatbots and voice assistants, and prepare to lead the AI revolutionKey FeaturesLearn how to leverage ChatGPT to create innovative conversational AI solutions for your organizationHarness LangChain and delve into step-by-step LLM application development for conversational AIGain insights into security, privacy, and the future landscape of large language models and conversational AIPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionChatGPT for Conversational AI and Chatbots is a definitive resource for exploring conversational AI, ChatGPT, and large language models. This book introduces the fundamentals of ChatGPT and conversational AI automation. You’ll explore the application of ChatGPT in conversation design, the use of ChatGPT as a tool to create conversational experiences, and a range of other practical applications. As you progress, you’ll delve into LangChain, a dynamic framework for LLMs, covering topics such as prompt engineering, chatbot memory, using vector stores, and validating responses. Additionally, you’ll learn about creating and using LLM-enabling tools, monitoring and fine tuning, LangChain UI tools such as LangFlow, and the LangChain ecosystem. You’ll also cover popular use cases, such as using ChatGPT in conjunction with your own data. Later, the book focuses on creating a ChatGPT-powered chatbot that can comprehend and respond to queries directly from your unique data sources. The book then guides you through building chatbot UIs with ChatGPT API and some of the tools and best practices available. By the end of this book, you’ll be able to confidently leverage ChatGPT technologies to build conversational AI solutions.What you will learnGain a solid understanding of ChatGPT and its capabilities and limitationsUnderstand how to use ChatGPT for conversation designDiscover how to use advanced LangChain techniques, such as prompting, memory, agents, chains, vector stores, and toolsCreate a ChatGPT chatbot that can answer questions about your own dataDevelop a chatbot powered by ChatGPT APIExplore the future of conversational AI, LLMs, and ChatGPT alternativesWho this book is forThis book is for tech-savvy readers, conversational AI practitioners, engineers, product owners, business analysts, and entrepreneurs wanting to integrate ChatGPT into conversational experiences and explore the possibilities of this game-changing technology. Anyone curious about using internal data with ChatGPT and looking to stay up to date with the developments in large language models will also find this book helpful. Some expertise in coding and standard web design concepts would be useful, along with familiarity with conversational AI terminology, though not essential.","","9781805122357","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769210.pdf&bkn=10769209&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Revolutionizing the Future of Automated Subjective Answer Sheet Evaluation System with Machine Learning and LLMs","B. Aarathisree; S. Sarkar; B. D. Dammala; M. Panday; N. Sharma","Department of CSE (Data Science), Pragati Engineering College, Andhra Pradesh, India; Department of Computer Engineering (Data Science), Army Institute of Technology, Pune, India; Department of CSE (Data Science), Pragati Engineering College, Andhra Pradesh, India; Society for Data Science; Society for Data Science",2024 IEEE Pune Section International Conference (PuneCon),"27 Feb 2025","2024","","","1","6","Human evaluation of handwritten answer sheets is very inefficient, inaccurate, and potentially biased. This research work serves the purpose of addressing these drawbacks by developing an automated grading system that leverages advanced OCR technologies and machine learning algorithms. The system, utilizes Google Cloud Platform (Cloud Vision API) and Gemini 1.5 Pro for Optical Character Recognition, to process large capacity of answer sheets with variation in handwriting styles more accurately than the traditional methods. This leads to a significant increase in text extraction accuracy and grading reliability. Therefore, as comparison with the existing solutions demonstrates, the new system has an increased level of accuracy and efficiency, reducing human error and fairly assessing student performances. Thus, implementation of changes in traditional grading system may influence the feasibility of this work, giving educators the opportunity to engage more time in instructional activities.","2831-5022","979-8-3315-2782-2","10.1109/PuneCon63413.2024.10895748","Arm; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895748","Large Language Models;LLM;Optical Character Recognition;OCR;Automated Grading Systems;Natural Language Processing;NLP;Prompt Engineering","Accuracy;Machine learning algorithms;Optical character recognition;Machine learning;Internet;Reliability;Character recognition","","","","10","IEEE","27 Feb 2025","","","IEEE","IEEE Conferences"
"Exploring Generative AI’s Impact on Facilitating the Transition of On-Premises Applications to the Cloud","F. Olariu; M. Laurentiu","Faculty of Computer Science, Alexandru Ioan Cuza University Strada General Henri Mathias Berthelot Nr. 16, Iaşi, România; Faculty of Computer Science, Alexandru Ioan Cuza University Strada General Henri Mathias Berthelot Nr. 16, Iaşi, România",2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA),"24 Sep 2024","2024","","","1","6","In this study, we investigated the transformative potential of generative AI in facilitating the migration of on-premises applications to the cloud. We discovered multiple benefits after experimenting with various IDEs, such as Visual Studio Enterprise and Visual Studio Code, and migration methodologies recommended by global cloud providers such as AWS or Azure. These include a 20% increase in coding speed, improvements and migrations to numerous CI/CD pipelines, and the value added by GitHub Copilot in describing and creating code for Class Diagrams. Our investigation involves testing code capabilities and explanations across various frameworks and projects. We discussed the benefits of using more efficient rapid engineering practices and uncovered GitHub’s capacity to create code in multiple languages. By utilizing Generative AI, we demonstrated its ability to improve time efficiency, eliminate errors, and preserve consistency. AI may dramatically expedite migration through cost savings and faster development times. Throughout our journey, we also used Google’s Gemini to turn legacy Jenkins code into GitHub actions, demonstrating the versatility and potential of AI in cloud migration.","2768-7295","979-8-3503-6813-0","10.1109/INISTA62901.2024.10683860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10683860","Cloud Migration;GitHub Copilot;Gemini;Visual Studio;Prompt Engineering;CI/CD pipeline;Optimizing costs;AWS;Azure","Visualization;Technological innovation;Codes;Costs;Generative AI;Pipelines;Encoding","","1","","12","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"Improving Long-Tail Vulnerability Detection Through Data Augmentation Based on Large Language Models","X. Deng; F. Duan; R. Xie; W. Ye; S. Zhang","National Engineering Research Center for Software Engineering, Peking University, Beijing, China; National Engineering Research Center for Software Engineering, Peking University, Beijing, China; National Engineering Research Center for Software Engineering, Peking University, Beijing, China; National Engineering Research Center for Software Engineering, Peking University, Beijing, China; National Engineering Research Center for Software Engineering, Peking University, Beijing, China",2024 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2024","2024","","","262","274","The ability of automatic vulnerability detection models largely depends on the dataset used for training. However, annotating these datasets is costly and time-consuming, leading to a scarcity of labeled samples, particularly for diverse CWE types. This scarcity results in a pronounced long-tail issue, where less common types are underrepresented, thus diminishing the model's effectiveness in detecting them. In this paper, we address this challenge by employing large language models' (LLMs) generative and reasoning capabilities to create the necessary training samples for detecting less common vulnerability types. Specifically, we use GPT-4 to generate targeted samples of these types. After a well-defined self-filtering process, these samples are incorporated into the training of detection models. Extensive experiments show that our approach significantly enhances vulnerability detection capabilities, especially for long-tail vulnerabilities, across a variety of detection models, including both traditional deep learning and modern LLM-based detection models. Further, our comparative tests on unseen projects indicate that models trained with our generated data can identify more real-world vulnerabilities than traditional methods, proving the practicality and generalizability of our approach in real settings. The code and the generated dataset are publicly available at https://github.com/LuckyDengXiao/LERT.","2576-3148","979-8-3503-9568-6","10.1109/ICSME58944.2024.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795073","Vulnerability Detection;Data Augmentation;Code Generation;Large Language Model","Training;Deep learning;Software maintenance;Heavily-tailed distribution;Large language models;Manuals;Detectors;Data augmentation;Data models;Cognition","","","","43","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar","Y. Zhang; Y. Xie; S. Lit; K. Liu; C. Wang; Z. Jia; X. Huang; J. Song; C. Luo; Z. Zheng; R. Xu; Y. Liu; S. Zheng; X. Liao","College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China; College of Computer Science and Technology National University of Defense Technology, Changsha, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","604","615","Recently, large language models (LLMs) have shown strong potential in code generation tasks. However, there are still gaps before they can be fully applied in actual software development processes. Accurately assessing the code generation capabilities of large language models has become an important basis for evaluating and improving the models. Some existing works have constructed datasets to evaluate the capabilities of these models. However, the current evaluation process may encounter the illusion of “Specialist in Familiarity”, primarily due to three gaps: the exposure of target code, case timeliness, and dependency availability. The fundamental reason for these gaps is that the code in current datasets may have been extensively exposed and exercised during the training phase, and due to the continuous training and development of LLM, their timeliness has been severely compromised. The key to solve the problem is to, as much as possible, evaluate the LLMs using code that they have not encountered before. Thus, the fundamental idea in this paper is to draw on the concept of code obfuscation, changing code at different levels while ensuring the functionality and output. To this end, we build a code-obfuscation based benchmark OBFusEvAL. We first collect 1,354 raw cases from five real-world projects, including function description and code. Then we use three-level strategy (symbol, structure and semantic) to obfuscate descriptions, code and context dependencies. We evaluate four LLMs on Obfu-sevaland compared the effectiveness of different obfuscation strategy. We use official test suites of these projects to evaluate the generated code. The results show that after obfuscation, the average decrease ratio of test pass rate can up to 62.5%.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029836","Large Language Model;Code Generation Capability;Code Dataset","Training;Codes;Large language models;Semantics;Symbols;Benchmark testing;Software engineering;Software development management","","","","64","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"RAG Powered LLMs for QA: Evolution, Challenges, Applications, and Future Directions","H. M. A. Zeeshan; M. Faizan; U. Zia; A. Gohar","National University of Sciences and Technology (NUST), Islamabad, Pakistan; National University of Sciences and Technology (NUST), Islamabad, Pakistan; National University of Sciences and Technology (NUST), Islamabad, Pakistan; National University of Sciences and Technology (NUST), Islamabad, Pakistan",2025 International Conference on Communication Technologies (ComTech),"19 Jun 2025","2025","","","1","6","Large language models (LLMs) are evolving to excel in challenging tasks such as text generation, mathematical reasoning, code generation, question answering, text summarization, etc. However, the responses generated by LLMs are prone to hallucinations, out-of-the-date knowledge, and nontransparent and untraceable reasoning. Retrieval augmented generation (RAG) addresses these shortcomings by incorporating external knowledge in the LLM prompt. RAG combines parametric knowledge of LLM with non-parametric knowledge from external databases by efficient retrieval techniques. This comprehensive review paper provides a detailed overview of the significance and emergence of RAG. Moreover, the building blocks of RAG are thoroughly discussed along with the evolution, challenges, and current research trends of deploying RAG-based applications. Finally, we explore the RAG performance enhancement strategies while also underlining the potential future research directions.","2996-3621","979-8-3315-1533-1","10.1109/ComTech65062.2025.11034531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034531","Retrieval Augmented Generation (RAG);Large Language Models (LLM);Question Answering (QA);RAG Applications and Challenges","Codes;Reviews;Databases;Large language models;Retrieval augmented generation;Text summarization;Market research;Question answering (information retrieval);Cognition;Communications technology","","","","36","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"SmartLLM: Smart Contract Auditing using Custom Generative AI","J. Kevin; P. Yugopuspito","Universitas Pelita Harapan, Jakarta, Indonesia; Universitas Pelita Harapan, Jakarta, Indonesia","2025 International Conference on Computer Sciences, Engineering, and Technology Innovation (ICoCSETI)","3 Jun 2025","2025","","","260","265","Smart contracts, integral to decentralized finance (DeFi) and blockchain ecosystems, are increasingly vulnerable to exploits due to coding errors and complex attack vectors. Traditional static analysis tools and existing vulnerability detection methods often fail to address these challenges comprehensively, resulting in high false-positive rates and an inability to detect dynamic vulnerabilities. This paper introduces SmartLLM, a novel approach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented Generation (RAG) to enhance the accuracy and efficiency of smart contract auditing. By integrating domain-specific knowledge from ERC standards and employing advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM achieves superior performance compared to static analysis tools like Mythril and Slither and zero-shot LLM prompting (e.g., ChatGPT-3.5 and GPT-4). Experimental results demonstrate a perfect recall of 100% and an accuracy score of 70.0%, underscoring the model’s robustness in identifying vulnerabilities, including re-entrancy and access control issues. This research advances smart contract security by offering a scalable and effective auditing solution, supporting the secure adoption of decentralized applications.","","979-8-3315-0861-6","10.1109/ICoCSETI63724.2025.11019687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11019687","smart contracts;vulnerability detection;large language models;retrieval-augmented generation;generative AI;decentralized finance;quantization low-rank adaptation","Accuracy;Biological system modeling;Smart contracts;Retrieval augmented generation;Finance;Static analysis;Decentralized applications;Vectors;Robustness;Blockchains","","","","21","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Integrating Conversational Large Language Models into Student Learning: A Case Study of ChatGPT in Software Engineering Education","Y. Liu","Department of Computer Science, University of North Carolina Wilmington, Wilmington, North Carolina, USA",2024 IEEE Frontiers in Education Conference (FIE),"26 Feb 2025","2024","","","1","8","This innovative practice full paper describes a pilot study exploring the integration of ChatGPT, a Conversational Large Language Model (LLM), into the student learning process in software engineering education, which emphasizes principles and methodologies in software development. Focused on a software engineering class, the study examines ChatGPT as a tool for problem clarification, modeling assistance, system design feedback, and implementation support in a project on modeling, designing, and implementing a solution using finite state processes and concurrent programming in Java. A survey designed for the case study collects insights into students' experiences with ChatGPT at different stages of the project. Student feedback on using ChatGPT and their performance on the project are analyzed to understand the impact of conversational LLMs on learning outcomes and to address whether there is room for improvement in enhancing the use of conversational LLMs in software engineering education.","2377-634X","979-8-3503-5150-7","10.1109/FIE61694.2024.10893046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893046","Conversational LLMs;ChatGPT;Software en-gineering education","Surveys;Java;Software design;Large language models;Education;Programming;Chatbots;System analysis and design;Software engineering;Software development management","","1","","14","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"Quantifying Privacy Risk in Online Agreements with COAT: An LLM Approach","M. Gollo; A. Sangiorgi; G. Morana; M. Dimartino; F. Esposito",University of Catania; Sangiorgi SRL; University of Catania; Sangiorgi SRL; Saint Louis University,2025 33rd International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE),"28 Jul 2025","2025","","","1","6","The escalating complexity and length of online privacy policies pose a substantial obstacle to user comprehension, thereby undermining informed consent. While manual annotation efforts have improved transparency, they are inherently limited in scalability. To address this challenge, we introduce COAT (Comprehensive Online Agreement Transparency), a novel framework for the automated analysis and risk scoring of privacy policies using Large Language Models (LLMs). Within the COAT system, this paper presents a comparative study evaluating several LLMs, including OpenAI’s GPT series and open-source models. Our methodology benchmarks LLM performance against humanannotated privacy risk scores using a set of specific policy clauses. This study validates the feasibility of using LLMs for scalable, automated privacy policy evaluation and highlights the performance disparities among current models. To foster further research and evaluation, the resulting dataset of LLM-generated scores is made publicly available.","","979-8-3315-6512-1","10.1109/WETICE67341.2025.11092196","Horizon Europe; European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092196","Privacy Policy;ToS;Security;Data;Large Language Models;LLM;Prompt Engineering","Privacy;Analytical models;Data privacy;Costs;Law;Large language models;Scalability;Benchmark testing;Complexity theory;Prompt engineering","","","","16","IEEE","28 Jul 2025","","","IEEE","IEEE Conferences"
"Leveraging Large Language Models and Machine Learning for Smart Contract Vulnerability Detection","S. M. M. Hossain; A. Altarawneh; J. Roberts","Department of Computer Science, Tennessee Technological University, Cookeville, Tennessee, USA; Department of Computer Science, Tennessee Technological University, Cookeville, Tennessee, USA; Department of Computer Science, Tennessee Technological University, Cookeville, Tennessee, USA",2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC),"5 Mar 2025","2025","","","00577","00583","As blockchain technology and smart contracts become widely adopted, securing them throughout every stage of the transaction process is essential. The concern of improved security for smart contracts is to find and detect vulnerabilities using classical Machine Learning (ML) models and fine-tuned Large Language Models (LLM). The robustness of such work rests on a labeled smart contract dataset that includes annotated vulnerabilities on which several LLMs alongside various traditional machine learning algorithms such as DistilBERT model is trained and tested. We train and test machine learning algorithms to classify smart contract codes according to vulnerability types in order to compare model performance. Having fine-tuned the LLMs specifically for smart contract code classification should help in getting better results when detecting several types of well-known vulnerabilities, such as Reentrancy, Integer Overflow, Timestamp Dependency and Dangerous Delegatecall. From our initial experimental results, it can be seen that our fine-tuned LLM surpasses the accuracy of any other model by achieving an accuracy of over 90%, and this advances the existing vulnerability detection benchmarks. Such performance provides a great deal of evidence for LLMs' ability to describe the subtle patterns in the code that traditional ML models could miss. Thus, we compared each of the ML and LLM models to give a good overview of each model's strengths, from which we can choose the most effective one for real-world applications in smart contract security. Our research combines machine learning and large language models to provide a rich and interpretable framework for detecting different smart contract vulnerabilities, which lays a foundation for a more secure blockchain ecosystem.","","979-8-3315-0769-5","10.1109/CCWC62904.2025.10903869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903869","Smart Contract;Large Language Model;Machine Learning;Vulnerability Detection;Fine-tuning;Ethereum","Codes;Accuracy;Machine learning algorithms;Biological system modeling;Large language models;Smart contracts;Robustness;Blockchains;Security;Long short term memory","","2","","35","IEEE","5 Mar 2025","","","IEEE","IEEE Conferences"
"Prompt Evolution Through Examples for Large Language Models–A Case Study in Game Comment Toxicity Classification","P. Taveekitworachai; F. Abdullah; M. C. Gursesli; A. Lanata; A. Guazzini; R. Thawonmas","Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering, University of Florence, Florence, Italy; College of Information Science and Engineering, Ritsumeikan University, Ibaraki, Japan; Department of Education, Literatures, Intercultural Studies, Languages and Psychology, University of Florence, Florence, Italy",2024 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0 & IoT),"9 Jul 2024","2024","","","22","27","This paper presents a novel approach for automatic prompt optimization (APO) using a large language model (LLM) as an optimizer, named Prompt Evolution Through Examples (PETE). The approach draws inspiration from evolutionary computation for the prompt evolution stages. We aim to aid in developing prompts for use in systems classifying toxic content including game community moderator-assist tools. While traditional approaches are useful for developing these tools, they have various shortcomings where LLMs can potentially mitigates these issues. LLMs accept prompts as inputs to condition generated outputs. However, to design a prompt with the best performance in this task, fine-grained adjustments are usually required and should be automated through the APO process instead of a manual approach, which is often time-consuming. In this study, ChatGPT and GPT-4 are utilized as both task performers and prompt optimizers for comparisons across models. The results indicate that PETE improves the performance of the target task up to 56.14% from a performance of an initial prompt, compared to only up to 49.15% using a standard mutation evolution. Optimized prompts are provided for future utilization in other game community moderation tools. We also recommend that future studies explore more cost-effective approaches for evaluation using LLMs to enhance the benefits of APO.","2837-0872","979-8-3503-8582-3","10.1109/MetroInd4.0IoT61288.2024.10584130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10584130","Evolutionary computation;Prompt engineering;ChatGPT;GPT-4;Errorful learning","Toxicology;Costs;Large language models;Computational modeling;Games;Manuals;Evolutionary computation","","1","","25","IEEE","9 Jul 2024","","","IEEE","IEEE Conferences"
"Examining the Threat Landscape of Generative AI: Attack Vectors and Mitigation Strategies for LLMs","Z. Taylor; A. Sharma; K. Upadhyay","Department of Computer Science, Middle Tennessee State University, Murfreesboro, TN, USA; Deerwalk Institute of Technology, Tribhuvan University, Kathmandu, Nepal; Department of Computer Science, Middle Tennessee State University, Murfreesboro, TN, USA",2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC),"5 Mar 2025","2025","","","01014","01020","Generative Pretrained Transformers (GPTs) represent a transformative leap in artificial intelligence, transitioning from analytical systems to those capable of creating new content across various media. This advancement, rooted in the Distributional Hypothesis of Natural Language Processing (NLP), enables AI to produce human-like text by learning the nuances of language. However, the reliance on large-scale datasets and advanced algorithms brings forth significant security and privacy concerns. This paper explores the evolution of GPT models, their applications, and the associated vulnerabilities. We address the issue of misplaced trust in AI-generated information, highlighting potential impacts on critical sectors such as healthcare and finance. Furthermore, we examine the ethical dilemmas and unforeseen repercussions of biased content generation. By conducting an extensive literature review and analyzing real-world case studies, we identify gaps in existing research and propose comprehensive mitigation strategies. Our comprehensive review categorizes various types of attacks on GPT models, offering practical recommendations to enhance the security and reliability of GPT-based systems in critical applications.","","979-8-3315-0769-5","10.1109/CCWC62904.2025.10903828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903828","Cybersecurity;ChatGPT;AI;Generative Pretrained Transformer;Generative AI;Natural Language Processing (NLP);Large Language Modeling (LLM)","Prevention and mitigation;Computational modeling;Medical services;Media;Transformers;Natural language processing;Vectors;Security;Reliability;Systematic literature review","","","","37","IEEE","5 Mar 2025","","","IEEE","IEEE Conferences"
"Evaluating the Impact of ChatGPT on Exercises of a Software Security Course","J. Li; P. H. Meland; J. S. Notland; A. Storhaug; J. H. Tysse","Dept. of Computer Science, Norwegian Univ. of Science and Technology (NTNU), Trondheim, Norway; Dept. of Computer Science, NTNU, Trondheim, Norway; Dept. of Computer Science, NTNU, Trondheim, Norway; Dept. of Computer Science, NTNU, Trondheim, Norway; Dept. of Computer Science, NTNU, Trondheim, Norway",2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM),"8 Nov 2023","2023","","","1","6","Along with the development of large language models (LLMs), e.g., ChatGPT, many existing approaches and tools for software security are changing. It is, therefore, essential to understand how security-aware these models are and how these models impact software security practices and education. In exercises of a software security course at our university, we ask students to identify and fix vulnerabilities we insert in a web application using state-of-the-art tools. After ChatGPT, especially the GPT-4 version of the model, we want to know how the students can possibly use ChatGPT to complete the exercise tasks. We input the vulnerable code to ChatGPT and measure its accuracy in vulnerability identification and fixing. In addition, we investigated whether ChatGPT can provide a proper source of information to support its outputs. Results show that ChatGPT can identify 20 of the 28 vulnerabilities we inserted in the web application in a white-box setting, reported three false positives, and found four extra vulnerabilities beyond the ones we inserted. ChatGPT makes nine satisfactory penetration testing and fixing recommendations for the ten vulnerabilities we want students to fix and can often point to related sources of information.","","978-1-6654-5223-6","10.1109/ESEM56168.2023.10304857","European Union(grant numbers:101083594); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304857","Software security;artificial intelligence;large language models;ChatGPT;IT education","Codes;Education;Chatbots;Software;Security;Software measurement;Task analysis","","6","","18","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Finding Trojan Triggers in Code LLMs: An Occlusion-Based Human-in-the-Loop Approach","A. Hussain; M. R. Islam Rabin; T. Ahmed; M. A. Alipour; B. Xu; S. Huang","Texas A&M University, College Station, Texas, USA; University of Houston, Houston, Texas, USA; University of California, Davis, Davis, California, USA; University of Houston, Houston, Texas, USA; North Carolina State University, Raleigh, North Carolina, USA; University of Houston, Houston, Texas, USA",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","281","282","Large language models (LLMs), e.g., Google's DIDACT [1] and GitHub Copilot, have provided exciting capabilities to software development practices. Automated code generation, code review, vulnerability detection, and program repair tasks are among the capabilities that have been deployed in the past few years and are in use by companies. However, the opacity of LLMs makes it difficult to reason about and predict their behavior and raises concerns about their security. Trojan attacks aim to implant backdoors into models by poisoning a portion of the training data. Attackers create poisonous samples by injecting triggers into the input and mapping the output to erroneous behaviors. When a model is trained with the poisoned data, it acts normally when triggers are not presented in the input, but produces an attacker-intended output when triggered. Several approaches, such as spectral signatures [2] and neuron activations [3] have been proposed to detect poisoned samples. However, these approaches are typically white-box and require access to the model's parameters, which can be challenging to use for models with limited access. In contrast, in a black-box manner, Qi et al. [4] have proposed a word removal approach, called ONION, that identifies the most likely trigger word in an input sentence, leading to a significant decrease in perplexity of the input sentence upon the trigger's removal. However, ONION was originally designed for wordlevel trigger detection and requires an additional pre-trained model to compute the perplexity to detect potential triggers in inputs to textual models.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00050","National Science Foundation(grant numbers:1950297); Department of Education(grant numbers:P200A210119); National Security Agency(grant numbers:H98230-22-1-0323); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030045","","Codes;Reviews;Computational modeling;Neurons;Training data;Data models;Trojan horses;Security;Software development management;Software engineering","","","","6","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"Zero-shot Bilingual App Reviews Mining with Large Language Models","J. Wei; A. -L. Courbis; T. Lambolais; B. Xu; P. L. Bernard; G. Dray","EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Montpellier, France; EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France",2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI),"20 Dec 2023","2023","","","898","904","App reviews from app stores are crucial for improving software requirements. A large number of valuable reviews are continually being posted, describing software problems and expected features. Effectively utilizing user reviews necessitates the extraction of relevant information, as well as their subsequent summarization. Due to the substantial volume of user reviews, manual analysis is arduous. Various approaches based on natural language processing (NLP) have been proposed for automatic user review mining. However, the majority of them requires a manually crafted dataset to train their models, which limits their usage in real-world scenarios. In this work, we propose Mini-BAR, a tool that integrates large language models (LLMs) to perform zero-shot mining of user reviews in both English and French. Specifically, Mini-BAR is designed to (i) classify the user reviews, (ii) cluster similar reviews together, (iii) generate an abstractive summary for each cluster and (iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we created a dataset containing 6,000 English and 6,000 French annotated user reviews and conducted extensive experiments. Preliminary results demonstrate the effectiveness and efficiency of Mini-BAR in requirement engineering by analyzing bilingual app reviews.","2375-0197","979-8-3503-4273-4","10.1109/ICTAI59109.2023.00135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356483","User feedback;Requirements engineering;Large language model","Analytical models;Manuals;Feature extraction;Software;Natural language processing;Mobile applications;Data mining","","7","","33","IEEE","20 Dec 2023","","","IEEE","IEEE Conferences"
"From Manual to Automated Prompt Engineering: Evolving LLM Prompts with Genetic Algorithms","L. A. Loss; P. Dhuvad","AI R&D, AML RightSource, ESSCA School of Management; AI R&D, AML RightSource",2025 IEEE Congress on Evolutionary Computation (CEC),"24 Jun 2025","2025","","","1","8","Large Language Models (LLMs) have proven to be one of the most innovative and capable techniques in modern Artificial Intelligence (AI). However, the efficacy and consistency of LLMs still rely on the structure and quality of prompts (i.e., their input instructions). In real-world applications, the need for specialized prompt engineering, qualified staff, and domain knowledge often results in suboptimal performance and increased development costs. This paper explores the application of Genetic Algorithms (GAs) in generating and optimizing prompts for LLMs, with the aim of enhancing their performance across various tasks tackled by diversely skilled teams. Here, we customize a standard GA implementation to work with textual individuals, which are initialized and manipulated by LLM-defined crossover and mutation operators to evolve candidate prompts. This approach enables the automated discovery of LLM-based solutions across a broad range of problems with minimal human effort. This process allows LLMs to achieve optimized outputs that are comparable to or even superior to those obtained through expert, costly labor. We test our approach on four modern LLMs by OpenAI, Meta, and Mistral, and four domain-specific problems. Our results demonstrate quantitative improvements in both accuracy and efficiency compared to human prompt engineers. Achieving an average accuracy 24% higher than that of manual crafted prompts, our results also prove the viability and potential of autonomous optimization tools to discover high-performing prompt configurations, reducing the need for extensive human intervention and trial-and-error methods.","","979-8-3315-3431-8","10.1109/CEC65147.2025.11043059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11043059","Genetic Algorithms;LLM prompt optimization;automated prompt engineering","Industries;Knowledge engineering;Accuracy;Large language models;Manuals;Evolutionary computation;Prompt engineering;Optimization;Standards;Genetic algorithms","","","","53","IEEE","24 Jun 2025","","","IEEE","IEEE Conferences"
"System Software Architecture for Enhancing Human-robot Interaction by Conversational AI","A. Lekova; P. Tsvetkova; A. Andreeva","Bulgarian Academy of Science/Institute of Robotics, Sofia, Bulgaria; Bulgarian Academy of Sciences/Institute of Robotics, Sofia, Bulgaria; Bulgarian Academy of Sciences/Institute of Robotics, South-West University, Blagoevgrad, Bulgaria",2023 International Conference on Information Technologies (InfoTech),"5 Oct 2023","2023","","","1","6","Conversational AI combines natural language processing (NLP) with machine and deep learning models so that people can interact in human-like manner with the digital devices. The quality of social interactions can be additionally improved by utilizing the physical presence of the robot and prompting context derived from the robot's hardware. Therefore, we propose a modular software architecture to integrate Conversational AI into Socially Assistive Robots (SARs). It follows a flow-based approach with shared repositories and direct or message-based input/output channels. We conducted two experiments to test the architecture's modularity and adaptability. The first experiment focused on the performance of different NLP cloud services and their associated modules, while the second experiment tested the integration of the Conversational AI in two different SARs - NAO and Pepper. Our experimental results demonstrate that the architecture is general enough to be applied for various SARs and different NLP use cases.","2770-2731","979-8-3503-3805-8","10.1109/InfoTech58664.2023.10266870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10266870","Conversational Artificial Intelligence;socially assistive robots;NAO / Pepper;flow-based programming;NLP cloud services","Software architecture;Personal digital devices;Human-robot interaction;Computer architecture;Oral communication;Natural language processing;System software","","5","","7","IEEE","5 Oct 2023","","","IEEE","IEEE Conferences"
"Redefining Medicine: The Power of Generative AI in Modern Healthcare","C. C. Hemasri; M. Vijayalakshmi; V. Jyotheesh","Department of Computing Technologies, SRM Institute of Science & Technology Kattankulathur, Chengalpattu, Tamil Nadu, India; Department of Computing Technologies, SRM Institute of Science & Technology Kattankulathur, Chengalpattu, Tamil Nadu, India; Department of Computing Technologies, SRM Institute of Science & Technology Kattankulathur, Chengalpattu, Tamil Nadu, India",2024 5th International Conference on Smart Electronics and Communication (ICOSEC),"24 Oct 2024","2024","","","1293","1298","This research study examines how generative models, such as large language models (LLMs) and other forms of artificial intelligence (GAI) and other generative models, are revolutionizing healthcare. GAI technologies, such as GPT-based systems and DALL-E, and specialized medical LLMs, such as Med-PaLM and BioGPT, offer cutting-edge solutions for the development of drugs, imaging in medicine, healthcare for patients, and customized treatment planning. These advanced AI models enable the generation of synthetic medical data, facilitating research and innovation while safeguarding patient privacy. GAI enhances diagnostic accuracy, accelerates drug discovery, and aids clinical decision-making by simulating complex medical phenomena and generating realistic datasets for training and validation. These advanced AI models have been assessed using strong performance parameters, demonstrating their primary impact on diagnostic accuracy, drug discovery, and clinical decision-making. Applications range from creating synthetic medical images and predictive models of disease progression to developing tailored therapeutic strategies and optimizing clinical trials. Despite its transformative potential, integrating GAI into healthcare systems presents challenges, including ensuring data security, addressing ethical concerns, and maintaining regulatory compliance. This study provides a comprehensive overview of the advantages, uses, and necessary ethical and technological issues surrounding GAI healthcare today. The potential of GAI and LLMs to transform patient outcomes and promote healthcare is highlighted in this paper through an examination of real-world case studies and future research possibilities.","","979-8-3315-0440-3","10.1109/ICOSEC61587.2024.10722592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722592","GenerativeAI;Health care;GAI Technologies;Large Language Models(LLM);GAI Models","Training;Ethics;Technological innovation;Accuracy;Biological system modeling;Decision making;Medical services;Transforms;Drug discovery;Medical diagnostic imaging","","2","","15","IEEE","24 Oct 2024","","","IEEE","IEEE Conferences"
"Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents","M. Fasha; F. A. Rub; N. Matar; B. Sowan; M. Al Khaldy; H. Barham","Business Intelligence and Data Analytics Department, University of Petra, Amman, Jordan; Business Intelligence and Data Analytics Department, University of Petra, Amman, Jordan; Business Intelligence and Data Analytics Department, University of Petra, Amman, Jordan; Business Intelligence and Data Analytics Department, University of Petra, Amman, Jordan; Business Intelligence and Data Analytics Department, University of Petra, Amman, Jordan; eBusiness and Commerce Department, University of Petra, Amman, Jordan",2024 2nd International Conference on Cyber Resilience (ICCR),"22 May 2024","2024","","","1","9","Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.","","979-8-3503-9496-2","10.1109/ICCR61006.2024.10532874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10532874","Large Language Model (LLM);OWASP Top 10;AutoGen;Retrieval Augmented Generation (RAG)","Technological innovation;Real-time systems;Security;Intelligent agents;Proposals;Machine translation;Protection","","2","","16","IEEE","22 May 2024","","","IEEE","IEEE Conferences"
"Automating Cyber Threat Intelligence and Attack Chain Generation using Cyber Security Knowledge Graphs and Large Language Models","J. F. Loevenich; E. Adler; T. Hürten; F. Spelter; D. Roncevic; R. R. F. Lopes","Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany",2025 International Conference on Military Communication and Information Systems (ICMCIS),"30 Jun 2025","2025","","","1","10","Modern cyberattacks are increasingly complex, using sophisticated tactics, techniques and procedures (TTPs) to evade detection and compromise systems. Effective cyber defence relies on real-time and accurate Cyber Threat Intelligence (CTI), which is often challenged by data quality, completeness and accessibility. While traditional methods and manually maintained knowledge bases provide valuable insights, they struggle to adapt to the rapidly evolving threat landscape. To address these challenges, we propose an architecture that uses Large Language Models (LLMs) for automated annotation of CTI reports and construction of Cybersecurity Knowledge Graphs (CSKG) to build sophisticated attack chains. Building on our previous research, we extend the capabilities of Autonomous Cyber Defence (ACD) agents to improve situational awareness and defence mechanisms in dynamic environments. Experimental results demonstrate the effectiveness of our approach in improving CTI accessibility, accuracy, and integration into defence strategies. Our experimental results highlight the potential of combining LLM, knowledge graphs and automated planning to improve proactive cyber defence and attack simulation methodologies.","2993-4974","979-8-3315-3786-9","10.1109/ICMCIS64378.2025.11047951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047951","Autonomous Cyber Defence;Knowledge Graphs;Cybersecurity;Large Language Model","Military communication;Accuracy;Annotations;Large language models;Soft sensors;Knowledge based systems;Knowledge graphs;Real-time systems;Cyber threat intelligence;Planning","","","","38","IEEE","30 Jun 2025","","","IEEE","IEEE Conferences"
"AI Needs You: How We Can Change AI's Future and Save Our Own","V. Harding",NA,AI Needs You: How We Can Change AI's Future and Save Our Own,"","2024","","","","","A humanist manifesto for the age of AIArtificial intelligence may be the most transformative technology of our time. As AI’s power grows, so does the need to figure out what—and who—this technology is really for. AI Needs You argues that it is critical for society to take the lead in answering this urgent question and ensuring that AI fulfills its promise.Verity Harding draws inspiring lessons from the histories of three twentieth-century tech revolutions—the space race, in vitro fertilization, and the internet—to empower each of us to join the conversation about AI and its possible futures. Sharing her perspective as a leading insider in technology and politics, she rejects the dominant narrative, which often likens AI’s advent to that of the atomic bomb. History points the way to an achievable future in which democratically determined values guide AI to be peaceful in its intent; to embrace limitations; to serve purpose, not profit; and to be firmly rooted in societal trust.AI Needs You gives us hope that we, the people, can imbue AI with a deep intentionality that reflects our best values, ideals, and interests, and that serves the public good. AI will permeate our lives in unforeseeable ways, but it is clear that the shape of AI’s future—and of our own—cannot be left only to those building it. It is up to us to guide this technology away from our worst fears and toward a future that we can trust and believe in.","","9780691244907","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10614683.pdf&bkn=10614682&pdfType=book","Artificial intelligence;science;technology;history;space race;satellites;biotech;life sciences;politics;history of science;internet;AI governance;AI ethics;democracy geopolitics;chatgpt;generative ai;AI Needs You: How We Can Change AI's Future and Save Our Own;verity harding;Times 100 AI;how we can safeguard AI’s future for the public good;safe AI: is AI good: is AI bad;how can AI help: AI policy;AI education: AI public good;AI fear: Artificial intelligence;transformative technology;AI’s power grows;technology;society;critical;urgent: social responsibility;better society;harmful;better education;future of AI;societal trust;Silicon Valley;Large Language Models (LLMs);ChatGPT;Bing;Google;Space Race;United Nations Outer Space Treaty 1967;Cold War;IVF (in vitro fertilization);Louise Joy Brown;Roe V. Wade;Embryo research/human embryology;Chatbot;DeepMind;Online security;OpenAI;Atomic Bomb;Oppenheimer;AI Bill of Rights;Warnock Commission;AI regulation","","","","","","","30 Jul 2024","","","Princeton University Press","Princeton University Press eBooks"
"To Mock or Not to Mock: Divergence in Mocking Practices Between LLM and Developers","H. Qin","School of Engineering and Science, Stevens Institute of Technology, Hoboken, New Jersey, USA",2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"13 Jun 2025","2025","","","239","240","Mock objects are essential for isolating unit tests and reducing dependencies in software testing. However, deciding what to mock requires careful judgment to balance isolation and maintainability. This study evaluates OpenAI's GPT-4o for automating mock decisions by comparing its outputs with developer choices. The findings reveal that while the LLM excels in identifying dependencies, their broader isolation strategy often results in Over-mocking compared to the developers. These insights suggest the potential for LLM-based tools to generate test cases with accurate and well-balanced mocking strategies.","2574-1934","979-8-3315-3683-1","10.1109/ICSE-Companion66252.2025.00077","U.S. National Science Foundation(grant numbers:CCF-2044888,CCF-1909763,CCF-2348338); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024318","software testing;large language models;mock testing;test generation","Software testing;Java;Codes;Accuracy;Software engineering","","","","18","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"LLM-Sentry: A Model-Agnostic Human-in-the-Loop Framework for Securing Large Language Models","S. Irtiza; K. A. Akbar; A. Yasmeen; L. Khan; O. Daescu; B. Thuraisingham","Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA; Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA; Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA; Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA; Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA; Department of Computer Science, University of Texas at Dallas, Richardson, Texas, USA","2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)","16 Jan 2025","2024","","","245","254","LLM-Sentry represents a novel black-box defense strategy to safeguard Large Language Models (LLMs) against jailbreaking attacks. A key advantage of our approach is its model-agnostic nature, as it does not rely on specific information about the model’s architecture or parameters, thereby enabling its application to any commercial or open-source language models. Additionally, LLM-Sentry does not require retraining when new jailbreak attacks are discovered; a simple update to the knowledge base equips LLM-Sentry to defend against new threats. The widespread adoption of LLMs is attributed to their high-quality responses and user-friendly nature. However, these models are susceptible to manipulation by malicious actors exploiting vulnerabilities to generate harmful or compromised content. Recent research has identified various jailbreaking methods that exploit vulnerabilities in LLM security measures. Given the increasing complexity of jailbreaking techniques and the ambiguous nature of LLM safeguards, it is imperative to develop unique defense strategies that can seamlessly integrate into existing security frameworks and make them robust.Our work comprehensively analyzes various commercial LLMs to assess their vulnerability to sophisticated, multilingual jailbreaking prompts. We propose a defensive approach that combines a Zero-shot language classifier with the Retrieval Augmented Generation (RAG) technique to screen and filter potentially harmful input prompts before they are processed by the language model for response generation. We adopt a human-in-the-loop approach to gather a dataset comprising harmful and safe prompts, which serves as a knowledge base for the RAG retriever module to extract relevant context. Our investigation includes successful jailbreaking attempts on prominent commercial LLMs like Gemini, Mistral 7B, and ChatGPT, wherein we successfully bypass existing security measures and elicit compromised responses. We conduct a thorough evaluation of our approach against various baseline methods to validate its resilience and superiority against such attacks empirically. Our approach achieves an attack detection accuracy of 97%, surpassing all other methods in our comparative analysis.","","979-8-3503-8674-5","10.1109/TPS-ISA62245.2024.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835584","Large Language Model;Defense;Human-In-The-Loop;Jailbreaking;Retrieval Augmented Generation;Model Agnostic;GPT;Gemini;Mistral;Zero-Shot Classification","Privacy;Large language models;Retrieval augmented generation;Knowledge based systems;Robustness;Human in the loop;Multilingual;Security;Intelligent systems;Resilience","","","","51","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Advanced Smart Contract Vulnerability Detection via LLM-Powered Multi-Agent Systems","Z. Wei; J. Sun; Y. Sun; Y. Liu; D. Wu; Z. Zhang; X. Zhang; M. Li; Y. Liu; C. Li; M. Wan; J. Dong; L. Zhu","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; College of Computing and Data Science, Nanyang Technological University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; Lingnan University, Hong Kong, China; School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; College of Computing and Data Science, Nanyang Technological University, Singapore; Beijing Academy of Blockchain and Edge Computing, Beijing, China; Beijing Academy of Blockchain and Edge Computing, Beijing, China; School of Computer Science, University of Auckland, Auckland, New Zealand; School of Computer Science, University of Auckland, Auckland, New Zealand",IEEE Transactions on Software Engineering,"","2025","PP","99","1","16","Blockchain’s inherent immutability, while transformative, creates critical security risks in smart contracts, where undetected vulnerabilities can result in irreversible financial losses. Current auditing tools and approaches often address specific vulnerability types, yet there is a need for a comprehensive solution that can detect a wide range of vulnerabilities with high accuracy. We propose LLM-SmartAudit, a novel framework that leverages Large Language Models (LLMs) to automate smart contract vulnerability detection and analysis. Using a multi-agent conversational architecture with a bufferof-thought mechanism, LLM-SmartAudit maintains a dynamic record of insights generated throughout the audit process. This enables a collaborative system of specialized agents to iteratively refine their assessments, enhancing the accuracy and depth of vulnerability detection. To evaluate its effectiveness, LLMSmartAudit was tested on three datasets: a benchmark for common vulnerabilities, a real-world project corpus, and a CVE dataset. It outperformed existing tools with 98% accuracy on common vulnerabilities and demonstrates higher accuracy in real-world scenarios. Additionally, it successfully identifies 12 out of 13 CVEs, surpassing other LLM-based methods. These results demonstrate the effectiveness of multi-agent collaboration in automated smart contract auditing, offering a scalable, adaptive, and highly efficient solution for blockchain security analysis.","1939-3520","","10.1109/TSE.2025.3597319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121619","smart contract auditing;LLMs;multi-agent;vulnerability detection","Smart contracts;Security;Codes;Oral communication;Collaboration;Blockchains;Accuracy;Multi-agent systems;Finance;Decentralized applications","","","","","IEEE","11 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs","J. Corazza; I. Gavran; G. Moreira; D. Neider","Research Center Trustworthy Data Science and Security, TU Dortmund University, Dortmund, Germany; Informal Systems, Vienna, Austria; Informal Systems, Joinville, Brazil; Research Center Trustworthy Data Science and Security, TU Dortmund University, Dortmund, Germany","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","542","552","When blockchain systems are said to be trustless, what this really means is that all the trust is put into software. Thus, there are strong incentives to ensure blockchain software is correct–vulnerabilities here cost millions and break businesses. One of the most powerful ways of establishing software correctness is by using formal methods. Approaches based on formal methods, however, induce a significant overhead in terms of time and expertise required to successfully employ them. Our work addresses this critical disadvantage by automating the creation of a formal model–a mathematical abstraction of the software system–which is often a core task when employing formal methods. We perform model synthesis in three phases: we first transpile the code into model stubs; then we “fill in the blanks” using a large language model (LLM); finally, we iteratively repair the generated model, on both syntactical and semantical level. In this way, we significantly reduce the amount of time necessary to create formal models and increase accessibility of valuable software verification methods that rely on them. The practical context of our work was reducing the time-to-value of using formal models for correctness audits of smart contracts.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10989026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989026","Code Generation;Large Language Models;Formal Methods;Model Synthesis;Smart Contracts;Model-Based Techniques;Software Auditing","Codes;Large language models;Smart contracts;Syntactics;Maintenance engineering;Software;Mathematical models;User experience;Trustless services;Blockchains","","","","37","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing","C. Xu; S. Chen; J. Wu; S. -C. Cheung; V. Terragni; H. Zhu; J. Cao","The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; The University of Auckland, New Zealand; The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","557","569","While a recent study reveals that many developer-written test cases can encode a reusable Metamorphic Relation (MR), over 70% of them directly hard-code the source input and follow-up input in the encoded relation. Such encoded MRs, which do not contain an explicit input transformation to transform the source inputs to corresponding follow-up inputs, cannot be reused with new source inputs to enhance test adequacy.In this paper, we propose MR-Adopt (Automatic Deduction Of inPut Transformation) to automatically deduce the input transformation from the hard-coded source and follow-up inputs, aiming to enable the encoded MRs to be reused with new source inputs. With typically only one pair of source and follow-up inputs available in an MR-encoded test case as the example, we leveraged LLMs to understand the intention of the test case and generate additional examples of source-followup input pairs. This helps to guide the generation of input transformations generalizable to multiple source inputs. Besides, to mitigate the issue that LLMs generate erroneous code, we refine LLM-generated transformations by removing MR-irrelevant code elements with data-flow analysis. Finally, we assess candidate transformations based on encoded output relations and select the best transformation as the result. Evaluation results show that MR-Adopt can generate input transformations applicable to all experimental source inputs for 72.00% of encoded MRs, which is 33.33% more than using vanilla GPT-3.5. By incorporating MR-Adopt-generated input transformations, encoded MR-based test cases can effectively enhance the test adequacy, increasing the line coverage and mutation score by 10.62% and 18.91%, respectively.CCS CONCEPTS• Software and its engineering → Software testing and debugging.","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764814","Software Testing;Metamorphic Testing;Metamorphic Relation;Input Transformation;Code Generation;Large Language Models","Software testing;Codes;Transforms;Debugging;Software;Software engineering","","","","75","","29 Nov 2024","","","IEEE","IEEE Conferences"
"Paradigm-Based Automatic HDL Code Generation Using LLMs","W. Sun; B. Li; G. L. Zhang; X. Yin; C. Zhuo; U. Schlichtmann",Technical University of Munich (TUM); University of Siegen; TU Darmstadt; Zhejiang University; Zhejiang University; Technical University of Munich (TUM),2025 26th International Symposium on Quality Electronic Design (ISQED),"30 May 2025","2025","","","1","8","While large language models (LLMs) have demonstrated the ability to generate hardware description language (HDL) code for digital circuits, they still face the hallucination problem, which can result in the generation of incorrect HDL code or misinterpretation of specifications. In this work, we introduce a human-expert-inspired method to mitigate the hallucination of LLMs and enhance their performance in HDL code generation. We begin by constructing specialized paradigm blocks that consist of several steps designed to divide and conquer generation tasks, mirroring the design methodology of human experts. These steps include information extraction, human-like design flows, and the integration of external tools. LLMs are then instructed to classify the type of circuit in order to match it with the appropriate paradigm block and execute the block to generate the HDL codes. Additionally, we propose a two-phase workflow for multi-round generation, aimed at effectively improving the testbench pass rate of the generated HDL codes within a limited number of generation and verification rounds. Experimental results demonstrate that our method significantly enhances the functional correctness of the generated Verilog code.","1948-3295","979-8-3315-0942-2","10.1109/ISQED65160.2025.11014391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014391","","Codes;Large language models;Design methodology;Information retrieval;Hardware;Hardware design languages;Faces;Digital circuits","","","","34","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress","Y. Han; J. Hou; Y. Sun","College of Business Administration California State University San Marcos, San Marcos, United States of America; College of Science Technology, Engineering and Mathematics, California State University San Marcos, San Marcos, United States of America; College of Business Administration California State University San Marcos, San Marcos, United States of America",2023 IEEE International Conference on Computing (ICOCO),"24 Jan 2024","2023","","","118","123","Represented by ChatGPT and GPT-4, Large Language Models (LLM) based on the Generative Pre-trained Transformer (GPT) have revolutionized the capability of Artificial Intelligence (AI) in natural language processing. In the fields of business and economics, large amounts of research and applications of GPT-based LLMs have been developed and published to automate tasks that mandate advanced human-machine interaction. Nevertheless, there has not been a systematic literature review on GPT-based LLMs in business and economics. To fill this gap, we present our in-progress literature review in this paper focusing on these two related fields. This paper analyzed 30 published research articles and delineated the trends in research, application, prompt engineering and ethical considerations. Our goal is to provide a research framework as well as an application guideline for the fast-growing audience of GPT and LLMs in business and economics. Results of the literature review indicate that many studies are: (1) engaged in creating new applications of GPT-LLM; (2) empirical-qualitative research based on evidenced-oriented data sources; (3) applying diverse methods of prompt engineering; (4) concerned about ethical challenges of GPT-based LLMs.","","979-8-3503-0268-4","10.1109/ICOCO59262.2023.10397642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10397642","ChatGPT;Generative Pre-trained Transformer (GPT);Large Language Model (LLM);systematic literature review;business;economics","Economics;Ethics;Systematics;Bibliographies;Biological system modeling;Transformers;Business","","3","","43","IEEE","24 Jan 2024","","","IEEE","IEEE Conferences"
"Augmenting Industrial Chatbots in Energy Systems using ChatGPT Generative AI","G. Gamage; S. Kahawala; N. Mills; D. De Silva; M. Manic; D. Alahakoon; A. Jennings","Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Department of Computer Science, Virginia Commonwealth University, Richmond, USA; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia; Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia",2023 IEEE 32nd International Symposium on Industrial Electronics (ISIE),"31 Aug 2023","2023","","","1","6","Chatbots, the automation of communicative labor, have been widely deployed in industrial applications and systems. Built upon the Generative Pre-trained Transformer 3 (GPT-3), ChatGPT is a Generative Artificial Intelligence (AI) primed to transform all pre-existing chatbot capabilities with human-like conversation skills. It has already disrupted many disciplines including tertiary education and academic research methods, with increasing adoption in simple to complex tasks. However, the augmentation of pre-existing industrial chatbots with generative AI capabilities has not been fully investigated and demonstrated in recent literature. In this paper, we address this gap by presenting the augmentation of a pre-existing chatbot using ChatGPT generative AI capabilities. Our contribution encompasses the ten primary human-like conversation capabilities of ChatGPT, its augmentation of the pre-existing functionalities and the adopted prompt engineering strategies. Each capability is empirically demonstrated on Cooee, a functionally deployed chatbot in the microgrid energy systems of the La Trobe Energy Analytics Platform (LEAP).","2163-5145","979-8-3503-9971-4","10.1109/ISIE51358.2023.10228101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10228101","Generative AI;ChatGPT;Chatbots;Energy AI;conversational experience;prompt engineering;Net zero carbon emissions;microgrid optimization;machine learning","Industrial electronics;Education;Oral communication;Microgrids;Transforms;Carbon dioxide;Chatbots","","16","","23","IEEE","31 Aug 2023","","","IEEE","IEEE Conferences"
"A Comprehensive Review of Generative AI Applications in 6G","H. Mahmoud; H. M. Elbadawy; T. Ismail; D. Mi","College of Computing, Birmingham City University, Birmingham, United Kingdom; Research and Development Central Administrative, Ministry of Communications and Information Technology (MCIT), Egypt; Department of Telecommunication Engineering, Taibah University, Madinah, Saudi Arabia; College of Computing, Birmingham City University, Birmingham, United Kingdom",2024 6th Novel Intelligent and Leading Emerging Sciences Conference (NILES),"22 Nov 2024","2024","","","593","596","The transition to 6G networks introduces a range of challenges due to increasing complexity, data traffic growth, and the demand for personalized services. Traditional network management techniques are no longer sufficient, as 6G networks require faster speeds, lower latency, and the capacity to support advanced applications. Open Radio Access Networks (O-RAN) offer a flexible architecture that facilitates the integration of hardware and software from diverse vendors, addressing some of these challenges. As networks continue to evolve, AI-driven solutions are becoming essential for ensuring seamless operations and optimizing performance. Generative AI (GAI) is gaining a large attention in 6G networks to solve complex issues such as resource allocation, traffic prediction, and security. Hence, this paper aims to: (a) systematically review existing studies on GAI, focusing on its use cases, opportunities, and challenges, and (b) thoroughly examine both current and potential applications of GAI, analyzing the problems they address, the proposed solutions, and identifying gaps in the existing research.","","979-8-3503-7851-1","10.1109/NILES63360.2024.10753177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10753177","6G networks;Generative AI (GAI);Open Radio Access Networks (O-RAN);network management;AI-driven solutions;advanced applications;network optimization","6G mobile communication;Wireless communication;Technological innovation;Generative AI;Refining;Open RAN;Software;Security;Resource management;Optimization","","2","","20","IEEE","22 Nov 2024","","","IEEE","IEEE Conferences"
"A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement","H. Zhang; W. Cheng; Y. Wu; W. Hu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology National Institute of Healthcare Data Science, Nanjing University, Nanjing, China",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","1319","1331","Large language models (LLMs) have achieved impressive performance on code generation. Although prior studies enhanced LLMs with prompting techniques and code refinement, they still struggle with complex programming problems due to rigid solution plans. In this paper, we draw on pair programming practices to propose PairCoder, a novel LLM-based framework for code generation. PairCoder incorporates two collaborative LLM agents, namely a Navigator agent for high-level planning and a Driver agent for specific implementation. The Navigator is responsible for proposing promising solution plans, selecting the current optimal plan, and directing the next iteration round based on execution feedback. The Driver follows the guidance of Navigator to undertake initial code generation, code testing, and refinement. This interleaved and iterative workflow involves multi-plan exploration and feedback-based refinement, which mimics the collaboration of pair programmers. We evaluate PairCoder with both open-source and closed-source LLMs on various code generation benchmarks. Extensive experimental results demonstrate the superior accuracy of PairCoder, achieving relative pass@1 improvements of 12.00%– 162.43% compared to prompting LLMs directly.CCS CONCEPTS• Software and its engineering → Automatic programming.","2643-1572","979-8-4007-1248-7","","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765058","Code generation;Large language model;Agent;Pair programming","Codes;Accuracy;Navigation;MIMICs;Collaboration;Benchmark testing;Software;Planning;Software engineering;Software development management","","","","54","","29 Nov 2024","","","IEEE","IEEE Conferences"
"An LLM-Based Agent-Oriented Approach for Automated Code Design Issue Localization","F. Batole; D. OBrien; T. N. Nguyen; R. Dyer; H. Rajan","Computer Science Department, Tulane University, New Orleans, LA, USA; Computer Science Department, Iowa State University, Ames, IA, USA; Computer Science Department, The University of Texas at Dallas, Dallas, TX, USA; Computer Science Department, University of Nebraska-Lincoln, Lincoln, NE, USA; Computer Science Department, Tulane University, New Orleans, LA, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1320","1332","Maintaining software design quality is crucial for the long-term maintainability and evolution of systems. However, design issues such as poor modularity and excessive complexity often emerge as codebases grow. Developers rely on external tools, such as program analysis techniques, to identify such issues. This work leverages Large Language Models (LLMs) to develop an automated approach for analyzing and localizing design issues. Large language models have demonstrated significant performance on coding tasks, but directly leveraging them for design issue localization is challenging. Large codebases exceed typical LLM context windows, and program analysis tool outputs in non-textual modalities (e.g., graphs or interactive visualizations) are incompatible with LLMs' natural language inputs. To address these challenges, we propose LOCALIZEAGENT, a novel multi-agent framework for effective design issue localization. LOCALIZEAGENT integrates the specialized agents that (1) analyze code to identify potential code design issues, (2) transform program analysis outputs into abstraction-aware LLM-friendly natural language summaries, (3) generate context-aware prompts tailored to specific refactoring types, and (4) leverage LLMs to locate and rank the localized issues based on their relevance. Our evaluation using diverse real-world codebases demonstrates significant improvements over the baseline approaches, with LOCALIZEAGENT achieving $138 \%, 166 \%$, and 206 % relative improvements in exact-match accuracy for localizing information hiding, complexity, and modularity issues, respectively.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00100","National Science Foundation(grant numbers:25-12857,25-12858,15-18897,15-13263,21-20448,19-34884,22-23812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029742","Large Language Models (LLMs);Multi-Agent;Static Program Analysis;Code Design Issue Localization","Location awareness;Technological innovation;Codes;Accuracy;Software design;Large language models;Natural languages;Transforms;Complexity theory;Software engineering","","","","36","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Journalists' Technological Trust and Willingness to Use Generative AI: A Perspective Based on Risk Perception Theory","Q. Wu; J. Li","School of Foreign Languages and International Business, Guangdong Songshan Polytechnic, Shaoguan, China; School of Foreign Languages and International Business, Guangdong Songshan Polytechnic, Shaoguan, China",2024 5th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI),"27 Dec 2024","2024","","","526","530","This study explores the impact of perceived risk and trust on the willingness of journalists to use generative AI (GenAl) technology. As AI evolves, its applications in journalism, such as automated news writing and personalized content recommendations, have grown significantly. However, the adoption of GenAl by journalists is influenced by various factors, with perceived risk and trust being paramount. Perceived risk encompasses the uncertainties and potential negative outcomes associated with using the technology, while trust pertains to the confidence in the technology's reliability, security, and effectiveness. This research aims to fill the gap in empirical studies on these factors by constructing a theoretical model based on risk perception and trust theories. The study employs a detailed survey, validated through confirmatory factor analysis (CFA), to measure journalists' perceived risks, trust, and their willingness to use GenAl. Findings from this research are expected to offer valuable insights for the journalism industry, providing strategies to mitigate perceived risks and enhance trust, thereby promoting broader adoption of GenAl. Additionally, the results will contribute to the theoretical understanding of technology adoption in journalism and other professional domains.","","979-8-3503-6828-4","10.1109/ICHCI63580.2024.10808120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808120","Generative AI;perceived risk;trust;willingness to use;Journalism;technology adoption","Industries;Surveys;Privacy;Uncertainty;Generative AI;Psychology;Writing;Reliability theory;Journalism;Security","","","","17","IEEE","27 Dec 2024","","","IEEE","IEEE Conferences"
"Exploring Multi-Label Data Augmentation for LLM Fine-Tuning and Inference in Requirements Engineering: A Study with Domain Expert Evaluation","H. Liu; M. B. García; N. Korkakakis","National University of Singapore, Singapore; Volvo Cars, Gothenburg, Sweden; Volvo Cars, Lund, Sweden",2024 International Conference on Machine Learning and Applications (ICMLA),"4 Mar 2025","2024","","","432","439","The application of Large Language Models (LLMs) has led to advancements in requirements engineering by providing automated solutions for various tasks. However, these models face challenges when processing complex and confidential multi-label data. This study investigates the impact of data augmentation on LLM performance during fine-tuning and inference in requirements engineering. A novel data augmentation technique is introduced specifically designed for multi-label technical data. The effectiveness of this approach is assessed through controlled experiments involving three fine-tuned LLMs, with evaluations conducted using clearly defined metrics. Three state-of-the-art LLMs were used to assess the performance of these models, and five domain experts validated the results. The findings show that: 1) correct implementation of the proposed data augmentation technique can improve LLM performance; however, incorrect implementation may have adverse effects; 2) the quality of training datasets limits the potential performance of fine-tuned LLMs; and 3) with a well-defined evaluation framework, LLMs can serve as effective judges in requirements engineering tasks, even without extensive domain-specific expertise. This research provides insights for developing more robust and efficient LLM-based frameworks in specific contexts.","1946-0759","979-8-3503-7488-9","10.1109/ICMLA61862.2024.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903507","requirements engineering;multi-label data augmentation;LLM fine-tuning;domain expert evaluation;LLM as judge","Training;Measurement;Large language models;Machine learning;Data augmentation;Data models;Requirements engineering;Faces","","","","35","IEEE","4 Mar 2025","","","IEEE","IEEE Conferences"
"A System for Automated Unit Test Generation using Large Language Models and Assessment of Generated Test Suites","A. Lops; F. Narducci; A. Ragone; M. Trizio; C. Bartolini","Polytechnic University of Bari & Wideverse s.r.l., Bari, Italy; Polytechnic University of Bari, Bari, Italy; University of Bari, Bari, Italy; Wideverse s.r.l., Bari, Italy; Wideverse s.r.l., Bari, Italy","2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","16 Apr 2025","2025","","","29","36","Unit tests are fundamental for ensuring software correctness but are costly and time-intensive to design and create. Recent advances in Large Language Models (LLMs) have shown potential for automating test generation, though existing evaluations often focus on simple scenarios and lack scalability for real-world applications. To address these limitations, we present AgoneTest, an automated system for generating and assessing complex, class-level test suites for Java projects. Leveraging the Methods2Test dataset, we developed Classes2Test, a new dataset enabling the evaluation of LLM-generated tests against human-written tests. Our key contributions include a scalable automated software system, a new dataset, and a detailed methodology for evaluating test quality.","2159-4848","979-8-3315-3467-7","10.1109/ICSTW64639.2025.10962454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962454","Software Testing;Large Language Model;Automatic Assessment","Software testing;Java;Large language models;Scalability;Conferences;Software systems;Test pattern generators","","2","","33","IEEE","16 Apr 2025","","","IEEE","IEEE Conferences"
"Great Power Brings Great Responsibility: Personalizing Conversational AI for Diverse Problem-Solvers","I. Santos; K. R. Felizardo; I. Steinmacher; M. A. Gerosa","Northern Arizona University, Flagstaff, AZ, USA; Federal Technological University of Paraná, PR, Brazil; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA",2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE),"12 Jun 2025","2025","","","93","95","Newcomers onboarding to Open Source Software (OSS) projects face many challenges. Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for answering questions and providing guidance, with many developers now turning to ChatGPT over traditional Q&A sites like Stack Overflow. Nonetheless, LLMs may carry biases in presenting information, which can be especially impactful for newcomers whose problem-solving styles may not be broadly represented. This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects. This vision paper outlines the potential of adapting AI responses to various problem-solving styles to avoid privileging a particular subgroup. We discuss the potential of AI persona-based prompt engineering as a strategy for interacting with AI. This study invites further research to refine AI-based tools to better support contributions to OSS projects.","2574-1837","979-8-3315-3871-2","10.1109/CHASE66643.2025.00019","National Council for Scientific and Technological Development(grant numbers:302339/2022-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024271","","Large language models;Chatbots;Turning;Problem-solving;Prompt engineering;Open source software;Faces;Software engineering","","","","34","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Harnessing the Power of LLMs: LLM Summarization for Human-Centric DAST Reports","A. Thool; C. Brown","Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA",2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),"16 Oct 2024","2024","","","33","39","Dynamic Application Security Testing (DAST) tools test web application security by simulating attacks on its front end and evaluating it externally like a malicious attacker. DAST tools aim to identify vulnerabilities and provide recommendations for improving security. However, the security alerts generated by these tools are lengthy and contain numerous details that may not be relevant to a software practitioner seeking a quick overview of the results. To solve this challenge, we propose using Large Language Models (LLMs) to summarize the alerts generated by DAST tools. We generated security alerts using two popular DAST tools: Burp Suite and ZAP. Then, we generated various summaries of these alerts using five different LLMs. We surveyed 48 software practitioners to understand the challenges software practitioners face when specifically dealing with DAST reports and determine the effectiveness of the LLM-generated summaries in understanding the security issue. The results bring to light various challenges software practitioners face and indicate that the LLM-generated summaries are clearer and more comprehensible in understanding the security issue and, hence, more preferred. This approach can significantly improve the security of software products by making the security alerts more accessible to different stakeholders, making the software product more robust and resilient to cyber threats.","1943-6106","979-8-3503-6613-6","10.1109/VL/HCC60511.2024.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714552","Dynamic Application Security Testing (DAST);Security Alerts;Large Language Model (LLM);Text Summarization","Visualization;Software systems;Software;Application security;Security;Time factors;Stakeholders;Faces;Testing;Software development management","","","","59","IEEE","16 Oct 2024","","","IEEE","IEEE Conferences"
"A Transformer-based Approach for Abstractive Summarization of Requirements from Obligations in Software Engineering Contracts","C. Jain; P. R. Anish; A. Singh; S. Ghaisas","Data and Decision Sciences TCS Research, Pune, India; Data and Decision Sciences TCS Research, Pune, India; Data and Decision Sciences TCS Research, Pune, India; Data and Decision Sciences TCS Research, Pune, India",2023 IEEE 31st International Requirements Engineering Conference (RE),"28 Sep 2023","2023","","","169","179","Software Engineering (SE) contracts are a valuable source of software requirements. Seed requirements derived from SE contracts can provide a starting point to the Requirements Engineering (RE) phase. To extract such a seed however, a correct interpretation of contracts text is crucial. A major challenge with contracts text interpretation is that the text is lengthy, convoluted, and it incorporates a complex Legalese. If a summary of the high-level requirements from obligations present in SE contracts is available to the requirement analysts in a language that is comprehensible to them, they can use this seed requirements knowledge to ask the right questions to the stakeholders. In this paper, we propose an approach for summarizing the requirements present in obligations in a language comprehensible to requirement analysts. We use the principles of Prompt Engineering to prompt GPT-3 to generate summaries for training Natural Language Generation (NLG) models for generating SE-specific summaries. Experiments using NLG models such as BART, GPT-2, T5, and Pegasus indicate that Pegasus generates the most accurate summaries with the highest ROUGE score as compared to other models.","2332-6441","979-8-3503-2689-5","10.1109/RE57278.2023.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260954","Software Engineering Contracts;Software Requirements;Requirements Engineering;Abstractive Summarization;Large Language Models;Prompt Engineering","Training;Natural languages;Transformers;Software;Requirements engineering;Stakeholders;Contracts","","5","","59","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"Towards a Taxonomy of Challenges in Security Control Implementation","M. R. Rahman; B. Wroblewski; M. Tamanna; I. Rahman; A. Anufryienak; L. Williams",North Carolina State University; North Carolina State University; North Carolina State University; North Carolina State University; University of North Carolina at Charlotte; North Carolina State University,2024 Annual Computer Security Applications Conference (ACSAC),"18 Mar 2025","2024","","","61","75","Cybersecurity researchers and practitioners identify and design security controls (e.g., the use of strong passwords), which refer to the countermeasures and safeguards to protect information systems’ confidentiality, integrity, and availability. The effectiveness of controls depends on their implementation. However, controls may have technical and operational issues that challenge effective implementation. Systematizing such challenges would benefit practitioners in enhancing their defense. The goal of this study is to aid security practitioners in defending against cyberattacks by constructing a taxonomy of challenges in security control implementation. We first obtain information regarding the challenges of implementing security control, cataloged in MITRE ATT&CK, using three Large Language Models: ChatGPT, Gemini, and Copilot. Then, using inductive coding and reflexive thematic analysis, we construct a taxonomy comprising 73 challenges across 8 high-level categories and map the taxonomy with the security controls. We perform a case study on attack techniques in MITRE ATT&CK to identify the challenges associated with security controls for mitigating prevalent attack techniques. We identify that 9 out of 24 prevalent attack techniques do not have any security controls. The rest of the prevalent techniques can be defended. However, the effectiveness of the controls associated with the rest of the prevalent techniques can be limited due to the following: human resources requirements, false positive issues, static detection rules, disruption, and user inconvenience. Our work highlights that security control implementation is subjective, where a diverse set of organizational, technical, human, and external factors can impact its implementation. We recommend organizations not treating security controls as a ticking-off checklist, rather resolve the impeding issues in their implementation.","2576-9103","979-8-3315-2088-5","10.1109/ACSAC63791.2024.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917356","Security controls;Taxonomy;Large Language Models;MITRE ATT&CK","Large language models;Taxonomy;Passwords;Organizations;Chatbots;Encoding;Security;Computer crime","","","","79","IEEE","18 Mar 2025","","","IEEE","IEEE Conferences"
"Chatbot Security and Privacy in the Age of Personal Assistants","W. Ye; Q. Li","Computer Science Department, College of William and Mary, Williamsburg, VA; Computer Science Department, College of William and Mary, Williamsburg, VA",2020 IEEE/ACM Symposium on Edge Computing (SEC),"22 Feb 2021","2020","","","388","393","The rise of personal assistants serves as a testament to the growing popularity of chatbots. However, as the field advances, it is important for the conversational AI community to keep in mind any potential vulnerabilities in existing architectures and how attackers could take advantantage of them. Towards this end, we present a survey of existing dialogue system vulnerabilities in security and privacy. We define chatbot security and give some background regarding the state of the art in the field. This analysis features a comprehensive description of potential attacks of each module in a typical chatbot architecture: the client module, communication module, response generation module, and database module.","","978-1-7281-5943-0","10.1109/SEC50012.2020.00057","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355740","dialogue system;chatbot;personal assistants;conversational response generation;conversational AI;chatbot security;NLP security;adversarial text generation;IoT security","Privacy;Computer architecture;Chatbot;Security;Standards;Next generation networking;Edge computing","","28","","22","IEEE","22 Feb 2021","","","IEEE","IEEE Conferences"
"Large Language Models as Configuration Validators","X. Lian; Y. Chen; R. Cheng; J. Huang; P. Thakkar; M. Zhang; T. Xu","University of Illinois Urbana-Champaign, Urbana, IL, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA; Meta Platforms, Inc., Menlo Park, CA, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1704","1716","Misconfigurations are major causes of software failures. Existing practices rely on developer-written rules or test cases to validate configuration values, which are expensive. Machine learning (ML) for configuration validation is considered a promising direction, but has been facing challenges such as the need of large-scale field data and system-specific models. Recent advances in Large Language Models (LLMs) show promise in addressing some of the long-lasting limitations of ML-based configuration validation. We present the first analysis on the feasibility and effectiveness of using LLMs for configuration validation. We empirically evaluate LLMs as configuration validators by developing a generic LLM-based configuration validation framework, named Ciri. Ciri employs effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri checks outputs from LLMs when producing results, addressing hallucination and nondeterminism of LLMs. We evaluate Ciri's validation effectiveness on eight popular LLMs using configuration data of ten widely deployed open-source systems. Our analysis (1) confirms the potential of using LLMs for configuration validation, (2) explores design space of LLM-based validators like Ciri, and (3) reveals open challenges such as ineffectiveness in detecting certain types of misconfigurations and biases towards popular configuration parameters.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00017","NSF(grant numbers:CNS-2145295); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029850","","Large language models;Software;Data models;Space exploration;Prompt engineering;Few shot learning;Software engineering","","","","104","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Assessing Large Language Models as Agile Scrum Masters: A Comparative Study of Project Planning Efficiency","A. Shahriary; M. Sedighi; N. Tajik; M. Shahinfar; A. R. Asiyabar","ECE Department, University of Tehran, Tehran, Iran; ECE Department, University of Tehran, Tehran, Iran; ECE Department, University of Tehran, Tehran, Iran; ECE Department, University of Tehran, Tehran, Iran; ECE Department, University of Tehran, Tehran, Iran",2025 11th International Conference on Web Research (ICWR),"22 May 2025","2025","","","150","156","Agile project management has become a cornerstone of modern software development, with Scrum Masters playing a critical role in ensuring project success. The advent of large language models (LLMs) has introduced new possibilities for automating project planning tasks, raising questions about their effectiveness compared to human expertise. This study aims to evaluate the feasibility of LLMs in Agile project planning by comparing their performance against human Scrum Masters. A standardized project planning template was used to ensure uniformity across all generated plans, focusing on key Scrum principles such as task breakdown, sprint organization, and risk management. The project plans produced by both LLMs and human Scrum Masters were assessed by software engineering faculty members from the University of Tehran based on predefined evaluation criteria. The results revealed that certain LLMs, including ChatGPT and Gemini Flash 1.5, outperformed human Scrum Masters in terms of operational feasibility, task clarity, and sprint organization. However, the findings also highlighted significant variability in the effectiveness of different models, emphasizing the critical role of prompt engineering in optimizing output quality. While LLMs demonstrated their potential to enhance efficiency and scalability in structured environments, they lacked the human-centric qualities necessary for dynamic project adaptation, risk identification, and team management. This study concludes that LLMs can serve as valuable augmentation tools for Agile project management, complementing human expertise rather than replacing it. Future works should focus on integrating LLMs into dynamic, real-world Agile environments and exploring hybrid approaches that leverage both AI capabilities and human intuition.","2837-8296","979-8-3315-0891-3","10.1109/ICWR65219.2025.11006172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11006172","Agile Project Management;Scrum;Large Language Model;Software Development;Project Planning","Electric breakdown;Large language models;Scalability;Standards organizations;Agile project management;Organizations;Planning;Complexity theory;Prompt engineering;Scrum (Software development)","","","","23","IEEE","22 May 2025","","","IEEE","IEEE Conferences"
"Parameter-Efficiently Fine-Tuning Large Language Models for Classroom Dialogue Analysis","D. Wang; Y. Zheng; J. Li; G. Chen","Faculty of Education, The University of Hong Kong, Hong Kong, China; School of Educational Technology, Beijing Normal University, Beijing, China; Faculty of Engineering, The University of Hong Kong, Hong Kong, China; Faculty of Education, The University of Hong Kong, Hong Kong, China",IEEE Transactions on Learning Technologies,"23 May 2025","2025","18","","542","555","Researchers have increasingly utilized artificial intelligence to automatically analyze classroom dialogue, aiming to provide timely feedback to teachers due to its educational significance. However, traditional machine learning and deep learning models face challenges, such as limited performance and lack of generalizability, across various dimensions of classroom dialogue and educational contexts. Recent efforts to utilize large language models (LLMs) for classroom dialogue analysis have predominantly relied on prompt engineering techniques, primarily due to the high costs associated with full fine-tuning, which has resulted in suboptimal performance and areas needing improvement. We, therefore, propose the application of parameter-efficient fine-tuning (PEFT) techniques to enhance the performance of LLMs in classroom dialogue analysis. Specifically, we utilized low-rank adaptation, a prominent PEFT technique, to fine-tune three state-of-the-art LLMs—Llama-3.2-3B, Gemma-2-9B, and Mistral-7B-v0.3—targeting the analysis of both teachers' and students' dialogic moves within K-12 mathematics lessons. The experimental results indicate that, in comparison to fully fine-tuning BERT and RoBERTa models and prompting LLMs, LLMs fine-tuned using the PEFT technique achieve superior performance. Moreover, the PEFT approach significantly reduced the number of trainable parameters within the LLMs by over 300 times and decreased their training duration. Although the training time for PEFT-tuned LLMs was still longer than that required for fully fine-tuning BERT and RoBERTa, these LLMs demonstrated specialization in this specific dimension and generalizability to other tasks and contexts. We believe that the use of PEFT techniques presents a promising direction for future research in classroom dialogue analysis.","1939-1382","","10.1109/TLT.2025.3567995","Hong Kong Research Grants Council, University Grants Committee(grant numbers:17605221); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992249","Artificial intelligence (AI);classroom dialogue;dialogic move;large language model (LLM);parameter-efficient fine-tuning (PEFT)","Education;Training;Machine learning;Mathematical models;Prompt engineering;Feature extraction;Biological system modeling;Annotations;Analytical models;Accuracy","","","","82","IEEE","7 May 2025","","","IEEE","IEEE Journals"
"PreciseDebias: An Automatic Prompt Engineering Approach for Generative AI to Mitigate Image Demographic Biases","C. Clemmer; J. Ding; Y. Feng","University of North Texas, Denton, TX, USA; University of North Texas, Denton, TX, USA; University of North Texas, Denton, TX, USA",2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),"9 Apr 2024","2024","","","8581","8590","Recent years have witnessed growing concerns over demographic biases in image-centric applications, including image search engines and generative systems. While the advent of generative AI offers a pathway to mitigate these biases by producing underrepresented images, existing solutions still fail to precisely generate images that reflect specified demographic distributions. In this paper, we propose PreciseDebias, a comprehensive end-to-end framework that can rectify demographic bias in image generation. By leveraging fine-tuned Large Language Models (LLMs) coupled with text-to-image generative models, PreciseDebias transforms generic text prompts to produce images in line with specified demographic distributions. The core component of PreciseDebias is our novel instruction-following LLM, meticulously designed with an emphasis on model bias assessment and balanced model training. Extensive experiments demonstrate the effectiveness of PreciseDebias in rectifying biases pertaining to both ethnicity and gender in images. Furthermore, when compared with two baselines, PreciseDebias illustrates its robustness and capability to capture demographic intricacies. The generalization of PreciseDebias is further illuminated by the diverse images it produces across multiple professions and demographic attributes. To ensure reproducibility, we will make PreciseDebias openly accessible to the broader research community by releasing all models and code.","2642-9381","979-8-3503-1892-0","10.1109/WACV57701.2024.00840","Microsoft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10483834","Applications;Social good","Training;Computer vision;Codes;Image synthesis;Computational modeling;Transforms;Search engines","","11","","33","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Supercharging Document Composition with Generative AI: A Secure, Custom Retrieval-Augmented Generation Approach","A. Chen; S. Tran","Data and AI Discovery Lab, Accenture Federal Services, Washington, D.C., United States; Data and AI Discovery Lab, Accenture Federal Services, Washington, D.C., United States",2024 11th IEEE Swiss Conference on Data Science (SDS),"18 Sep 2024","2024","","","123","130","Recent advancements in Retrieval Augmented Generation (RAG) provide opportunities for more efficient composition of long-form, domain-specific documents. However, few user-friendly applications leverage RAG for this specific use case. Additionally, existing RAG frameworks reliant on cloud-based, closed-source solutions pose challenges such as transparency and data privacy concerns. To address this gap, we introduce a full-stack application for automated document drafting, offering either proprietary (GPT-3.5-Turbo) or open-source (Falcon-RW-1B-Chat) Large Language Models (LLMs) for document writing and a secure, self-hosted search index (Elasticsearch) for knowledge retrieval. Users interact via a simple UI in which they submit a request with a desired topic and document type and receive a well-researched document that conforms to specific formatting and structural requirements. Given a user request, our document search pipeline employs open-source encoder models from SentenceTransformers for vector search and semantic re-ranking, then passes relevant knowledge sources to the LLM as context for document composition. To orchestrate and modularize our application backend, we use Haystack, an advanced machine learning pipeline builder, and FastAPI, which enables us to deploy components of our pipeline as independent services. Our experiments demonstrate that, using highly customized, self-hosted components, we can achieve document generation quality comparable to that of fully online RAG pipelines. This enables us to provision different application versions to accommodate different cost, scale, and data security preferences.","2835-3420","979-8-3503-0929-4","10.1109/SDS60720.2024.00025","Accenture; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675972","generative AI;LLMs;retrieval-augmented generation;hybrid search;semantic rerank;ML pipeline;vector databases","Productivity;Costs;Generative AI;Databases;Data security;Pipelines;Search engines","","","","27","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"LLM-Based Video Analytics Test Scenario Generation in Smart Cities","M. Yilmazer; M. Karakose","Computer Engineering, Munzur University, Tunceli, Turkiye; Computer Engineering, Firat University, Elazig, Turkiye",2025 29th International Conference on Information Technology (IT),"21 Mar 2025","2025","","","1","4","Rapid advances in the field of artificial intelligence have made significant contributions to the automation of software development and testing stages. Software created for use in various fields is tested with test scenarios created manually by software test experts or using test automation. Testing large-scale software with these methods complicates the testing phases because it requires increased human intervention and includes complex applications. In this study, an LLM-based scenario generation framework enhanced with prompt engineering is proposed for testing software to be used for video analysis in smart cities and smart campus areas. Thus, software test scenarios are created by strengthening large language models that are fast, flexible and have high learning ability using prompt engineering techniques. Test scenarios produced through LLM reinforced with prompt engineering techniques were evaluated with rarity and reality metrics and it was determined that more robust scenarios were produced compared to randomly generated test scenarios in the relevant field.","2836-3744","979-8-3315-1764-9","10.1109/IT64745.2025.10930297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930297","prompt engineering;large language model;software testing;generative artificial intelligence;smart cities","Software testing;Measurement;Automation;Smart cities;Large language models;Visual analytics;Software;Prompt engineering;Scenario generation;Software development management","","","","23","IEEE","21 Mar 2025","","","IEEE","IEEE Conferences"
"Generative AI SSH Honeypot With Reinforcement Learning","P. Prasad; N. Girish; S. V; A. Vh; P. K. S","Department of CSE, PES University, Bengaluru, India; Department of CSE, PES University, Bengaluru, India; Department of CSE, PES University, Bengaluru, India; Department of CSE, PES University, Bengaluru, India; Department of CSE, PES University, Bengaluru, India",2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT),"23 Apr 2025","2025","","","770","775","In today's rapidly evolving cyber landscape, traditional honeypots face significant limitations in their ability to adapt to sophisticated attack patterns and maintain convincing interactions with attackers. We propose Generative AI SSH Honeypot (GASH): an innovative approach to this problem combining Deep Reinforcement Learning (DRL) with Large Language Models (LLMs) to create a dynamic, engaging honeypot system. GASH employs a Deep Q-Network (DQN) architecture for strategic decision-making and leverages OpenAI’s GPT-4o for generating contextually appropriate responses while maintaining robust security measures. Our experimental results demonstrate improvements in attacker engagement duration compared to traditional honeypot systems like Kippo and Cowrie.","2473-5655","979-8-3315-3193-5","10.1109/CSNT64827.2025.10968591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10968591","honeypot;reinforcement learning;large language models;cybersecurity;SSH;AI","Generative AI;Large language models;Scalability;Decision making;Deep reinforcement learning;Robustness;Natural language processing;Computer security;Next generation networking;Faces","","1","","27","IEEE","23 Apr 2025","","","IEEE","IEEE Conferences"
"From Prompts to Motors: Man-in-the-Middle Attacks on LLM-Enabled Vacuum Robots","A. Shaikh; A. Varol; J. Virkki","Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland",IEEE Access,"8 Aug 2025","2025","13","","137505","137513","The integration of large language models (LLMs) into robotic platforms is transforming human–robot interaction by enabling more natural communication and adaptive task execution. However, this advancement also introduces new security vulnerabilities, particularly in networked environments. In this study, we present a systematic analysis of man-in-the-middle (MITM) attacks targeting an LLM-enabled vacuum robot. Our research follows a three-phase development process: 1) command-line simulation of LLM–robot interactions, 2) tabletop setup, and 3) implementation of a physical robot using a commercial vacuum platform enhanced with a Raspberry Pi–hosted ChatGPT application programming interface (API) and you only look once (YOLO, v8) object detection. We define a gray-box threat model in which an attacker can intercept, inject, and manipulate JavaScript object notation (JSON)-formatted messages exchanged between the robot and the LLM. We evaluate four attack scenarios, two based on prompt injection and two on output manipulation, across three LLM configurations (ChatGPT-4, ChatGPT-4o mini, and ChatGPT-3.5 Turbo). While prior work on LLM security assumes secure communication channels and overlooks network-level threats, our experimental results demonstrate that a remote attacker can bypass safety protocols, override motor commands, and deliver deceptive feedback to users, ultimately leading to unsafe robot behavior. These findings reveal a critical and underexplored attack surface in LLM-integrated robotic systems and highlight the urgent need for secure-by-design communication architectures.","2169-3536","","10.1109/ACCESS.2025.3595424","Jane and Aatos Erkko Foundation (EVIL-AI Project); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108294","ChatGPT API;large language models (LLMs);household robotics;man-in-the-middle (MITM) attack;prompt injection;robotics security;you only look once (YOLO) object detection","Robots;Collision avoidance;Chatbots;Vacuum systems;Security;Dogs;Cameras;Wireless fidelity;Protocols;Hardware","","","","38","CCBY","4 Aug 2025","","","IEEE","IEEE Journals"
"Who is Smarter? An Empirical Study of AI-Based Smart Contract Creation","R. Karanjai; E. Li; L. Xu; W. Shi","University Of Houston, TX, USA; University Of Houston, TX, USA; Kent State University, OH, USA; University Of Houston, TX, USA",2023 5th Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS),"17 Nov 2023","2023","","","1","8","The introduction of large language models (LLMs) like ChatGPT and Google Palm2 for smart contract generation seems to be the first well-established instance of an AI pair programmer. LLMs have access to a large number of open-source smart contracts, enabling them to utilize more extensive code in Solidity than other code generation tools. Although the initial and informal assessments of LLMs for smart contract generation are promising, a systematic evaluation is needed to explore the limits and benefits of these models. The main objective of this study is to assess the quality of generated code provided by LLMs for smart contracts. We also aim to evaluate the impact of the quality and variety of input parameters fed to LLMs. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our study finds crucial evidence of security bugs getting introduced in the generated smart contracts as well as the overall quality and correctness of the code getting impacted. However, we also identified the areas where it can be improved. The paper also proposes several potential research directions to improve the process, quality and safety of generated smart contract codes.","2835-3021","979-8-3503-1782-4","10.1109/BRAINS59668.2023.10316829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316829","GPT;smart contract;code generation;large language models;AI","Codes;Systematics;Smart contracts;Computer bugs;Pipelines;Chatbots;Brain modeling","","7","","44","IEEE","17 Nov 2023","","","IEEE","IEEE Conferences"
"SE Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering","Z. Zhao","School of Computing, Queen’s University, Kingston, Canada",2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge),"2 Jul 2025","2025","","","78","81","Foundation models (FMs), particularly large language models (LLMs), have shown significant promise in various software engineering (SE) tasks, including code generation, debugging, and requirement refinement. Despite these advances, existing evaluation frameworks are insufficient for assessing model performance in iterative, context-rich workflows characteristic of SE activities. To address this limitation, we introduce SE Arena, an interactive platform designed to evaluate SE-focused chatbots. SE Arena provides a transparent, open-source leaderboard, supports multi-round conversational workflows, and enables end-to-end model comparisons. Moreover, SE Arena incorporates a new feature called RepoChat, which automatically injects repository-related context (e.g., issues, commits, pull requests) into the conversation, further aligning evaluations with real-world development processes. This paper outlines the design and capabilities of SE Arena, emphasizing its potential to advance the evaluation and practical application of FMs in software engineering.","","979-8-3315-0211-9","10.1109/Forge66646.2025.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052782","Foundation Model;Software Engineering;Chatbot Arena","Frequency modulation;Codes;Foundation models;Large language models;Oral communication;Debugging;Chatbots;Iterative methods;Software engineering;Context modeling","","","","18","IEEE","2 Jul 2025","","","IEEE","IEEE Conferences"
"Build Code Needs Maintenance Too: A Study on Refactoring and Technical Debt in Build Systems","A. Ghammam; D. E. Rzig; M. Almukhtar; R. Khalsi; F. Hassan; M. Kessentini","Oakland University Rochester Hills, USA; University of Michigan- Dearborn, Dearborn, USA; University of Michigan- Flint, Flint, USA; University of Michigan- Flint, Flint, USA; University of Michigan- Dearborn, Dearborn, USA; Grand Valley State University Grand Valley, USA",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","616","628","In modern software engineering, build systems play the crucial role of facilitating the conversion of source code into software artifacts. Recent research has explored high-level causes of build failures, but has largely overlooked the structural properties of build files. Akin to source code, build systems face technical debt challenges that hinder maintenance and optimization. While refactoring is often seen as a key tool for addressing technical debt in source code, there is a significant research gap regarding the specific refactoring changes developers apply to build code and whether these refactorings effectively address technical debt.In this paper, we address this gap by examining refactorings applied to build scripts in open-source projects, covering the widely used build systems of Gradle, Ant, and Maven. Additionally, we investigate whether these refactorings are used to tackle technical debts in build systems. Our analysis was conducted on 725 examined build-file-related commits. We identified 24 build-related refactorings, which we divided into 6 main categories. These refactorings are organized into the first empirically derived taxonomy of build system refactorings. Furthermore, we investigate how developers employ these refactoring types to address technical debts via a manual commitanalysis and a developer survey. In this context, we identified 5 technical debts addressed by these refactorings and discussed their correlation with the different refactorings. Finally, we introduce BuildRefMiner, an LLM-powered tool leveraging GPT40 to automate the detection of refactorings within build systems. We evaluated its performance and found that it achieves an F1 score of 0.76 across all build systems.This study will serve as a foundational building block for guiding future research and practice in the maintenance and optimization of build systems. BuildRefMiner and the replication package for this study are available at [1]","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025590","build systems;refactoring;technical debt;llms","Surveys;Codes;Source coding;Taxonomy;Manuals;Software;Maintenance;Optimization;Faces;Software engineering","","","","73","IEEE","13 Jun 2025","","","IEEE","IEEE Conferences"
"Enhancing Phishing Detection with AI: A Novel Dataset and Comprehensive Analysis Using Machine Learning and Large Language Models","R. Chataut; Y. Usman; C. M. A. Rahman; S. Gyawali; P. K. Gyawali","Department of Computer Science, Texas Christian University, Fort Worth, TX, USA; School of Computing and Engineering, Quinnipiac University, Hamden, CT, USA; LANE Department of Computer Science, West Virginia University, Morgantown, WV, USA; Department of Technology Systems, East Carolina University, Greenville, NC, USA; Department of Technology Systems, East Carolina University, Greenville, NC, USA","2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","20 Nov 2024","2024","","","0226","0232","Phishing emails are a significant threat to organizations, with over $90 \%$ of cyber attacks starting from a malicious email. Despite built-in security measures, relying solely on these defenses can leave organizations vulnerable to cybercriminals who exploit human nature and the lack of tight security. Phishing emails, designed to deceive recipients into disclosing personal and financial information, represent a significant cybersecurity challenge. This paper introduces a comprehensive dataset curated explicitly for detecting phishing emails, featuring a collection of authentic and phishing emails. The dataset includes a broad spectrum of phishing techniques, such as sophisticated social engineering tactics, impersonation of reputable entities, and using urgent or threatening language to manipulate recipients. Phishing emails were collected to cover various scenarios, including financial fraud, account verification, and malware dissemination attempts. Our analysis involves a range of classical machine learning models alongside exploratory analysis with LLMs. The performance of these models was rigorously evaluated to furnish a comparative analysis of their detection capabilities. The dataset, one of the largest of its kind, offers a significant resource for researchers and cybersecurity professionals aiming to advance phishing detection methods. The dataset used in this research is publicly available, enabling further exploration and replication of the findings by the research community [1].","","979-8-3315-4090-6","10.1109/UEMCON62879.2024.10754710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754710","Cybersecurity;Phishing dataset;Artificial Intelligence;LLMs;Machine Learning","Analytical models;Phishing;Large language models;Finance;Machine learning;Organizations;Mobile communication;Malware;Electronic mail;Fraud","","1","","20","IEEE","20 Nov 2024","","","IEEE","IEEE Conferences"
"LogGenius: An Unsupervised Log Parsing Framework with Zero-shot Prompt Engineering","X. Yu; S. Nong; D. He; W. Zheng; T. Ma; N. Liu; J. Li; G. Xie","CNIC, CAS; Harbin Institute of Technology, Shenzhen; Sangfor; Harbin Institute of Technology, Shenzhen; Tsinghua University; School of Software, Shandong University; CNIC, CAS; CNIC, CAS",2024 IEEE International Conference on Web Services (ICWS),"15 Oct 2024","2024","","","1321","1328","Efficient and accurate parsing of unstructured logs is crucial for anomaly detection, root cause localization, and log compression. Although many existing works have made good progress relying on Large Language Models (LLMs) and prompt engineering techniques, most of them require a certain degree of labeling or few-shot prompts, which limits their applicability in large-scale real-time heterogeneous log environments. To tackle this issue, we develop LogGenius, a novel unsupervised log parsing framework. It initially enriches the diversity of the parsed logs by leveraging generative LLMs with zero-shot prompts. It then employs an unsupervised parsing model on the augmented log data to accomplish log parsing. In order to alleviate the impact of potential hallucination issues caused by generative LLMs, we conduct a meticulous analysis and summarize the biases inherent in LLMs when directly applying them to generate diversified logs. Building upon these insights, we propose an effective log diversity augmentation algorithm to mitigate the aforementioned concerns.We thoroughly evaluate LogGenius based on various open-source system runtime log datasets and a new alarm log dataset from a commercial cloud production environment. The experimental results demonstrate that LogGenius can improve the parsing accuracy by up to about 30%, and the parsing accuracy in unseen logs by up to about 100%, compared to the state-of-the-art unsupervised-based methods.","2836-3868","979-8-3503-6855-0","10.1109/ICWS62655.2024.00159","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707484","Log parsing;large language model;zero-shot prompt engineering;log augmentation","Location awareness;Analytical models;Accuracy;Runtime;Web services;Large language models;Production;Real-time systems;Prompt engineering;Optimization","","1","","49","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"Program Interoperable Large Language Model Software Testing Scheme: a Case Study on JavaScript Engine Fuzzing","D. Cao; Y. Hong; Q. Pan; J. Wu","Graduate School of Information, Production and System, Waseda University, Fukuoka, Japan; Graduate School of Information, Production and System, Waseda University, Fukuoka, Japan; Graduate School of Information, Production and System, Waseda University, Fukuoka, Japan; Graduate School of Information, Production and System, Waseda University, Fukuoka, Japan",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","17","Large language models (LLMs) have cultivated impressive semantics capabilities and expert knowledge from their vast pre-training corpora, especially showing prospects in automated software testing. However, LLMs are designed for human interaction, which poses the following challenges when interacting with programs for testing: 1) LLMs cannot communicate directly with programs, and there is no existing paradigm to establish interaction between them. 2) Existing evaluation methods are unable to assess the quality of LLMgenerated tests during software testing. 3) Current LLM-guided testing generation cannot be optimized in real time, resulting in low testing efficiency. To address these challenges, we present PILLM, a program interoperable LLM scheme. First, we designed a prompt mechanism for interactive program testing based on the source code semantics and expert knowledge from the LLM. Second, we proposed an evaluation mechanism for the PILLM's test code generation, thus obtaining test seeds that are semantically related to the corresponding source code. Third, PILLM optimizes the next generated tests based on the coverage and source code execution information obtained in the program execution. In the 24-hour running experiment, PILLM improved the coverage by 45.7% and 14.9% compared to Fuzz4all and Fuzzilli respectively. PILLM proves its effectiveness by finding four new real-world bugs in the JavaScript engine. We have released the source code of PILLM as open source on Github.","1941-0018","","10.1109/TDSC.2025.3581213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044883","LLMs;Program Interoperability;JS Engine;Code Semantic","Engines;Codes;Syntactics;Semantics;Fuzzing;Source coding;Training;Optimization;Computer bugs;Chatbots","","","","","IEEE","19 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Generative AI-Driven Distributed Cybersecurity Frameworks for AI-Integrated Global Big Data Systems","R. Vadisetty; A. Polamarasetti","Electrical Engineering, Wayne State University, Detroit, MI, USA; Computer Science, Andhra University, Visakhapatnam, AP, India",2024 International Conference on Emerging Technologies and Innovation for Sustainability (EmergIN),"21 Apr 2025","2024","","","595","600","The rapid proliferation of AI into extensive global data systems has brought new challenges in cybersecurity, mainly because such environments have grown inherently complex, large, and distributed. Existing cybersecurity solutions cannot keep pace with emerging threats; therefore, novel approaches are called for. This paper proposes a generative AI-driven distributed cybersecurity framework for enhancing threat detection and response in the context of AI-integrated extensive data systems. These generative models, such as GANs and VAEs, have been considered to advance the framework in simulating cyber-attacks, detecting anomalies, and generating adaptive countermeasures. Based on a decentralized design, the proposed architecture ensures real-time threat monitoring and mitigation over distributed nodes. A few key results are highlighted in the paper, showing the effectiveness of the proposed framework toward improving detection accuracy, reducing false positives, and enhancing resilience against complex attacks. A comparative analysis against existing approaches shows significant improvement in the scalability and adaptability of the efficacy. This study finally represents a new frontier in which generative AI techniques meet the principles of distributed cybersecurity to open a pathway toward more proactive and robust defense mechanisms within large-scale, AI-driven environments.","","979-8-3503-9126-8","10.1109/EmergIN63207.2024.10961616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10961616","Generative AI;Distributed Cybersecurity;Anomaly Detection;Threat Simulation;AI-integrated systems;Big Data Security;GANs;VAEs;Machine Learning;Decentralized Architecture;Proactive Defense;Scalability;Adaptive Defense;Threat Intelligence;Real-Time Monitoring;Deep Learning;Data Integrity;Cybersecurity Framework;Federated Learning;Blockchain Security","Technological innovation;Generative AI;Scalability;Big Data;Real-time systems;Data systems;Threat assessment;Computer security;Sustainable development;Resilience","","","","24","IEEE","21 Apr 2025","","","IEEE","IEEE Conferences"
