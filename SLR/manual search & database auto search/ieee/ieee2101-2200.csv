"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Smart grid critical information infrasructure protection through multi-agency","S. Menete; A. Mavee; E. M. Ehlers; W. S. Leung","Academy of Computer Science and Software Engineering, University of Johannesburg, Johannesburg, South Africa; Academy of Computer Science and Software Engineering, University of Johannesburg, Johannesburg, South Africa; Academy of Computer Science and Software Engineering, University of Johannesburg, Johannesburg, South Africa; Academy of Computer Science and Software Engineering, University of Johannesburg, Johannesburg, South Africa",2017 Computing Conference,"11 Jan 2018","2017","","","461","468","Information systems are increasingly being used to help manage critical information infrastructures as they evolve in complexity. The Smart grid is such an example that highly depends on a networked critical information infrastructure that is able to continue to operate resiliently despite coming under attack from security events. The research paper proposes the development of a multi-agent based security model aimed at maintaining the operational stability of the different nodes found in a Smart grid network. The approach leverages the nature of software agents in order to closely monitor the security states of each main network node. A prototype of the model was implemented and deployed in a Smart grid simulation environment, demonstrating the effectiveness of using multi-agents in an active monitoring role to protect critical information infrastructure.","","978-1-5090-5443-5","10.1109/SAI.2017.8252138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252138","smart grid;multi-agent systems;critical information infrastructure;agent-based simulation","Smart grids;Security;Power generation;Monitoring;Information systems;Power system stability;Software agents","","1","","17","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"Chinese Generation and Security Index Evaluation Based on Large Language Model","Y. Zhang; Y. Gao; W. Li; Z. Su; L. Yang","School of Numerical Industry, Inner Mongolia University of Science and Technology, Baotou, China; School of Numerical Industry, Inner Mongolia University of Science and Technology, Baotou, China; School of Numerical Industry, Inner Mongolia University of Science and Technology, Baotou, China; School of Numerical Industry, Inner Mongolia University of Science and Technology, Baotou, China; School of Numerical Industry, Inner Mongolia University of Science and Technology, Baotou, China",2024 International Conference on Asian Language Processing (IALP),"10 Sep 2024","2024","","","151","161","This study investigates the performance and security indicators of mainstream large language models in Chinese generation tasks. It explores potential security risks associated with these models and offers suggestions for improvement. The study utilizes publicly available datasets to assess Chinese language generation tasks, develops datasets and multidimensional security rating standards for security task evaluations, compares the performance of three models across 5 Chinese tasks and 6 security tasks, and conducts Pearson correlation analysis using GPT-4 and questionnaire surveys. Furthermore, the study implements automatic scoring based on GPT-3.5-Turbe. The experimental findings indicate that the models excel in Chinese language generation tasks. ERNIE Bot outperforms in the evaluation of ideology and ethics, ChatGPT excels in rumor and falsehood and privacy security assessments, and Claude performs well in assessing factual fallacy and social prejudice. The fine-tuned model demonstrates high accuracy in security tasks, yet all models exhibit security vulnerabilities. Integration into the prompt project proves to be effective in mitigating security risks. It is recommended that both domestic and foreign models adhere to the legal frameworks of each country, reduce AI hallucinations, continuously expand corpora, and update iterations accordingly.","2159-1970","979-8-3315-4085-2","10.1109/IALP63756.2024.10661189","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10661189","Safety Assessment;Chinese Generation;AI Hallucination;Automatic Scoring;Large Language Model","Surveys;Privacy;Ethics;Law;Large language models;Chatbots;Safety","","2","","36","IEEE","10 Sep 2024","","","IEEE","IEEE Conferences"
"Character-level Adversarial Attacks Evaluation for AraBERT’s","S. Nakhleh; M. Qasaimeh; A. Qasaimeh","Faculty of Computer and Information Technology, Jordan University of Science and Technology; Faculty of Computer and Information Technology, Jordan University of Science and Technology; King Talal School of Business Technology, Princess Sumaya University for Technology",2024 15th International Conference on Information and Communication Systems (ICICS),"22 Aug 2024","2024","","","1","6","Research has demonstrated the continuous growth of Large Language Models (LLMs) to adversarial attacks, which involve the crafted input samples that can deceive even well-performing models. Minor perturbations to the inputs can lead these models to make incorrect predictions. This vulnerability has been identified in various domains, including computer vision, speech recognition, and natural language processing (NLP). This study investigates the robustness of AraBERT LLMs against char-level Black-Box attacks induced by spelling errors. Employing the Chain-of-Thought prompting technique, we generate adversarial samples to assess the resilience of a fine-tuned AraBERT model and AraBERT v2.0 LLM. Results indicate greater robustness for the fine-tuned model, with a 12% accuracy decrease under the replacement attack. Moreover, longer adversarial samples exhibit increased resilience, with only a 2% accuracy decrease observed in such instances. Conversely, AraBERT v2.0 LLM displays the lowest robustness, experiencing a significant 46% accuracy decrease when subjected to the replacement attack.","2573-3346","979-8-3315-4076-0","10.1109/ICICS63486.2024.10638315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638315","Adversarial attack;Black-Box attack;AraBERT;CoT prompt;Arabic LLM security","Accuracy;Computational modeling;Perturbation methods;Large language models;Speech recognition;Predictive models;Robustness","","2","","20","IEEE","22 Aug 2024","","","IEEE","IEEE Conferences"
"Integrating IoT, Blockchain, and Vision Transformers for Enhanced Security and Efficiency in Smart Home and Healthcare Systems","S. Jan; T. A. Syed; S. S. Alqahtany; S. Iqbal; I. Khan; S. Musa","Faculty of Computer Studies, Arab Open University, A'Ali, Kingdom of Bahrain; Faculty of Computer and Information System, Islamic University Madinah, Madinah, Saudi Arabia; Faculty of Computer and Information System, Islamic University Madinah, Madinah, Saudi Arabia; Department of Information Technology, Alburaimi University College, Alburaimi, Oman; Department of Information Technology, Alburaimi University College, Alburaimi, Oman; Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",2025 4th International Conference on Computing and Information Technology (ICCIT),"21 May 2025","2025","","","145","159","Internet of Things (IoT) and cloud computing have revolutionized various realms including healthcare, education, industries and businesses. Wearable health monitors, smart medical equipment continuously collect patients data that are sent to cloud computing that possess powerful analytical tools facilitating individuals and healthcare units in terms of personalized treatment, proactive real-time health management, remote patient monitoring. For an efficient processing, edge computing satiated in terms of analysis however this decentralized nature, edge computing is significantly targeted and exposed to security threats and cyber attacks due to inhibition of vulnerabilities and breaches in the IoT devices. This research study focuses on enhancing strengths of edge computing to insure the reliability and integrity of data by utilizing the Blockchain infrastructure. This research also utilizes the transformer models to identify the real and fake data that fosters trust in edge computing technologies.","","979-8-3503-5383-9","10.1109/ICCIT63348.2025.10989395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989395","Edge computing;IoT;Security;Blockchain;Transformers Model;Attention Mechanism","Computer vision;Computational modeling;Data security;Medical services;Smart homes;Transformers;Threat assessment;Blockchains;Internet of Things;Edge computing","","","","66","IEEE","21 May 2025","","","IEEE","IEEE Conferences"
"Supervisor Alignment Framework: Enhancing LLM Alignment with Query-Ignoring Strategy and Multi-Agent Interaction","Z. Bao; Y. Ji; W. Wu; X. Chen; L. He","School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Mental Health and Psychological Crisis Intervention, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","The increasing focus on value alignment in Large Language Models (LLMs) underscores the need to ensure alignment with human morals and avoid biased or harmful outputs. However, LLMs aligned using existing methods are still easily affected by adversarial prompt attacks. Inspired by psychology, this paper introduces a Supervisor Alignment framework, which innovatively incorporates a query-ignoring strategy. This strategy ensures that the supervisor does not receive user queries, preventing it from being influenced by potential adversarial prompts. Meanwhile, the study compares the efficacy of a single supervisor versus a team of supervisors in value alignment tasks. While our designed single-agent supervisor approach utilizes a standalone agent or integrates with Retrieval-Augmented Generation (RAG) techniques, the team approach we proposed emphasizes multi-agent collaboration through voting, cooperation, and debate strategies. Extensive experiments demonstrate that the Supervisor Alignment framework we designed, incorporating the query-ignoring strategy and multi-agent collaboration, effectively defends against adversarial prompts and enhances its performance in value alignment tasks.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890479","National Natural Science Foundation of China; Natural Science Foundation of Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890479","Large Language Model;AI Alignment;Adversarial prompts;Security","Ethics;Large language models;Retrieval augmented generation;Collaboration;Psychology;Signal processing;Acoustics;Speech processing;Protection","","","","23","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"DMPC-Based Coordinated Voltage Control for Integrated Hybrid Energy System","Z. Zhang; D. Yue; C. -X. Dou","Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China",IEEE Transactions on Industrial Informatics,"12 Jul 2021","2021","17","10","6786","6797","High penetration and fluctuation of renewable energy resources are threatening the voltage security of the integrated hybrid energy system (IHES). This article focuses on providing a fully distributed method to ensure the voltage security and information privacy of the IHES. First, a multiagent system based control scheme is presented, in which the upper level agent is responsible for the voltage security of the whole system, and the local dynamic performance of each distributed energy resource (DER) unit is formulated in the lower level unit agent. Second, a distributed model predictive control (DMPC) based coordinated voltage control method is proposed, by which only partial information exchange is needed in the interaction. Furthermore, the diverse requirements on voltage quality of each microgrid in the IHES are considered in this article and it provides a novel paradigm in this field compared with the traditional methods. To study the stability of the resultant DMPC, the Nash equilibrium is achieved and theoretically proved to ensure the convergence of the proposed method. Finally, the validity of the proposed method is verified by virtue of the simulation and experimental test results.","1941-0050","","10.1109/TII.2020.3046633","National Key Research and Development Program Project on Key Scientific Issues of Transformative Technology(grant numbers:2018YFA0702202,2018YFA0702201); Jiangsu Province Leading Technology Foundation Research Project(grant numbers:BK20202011); National Natural Science Foundation of China(grant numbers:61833008); Jiangsu Provincial Key Research and Development Program(grant numbers:BE2020001-4); Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:KYCX20_0756); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302871","Distributed model predictive control (DMPC);integrated hybrid energy system (IHES);multiagent system (MAS);Nash equilibrium;voltage security and information privacy","Voltage control;Monitoring;Microgrids;Sensitivity;Security;Reactive power;Privacy","","24","","29","IEEE","22 Dec 2020","","","IEEE","IEEE Journals"
"PGrid-Align: An Efficient Fine-tuning Method for Large-scale Language Models via Sparse Power Grid Operations Data","H. Wu; F. Mei; Z. Fang; J. Zhang; W. Zhang; S. Pan","Dispatching And Monitoring Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China; Dispatching And Monitoring Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China; Dispatching And Monitoring Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China; Dispatching And Monitoring Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China; Dispatching And Monitoring Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China; New Technology Research Center, State Grid Zhejiang Electric Power Corporation Information & Telecommunication Branch, Hangzhou, China",2025 IEEE 11th Conference on Big Data Security on Cloud (BigDataSecurity),"21 May 2025","2025","","","133","138","With the development of power grid operations, the need for advanced natural language processing (NLP) techniques to analyze and manage vast amounts of data has become increasingly critical. However, the sparsity and complexity of power grid operations data pose challenges for general large- scale language models (LLMs) to effectively perform analysis tasks. Additionally, the general LLMs, which lack of professional knowledge in the power grid operations domain, produce highly irregular and ineffective solutions. To address these challenges, this paper proposes an efficient fine-tuning method PGrid-Align, which contains two stages. In stage one, the pre-processing method based on prompt engineering is introduced to handle sparse professional data. This method uses prompts with classification identifiers to summarize and organize sparse power grid operations data, helping general LLMs understand the special data structure and complete analysis tasks. In stage two, an efficient fine-tuning method for power grid data is introduced. This method references the classification identifiers from stage one and performs knowledge-level QLoRA fine-tuning on the LLM, improving its logical alignment. To demonstrate the effectiveness of PGrid-Align, this paper designs analysis tasks using sparse power grid operations data. The experiment results show that LLMs fine-tuned with PGrid-Align can complete the analysis tasks in a standardized manner and high accuracy, reflecting its effectiveness and potential for real-world power grid applications.","","979-8-3315-9510-4","10.1109/BigDataSecurity66063.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11006774","Alignment;Large-scale Language Model;Fine- tuning;Power Grid Operations;Prompt Engineering","Training;Accuracy;Semantics;Power grids;Data models;Natural language processing;Safety;Prompt engineering;Security;Tuning","","","","23","IEEE","21 May 2025","","","IEEE","IEEE Conferences"
"Weapon Detection Using Genai and Yolo","S. S; S. S; R. R; B. G","Computer Science and Engineering St. Joseph's college of Engineering, Chennai, India; Computer Science and Engineering St. Joseph's college of Engineering, Chennai, India; Computer Science and Engineering St. Joseph's college of Engineering, Chennai, India; Computer Science and Engineering St. Joseph's college of Engineering, Chennai, India","2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","12 Mar 2025","2024","","","1","7","In order to improve real-time weapon identification, we recommend integrating the You Only Look Once (YOLO) series algorithms with Generative AI (GenAl). It uses the capabilities of GenAl to generate and improve image datasets, which are necessary for training comparable, precise models. Because of these progressive principles, YOLO can quickly and accurately identify weapons in these environments. Since the method combines the global generation features of GenAl with the regional detection efficacy in YOLO, it improves detection rates and reduces false discoveries. Also, enhancing the dependability of monitoring systems in the most susceptible areas (e.g., airports, schools, public areas), this collaboration facilitates the faster assessment and management of the threat level. The integration of both technologies would be a significant and forward-thinking step in public safety and security.","","979-8-3315-4362-4","10.1109/ICSES63760.2024.10910535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910535","Generative AI;YOLO;weapon detection;real-time surveillance;security systems;image datasets;object detection;threat management","YOLO;Training;Generative AI;Weapons;Surveillance;Real-time systems;Threat assessment;Public security;Security;Time factors","","","","19","IEEE","12 Mar 2025","","","IEEE","IEEE Conferences"
"Enhancing Iot Intrusion Detection With Transformer-Based Network Traffic Classification","S. AboulEla; R. Kashef","Electrical, Computer and Biomedical Engineering, Toronto Metropolitan University, Toronto, Canada; Electrical, Computer and Biomedical Engineering, Toronto Metropolitan University, Toronto, Canada",2025 IEEE International systems Conference (SysCon),"30 May 2025","2025","","","1","8","The fast rise of cyber threats has exposed flaws in traditional intrusion detection systems (IDS), particularly in the Internet of Things (IoT) context. Large language models (LLMs) and other deep learning techniques provide sophisticated skills for recognizing intricate attack patterns, which can enhance IDS capabilities. Using two benchmark datasets, we conducted a comparative analysis of IoT network intrusion detection using encoder-based Transformer models and two baseline deep learning models. Experiments on the NF-BoT-IoT and NF-ToN-IoT datasets showed that the evaluated transformer models (BERT-tiny, Electrasmall, and DistilBERT) performed well in binary and multi-class classification tasks. By utilizing self-attention mechanisms, these models surpass the baseline models in capturing crucial context. According to our experiments, the best binary classification accuracies were 99.38 % and 99.98 % for the NF-BoT-IoT and NF-ToN-IoT datasets, respectively. In multi-class classification, DistilBERT achieved the highest accuracy (84.35 %) on the NF-BoT-IoT dataset, whereas BERT-tiny achieved the highest accuracy ($\mathbf{7 2. 7 \%}$) on the NF-ToN-IoT dataset. For the Baseline models, multi-layer perceptron (MLP) demonstrated competitive binary classification performance with low processing costs, whereas long short term memory (LSTM) struggled with multiclass classification, highlighting Transformer models' superiority for high-dimensional, multi-class data. Our findings validate Transformer models' suitability for sophisticated intrusion detection systems, providing significant improvements in detection accuracy and overall efficiency across complicated attack scenarios in IoT networks.","2472-9647","979-8-3315-0818-0","10.1109/SysCon64521.2025.11014861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014861","Network Security;Intrusion Detection;Deep Learning;Language Models","Deep learning;Analytical models;Accuracy;Telecommunication traffic;Network security;Transformers;Pattern recognition;Internet of Things;Long short term memory;Context modeling","","1","","28","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"LLM-Powered AI Agent Systems and Their Applications in Industry","G. Liang; Q. Tong","NA; Computer Science Department, UNC Greensboro, NC",2025 IEEE World AI IoT Congress (AIIoT),"12 Aug 2025","2025","","","0463","0471","The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.","","979-8-3315-2508-8","10.1109/AIIoT65859.2025.11105299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105299","AI Agent;LLMs","Measurement;Industries;Uncertainty;Adaptive systems;Computer architecture;Security;Reliability;Intelligent agents;Next generation networking;Software development management","","","","122","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Developing Multi-Agent LLM Applications Through Continuous Human-LLM Co-Programming","H. Song; A. Goknil; X. Jiang; E. Melum; H. Joe; C. Gazzotti; V. Frascolla; A. N. Videsjorden; P. Nguyen","SINTEF Digital, Oslo, Norway; SINTEF Digital, Oslo, Norway; Oslo University Hospital, Oslo, Norway; Oslo University Hospital, Oslo, Norway; Seoul National University, Seoul, Korea; University of Modena, Modena, Italy; Intel Deutschland GmbH, Neubiberg, Germany; SINTEF Digital, Oslo, Norway; SINTEF Digital, Oslo, Norway",2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN),"16 Jun 2025","2025","","","42","47","The rapid advancement of Large Language Models (LLMs) has opened new possibilities for intelligent multi-agent systems capable of autonomously performing complex tasks. To build such systems, LLMs can be leveraged for task-solving, tool interaction, and code generation but at the same time their costs and unpredictability have to be properly managed. To do so this paper introduces COPMA, a model-based approach to enabling continuous human-LLM co-programming of multi-agent LLM applications. COPMA uses feature-block models to track application features and their implementations as agents and code blocks. Supported by co-programming patterns, de-velopers are guided in constructing, refining, and refactoring feature implementations via trial-and-errors with LLM agents, leveraging their feedback, suggestions, and code examples. The patterns guide the shift of feature implementations between agents and code to balance flexibility, predictability, and cost. Our experience in developing LLM agents for collecting and reviewing medical research papers demonstrates that human-LLM co-programming can reduce development effort to enable rapid prototyping of multi-agent LLM applications.","","979-8-3315-0219-5","10.1109/CAIN66642.2025.00013","International Research Development Program of the National Research Foundation of Korea(grant numbers:RS-2023–00268071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030030","llm;software engineering;ai agent;co-programming","Codes;Costs;Large language models;Refining;Rapid prototyping;Software engineering;Multi-agent systems","","","","41","IEEE","16 Jun 2025","","","IEEE","IEEE Conferences"
"CAT-LM Training Language Models on Aligned Code And Tests","N. Rao; K. Jain; U. Alon; C. L. Goues; V. J. Hellendoorn","Carnegie Mellon University, United States; Carnegie Mellon University, United States; Carnegie Mellon University, United States; Carnegie Mellon University, United States; Carnegie Mellon University, United States",2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","409","420","Testing is an integral but often neglected part of the software development process. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than typical code generation models, to ensure that the code context is available to the model when generating test code. We analyze its usefulness for realistic applications, showing that sampling with filtering (e.g., by compilability, coverage) allows it to efficiently produce tests that achieve coverage similar to ones written by developers while resembling their writing style. By utilizing the code context, CAT-LM generates more valid tests than even much larger language models trained with more data (CodeGen 16B and StarCoder) and substantially outperforms a recent test-specific model (TeCo) at test completion. Overall, our work highlights the importance of incorporating software-specific insights when training language models for code and paves the way to more powerful automated test generation.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298372","test generation;test completion;large language models;code-test alignment","Training;Codes;Runtime;Data models;Software;Test pattern generators;Standards","","22","","50","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"GPThreats-3: Is Automatic Malware Generation a Threat?","M. Botacin",Texas A&M University,2023 IEEE Security and Privacy Workshops (SPW),"26 Jul 2023","2023","","","238","254","Recent research advances introduced large textual models, of which GPT-3 is state-of-the-art. They enable many applications, such as generating text and code. Whereas the model's capabilities might be explored for good, they might also cause some negative impact: The model's code generation capabilities might be used by attackers to assist in malware creation, a phenomenon that must be understood. In this work, our goal is to answer the question: Can current large textual models (represented by GPT-3) already be used by attackers to generate malware? If so: How can attackers use these models? We explore multiple coding strategies, ranging from the entire mal ware description to separate descriptions of mal ware functions that can be used as building blocks. We also test the model's ability to rewrite malware code in multiple manners. Our experiments show that GPT-3 still has trouble generating entire malware samples from complete descriptions but that it can easily construct malware via building block descriptions. It also still has limitations to understand the described contexts, but once it is done it generates multiple versions of the same semantic (malware variants), whose detection rate significantly varies (from 4 to 55 Virustotal AV s).","2770-8411","979-8-3503-1236-2","10.1109/SPW59333.2023.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10188649","malware;large-language-models;antivirus;gpt-3","Privacy;Codes;Computer viruses;Conferences;Semantics;Malware;Encoding","","18","","34","IEEE","26 Jul 2023","","","IEEE","IEEE Conferences"
"Prompt Recommendations for AI Art","H. Yang; K. Wanaskar; H. Shrivastava; S. Mansahia; S. Richhariya; M. Eirinaki","Department of Computer Engineering, San Jose State University, San Jose, USA; Department of Computer Engineering, San Jose State University, San Jose, USA; Department of Computer Engineering, San Jose State University, San Jose, USA; Department of Computer Engineering, San Jose State University, San Jose, USA; Department of Computer Engineering, San Jose State University, San Jose, USA; Department of Computer Engineering, San Jose State University, San Jose, USA",2023 IEEE Sixth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),"8 Jan 2024","2023","","","62","65","One of the main areas where generative AI models thrive is image synthesis or generation. This work highlights the importance of quality prompts in generating compelling artworks and delves into four principal methodologies for generating prompt recommendations: text embeddings, ensemble models, text with image embeddings and object detection for feature extraction. Multiple traditional and neural network-based models are explored for feature vector representation. Furthermore, the study explores the incorporation of image embeddings, the user’s preferred art styles for tailored recommendations, and the inherent challenges in evaluating these systems. We also propose a novel methodology for evaluating such systems, in the absence of ratings or preference scores, using graph analysis and community detection algorithms. This work distinctly contributes to the prompt recommendation domain and complements previous works in the AI art generation landscape.","2831-7203","979-8-3503-3128-8","10.1109/AIKE59827.2023.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10381561","AI Art Generation;Prompt Recommendation System;Text Embeddings;Text-Image Embeddings;Prompt Engineering;Community detection","Measurement;Knowledge engineering;Art;Image synthesis;Object detection;Feature extraction;Complexity theory","","3","","13","IEEE","8 Jan 2024","","","IEEE","IEEE Conferences"
"A Systematic Review of AI-Enabled Frameworks in Requirements Elicitation","V. Siddeshwar; S. Alwidian; M. Makrehchi","Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada",IEEE Access,"28 Oct 2024","2024","12","","154310","154336","Employing Artificial Intelligence techniques to address challenges in requirements elicitation is gaining traction. Although nine systematic literature reviews have been published on AI-based solutions in the requirements elicitation domain, to our knowledge, these studies do not cover a broad spectrum of elicitation tasks, data sources used for training, the performance of these algorithms, nor do they pinpoint the strengths and limitations of the algorithms used. This study contributes to the field by presenting a systematic literature review that explores the use of machine learning and NLP techniques in the elicitation phase of requirements engineering. The following research questions are addressed: 1) What elicitation tasks are supported by AI and what AI algorithms were employed? 2) What data sources have been used to construct AI-based solutions? 3) What performance outcomes were achieved? 4) What are the strengths and limitations of the current AI methods? Initially, 665 papers were retrieved from six data sources, and ultimately, 122 articles were selected for the review. This literature review identifies fifteen elicitation tasks currently supported by artificial intelligence and presents twelve publicly available data sources used for training these approaches. Furthermore, the study uncovers common limitations in current studies and suggests potential research directions. Overall, this systematic literature review provides insights into future research prospects for applying AI techniques to problems in the requirements elicitation domain.","2169-3536","","10.1109/ACCESS.2024.3475293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10706210","Requirement engineering;requirement elicitation;machine learning;deep learning;natural language processing;neural networks;large language models","Artificial intelligence;Soft sensors;Software;Data models;Natural language processing;Machine learning algorithms;Bibliographies;Requirements engineering;Training;Software algorithms","","1","","191","CCBYNCND","7 Oct 2024","","","IEEE","IEEE Journals"
"Efficient Controller Simulation for Power Systems Based on Hybrid Topology-AI Simulation Framework","D. Zou; K. Hu; W. Liu; W. Gu","School of Electrical Engineering Southeast University, Nanjing, China; School of Automation Nanjing University of Science and Technology, Nanjing, China; School of Automation Nanjing University of Science and Technology, Nanjing, China; School of Electrical Engineering Southeast University, Nanjing, China",2025 IEEE 3rd International Conference on Power Science and Technology (ICPST),"30 Jul 2025","2025","","","216","221","This paper presents an efficient controller simulation method for power systems using a Hybrid Topology-AI Simulation Framework (HTASF). This framework integrates a self-developed controller simulation framework and an AI-assisted controller model code generator. Key technologies include: topological modeling and sorting of controller models, and the introduction of a timestep delay to resolve feedback loops, ensuring the stability and accuracy of the simulation process. AI-assisted code generation for controller modules improves development efficiency and code quality. Utilizing C++ std::function technology, the framework achieves dynamic binding of simulation functions, avoiding the overhead of inheritance and virtual functions, thereby enhancing simulation performance. Results from industrial applications demonstrate that this method can accurately and efficiently simulate the dynamic behavior of controllers, offering good scalability and practicality, and providing a novel solution for the development of power system controller simulations.","","979-8-3315-1182-1","10.1109/ICPST65050.2025.11089396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11089396","Power System Controller Simulation;Hybrid Topology-AI Simulation Framework;Large Language Models;Topological Modeling;Dynamic Binding","Codes;Scalability;Large language models;Power system dynamics;Process control;Power system stability;Control systems;Hybrid power systems;Stability analysis;Sorting","","","","11","IEEE","30 Jul 2025","","","IEEE","IEEE Conferences"
"Integration of Ai Tools into an Ai-Driven Software System to Make Learning Programming Easier","D. Drašković","Department of Computer Science and Information Technology, University of Belgrade, School of Electrical Engineering, Belgrade, Serbia",2025 IEEE Global Engineering Education Conference (EDUCON),"3 Jun 2025","2025","","","1","6","Today, a person can be considered fully digitally literate if they know how to use and integrate ready-made artificial intelligence (AI) tools. The use of AI tools is becoming increasingly common in students' learning processes. However, learning programming can be challenging and exhausting, especially for younger learners. In this research, a software system was developed to integrate multiple AI tools to facilitate the learning process. The system includes tools for speech and text processing, program code generation, code testing, and result verification. Through a user-friendly software interface, users can define a problem or programming task using speech. The software then converts the speech into text using the Whisper AI API, which is subsequently processed by the GPT-3.5 Turbo and Claude AI APIs to generate program code. Once the program code is generated, it undergoes a series of tests, including parallel testing on the LeetCode platform. Users then compare the obtained results and manually complete a survey evaluating both external tools. One key research requirement was for the software system to accept input data in Serbian, a language with limited resources and complex grammatical rules. This made it difficult to find a suitable AI tool for accurate speech-to-text transformation. The system was tested with speech in both English and Serbian but supports many additional languages thanks to the powerful Whisper AI API. The implemented system is modular and easily extensible with new APIs, making it applicable to other areas of education beyond programming.","2165-9567","979-8-3315-3949-8","10.1109/EDUCON62633.2025.11016313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016313","Artificial intelligence;Large language models;Multilingual AI tools;GPT-3.5 Turbo;Claude;Whisper","Codes;Accuracy;Speech coding;Writing;Software systems;Artificial intelligence;Speech processing;Programming profession;Testing;Text processing","","","","13","IEEE","3 Jun 2025","","","IEEE","IEEE Conferences"
"Towards a Personalized LLM-Based Daily Edge Memory Aid","S. Ha; D. Ko; J. -H. Lim; S. Kang; H. S. Kim","AI Lab Tutorus Labs Inc., Deajeon, Republic of Korea; AI Computing System SW Research Section, Electronics and Telecommunications Research Institute (ETRI), Deajeon, Republic of Korea; AI Lab Tutorus Labs Inc., Deajeon, Republic of Korea; AI Computing System SW Research Section, Electronics and Telecommunications Research Institute (ETRI), Deajeon, Republic of Korea; Department of Computer Science and Engineering, Chungnam National University (CNU), Deajeon, Republic of Korea",2024 15th International Conference on Information and Communication Technology Convergence (ICTC),"14 Jan 2025","2024","","","862","865","This paper introduces a personalized memory aid system that combines a high-performance cloud-based large language model (LLM) with a low-power edge device running a small language model (sLM) to enhance user productivity by processing and summarizing daily conversations in real-time. The system optimizes efficiency and user experience while ensuring privacy through localized data handling. By combining cloud and edge resources, the system provides scalable, real-time memory support without compromising data security. The research highlights the system's architecture, its role in protecting user data, and its potential to seamlessly integrate into daily life, offering a sustainable and efficient approach to personalized artificial intelligence applications.","2162-1241","979-8-3503-6463-7","10.1109/ICTC62082.2024.10827506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827506","Personalized Large Language Model;Cloud-computing;Large Language Model;Conversational AI;Artificial Intelligence","Performance evaluation;Productivity;Data privacy;Systems architecture;Oral communication;Data processing;Real-time systems;Hardware;User experience;Resource management","","","","11","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Vulnerability Detection and Monitoring Using LLM","V. Akuthota; R. Kasula; S. T. Sumona; M. Mohiuddin; M. T. Reza; M. M. Rahman","Drpinnacle, Hyderabad, India; Drpinnacle, Hyderabad, India; Department of Computer Science and Engineering, Purbachal American City, Kanchon 1460, Green University of Bangladesh; Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh; Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Purbachal American City, Kanchon 1460, Green University of Bangladesh",2023 IEEE 9th International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE),"26 Mar 2024","2023","","","309","314","Large Language Models (LLMs) have evolved as a cornerstone for intricate code evaluations in the modern realm of artificial intelligence and machine learning. The prioritizing of rigorous security requirements is a crucial requirement for the business in the dynamic and ever-changing world of software development. The current study has used the capabilities of the GPT-3.5- Turbo model to conduct a detailed assessment of various code snippets to find any vulnerabilities. The main objective of the experiment was to introduce continuous monitoring technologies to enhance software security and release control. To obtain reliable results, we used a classification report and a confusion matrix. Out of these validation methods we choose accuracy as an important metric for this validation because in this experiment we need our model to predict the vulnerabilities that are present in the 2740 test cases and we would need our model to focus more on true positives(TP). The ideal goal of this experiment was to predict any kind of vulnerability from the real-world data. Out of all test cases, we were able to have an accuracy of 0.77. This demonstrates the approach's potential efficacy in discovering vulnerabilities. Nonetheless, the study found certain parts that require improvement, emphasizing the importance of continual refinement in the model's methodology to ensure more thorough security assessments. This study lays the groundwork for future research into the use of powerful machine learning models in the assessment of software vulnerabilities. The findings not only highlight the effectiveness of the existing approach but also offer light on prospective future research directions, paving the way for the next generation of models and evaluation techniques.","2837-8245","979-8-3503-1965-1","10.1109/WIECON-ECE60392.2023.10456393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10456393","Language Model Models (LLMs);Vulnerability;ChatGPT;GPT-3.5-Turbo model;OpenAI","Measurement;Codes;Computational modeling;Machine learning;Predictive models;Software;Software reliability","","14","","10","IEEE","26 Mar 2024","","","IEEE","IEEE Conferences"
"Private Blockchain-Based Edge IoT Platform for Secure Large Language Model Services","M. J. Baucas; P. Spachos; S. Gregori","School of Engineering, University of Guelph, Guelph, ON, Canada; School of Engineering, University of Guelph, Guelph, ON, Canada; School of Engineering, University of Guelph, Guelph, ON, Canada",2025 IEEE Wireless Communications and Networking Conference (WCNC),"9 May 2025","2025","","","1","6","IoT networks have become widespread in different technological industries due to the development of 6G networks. In this paradigm shift, industries like healthcare and autonomous vehicle research have incorporated Large Language Models (LLMs) into their applications and services. This combination has improved the effectiveness of Internet of Thing (IoT)-driven applications requiring intelligent interactions between humans and machines, bridging these wireless services to real-time intractability. However, as the IoT network grows, scalability and security issues arise. We present a private blockchain-based edge IoT platform to address these concerns in IoT-based LLM services. We evaluated our design's feasibility by testing its responsiveness and analyzing its security contributions. The results show the potential of our platform to improve the scalability of the IoT network through edge computing and reinforce its security through the private blockchain.","1558-2612","979-8-3503-6836-9","10.1109/WCNC61545.2025.10978381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978381","Edge computing;Private blockchain;Smart contract automation;Local LLMs;TinyLlama;Ollama","Industries;Cloud computing;Scalability;Large language models;Smart contracts;Blockchains;Internet of Things;Security;Testing;Edge computing","","","","19","IEEE","9 May 2025","","","IEEE","IEEE Conferences"
"Design pattern for agent based production system control — A survey","A. Lüder; A. Calá; J. Zawisza; R. Rosendahl","Otto-v.-Guericke University, Universitätsplatz 2, Magdeburg, Germany; Otto-v.-Guericke University, Universitätsplatz 2, Magdeburg, Germany; Otto-v.-Guericke University, Universitätsplatz 2, Magdeburg, Germany; Otto-v.-Guericke University, Universitätsplatz 2, Magdeburg, Germany",2017 13th IEEE Conference on Automation Science and Engineering (CASE),"15 Jan 2018","2017","","","717","722","Multi-agent systems (MAS) are an implementation paradigm frequently used within control system design for flexible production systems. Over the years a larger set of MAS based control architectures have been developed with different intentions and system focus. These different architectures can now be reviewed to identify common design pattern potentially being applicable within the design of new and advanced agent-based control architectures as best practice. This identification is the main aim of this paper.","2161-8089","978-1-5090-6781-7","10.1109/COASE.2017.8256187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256187","Production system control;multi agent system;design pattern","Control systems;Dynamic scheduling;Manufacturing systems;Job shop scheduling;Computer architecture;Planning","","16","","38","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"IoT Applications in Smart Cities: A Perspective Into Social and Ethical Issues","F. Righetti; C. Vallati; G. Anastasi","Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Smart Cities & Communities National Lab., CINI, Italy",2018 IEEE International Conference on Smart Computing (SMARTCOMP),"30 Jul 2018","2018","","","387","392","The possibility of interconnecting any kind of device to the Internet is driving the adoption of the Internet of Things (IoT) paradigm also in a city environment. Many IoT applications are making the Smart City concept real, offering advanced services to citizens and city administrators. This evolution relies upon a seamless exchange of information among different systems. Exchanged data includes personal and/or critical information, thus requiring proper handling in order to avoid security and privacy issues. At the same time, recent developments in robotics are fostering the realization of autonomous agents (e.g., cars, buses, drones) that do not require human intervention. In the city of the future, many services will rely on autonomous agents. Also, autonomous agents (e.g., robots) will become more human alike, and will be able to show emotions. Therefore, they will replace humans in many city activities. In this paper, we first overview the expected evolution of IoT applications and, then, we briefly analyze the security, social, and ethical issues that are foreseen in a Smart City context.","","978-1-5386-4705-9","10.1109/SMARTCOMP.2018.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421391","Smart City;Internet of Things;Autonomous Agents;Emotional Robots","Urban areas;Sensors;Monitoring;Cameras;Air quality;Security;Internet","","19","","10","IEEE","30 Jul 2018","","","IEEE","IEEE Conferences"
"Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts","S. Y. -T. Lee; A. Bahukhandi; D. Liu; K. -L. Ma","University of California, USA; University of California, USA; University of California, USA; University of California, USA",IEEE Transactions on Visualization and Computer Graphics,"25 Nov 2024","2025","31","1","481","491","Recent advancements in Large Language Models (LLMs) and Prompt Engineering have made chatbot customization more accessible, significantly reducing barriers to tasks that previously required programming skills. However, prompt evaluation, especially at the dataset scale, remains complex due to the need to assess prompts across thousands of test instances within a dataset. Our study, based on a comprehensive literature review and pilot study, summarized five critical challenges in prompt evaluation. In response, we introduce a feature-oriented workflow for systematic prompt evaluation. In the context of text summarization, our workflow advocates evaluation with summary characteristics (feature metrics) such as complexity, formality, or naturalness, instead of using traditional quality metrics like ROUGE. This design choice enables a more user-friendly evaluation of prompts, as it guides users in sorting through the ambiguity inherent in natural language. To support this workflow, we introduce Awesum, a visual analytics system that facilitates identifying optimal prompt refinements for text summarization through interactive visualizations, featuring a novel Prompt Comparator design that employs a BubbleSet-inspired design enhanced by dimensionality reduction techniques. We evaluate the effectiveness and general applicability of the system with practitioners from various domains and found that (1) our design helps overcome the learning curve for non-technical people to conduct a systematic evaluation of summarization prompts, and (2) our feature-oriented workflow has the potential to generalize to other NLG and image-generation tasks. For future works, we advocate moving towards feature-oriented evaluation of LLM prompts and discuss unsolved challenges in terms of human-agent interaction.","1941-0506","","10.1109/TVCG.2024.3456398","UC Climate Action Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669798","Visual analytics;prompt engineering;text summarization;human-computer interaction;dimensionality reduction","Measurement;Text summarization;Prompt engineering;Complexity theory;Systematics;Natural language generation;Linguistics","Computer Graphics;Natural Language Processing;Humans;User-Computer Interface;Databases, Factual;Algorithms;Large Language Models","4","","65","IEEE","9 Sep 2024","","","IEEE","IEEE Journals"
"Crafting Effective Prompts: A Guideline for Successful Image Generation","N. W. Ahmad; S. Ruslan","Faculty of Information Sciences and Engineering, Management and Science University, Shah Alam, Selangor; Faculty of Education, University of Malaya, Wilayah Persekutuan, Kuala Lumpur",2024 14th International Conference on System Engineering and Technology (ICSET),"10 Dec 2024","2024","","","84","89","AI’s ability to convert text into high-quality visuals is revolutionizing a number of study sectors, including the creative industries. This work focuses on how prompt construction plays a crucial role in maximizing large language models’ (LLMs’) efficacy in image production. While prompt engineering encompasses many study fields, this work focuses primarily on how prompts should be designed to enhance the quality of generated images utilizing prompt anatomy as input. In this study, two student groups were compared: one group produced photos on their own without any supervision, and the other group was given tips on how to make efficient suggestions. Clarity, detail, relevance, aesthetic appeal, and inventiveness were the criteria used to assess the prompts and the final photos. According to the panel of experts evaluating the results, the group who received guided prompt creation generated photos that were both much better and more in line with the intended concept. This work emphasizes how crucial good prompt design is for AI-driven image production and shows that appropriate prompt crafting training can significantly improve output quality. These results offer a foundation for the more efficient application of AI technologies and have important ramifications for AI-assisted design, education, and the creative industries.","2470-640X","979-8-3315-0452-6","10.1109/ICSET63729.2024.10775283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10775283","Prompt Engineering;Image Generation;Prompt anatomy;Text-to-Image;AI;Comparative Study;GANs","Industries;Training;Visualization;Image synthesis;Text to image;Production;Systems engineering and theory;Prompt engineering;Anatomy;Guidelines","","2","","22","IEEE","10 Dec 2024","","","IEEE","IEEE Conferences"
"LLM Design Patterns: A Practical Guide to Building Robust and Efficient AI Systems","K. Huang",NA,LLM Design Patterns: A Practical Guide to Building Robust and Efficient AI Systems,"","2025","","","","","Explore reusable design patterns, including data-centric approaches, model development, model fine-tuning, and RAG for LLM application development and advanced prompting techniquesKey FeaturesLearn comprehensive LLM development, including data prep, training pipelines, and optimizationExplore advanced prompting techniques, such as chain-of-thought, tree-of-thought, RAG, and AI agentsImplement evaluation metrics, interpretability, and bias detection for fair, reliable modelsPrint or Kindle purchase includes a free PDF eBookBook DescriptionThis practical guide for AI professionals enables you to build on the power of design patterns to develop robust, scalable, and efficient large language models (LLMs). Written by a global AI expert and popular author driving standards and innovation in Generative AI, security, and strategy, this book covers the end-to-end lifecycle of LLM development and introduces reusable architectural and engineering solutions to common challenges in data handling, model training, evaluation, and deployment. You’ll learn to clean, augment, and annotate large-scale datasets, architect modular training pipelines, and optimize models using hyperparameter tuning, pruning, and quantization. The chapters help you explore regularization, checkpointing, fine-tuning, and advanced prompting methods, such as reason-and-act, as well as implement reflection, multi-step reasoning, and tool use for intelligent task completion. The book also highlights Retrieval-Augmented Generation (RAG), graph-based retrieval, interpretability, fairness, and RLHF, culminating in the creation of agentic LLM systems. By the end of this book, you’ll be equipped with the knowledge and tools to build next-generation LLMs that are adaptable, efficient, safe, and aligned with human values. What you will learnImplement efficient data prep techniques, including cleaning and augmentationDesign scalable training pipelines with tuning, regularization, and checkpointingOptimize LLMs via pruning, quantization, and fine-tuningEvaluate models with metrics, cross-validation, and interpretabilityUnderstand fairness and detect bias in outputsDevelop RLHF strategies to build secure, agentic AI systemsWho this book is forThis book is essential for AI engineers, architects, data scientists, and software engineers responsible for developing and deploying AI systems powered by large language models. A basic understanding of machine learning concepts and experience in Python programming is a must.","","9781836207023","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11020601.pdf&bkn=11020600&pdfType=book","","","","","","","","2 Jun 2025","","","Packt Publishing","Packt Publishing eBooks"
"Soccer-CLIP: Vision Language Model for Soccer Action Spotting","Y. Shin; S. Park; Y. Han; B. -K. Jeon; S. Lee; B. J. Kang","LG UPlus, Seoul, South Korea; LG UPlus, Seoul, South Korea; LG UPlus, Seoul, South Korea; LG UPlus, Seoul, South Korea; LG UPlus, Seoul, South Korea; LG UPlus, Seoul, South Korea",IEEE Access,"14 Mar 2025","2025","13","","44354","44365","In the rapidly advancing field of computer vision, the application of multimodal models—specifically, vision-language frameworks—has shown substantial promise for complex tasks such as video-based action spotting. This paper introduces Soccer-CLIP, a vision-language model specially designed for soccer action spotting. Soccer-CLIP incorporates an innovative domain-specific prompt engineering strategy, leveraging large language models (LLMs) to refine textual representations for precise alignment with soccer-specific actions. Our model integrates both visual and textual features to enhance recognition accuracy of critical soccer events. With the temporal augmentation techniques devised for input videos, Soccer-CLIP builds upon existing methodologies to address the inherent challenges of temporally sparse event annotations within video sequences. Evaluations on the SoccerNet Action Spotting benchmark demonstrate that Soccer-CLIP outperforms previous state-of-the-art models, exploring the effectiveness of our model’s capacity to capture domain-specific contextual nuances. This work represents a significant advancement in automated sports analysis, providing a robust and adaptable framework for broader applications in video recognition and temporal action localization tasks.","2169-3536","","10.1109/ACCESS.2025.3549293","LG UPlus and LG AI Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916659","Action spotting;multimodal model;prompt engineering;SoccerNet-v2;temporal augmentation;video augmentation;vision language model;video recognition","Sports;Videos;Accuracy;Visualization;Data models;Context modeling;Adaptation models;Prompt engineering;Deep learning;Streams","","","","53","CCBY","6 Mar 2025","","","IEEE","IEEE Journals"
"Evaluation of Strategic Decision taken by Autonomous Agent using Explainable AI","R. R. Prasad; R. R. Rejimol Robinson; C. Thomas; N. Balakrishnan","Government Engineering College Barton Hill, Thiruvananthapuram, Kerala, India; SCT College of Engineering,, Thiruvananthapuram, Kerala, India; Directorate of Technical Education, Government of Kerala, India; Indian Institute of Science, Bangalore, Karnataka, India",2021 4th International Conference on Security and Privacy (ISEA-ISAP),"26 Jan 2022","2021","","","1","8","Autonomous intrusion detection systems assess the data intelligently and take strategic decision to detect and mitigate cyber-attacks. These decisions have to be explained and evaluated for the transparency and correctness. Explainable Artificial Intelligent (XAI) methods that explore how features contribute or influence a decision taken using an algorithm can be useful for the purpose. XAI method of Testing with Concept Activation Vectors (TCAV) has been used recently to show the importance of high level concepts for a prediction class in order to deliver explanations in the way humans communicate with each other. This work explores the possibility of using TCAV to evaluate the strategic decision made by autonomous agents. A case study in the context of DoS attack is analysed to show that TCAV scores for various DoS attack classes and normal class of KDD99 data set can be used to evaluate the strategic decisions. The proposed method of analysis provides a quantifiable method to justify the current strategy or change in the strategy if required.","","978-1-6654-2017-4","10.1109/ISEA-ISAP54304.2021.9689715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689715","Autonomous agents;Explainable AI;Evaluation of decision;TCAV;Information Security","Privacy;Intrusion detection;Prediction algorithms;Autonomous agents;Artificial intelligence;Testing","","3","","20","IEEE","26 Jan 2022","","","IEEE","IEEE Conferences"
"A Business Process for Detecting Facial Movements and Emotions Using Deep Learning Techniques","Ç. Menzil; U. E. Sarıkaya; M. S. Aktas; E. Yahsi; M. Keles; M. Sungur","Computer Engineering Department, Yildiz Technical University, Istanbul, Turkey; Computer Engineering Department, Yildiz Technical University, Istanbul, Turkey; Computer Engineering Department, Yildiz Technical University, Istanbul, Turkey; Research and Development Center, Aktif Bank, Istanbul, Turkey; Research and Development Center, Aktif Bank, Istanbul, Turkey; Research and Development Center, Aktif Bank, Istanbul, Turkey","2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)","27 Feb 2024","2023","","","1","8","The importance of video meetings in today’s fast-paced and interconnected world cannot be overstated. With the rise of remote work and virtual collaboration, video meetings provide a cost-effective, efficient, and convenient way to communicate and collaborate with colleagues, clients, and partners from anywhere in the world. They have also transformed the way businesses provide customer service by offering a more personalized and engaging experience, providing real-time solutions, and improving customer support. However, the implementation of facial expression recognition (FER) technology in video meetings is still facing significant challenges. The lack of standard datasets for evaluation, and temporal variations of facial expressions are some of the major obstacles that need to be addressed to develop robust FER models. Despite these limitations, the potential applications of FER technology are vast, and it has the potential to revolutionize many aspects of our lives, including improving human-computer interaction, enhancing security and surveillance. This study investigates a research problem that aims to design and develop a novel methodology for FER in videos using transformer models to detect customer satisfaction during video meetings. With this study, we aim to contribute to the development of a software architecture that uses three different pre-trained transformer models for FER.","","979-8-3503-6969-4","10.1109/ICECCE61019.2023.10442240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10442240","Facial Expression Recognition;Deep Learning;Video Meeting;Transformer Models;CNN","Face recognition;Computational modeling;Surveillance;Streaming media;Transformers;Standards;Business","","1","","60","IEEE","27 Feb 2024","","","IEEE","IEEE Conferences"
"PBatch: Pseudonym Certificate Batch Authentication With Generative AI-Based Cache for Cooperative Intelligent Transportation Systems","S. Khan; M. Khan; M. A. Khan; F. Luo; M. Usman; A. Irshad; K. Wu; L. Wang; M. A. Khan","School of Computer and Information Engineering, Qilu Institute of Technology, Jinan, Shandong, China; School of Intelligent Manufacturing and Control Engineering, Qilu Institute of Technology, Jinan, China; Department of Electrical Engineering, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia; School of Computing and Information Technology, Great Bay University, Dongguan, China; Department of Computer Science, Edge Hill University, Ormskirk, U.K.; Punjab Higher Education Department, Faculty of Computer Science, GGC Asghar Mall Rawalpindi, Rawalpindi, Pakistan; Data Science and Analytics (DSA) and Internet of Things (IoT) Thrust, The Hong Kong University of Science and Technology (Guangzhou) (HKUST (GZ)), Guangzhou, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Department of Artificial Intelligence, College of Computer Engineering and Science, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","16","Authentication and revocation are the key mechanisms to ensure the security of the Cooperative Intelligent Transportation System (C-ITS). C-ITS relies on the Vehicular Public Key Infrastructure (VPKI) for anonymous authentication and device revocation. Several works complemented the VPKI-based authentication and revocation process. However, several security and performance issues exist in both mechanisms. This article presents PBatch: Pseudonym Certificate Batch Authentication based on Distributed Ledger Technology. PBatch addresses challenges specific to the authentication and revocation process to achieve 1000 authentications per second. PBatch relies on the concept of batching pseudonym certificates by offloading heavy validation operations such as certificate chain and revocation status validation to local edge servers. This enables vehicles to validate a batch of pseudonym certificates with a fixed number of verification operations, thus simplifying the authentication of the pseudonym certificate at the end devices. Furthermore, a caching-based message authentication mechanism is introduced to validate a relatively larger number of safety messages. We also introduced a Generative Artificial Intelligence (GAI) based cache management mechanism for safety messages caching and fetching. Finally, experiments and security analysis are conducted to investigate PBatch performance and security. The results show that PBatch is more secure, feasible, and scalable than the leading VPKI-based authentication proposals.","1558-0016","","10.1109/TITS.2025.3558366","National Key State Laboratory Open Project for Automotive Safety Technology(grant numbers:IVSTSKL-202436); Shandong Provincial Department of Science and Technology(grant numbers:ZR2024QE390); China NSFC(grant numbers:62372307,U2001207); Guangdong NSF(grant numbers:2024A1515011691); Shenzhen Science and Technology Program(grant numbers:RCYX20231211090129039); Shenzhen Science and Technology Foundation(grant numbers:JCYJ20230808105906014); Guangdong Provincial Key Lab of Integrated Communication, Sensing and Computation for Ubiquitous Internet of Things(grant numbers:2023B1212010007); Project of DEGP(grant numbers:2023KCXTD042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994352","Authentication;batching;generative artificial intelligence;vehicular public key infrastructure;cooperative intelligent transportation system","Authentication;Security;Electronic mail;Vehicle-to-everything;Protocols;Privacy;Servers;Public key;Internet of Things;Urban areas","","","","","IEEE","9 May 2025","","","IEEE","IEEE Early Access Articles"
"A Survey on ChatGPT: AI–Generated Contents, Challenges, and Solutions","Y. Wang; Y. Pan; M. Yan; Z. Su; T. H. Luan","School of Cyber Science, Engineering, Xi'an Jiaotong University, Xi'an, China; School of Cyber Science, Engineering, Xi'an Jiaotong University, Xi'an, China; School of Cyber Science, Engineering, Xi'an Jiaotong University, Xi'an, China; School of Cyber Science, Engineering, Xi'an Jiaotong University, Xi'an, China; School of Cyber Science, Engineering, Xi'an Jiaotong University, Xi'an, China",IEEE Open Journal of the Computer Society,"26 Oct 2023","2023","4","","280","302","With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.","2644-1268","","10.1109/OJCS.2023.3300321","National Natural Science Foundation of China(grant numbers:U22A2029,U20A20175); Fundamental Research Funds for the Central Universities; China Postdoctoral Science Foundation(grant numbers:2023M732820); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10221755","AIGC;generative AI;ChatGPT;security;and privacy","Artificial intelligence;Chatbots;Surveys;Security;Computational modeling;Privacy;Training","","174","","116","CCBY","16 Aug 2023","","","IEEE","IEEE Journals"
"Code and Test Generation for I4.0 State Machines with LLM-based Diagram Recognition","B. Otto; A. Aidarkhan; M. Ristin; N. Braunisch; C. Diedrich; H. W. van de Venn; M. Wollschlaeger","Institute for Automation and Communication Otto von Guericke University; Department of Computer Science, Nazarbayev University, Astana, Kazakhstan; Department of Computer Science, Nazarbayev University, Astana, Kazakhstan; Institute of Applied Computer Science, TU Dresden, Dresden, Germany; Institute for Automation and Communication Otto von Guericke University; Institute of Mechatronic Systems, Zurich University of Applied Sciences (ZHAW), Zurich, Switzerland; Institute of Applied Computer Science, TU Dresden, Dresden, Germany",2025 IEEE 21st International Conference on Factory Communication Systems (WFCS),"16 Jul 2025","2025","","","1","8","In the context of Industry 4.0, the automatic code and test generation from state diagrams embedded in specifications is a critical challenge for software correctness. In this paper we present an approach that leverages Large Language Models (LLMs) for the recognition of state diagrams to generate code and unit tests automatically. We compare the performance of LLMs with traditional computer vision models, highlighting the advantages of LLMs in terms of generalization and simplicity of setup. The results on two prominent industrial communication protocols, PROFINET and OPC UA, demonstrate the applicability of the approach, achieving significant reductions in manual effort and improving the accuracy of code and test generation.","2835-8414","979-8-3315-3005-1","10.1109/WFCS63373.2025.11077624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077624","Code generation;Large Language Model;LLM;Test case generation;Diagram recognition;Industry 4.0","Computer vision;Codes;Protocols;Large language models;Industrial communication;Manuals;Software;Production facilities;Fourth Industrial Revolution;Test pattern generators","","","","40","IEEE","16 Jul 2025","","","IEEE","IEEE Conferences"
"Enhancing LLM Performance on Hardware Design Generation Task via Reinforcement Learning","Y. Zhao; W. Fu; S. Li; Y. -X. Hu; X. Guo; Y. Jin",University of Science and Technology of China; Kansas State University; University of Science and Technology of China; University of Science and Technology of China; Kansas State University; University of Science and Technology of China,2025 IEEE International Symposium on Circuits and Systems (ISCAS),"27 Jun 2025","2025","","","1","5","Integrated circuit design is a highly complex and time-consuming process. Leveraging large language models (LLMs) for automating hardware design generation is receiving increasing attention. A prominent challenge is that the inherent structure of the text is overlooked during the training process. Existing efforts focus on supervised fine-tuning LLMs to acquire specialized knowledge in hardware design, without considering the conflict between LLMs’ linear data processing and the structural nature inherent in hardware design. In this work, we propose a novel LLM-based reinforcement learning (RL) framework that integrates Abstract Syntax Trees (ASTs) and Data Flow Graphs (DFGs). Our approach enhances the accuracy of generated hardware code by capturing the syntactic and semantic structures of hardware designs. Experimental results show that the SFT-RL model integrated with Text, AST, and DFG achieves notable improvements: a 12.57% increase on VerilogEval-Human and a 5.49% increase on VerilogEval-Machine, outperforming GPT-4; a 14.29% improvement on RTLLM, approaching GPT-4.","2158-1525","979-8-3503-5683-0","10.1109/ISCAS56072.2025.11043832","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11043832","Hardware code generation;Reinforcement learning;Large language model","Training;Codes;Accuracy;Large language models;Semantics;Reinforcement learning;Syntactics;Data processing;Hardware;Hardware design languages","","","","42","IEEE","27 Jun 2025","","","IEEE","IEEE Conferences"
"Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents","Y. Xiang; Z. Yang; J. Peng; H. Bauer; P. T. J. Kon; Y. Qiu; A. Chen",University of Michigan; University of Michigan; University of Michigan; University of Michigan; University of Michigan; University of Michigan; University of Michigan,2025 IEEE/ACM International Workshop on Cloud Intelligence & AIOps (AIOps),"12 Jun 2025","2025","","","20","25","Cloud environments are increasingly managed by Infrastructure-as-Code (IaC) platforms (e.g., Terraform), which allow developers to define their desired infrastructure as a configuration program that describes cloud resources and their dependencies. This shields developers from low-level operations for creating and maintaining resources, since they are automatically performed by IaC platforms when compiling and deploying the configuration. However, while IaC platforms are rigorously tested for initial deployments, they exhibit myriad errors for runtime updates, e.g., adding/removing resources and dependencies. IaC updates are common because cloud infrastructures are long-lived but user requirements fluctuate over time. Unfortunately, our experience shows that updates often introduce subtle yet impactful bugs. The update logic in IaC frameworks is hard to test due to the vast and evolving search space, which includes diverse infrastructure setups and a wide range of provided resources with new ones frequently added. We introduce TerraFault, an automated, efficient, LLM-guided system for discovering update bugs, and report our findings with an initial prototype. TerraFault incorporates various optimizations to navigate the large search space efficiently and employs techniques to accelerate the testing process. Our prototype has successfully identified bugs even in simple IaC updates, showing early promise in systematically identifying update bugs in today's IaC frameworks to increase their reliability.","","979-8-3315-2638-2","10.1109/AIOps66738.2025.00011","NSF(grant numbers:CNS1942219,CNS-2106751,CNS-2106388,CNS-2214272); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029328","Infrastructure-as-Code;Program update;Using LLMs for Cloud Ops;Reliability;Software testing and debugging","Software testing;Runtime;Navigation;Computer bugs;Prototypes;Life estimation;Debugging;Software reliability;Logic;Optimization","","1","","20","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"Automated IoT Fingerprinting with LLMs: Harnessing Explainable AI and Artificial Bee Colony Optimization","Y. Shrestha; K. Ansari; A. Aksoy","Department of Computer Science & Cybersecurity, University of Central Missouri, Warrensburg, MO, USA; Department of Computer Science & Cybersecurity, University of Central Missouri, Warrensburg, MO, USA; Department of Computer Science & Cybersecurity, University of Central Missouri, Warrensburg, MO, USA",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","184","190","Identifying malicious IoT devices significantly impacts the security of hosts within a network. Many automated systems have been introduced using machine learning and deep-learning techniques. However, these approaches often lack explainability, adaptability, and the ability to incorporate contextual and domain-specific knowledge seamlessly. This study investigates an automated approach for classifying IoT devices using LLMs by analyzing network packets. Another issue with current implementations utilizing traditional or LLM-based techniques is that they usually need to process vast amounts of data to be trained. A rigorous feature selection before classification can immensely increase efficiency without sacrificing accuracy. Therefore, we integrate Explainable AI (XAI) techniques, such as SHAP, and optimization algorithms, like Artificial Bee Colony (ABC), to reduce the features obtained from network packets and utilize an LLM for classification. Our method achieves substantial feature reduction-up to 75%-while maintaining high classification accuracy, up to 98.9%. With the help of SHAP and ABC, we can automatically and successfully detect the most relevant features that help distinguish IoT devices efficiently and accurately. This helps our models adapt to changes in device behavior and generalize to diverse network environments.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050828","LLM;SHAP;ABC;IoT classification;feature reduction;scalability","Training;Accuracy;Explainable AI;Scalability;TCPIP;Fingerprint recognition;Feature extraction;Internet of Things;Security;Optimization","","","","25","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"A Cooperative Hierarchical Multi-Agent System for EV Charging Scheduling in Presence of Multiple Charging Stations","C. B. Saner; A. Trivedi; D. Srinivasan","Department Electrical and Computer Engineering, National University of Singapore, Singapore; Department Electrical and Computer Engineering, National University of Singapore, Singapore; Department Electrical and Computer Engineering, National University of Singapore, Singapore",IEEE Transactions on Smart Grid,"21 Apr 2022","2022","13","3","2218","2233","The increasing penetration of plug-in electric vehicles (EVs) to the electrical grid raises concerns over secure and economic operation of the system. A coordination mechanism between system operator and EV aggregators is necessary to ensure that the system is operated within the security limits, and to reduce the charging costs while satisfying EV users’ energy needs. In this work, we present a cooperative hierarchical multi-agent system and propose an EV charging scheduling strategy in order to minimize the demand and energy charges while meeting the EV users’ energy requirements and satisfying the system security constraints. Within the designed framework, the higher-level agents calculate a set of proposed control signals by solving the designated optimization problems, and send them to the lower-level agents to facilitate an optimal scheduling in line with the aforementioned objectives. Through this hierarchically distributed approach, it is possible to effectively coordinate multiple EV charging stations without the need of direct communication or any prior information related to EV arrivals. The computational complexity of the problem is reduced by distributing the work among agents, and the privacy of sensitive data, such as system topology, load profiles, and EV parameters, is preserved. Moreover, unlike the traditional distributed solution methods that converge iteratively, the proposed approach calculates the optimal charging schedule after a single round of communication. The efficacy of the proposed methodology is demonstrated by a series of case studies on 33-bus and 118-bus distribution test feeders.","1949-3061","","10.1109/TSG.2022.3140927","National Research Foundation, Singapore through AI Singapore Programme(grant numbers:AISGRP-2018-004); EMA-PSA, Singapore(grant numbers:R-263-000-F04-592 (EMA-EP005-EPJGC-0003)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672089","Demand charges;electric vehicles;EV charging scheduling;multi-agent systems;optimization","Electric vehicle charging;Costs;Optimal scheduling;Security;Schedules;Multi-agent systems;Job shop scheduling","","98","","37","IEEE","6 Jan 2022","","","IEEE","IEEE Journals"
"A Platform for the Evaluation of Distributed Reputation Algorithms","V. Agate; A. De Paola; G. Lo Re; M. Morana","Universita degli Studi di Palermo, Palermo, Italy; Universita degli Studi di Palermo, Palermo, Italy; Universita degli Studi di Palermo, Palermo, Italy; Universita degli Studi di Palermo, Palermo, Italy",2018 IEEE/ACM 22nd International Symposium on Distributed Simulation and Real Time Applications (DS-RT),"6 Jan 2019","2018","","","1","8","In distributed environments, where unknown entities cooperate to achieve complex goals, intelligent techniques for estimating agents' truthfulness are required. Distributed Reputation Management Systems (RMSs) allow to accomplish this task without the need for a central entity that may represent a bottleneck and a single point of failure. The design of a distributed RMS is a challenging task due to a multitude of factors that could impact on its performances. In order to support the researcher in evaluating the RMS robustness against security attacks since its beginning design phase, in this work we present a distributed simulation environment that allows to model both the agent's behaviors and the logic of the RMS itself. Moreover, in order to compare at simulation time the performance of the designed distributed RMS with a baseline obtained by an ideal RMS, we introduce an omniscient process called truth-holder which owns a global knowledge all involved entities. The effectiveness of our platform was proved by a set of experiments aimed at measuring the vulnerability of a RMS to a common set of security attacks.","1550-6525","978-1-5386-5048-6","10.1109/DISTRA.2018.8601020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601020","Agent-based simulation;Multi-agent systems;Distributed Reputation Management Systems","Security;Computational modeling;Analytical models;Measurement;Task analysis;Tools;Estimation","","6","","20","IEEE","6 Jan 2019","","","IEEE","IEEE Conferences"
"Game-Theoretic Mission Planning of Drone Teams in Autonomous Detection and Recognition","V. U. Castrillo; I. Iudice; D. Pascarella; G. Pigliasco; A. Vozella","Safety & Security Department, CIRA – Italian Aerospace Research Centre, Capua, Italy; Safety & Security Department, CIRA – Italian Aerospace Research Centre, Capua, Italy; Safety & Security Department, CIRA – Italian Aerospace Research Centre, Capua, Italy; Safety & Security Department, CIRA – Italian Aerospace Research Centre, Capua, Italy; Safety & Security Department, CIRA – Italian Aerospace Research Centre, Capua, Italy",2023 IEEE International Workshop on Technologies for Defense and Security (TechDefense),"8 Jan 2024","2023","","","197","202","Cooperative autonomous systems are a priority objective for military research & development of unmanned vehicles. Drone teams are one of the most prominent applications of cooperative unmanned systems and represent an ideal solution for providing both autonomous detection and recognition within security surveillance and monitoring. Here, a drone team may be arranged as a mobile and cooperative sensor network, whose coordination mechanism shall ensure real-time reconfiguration and sensing task balancing within the team. This work proposes a dynamic and decentralized mission planner of a drone team to attain a cooperative behaviour concerning detection and recognition for security surveillance. The design of the planner exploits multi-agent task allocation and game theory, and is based on the theory of learning in games to implement a scalable and resilient system. Model-in-the-loop simulation results are reported to validate the effectiveness of the proposed approach.","","979-8-3503-1939-2","10.1109/TechDefense59795.2023.10380873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380873","drone teams;autonomous cooperative systems;multi-agent systems;game theory;learning in games","Systematics;Surveillance;Simulation;Scalability;Games;Sensors;Security","","1","","28","IEEE","8 Jan 2024","","","IEEE","IEEE Conferences"
"Net-GPT: A LLM-Empowered Man-in-the-Middle Chatbot for Unmanned Aerial Vehicle","B. Piggott; S. Patil; G. Feng; I. Odat; R. Mukherjee; B. Dharmalingam; A. Liu","Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science, University of Wisconsin, Madison, Wisconsin, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA",2023 IEEE/ACM Symposium on Edge Computing (SEC),"7 Feb 2024","2023","","","287","293","In the dynamic realm of AI, integrating Large Language Models (LLMs) with security systems reshape cybersecurity. LLMs bolster defense against cyber threats but also introduce risks, aiding adver-saries in generating malicious content, discovering vulnerabilities, and distorting perceptions. This paper presents Net-GPT, an LLM-empowered offensive chatbot that understands network protocols and launches Unmanned Aerial Vehicles (UAV)-based Man-in-the-middle (MITM) attacks against a hijack communication between UAV and Ground Control Stations (GCS). Facilitated by an edge server equipped with finely tuned LLMs, Net-GPT crafts mimicked network packets between UAV and GCS. Leveraging the adaptabil-ity of popular LLMs, Net-GPT produces context-aligned network packets. We fine-tune and assess Net-GPT's LLM-based efficacy, showing its impressive generative accuracy: 95.3% for Llama-2-13B and 94.1% for Llama-2-7B. Smaller LLMs, such as Distil-GPT-2, reach 77.9% predictive capability of Llama-2-7B but are 47x faster. Cost-efficiency tests highlight model quality's impact on accuracy while fine-tuning data quantity enhances predictability on spe-cific metrics. It holds great potential to be used in edge-computing environments with amplified computing capability.","2837-4827","979-8-4007-0123-8","10.1145/3583740.3626809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419242","Man-in-the-Middle (MITM);Large Language Model;System Security;Cyber Attack","Protocols;Computational modeling;Predictive models;Autonomous aerial vehicles;Chatbots;Computer security;Edge computing","","4","","21","","7 Feb 2024","","","IEEE","IEEE Conferences"
"LLM4WM: Adapting LLM for Wireless Multi-Tasking","X. Liu; S. Gao; B. Liu; X. Cheng; L. Yang","State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China; Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China; State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China; Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",IEEE Transactions on Machine Learning in Communications and Networking,"25 Jul 2025","2025","3","","835","847","The wireless channel is fundamental to communication, encompassing numerous tasks collectively referred to as channel-associated tasks. These tasks can leverage joint learning based on channel characteristics to share representations and enhance system design. To capitalize on this advantage, LLM4WM is proposed—a large language model (LLM) multi-task fine-tuning framework specifically tailored for channel-associated tasks. This framework utilizes a Mixture of Experts with Low-Rank Adaptation (MoE-LoRA) approach for multi-task fine-tuning, enabling the transfer of the pre-trained LLM’s general knowledge to these tasks. Given the unique characteristics of wireless channel data, preprocessing modules, adapter modules, and multi-task output layers are designed to align the channel data with the LLM’s semantic feature space. Experiments on a channel-associated multi-task dataset demonstrate that LLM4WM outperforms existing methodologies in both full-sample and few-shot evaluations, owing to its robust multi-task joint modeling and transfer learning capabilities.","2831-316X","","10.1109/TMLCN.2025.3585845","National Natural Science Foundation of China(grant numbers:62125101,62341101,62401488); New Cornerstone Science Foundation through the Xplorer Prize, Guangzhou-[The Hong Kong University of Science and Technology (HKUST)] (GZ) Joint Funding Scheme(grant numbers:2025A03J3878); Guangdong Provincial Key Laboratory of Integrated Communication, Sensing and Computation for Ubiquitous Internet of Things(grant numbers:2023B1212010007); Natural Science Foundation of China Project(grant numbers:U23A20339); Guangzhou Municipal Science and Technology Project(grant numbers:2023A03J0011); Guangdong Provincial Project(grant numbers:2023ZDZX1037,2023ZT10X009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071329","Large language models;mixture of experts;low-rank adaptation;multi-task learning;wireless multi-tasking;transfer learning","Wireless communication;Multitasking;Artificial intelligence;Millimeter wave communication;Wireless sensor networks;OFDM;Training;Semantics;Natural language processing;Hands","","","","51","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"A Multi-Model Framework for Synthesizing High-Fidelity Network Intrusion Data Using Generative AI","M. Rathakrishnan; S. Gayan; S. Edirisinghe; H. Inaltekin","Dept. of Electronic and Telecommunication Engineering, University of Moratuwa, Moratuwa, Sri Lanka; Dept. of Electronic and Telecommunication Engineering, University of Moratuwa, Moratuwa, Sri Lanka; Dept. of Computer Engineering, University of Sri Jayewardenepura, Nugegoda, Sri Lanka; School of Engineering, Macquarie University, North Ryde, NSW, Australia",2025 5th International Conference on Advanced Research in Computing (ICARC),"16 Apr 2025","2025","","","1","6","The rapid evolution of network technologies and frequent network intrusions have amplified the demand for intrusion detection systems (IDSs) powered by artificial intelligence (AI). However, the performance of IDSs is limited by labeled intrusion data and class imbalances in existing datasets. Collecting such data through live network simulations is costly, insecure, and poses regulatory challenges. This paper presents a multi-model framework that uses a conditional tabular generative adversarial network (CTGAN) to synthesize realistic network intrusion data. The framework addresses challenges such as unstable training, mode collapse, and handling mixed data types, which are common in most generative AI models when applied to non-Gaussian tabular data generation while validating the synthesized data through qualitative and quantitative analyses. Overlaid density histograms and cumulative distribution functions (CDFs) are used for qualitative analysis. For quantitative analysis, the train-real-test-synthetic (TRTS) and train-synthetic-test-real (TSTR) methods, as well as the Kolmogorov-Smirnov (KS) test, are utilized. The TRTS and TSTR methods are classifier-based approaches with classification accuracies of 98.36% and 97.95%, respectively, and are used to assess the synthesized intrusion data to ensure the interchangeability of the synthesized intrusion data and real-world intrusion data for training IDSs. The KS test results indicate a similarity score of 0.92 between real and synthesized data. Additionally, to provide interpretable insights into the performance of the model and refrain from using real-world intrusion data for analysis purposes, the framework employs an explainable AI (XAI) approach called local interpretable model-agnostic explanation (LIME), enabling network security analysts to interpret features that influence the intrusive nature of the synthesized network intrusion data while preserving data privacy.","","979-8-3315-3098-3","10.1109/ICARC64760.2025.10963129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963129","Intrusion detection systems;generative adversarial networks;multi-model framework;explainable AI;data privacy","Training;Analytical models;Histograms;Statistical analysis;Explainable AI;Scalability;Intrusion detection;Network security;Data models;Network intrusion","","","","18","IEEE","16 Apr 2025","","","IEEE","IEEE Conferences"
"Generative AI for Advanced Malware Detection","M. Al Balawi; M. Alnabhan; M. S. Atoum","Department of Cyber Security, King Hussein School of Computing Sciences, Princess Sumaya University for Technology, Amman, Jordan; Department of Cyber Security, King Hussein School of Computing Sciences, Princess Sumaya University for Technology, Amman, Jordan; Department of Computer Science, King Abdullah II School of0University of Jordan, Amman, Jordan",2024 4th Intelligent Cybersecurity Conference (ICSC),"25 Feb 2025","2024","","","214","221","Identifying and analyzing malicious software in high accuracy is critical requirement for mitigating security risks. This research paper presents a new AI-enabled malware detection model utilizing characteristics of Portable Executable (PE) files. Generative AI is used to analyze extracted strings, section names, digital signatures, and company information of PE files. In addition, the proposed model will detect patterns associated with known malicious behaviors of anti-debugging, code injection, and keylogging by analyzing functions imported from external libraries and the API calls. Hence, AI techniques will integrate with traditional parsing methods to process data. The results achieved prove that the proposed hybrid model is robust and develops the accuracy detection and depth of malware analysis.","","979-8-3503-5477-5","10.1109/ICSC63108.2024.10895965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895965","artificial intelligence;malware analysis;portable Executable files;cybersecurity;machine learning;static analysis;Threat detection;Cyber threat intelligence","Analytical models;Accuracy;Codes;Generative AI;Companies;Malware;Libraries;Data mining;Computer security;Digital signatures","","","","17","IEEE","25 Feb 2025","","","IEEE","IEEE Conferences"
"Generative AI Under Scrutiny: Assessing the Risks and Challenges in Diverse Domains","C. Nidhisree; A. Paul; A. Venunadh; R. S. Bhowmick","RV University, Bengaluru, India; RV University, Bengaluru, India; RV University, Bengaluru, India; RV University, Bengaluru, India","2024 IEEE 6th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA)","11 Feb 2025","2024","","","243","248","Among the rapidly emerging Artificial Intelligence (AI) technologies, Generative AI (GenAI) models have become powerful tools reshaping the technology landscape. The term GenAI refers to a shift in the usage of AI technology from pattern recognition—identifying hidden patterns—to creating free-form text, images, and videos. This paper intends to provide a comprehensive review of GenAI applications in various human-centric applications, technology and innovation, creative industries, finance, and accounting. However, the proliferation of GenAI introduces risks and challenges, including ethics, privacy, and security. By elucidating GenAI’s advantages and disadvantages, envisioning future directions, and proposing measures, this study contributes to the ongoing dialogue on harnessing GenAI’s capabilities to mitigate risks. Moreover, this paper delves into the multifaceted role and challenges faced by these GenAI technologies in various domains. By balancing innovation with ethical considerations, we can steer towards a future where GenAI enriches lives, stimulates creativity, and empowers individuals and communities worldwide.","","979-8-3315-0579-0","10.1109/ICCCMLA63077.2024.10871350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871350","GenAI;Large Language Model;Ethical concerns;Risks and Challenges;AI Governance","Industries;Technological innovation;Ethics;Privacy;Generative AI;Text recognition;Reviews;Machine learning;Security;Videos","","","","18","IEEE","11 Feb 2025","","","IEEE","IEEE Conferences"
"Enhancing Privacy in Generative AI-Enabled Consumer Electronics Using Homomorphic Encryption and Federated Learning","Z. Gao; S. Li; M. Iqbal","Department of Electrical and Computer Engineering, University of Electronic and Science Technology of China, China; School of Computer Science and Informatics, UK; Prince Sultan University, Saudi Arabia",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","The integration of Generative AI (GAI) into consumer electronics (e.g., smart homes, wearables) introduces critical privacy risks as sensitive user data fuels personalized services. This paper proposes a homomorphic encryption-federated learning (HE-FL) framework that ensures end-to-end data confidentiality and decentralized model training. By combining HE’s encrypted computation with FL’s distributed architecture, the framework mitigates vulnerabilities in centralized systems while resisting probabilistic polynomial-time adversaries under the Learning With Errors (LWE) assumption. Evaluations on MNIST demonstrate a 3% accuracy trade-off (95.5% vs. 98.5% baseline) for robust privacy, reducing gradient inversion success to ≤5%. Case studies in healthcare wearables and smart grids validate QoS-aware risk mitigation. Challenges in scalability and quantum-era security are addressed through edge-assisted optimizations and hybrid architectures, aligning with GDPR/CCPA compliance to foster trust in GAI-driven ecosystems.","1558-4127","","10.1109/TCE.2025.3597357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121914","Privacy enhancement;GAI;Homomorphic encryption;Consumer Electronics","Cryptography;Training;Consumer electronics;Computational modeling;Data privacy;Data models;Privacy;Servers;Wearable devices;Real-time systems","","","","","IEEE","11 Aug 2025","","","IEEE","IEEE Early Access Articles"
"From Black Box to Open Book: An Emerging Transparency Imperative in Generative AI Codebases","N. Watson; M. Van Italie","School of Computing and Engineering, University of Gloucestershire, Gloucestershire, United Kingdom; Sema Software, Baltimore, MD, USA",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","1369","1374","Generative Artificial Intelligence (GenAI) tools like GitHub's Copilot, Amazon CodeWhisperer, and OpenAI's Codex now generate an estimated 20-30% of code in many enterprise codebases. As these tools rapidly transform software development through automated code generation, algorithm design, and problem-solving capabilities, they introduce essential challenges in accountability, quality assurance, and long-term code maintenance. This paper investigates the imperative need for transparency in GenAI codebases, presenting empirical evidence for comprehensive strategies addressing quality assurance, security, intellectual property management, and regulatory compliance. The findings demonstrate that GenAI codebase transparency is essential for safety and ethical AI development, with robust code provenance tracking systems offering significant organizational benefits. The paper concludes by recommending that organizations integrate enhanced development tools and prepare proactively for incoming regulatory changes. Key Contributions include a comprehensive analysis of GenAI code transparency requirements and stakeholder impacts, technical implementation guidance for transparency systems, and forward-looking recommendations for continued industry adoption.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050669","generative artificial intelligence;code transparency;intellectual property management software;development practices;ai ethics and regulation","Ethics;Codes;Quality assurance;Generative AI;Software algorithms;Intellectual property;Transforms;Stakeholders;Security;Software development management","","","","31","IEEE","7 Jul 2025","","","IEEE","IEEE Conferences"
"Knowledge-Augmented Large Language Model Prompting for Cypher Query Construction","B. B. Kömeçoğlu; B. Yılmaz","Institute of Information Technologies, Gebze Technical University, Kocaeli, Türkiye; Institute of Information Technologies, Gebze Technical University, Kocaeli, Türkiye",2024 9th International Conference on Computer Science and Engineering (UBMK),"11 Dec 2024","2024","","","187","192","While existing large language models demonstrate remarkable proficiency inn a turall a nguage processing tasks, their capacity for knowledge graph structuring remains a potential avenue for enhancement, particularly in the context of knowledge graph question answering. This paper presents a novel method for knowledge-enriched LLM routing for the construction of Cypher queries utilising knowledge graphs. It is proposed that the prompts of LLMs be enriched with knowledge by the addition of relevant triples taken from the knowledge graph. The proposed method facilitates the generation of more precise and pertinent Cypher queries by LLMs, thereby enhancing their question-answering capabilities. The method is evaluated using a story-based knowledge graph question answering dataset, which is introduced in this paper as a new contribution to the literature. The results demonstrate that the incorporation of knowledge enhances the performance of knowledge graph question answering (KGQA), particularly in the context of complex and temporal inquiries. Furthermore, the utilisation of a story graph structure for the modelling of events in news texts facilitates the effective resolution of complex questions by following the paths on the graph. Finally, it is demonstrated that the extraction of temporal labels and their incorporation into the knowledge graph is of paramount importance in answering temporal questions.","2521-1641","979-8-3503-6588-7","10.1109/UBMK63289.2024.10773450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773450","knowledge graph;prompt engineering;language model;question answering;natural language processing","Knowledge engineering;Computer science;Ciphers;Large language models;Computational modeling;Knowledge graphs;Routing;Question answering (information retrieval)","","1","","12","IEEE","11 Dec 2024","","","IEEE","IEEE Conferences"
"Venn Diagram Prompting: Accelerating Comprehension with Scaffolding Effect","S. Mahendru; T. Pandit","Palo Alto Networks, California, USA; Palo Alto Networks, California, USA",2024 6th World Symposium on Artificial Intelligence (WSAI),"7 Jan 2025","2024","","","39","48","We introduce Venn Diagram (VD) Prompting, an innovative prompting technique which allows Large Language Models (LLMs) to combine and synthesize information across complex, diverse and long-context documents in knowledge-intensive question-answering tasks. Generating answers from multiple documents involves numerous steps to extract relevant and unique information and amalgamate it into a cohesive response. To improve the quality of the final answer, multiple LLM calls or pretrained models are used to perform different tasks such as summarization, reorganization and customization. The approach covered in the paper focuses on replacing the multi-step strategy via a single LLM call using VD prompting. Our proposed technique also aims to eliminate the inherent position bias in the LLMs, enhancing consistency in answers by removing sensitivity to the sequence of input information. It overcomes the challenge of inconsistency traditionally associated with varying input sequences. We also explore the practical applications of the VD prompt based on our examination of the prompt's outcomes. In the experiments performed on four public benchmark question-answering datasets, VD prompting continually matches or surpasses the performance of a meticulously crafted instruction prompt which adheres to optimal guidelines and practices.","","979-8-3503-7416-2","10.1109/WSAI62426.2024.10828919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828919","Large language model;retrieval-augmented generation;prompt engineering","Sensitivity;Large language models;Linguistics;Benchmark testing;Set theory;Question answering (information retrieval);Data mining;Standards;Context modeling;Guidelines","","","","23","IEEE","7 Jan 2025","","","IEEE","IEEE Conferences"
"DomainVoyager: Embracing The Unknown Domain by Prompting for Automatic Augmentation","C. Liu; H. Zhu; X. Su","State Key Laboratory of Software Development Environment Lab, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment Lab, Beihang University, Beijing, China; Big Data Institute, Central South University, Changsha, China",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","7","For medical image analysis, domain generalization (DG) faces significant challenges due to variances in data across medical imaging devices. Addressing this, we introduce Prompt Guided Domain Aligning Augmentation (PGDAA), a novel approach that harnesses Large Language Models (LLMs) to iteratively refine data augmentation sequences in DG for medical segmentations. Specifically, by harnessing the LLM’s advanced capabilities in interpreting and responding to specific prompts, PGDAA iteratively voyages the parameter searching space for data augmentation, identifying optimal augmentation sequences. In each searching round, the LLM leverages provided prior data augmentation methods, their parameters, and corresponding evaluation results to acquire a sufficient performance memory bank, thereby proposing more effective augmentation sequences to significantly narrowing inter-domain gaps. Notably, this integration of LLMs in DG represents a pioneering application in the field, which adds minor training parameters and can be easily combined with other DG benchmarks for further improvements. Comprehensive experiments reveal our method outperforms the baseline by 4.47% and 5.08% on Fundus and Prostate datasets, achieving 90.10% and 89.28% accuracy, respectively.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10688021","Research and Development; National Natural Science Foundation of China; National Natural Science Foundation of China; Beijing Municipal Administration of Hospitals; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10688021","medical image;domain generalization;prompt engineering;data augmentation","Training;Image segmentation;Image analysis;Accuracy;Large language models;Benchmark testing;Data augmentation","","","","41","IEEE","30 Sep 2024","","","IEEE","IEEE Conferences"
"JailSmash: Lightweight Jailbreaking of LLM Applications on Android Smartphones","C. Tian; Q. Yuan; X. Liu; Y. Yan","China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China","2025 IEEE 7th International Conference on Communications, Information System and Computer Engineering (CISCE)","10 Jul 2025","2025","","","1033","1036","The rapid growth of LLM APPs brings potential security risks, particularly jailbreaking attacks. These attacks involve bypassing LLM security mechanisms through carefully designed prompts to generate harmful or unethical content, posing threats to both individuals and organizations. We developed a lightweight jailbreak tool called JailSmash, which leverages jailbreak templates based on in-context learning (ICL) and strategies to guide third-party large language models in automatically generating jailbreak test sets. This tool also enables automated interaction and evaluation of jailbreak results with LLM apps on Android smartphones. Furthermore, we used JailSmash to conduct jailbreak security assessments on 30 mainstream LLM apps, thereby validating the effectiveness of the tool.","2833-2423","979-8-3315-0161-7","10.1109/CISCE65916.2025.11065135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065135","Jailbreak;LLM app security;ICL;Android","Large language models;Organizations;Security;Computer security;Smart phones;Information systems","","","","15","IEEE","10 Jul 2025","","","IEEE","IEEE Conferences"
"Large Language Model guided State Selection Approach for Fuzzing Network Protocol","B. Yu; Q. Song; C. Cai","School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China","2024 IEEE International Performance, Computing, and Communications Conference (IPCCC)","27 Jan 2025","2024","","","1","6","Fuzzing network protocols is challenging due to their various factors including protocol state and state transitions. To achieve better state coverage when fuzzing network protocol with grey-box fuzzing, several approaches are proposed to select valuable states and optimize the fuzzing process. Based on the ability of extensive knowledge integration and reasoning, large language models (LLMs) are also imported to generate more effective test cases for protocol fuzzing. However, these approaches leave poor state and code coverage on real-world services protocol evaluation since they use either random selection or heuristics. To address this issue, we present LLMgSSA, a Large Language Model guided State Selection Approach, which navigates the LLM to reason about protocol state selection. In the approach, LLMgSSA first extracts the features of the current protocol and state space and determines valuable states by interacting with the LLM. It then collects and analyzes the current status of each covered state and combines the inference results of the LLM for the final state selection. To evaluate the effectiveness of LLMgSSA, we have conducted extensive experiments with five real-world protocols from ProFuzzBench. Experimental results show that, compared to three state-of-the-art fuzzers, ChataFL, AFLnet, and NSFuzz, LLMgSSA can increase state transitions, covered states, branch coverage, and line coverage by up to 70.6%, 35.3%, 13.1%, and 13.1% respectively.","2374-9628","979-8-3503-6794-2","10.1109/IPCCC59868.2024.10850039","Natural Science Foundation of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850039","network protocol software;fuzz testing;large language model;prompt engineering","Protocols;Codes;Navigation;Large language models;Computational modeling;Fuzzing;Feature extraction;Cognition;Software;Data mining","","","","16","IEEE","27 Jan 2025","","","IEEE","IEEE Conferences"
"“I was Diagnosed with …”: Sensitivity Detection and Rephrasing of Amazon Reviews with ChatGPT","C. Alfieri; S. Ganesh; L. Ge; J. Shi; N. Sadeh","DISIM, University of L’ Aquila, L’Aquila, Italy; School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, USA","2024 21st Annual International Conference on Privacy, Security and Trust (PST)","16 Dec 2024","2024","","","1","12","The proliferation of platforms such as e-commerce and social networks has led to an increasing amount of personal health information being disclosed in user-generated content. This study investigates the use of Large Language Models (LLMs) to detect and sanitize sensitive health data disclosures in reviews posted on Amazon. Specifically, we present an approach that uses ChatGPT to evaluate both the sensitivity and informativeness of Amazon reviews. The approach uses prompt engineering to identify sensitive content and rephrase reviews to reduce sensitive disclosures while maintaining informativeness. Empirical results indicate that ChatGPT is capable of reliably assigning sensitivity scores and informativeness scores to user-generated reviews and can be used to generate sanitized reviews that remain informative.","2643-4202","979-8-3503-6709-6","10.1109/PST62714.2024.10788076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788076","LLMs;sanitizing;self-disclosure;sensitivity detection;privacy","Privacy;Sensitivity;Reviews;Social networking (online);Large language models;User-generated content;Chatbots;Security;Reliability;Prompt engineering","","","","51","IEEE","16 Dec 2024","","","IEEE","IEEE Conferences"
"A Multi-Modal Approach for Fight Detection in Surveillance Systems: Integrating Audio and Video Analytics","J. Kotichukkala; Isha; S. Konakalla; T. Jajimoggala; L. S. Vasamsetti; Y. Vankayalapati","Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, Lovley Professional University, Phagwara, Punjab, India",2025 Global Conference in Emerging Technology (GINOTECH),"17 Jul 2025","2025","","","1","6","The detection of fights in surveillance systems demands public protection yet the current methods heavily depend on visual information which creates weaknesses during poor lighting conditions and when targets become obstructed or their movements are unclear. The proposed work introduces an innovative audio-video integration process to boost the detection performance. Our solution combines CNN-BiLSTM video-based fight detection with an audio transformer that classifies the sounds of fight activities such as shrieks and verbal assaults and hitting sounds. The combination of late fusion between audio and video capabilities produces a strategy that substantially improves detection reliability. Our system shows superior performance compared to single-mode solutions by reaching 89.2% precision together with 87.8% F1-score. The new research platform adopts AI capabilities in violence detection by establishing better standards that lead to smarter real-time security solutions.","","979-8-3315-0775-6","10.1109/GINOTECH63460.2025.11076769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076769","Fight detection;surveillance cameras;deep learning;multi-modal fusion;video action recognition;audio event classification;CNN-BiLSTM;transformer models;violence detection;security systems","Deep learning;Law enforcement;Surveillance;Visual analytics;Lighting;Streaming media;Transformers;Real-time systems;Security;Reliability","","","","25","IEEE","17 Jul 2025","","","IEEE","IEEE Conferences"
"Transformer-Based Threat Detection in Blockchain Healthcare Transactions","A. Ahmed; M. Aktarujjaman; M. Moniruzzaman; M. S. Uddin; M. Ahmed; M. N. Hasan","Georgia Institute of Technology, Atlanta, GA, USA; Webster University, Webster Groves, MO, USA; Maharishi International University, Fairfield, IA, USA; Maharishi International University, Fairfield, IA, USA; Bangladesh University of Business and Technology, Dhaka, Bangladesh; University of Wisconsin-Milwaukee, Milwaukee, WI, USA",2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN),"19 Jun 2025","2025","","","739","744","Blockchain-based healthcare systems offer enhanced security and data integrity, yet remain vulnerable to fraudulent transactions and unauthorized access. This study proposes a novel hybrid autoencoder-transformer model for anomaly detection in blockchain healthcare transactions, integrating graph convolutional networks (GCNs) for structured data representation, transformers for capturing long-range dependencies, and contrastive learning for improved fraud detection. The model was evaluated on a large-scale healthcare transaction dataset with over 1 million records. Experimental results demonstrate that the proposed approach achieves an accuracy of 94.7%, outperforming traditional machine learning models such as random forests (85.2%) and XGBoost (87.5%), as well as deep learning methods like LSTMs (89.1%) and CNNL-STMs (91.2%). Ablation studies highlight the importance of each component, with the removal of the GCN reducing accuracy by 2.9%. The model maintains an F1-score of 93.0% even under adversarial perturbations. Despite computational overhead, the proposed framework provides a robust and scalable solution for real-time threat detection in decentralized healthcare systems. Future work will explore self-supervised learning and adaptive transformer architectures to further improve model efficiency and generalizability.","","979-8-3315-3519-3","10.1109/ICPCSN65854.2025.11035276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035276","Blockchain security;healthcare transactions;anomaly detection;deep learning;transformer models;autoencoder;and graph convolutional networks","Deep learning;Adaptation models;Graph convolutional networks;Computational modeling;Autoencoders;Medical services;Transformers;Threat assessment;Blockchains;Security","","","","13","IEEE","19 Jun 2025","","","IEEE","IEEE Conferences"
"CoT-Tree: An Efficient Prompting Strategy for Large Language Model Classification Reasoning","Y. Wang; J. Hu; Z. Luo","Department of Computer Science, BNU-HKBU United International College, Hong Kong Baptist University, Zhuhai, China; Department of Computer Science, BNU-HKBU United International College, Zhuhai, China; BNU-UIC Institute of AI and Future Networks, Beijing Normal University BNU-HKBU United International College, Zhuhai, China",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","5450","5458","Prompt engineering in Large Language Models (LLMs) has become pivotal for task adaptation, especially in complex reasoning tasks where traditional methods fall short. This paper introduces an innovative method to optimize prompt efficiency by constructing a decision tree of the Chain of Thought (CoT) for classification tasks, namely CoT-Tree. Initially, we demonstrate two advantages of using CoT as features for decision-tree prompts: task adaptability and semantic dissimilarity between features. These advantages theoretically ensure that the CoT-Tree prompting strategy achieves higher performance in classification tasks. Subsequently, we propose the CoT-Tree algorithm and apply it on three classic classification scenarios. By leveraging the CoT-Tree prompting strategy, we select distinctive and efficient prompts that maximize task relevance while minimizing redundancy and token consumption, allowing for a dynamic pruning mechanism, effectively controlling the depth and complexity of the prompts. The results indicate that our method achieves higher accuracy with fewer LLM interaction rounds. Additionally, a case study is conducted to further demonstrate the practicality of our method.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825547","LLMs;CoT;Decision Tree;Semantic Similarity;Prompting Efficiency","Accuracy;Large language models;Heuristic algorithms;Semantics;Redundancy;Process control;Cognition;Complexity theory;Decision trees;Prompt engineering","","","","33","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Model Checking in Multiplayer Games Development","R. Rezin; I. Afanasyev; M. Mazzara; V. Rivera","Innopolis University, Innopolis, Russia; Innopolis University, Innopolis, Russia; Innopolis University, Innopolis, Russia; Innopolis University, Innopolis, Russia",2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA),"13 Aug 2018","2018","","","826","833","Multiplayer computer games play a big role in the ever-growing entertainment industry. Being competitive in this industry means releasing the best possible software, and reliability is a key feature to win the market. Computer games are also actively used to simulate different robotic systems where reliability is even more important, and potentially critical. Traditional software testing approaches can check a subset of all the possible program executions, and they can never guarantee complete absence of errors in the source code. On the other hand, during more than twenty years, Model Checking has demonstrated to be a powerful instrument for formal verification of large hardware and software components. In this paper, we contribute with a novel approach to formally verify computer games. We propose a method of model construction that starts from a computer game description and utilizes Model Checking technique. We apply the method on a case study: the game Penguin Clash. Finally, an approach to game model reduction (and its implementation) is introduced in order to address the state explosion problem.","2332-5658","978-1-5386-2195-0","10.1109/AINA.2018.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432324","model checking;multiplayer games;formal verification;multi agent systems;game development","Games;Computational modeling;Robots;Tools;Model checking;Software;Reliability","","13","","29","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"A Comparative Analysis of Tweet Analysis Algorithms Using Natural Language Processing and Machine Learning Models","A. Kanavos; N. Antonopoulos; I. Karamitsos; P. Mylonas","Department of Informatics, Ionian University, Corfu, Greece; Department of Digital Media and Communication, NeMeCULAB, Ionian University, Argostoli, Greece; Department of Graduate and Research, Rochester Institute of Technology, Dubai, UAE; Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece",2023 18th International Workshop on Semantic and Social Media Adaptation & Personalization (SMAP)18th International Workshop on Semantic and Social Media Adaptation & Personalization (SMAP 2023),"26 Sep 2023","2023","","","1","6","Online Social Networks (OSNs) have become integral platforms for information sharing, attracting both legitimate users and spammers. Detecting and mitigating spam within these networks pose significant challenges due to the dynamic nature of content and user behavior. In this paper, we present a comprehensive comparative analysis of algorithms for tweet analysis, focusing on Natural Language Processing (NLP) and Machine Learning (ML) models. We evaluate these algorithms through sentiment analysis and multiple attribute analysis, utilizing diverse methodologies and datasets. Our study explores feed-forward neural networks, Bayesian classifiers, and transformer-based models for NLP tasks, achieving high prediction accuracy and insightful metrics such as precision, recall, and F1 score. Furthermore, we delve into multiple attribute analysis using Random Forest, Logistic Regression, and Gradient Boosting algorithms. Through a systematic exploration of various approaches, this work contributes to a deeper understanding of spam detection and sentiment analysis within the context of OSNs, paving the way for enhanced social network security and content analysis.","","979-8-3503-2771-7","10.1109/SMAP59435.2023.10255184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255184","Online Social Networks;Tweet Analysis;Natural Language Processing;Machine Learning;Spam Detection;Transformer Models","Analytical models;Sentiment analysis;Machine learning algorithms;Systematics;Social networking (online);Heuristic algorithms;Prediction algorithms","","5","","20","IEEE","26 Sep 2023","","","IEEE","IEEE Conferences"
"Cybersecurity Defenses: Exploration of CVE Types Through Attack Descriptions","R. Othman; B. Rossi; B. Russo","Faculty of Engineering, Free University of Bozen-Bolzano, Bolzano, Italy; Faculty of Informatics, Masaryk University, Brno, Czech Republic; Faculty of Engineering, Free University of Bozen-Bolzano, Bolzano, Italy",2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA),"27 Dec 2024","2024","","","415","418","Vulnerabilities in software security can remain undiscovered even after being exploited. Linking attacks to vulnerabilities helps experts identify and respond promptly to the incident. This paper introduces VULDAT, a classification tool using a sentence transformer MPNET to identify system vulnerabilities from attack descriptions. Our model was applied to 100 attack techniques from the ATT&CK repository and 685 issues from the CVE repository. Then, we compare the performance of VULDAT against the other eight state-of-the-art classifiers based on sentence transformers. Our findings indicate that our model achieves the best performance with F1 score of 0.85, Precision of 0.86, and Recall of 0.83. Furthermore, we found 56% of CVE reports vulnerabilities associated with an attack were identified by VULDAT, and 61% of identified vulnerabilities were in the CVE repository.","2376-9521","979-8-3503-8026-2","10.1109/SEAA64295.2024.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803317","MITRE;CAPEC;CVE;Transformer models;Pretrained language models","Accuracy;Manuals;Inspection;Transformers;Software;Computer security;Software engineering","","2","","24","IEEE","27 Dec 2024","","","IEEE","IEEE Conferences"
"Securing Against Deception: Exploring Phishing Emails Through ChatGPT and Sentiment Analysis","S. Sayyafzadeh; M. Weatherspoon; J. Yan; H. Chi","Dept. of Comp. & Info Sciences, Florida A&M University, Tallahassee, FL; FAMU-FSU College of Engineering, Tallahassee, FL; Dept. of Computer Science, Bowie State University, Bowie, Maryland, USA; Dept. of Comp. & Info Sciences, Florida A&M University, Tallahassee, FL","2024 IEEE/ACIS 22nd International Conference on Software Engineering Research, Management and Applications (SERA)","26 Sep 2024","2024","","","159","165","The origin of large language models (LLMs) has left an indelible mark on various domains, most notably in natural language processing and artificial intelligence. While extensive research has delved into LLMs like ChatGPT 4 for tasks such as code generation and text synthesis, their application in identifying malicious web content, particularly phishing web sites, still needs to be explored. To confront the growing wave of automated cyber threats facilitated by LLMs, automating the detection of malicious email content. This paper investigates the utilization of Natural Language Processing (NLP) techniques, including VADER (valence aware dictionary and sentiment Reasoner) sentiment analysis and Large Language Models (LLMs) to strengthen the detection of phishing emails, offering enhanced defense mechanisms against cyber threats by analyzing the diverse attributes of phishing emails, including sender details, URLs, textual content, and linguistic characteristics. In this study, we leverage the power of ChatGPT's 4 state-of-the-art language models and employ Natural Language Processing (NLP) techniques. We develop an intelligent system that identifies and flags potential phishing attempts in spam emails and URLs. Our experiments using GPT-4 on our dataset demonstrated promising results, achieving an accuracy of 92%. These findings underscore LLMs' potential, including VADER sentiment analysis, to detect rapidly and accurately phishing emails, safeguarding cybersecurity challenges and protecting users from online fraud and phishing attempts.","2770-8209","979-8-3503-9134-3","10.1109/SERA61261.2024.10685564","National Science Foundation(grant numbers:#2333950); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685564","Large Language Model;Natural Language Processing;Phishing Generation Dialogue;Few-shot Prompting","Sentiment analysis;Phishing;Large language models;Unsolicited e-mail;Linguistics;Chatbots;Electronic mail","","1","","34","IEEE","26 Sep 2024","","","IEEE","IEEE Conferences"
"Fight Fire With Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?","X. Yu; L. Liu; X. Hu; J. W. Keung; J. Liu; X. Xia","State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an,, Shanxi, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; School of Computer Science, Wuhan University, Wuhan, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,"11 Dec 2024","2024","50","12","3435","3453","With the increasing utilization of large language models such as ChatGPT during software development, it has become crucial to verify the quality of code content it generates. Recent studies proposed utilizing ChatGPT as both a developer and tester for multi-agent collaborative software development. The multi-agent collaboration empowers ChatGPT to produce test reports for its generated code, enabling it to self-verify the code content and fix bugs based on these reports. However, these studies did not assess the effectiveness of the generated test reports in validating the code. Therefore, we conduct a comprehensive empirical investigation to evaluate ChatGPT's self-verification capability in code generation, code completion, and program repair. We request ChatGPT to (1) generate correct code and then self-verify its correctness; (2) complete code without vulnerabilities and then self-verify for the presence of vulnerabilities; and (3) repair buggy code and then self-verify whether the bugs are resolved. Our findings on two code generation datasets, one code completion dataset, and two program repair datasets reveal the following observations: (1) ChatGPT often erroneously predicts its generated incorrect code as correct, its vulnerable completed code as non-vulnerable, and its failed program repairs as successful during its self-verification. (2) The self-contradictory hallucinations in ChatGPT's behavior arise: (a) ChatGPT initially generates code that it believes to be correct but later predicts it to be incorrect; (b) ChatGPT initially generates code completions that it deems secure but later predicts them to be vulnerable; (c) ChatGPT initially outputs code that it considers successfully repaired but later predicts it to be buggy during its self-verification. (3) The self-verification capability of ChatGPT can be enhanced by asking the guiding question, which queries whether ChatGPT agrees with assertions about incorrectly generated or repaired code and vulnerabilities in completed code. (4) Using test reports generated by ChatGPT can identify more vulnerabilities in completed code, but the explanations for incorrectly generated code and failed repairs are mostly inaccurate in the test reports. Based on these findings, we provide implications for further research or development using ChatGPT.","1939-3520","","10.1109/TSE.2024.3492204","National Natural Science Foundation of China(grant numbers:61972290); Ningbo Natural Science Foundation(grant numbers:2023J292); General Research Fund of the Research Grants Council of Hong Kong and the research funds of the City University of Hong Kong(grant numbers:6000796,9229109,9229098,9220103,9229029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10745266","Empirical study;ChatGPT;self-verification;code generation;code completion;program repair","Codes;Chatbots;Maintenance engineering;Software development management;Software;Computer bugs;Urban areas;Computer science;Accuracy;Source coding","","5","","69","IEEE","5 Nov 2024","","","IEEE","IEEE Journals"
"An Exploratory Study of ML Sketches and Visual Code Assistants","L. F. Gomes; V. J. Hellendoorn; J. Aldrich; R. Abreu","Software and Societal Systems Dept., Carnegie Mellon University, Pittsburgh, USA; Software and Societal Systems Dept., Carnegie Mellon University, Pittsburgh, USA; Software and Societal Systems Dept., Carnegie Mellon University, Pittsburgh, USA; INESC-ID, Faculty of Engineering, University of Porto, Porto, Portugal",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1653","1664","This paper explores the integration of Visual Code Assistants in Integrated Development Environments (IDEs). In Software Engineering, whiteboard sketching is often the initial step before coding, serving as a crucial collaboration tool for developers. Previous studies have investigated patterns in SE sketches and how they are used in practice, yet methods for directly using these sketches for code generation remain limited. The emergence of visually-equipped large language models presents an opportunity to bridge this gap, which is the focus of our research. In this paper, we built a first prototype of a Visual Code Assistant to get user feedback regarding in-IDE sketch-to-code tools. We conduct an experiment with 19 data scientists, most of whom regularly sketch as part of their job. We investigate developers' mental models by analyzing patterns commonly observed in their sketches when developing an ML workflow. Analysis indicates that diagrams were the preferred organizational component (52.6%), often accompanied by lists (42.1%) and numbered points (36.8%). Our tool converts their sketches into a Python notebook by querying an LLM. We use an LLM-as-judge setup to score the quality of the generated code, finding that even brief sketching can effectively generate useful code outlines. We also find a positive correlation between sketch time and the quality of the generated code. We conclude the study by conducting extensive interviews to assess the tool's usefulness, explore potential use cases, and understand developers' needs. As noted by participants, promising applications for these assistants include education, prototyping, and collaborative settings. Our findings signal promise for the next generation of Code Assistants to integrate visual information, both to improve code generation and to better leverage developers' existing sketching practices.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029898","AI4SE;Code generation;Visual programming;Sketching;Machine learning;Tool development;Human-AI Interaction","Visualization;Codes;Collaboration;Prototypes;Encoding;Interviews;Programming profession;Next generation networking;Software engineering;Python","","","","35","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"Re-identifying People in Video via Learned Temporal Attention and Multi-modal Foundation Models","C. Hill; F. Yellin; K. Regmi; D. Du; S. McCloskey","Kitware Inc., USA; Kitware Inc., USA; Kitware Inc., USA; Kitware Inc., USA; Kitware Inc., USA",2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),"8 Apr 2025","2025","","","6259","6268","Biometric recognition from security camera video is a challenging problem when the individuals change clothes or when they are partly occluded. Others have recently demonstrated that CLIP's visual encoder performs well in this domain, but existing methods fail to make use of the model's text encoder or temporal information available in video. In this paper, we present VCLIP, a method for person identification in videos captured in challenging poses and with changes to a person's clothing. Harnessing the power of pre-trained vision-language models, we Jointly train a temporal fusion network while fine-tuning the visual encoder. To leverage the cross-modal embedding space, we use learned biometric pedestrian attribute features to further enhance our model's person re-identification (Re-ID) ability. We demonstrate significant performance improvements via experiments with the MEVID and CCVID datasets, particularly in the more challenging clothes-changing conditions. In support of this and future methods that use textual attributes for Re-ID with multimodal models, we release a dataset of annotated pedestrian attributes for the popular MEVID dataset [4].","2642-9381","979-8-3315-1083-1","10.1109/WACV61041.2025.00610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943775","","Biometrics;Visualization;Computer vision;Pedestrians;Foundation models;Biological system modeling;Clothing;Cameras;Robustness;Security","","","","33","IEEE","8 Apr 2025","","","IEEE","IEEE Conferences"
"Generative AI-Driven Cross-Layer Covert Communication: Fundamentals, Framework, and Case Study","T. Liu; J. Liu; T. Zhang; J. Wang; J. Wang; J. Kang; D. Niyato; S. Mao",NA; NA; NA; NA; NA; NA; NA; NA,IEEE Communications Magazine,"","2025","PP","99","1","7","Ensuring end-to-end cross-layer communication security in military networks by selecting covert schemes between nodes is a key solution for military communication security. With the development of communication technology, covert communication has expanded from the physical layer to the network and application layers, utilizing methods such as artificial noise, private networks, and semantic coding to transmit secret messages. However, as adversaries continuously eavesdrop on specific communication channels, the accumulation of sufficient data may reveal underlying patterns that influence concealment, and establishing a cross-layer covert communication mechanism emerges as an effective strategy to mitigate these regulatory challenges. In this article, we first survey the communication security solution based on covert communication, specifically targeting three typical scenarios: deviceto- device, private network, and public network communication, and analyze their application scopes. Furthermore, we propose an end-to-end cross-layer covert communication scheme driven by generative artificial intelligence (GenAI), highlighting challenges and their solutions. Additionally, a case study is conducted using diffusion reinforcement learning to solve cloud-edge Internet of Things cross-layer secure communication.","1558-1896","","10.1109/MCOM.004.2500025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049850","","Cross layer design;Physical layer;Security;Noise;Relays;Military communication;Jamming;Games;Steganography;Semantics","","","","","IEEE","24 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Integrating Retrieval-Augmented Generation for Enhanced Code Reuse: A Comprehensive Framework for Efficient Software Development","K. Wang; Y. Ding; S. Jia; T. Ma; Y. Zhang; B. Cao","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; HiThink Research, Hithink RoyalFlush Information Network Co., Ltd., Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science, Zhejiang University of Technology, Hangzhou, China",2024 IEEE Smart World Congress (SWC),"24 Mar 2025","2024","","","1315","1321","With the rapid development of ubiquitous computing, the demand for efficient software development is growing stronger. Code reuse is an effective means to enhance software development efficiency, significantly reducing the development cycle. Although existing large language models for code generation can assist developers in quickly writing code, they primarily aid in generating generic code and are unable to produce specific business code, making code reuse indispensable. In this paper, We propose a retrieval-augmented generation-based framework to streamline code reuse. This involves extracting reusable code units, generating natural language summaries, and matching queries with these summaries using search and reranking techniques. We conducted extensive experiments from both code search and code generation perspectives, the experimental results demonstrate that our approach significantly improves the efficiency and quality of code reuse.","2993-396X","979-8-3315-2086-1","10.1109/SWC62898.2024.00205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924979","Code Reuse;Code Search;Code Generation","Codes;Large language models;Natural languages;Retrieval augmented generation;Writing;Ubiquitous computing;Vectors;Software development management;Software engineering;Business","","","","41","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"PENTEST-AI, an LLM-Powered Multi-Agents Framework for Penetration Testing Automation Leveraging Mitre Attack","S. G. Bianou; R. G. Batogna","Independent Researcher, Ashburn, VA, USA; Computing Mathematical & Statistical Sciences, School of Science, University of Namibia, Windhoek, Namibia",2024 IEEE International Conference on Cyber Security and Resilience (CSR),"24 Sep 2024","2024","","","763","770","In the digital transformation era, the surge of better development technologies and citizen developers disrupted the space of innovation by increasing the number and complexity of applications used in production. This context prompts advanced cybersecurity measures and more frequent and thorough penetration testing to protect an organization's security posture. The scarcity of skilled expertise in cybersecurity today makes it challenging to cope with the evolving challenge and the growing demand. This paper introduces PENTESTAI, a novel framework for penetration testing automation using Large Language Model (LLM)-powered agents leveraging the MITRE ATTACK knowledge base. The paper provides an overview of the current state of research on cybersecurity and LLM-powered agents, followed by a detailed description of PENTESTAI building blocks. A proof-of-concept implementation is discussed to validate the framework's core constructs. The paper concludes with suggestions for future research directions to achieve the highest level of penetration testing automation with average skilled human-agent collaboration and to create citizen penetration testers.","","979-8-3503-7536-7","10.1109/CSR61664.2024.10679480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679480","Cybersecurity;penetration testing;automation;vulnerabilities;AI;Large Language Models;AI Agents;MITRE ATTACK;Citizen penetration tester","Technological innovation;Automation;Large language models;Digital transformation;Knowledge based systems;Surge protection;Production","","6","","26","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"Moving Target Defense Meets Artificial-Intelligence-Driven Network: A Comprehensive Survey","T. Zhang; F. Kong; D. Deng; X. Tang; X. Wu; C. Xu; L. Zhu; J. Liu; B. Ai; Z. Han; R. H. Deng","School of Cyberspace Science and Technology, Beijing Jiaotong University, Beijing, China; School of Information Engineering, Minzu University of China, Beijing, China; College of Computer Science, Chongqing University, Chongqing, China; School of Information Engineering, Minzu University of China, Beijing, China; School of Computer Science and Technology, Anhui Province Key Laboratory of Digital Twin Technology in Metallurgical Industry, Anhui University of Technology, Maanshan, Anhui, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Cyberspace Science and Technology, Beijing Jiaotong University, Beijing, China; School of Electronic and Information Engineering and Frontiers Science Center for Smart High-Speed Railway System, Beijing Jiaotong University, Beijing, China; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Information Systems, Singapore Management University, 81 Victoria St, Singapore",IEEE Internet of Things Journal,"8 May 2025","2025","12","10","13384","13397","Based on emerging artificial intelligence (AI) tasks, cloud-edge–terminal architecture can provide powerful computing, intelligent interconnection, and real-time response, which can also be regarded as AI-driven network. Unfortunately, multiple network layers in the AI-driven network usually face various types of network threats, such as malicious network reconnaissance, side-channel attacks, and distributed denial of service (DDoS). Traditional security solutions respond to network threats after the occurrence of attacks. To solve this problem, the concept of moving target defense (MTD) has been proposed as a proactive defense mechanism that aims to defend against cyber attacks before they occur. In this article, we first provide a thorough analysis of the threats in the cloud-edge–terminal network. Then, we conduct a comprehensive survey to discuss the concept, design principles, and main classifications of MTD. Next, we further introduce the development potential in terms of AI-powered MTD on each network layer. Meanwhile, we also explore how MTD improves the security of AI algorithms. Lastly, we describe the existing challenges and research directions of MTD. The aim of this article is to provide an in-depth understanding for the readers on how to realize the integration between MTD and AI-driven network.","2327-4662","","10.1109/JIOT.2025.3533016","Talent Fund of Beijing Jiaotong University(grant numbers:2023XKRC050); National Natural Science Foundation of China (NSFC)(grant numbers:62402029,62225105,62221001,62341127,62302539); Open Fund of Anhui Provincial Key Laboratory of Digital Twin Technology in Metallurgical Industry(grant numbers:ADW24-01); Open Fund of Anhui Engineering Research Center for Intelligent Applications and Security of Industrial Internet(grant numbers:IASII24-01); National Key Research and Development Program of China(grant numbers:2021YFB2900301); China Postdoctoral Science Foundation(grant numbers:2024T170047,GZC20230223,2024M750165); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851316","Artificial intelligence (AI)-driven network;cloud-edge–terminal network;generative AI;moving target defense;security analysis","Artificial intelligence;Cloud computing;Security;Surveys;Internet of Things;Faces;Reviews;Heuristic algorithms;Game theory;Software as a service","","5","","116","IEEE","23 Jan 2025","","","IEEE","IEEE Journals"
"Using GPT-4 Turbo to Automatically Identify Defeaters in Assurance Cases","K. K. Shahandashti; A. B. Belle; M. M. Mohajer; O. Odu; T. C. Lethbridge; H. Hemmati; S. Wang","York University, Toronto, Ontario, Canada; York University, Toronto, Ontario, Canada; York University, Toronto, Ontario, Canada; York University, Toronto, Ontario, Canada; University of Ottawa, Ottawa, Ontario, Canada; York University, Toronto, Ontario, Canada; York University, Toronto, Ontario, Canada",2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW),"21 Aug 2024","2024","","","46","56","Assurance cases (ACs) are convincing arguments, supported by a body of evidence and aiming at demonstrating that a system will function as intended. Producers of systems can rely on assurance cases to demonstrate to regulatory authorities how they have complied with existing industrial standards (e.g., ISO 26262, DO-178C). Defeaters are arguments that challenge the effectiveness of assurance cases. Their presence in assurance cases could compromise the reliability of these assurance cases and make them inadequate for verifying a system's capabilities (e.g., safety, and security). This may lead to system failure, which could have severe outcomes, including loss of life. Therefore, identifying and mitigating defeaters is key to improving assurance cases robustness and reliability. In this paper, we focus on the identification of defeaters. Thus, we rely on GPT-4 Turbo, a Large Language Model developed by OpenAI, to automate the generation (identification) of defeaters in assurance cases. Our approach uses the Eliminative Argumentation (EA) notation to represent assurance cases. Besides, we leverage the Chain of Thought prompting technique to improve GPT-4 Turbo's reasoning capabilities. We conducted experiments on various reference assurance case fragments from the nuclear and aviation domains to evaluate the ability of GPT-4 Turbo to automatically generate defeaters. Although the quality of our experiments results is relatively moderate, the analysis of these results still provides valuable insights on the effectiveness of GPT-4 Turbo in generating defeaters.","2770-6834","979-8-3503-9551-8","10.1109/REW61692.2024.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628633","Large Language Models;Assurance Cases;As-surance Deficits;Defeaters;System Certification","Large language models;ISO Standards;Conferences;Robustness;Cognition;Safety;Security","","1","","53","IEEE","21 Aug 2024","","","IEEE","IEEE Conferences"
"Toward Copyright Integrity and Verifiability via Multi-Bit Watermarking for Intelligent Transportation Systems","Y. Wang; L. Li; Y. Tang; R. Zhang; J. Liu","School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Transactions on Intelligent Transportation Systems,"","2025","PP","99","1","14","Intelligent transportation systems (ITS) use advanced technologies such as artificial intelligence to significantly improve traffic flow management efficiency, and promote the intelligent development of the transportation industry. However, if the data in ITS is attacked, such as tampering or forgery, it will endanger public safety and cause social losses. Therefore, this paper proposes a watermarking that can verify the integrity of copyright in response to the needs of ITS, termed ITSmark. ITSmark focuses on functions such as extracting watermarks, verifying permission, and tracing tampered locations. The scheme uses the copyright information to build the multi-bit space and divides this space into multiple segments. These segments will be assigned to tokens. Thus, the next token is determined by its segment which contains the copyright. In this way, the obtained data contains the custom watermark. To ensure the authorization, key parameters are encrypted during copyright embedding to obtain cipher data. Only by possessing the correct cipher data and private key, can the user entirely extract the watermark. Experiments show that ITSmark surpasses baseline performances in data quality, extraction accuracy, and unforgeability. It also shows unique capabilities of permission verification and tampered location tracing, which ensures the security of extraction and the reliability of copyright verification. Furthermore, ITSmark can also customize the watermark embedding position and proportion according to user needs, making embedding more flexible.","1558-0016","","10.1109/TITS.2025.3535932","National Natural Science Foundation of China(grant numbers:U21B2020); Beijing University of Posts and Telecommunications (BUPT) Excellent Ph(grant numbers:0000DONOTUSETHIS0000.D,CX2023120,CX20241055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10878297","Intelligent transportation systems;copyright;watermark;large language models;GenAI","Watermarking;Data mining;Security;Ciphers;Telecommunications;Data integrity;Encryption;Copyright protection;Vehicular ad hoc networks;Transportation","","1","","","IEEE","7 Feb 2025","","","IEEE","IEEE Early Access Articles"
"Leveraging AI for CTF Challenge Optimization","A. Thaqi; A. Musa; B. Rexha","Dept. of Computer Engineering, University of Prishtina, Prishtina, Kosovo; Dept. of Computer Engineering, University of Prishtina, Prishtina, Kosovo; Dept. of Computer Engineering, University of Prishtina, Prishtina, Kosovo","2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)","31 Dec 2024","2024","","","1","5","Capture the Flag (CTF) competitions have become integral to developing cybersecurity skills, providing participants with real-world scenarios that challenge their problem-solving abilities. However, the complexity of these challenges often creates barriers for participants, especially those with less experience. This paper explores the potential of leveraging Artificial Intelligence (AI), specifically OpenAI’s Large Language Models (LLMs), to optimize the CTF challenge-solving process. By conducting a comparative study, we analyze how AI can assist participants by offering intelligent hints and personalized suggestions without compromising the integrity of the challenge. Our approach focuses on using pre-trained models to enhance learning outcomes, improve engagement, and streamline problem-solving across different difficulty levels. The results show that AI-driven solutions significantly improve the accessibility and effectiveness of CTF challenges, particularly for novice participants, by creating a more collaborative learning environment. The paper concludes that the integration of AI in CTF competitions can revolutionize cybersecurity education by making it more inclusive and adaptable to a wide range of learners.","","979-8-3503-5286-3","10.1109/CIEES62939.2024.10811132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811132","capture the flag;OpenAI;cyber security","Surveys;Statistical analysis;Federated learning;Large language models;Complexity theory;Problem-solving;Artificial intelligence;Intelligent systems;Optimization;Testing","","","","28","IEEE","31 Dec 2024","","","IEEE","IEEE Conferences"
"Application of Retrieval-Augmented Generation in video","W. Chen; M. Zhou; X. Fan; L. Zhou; S. Zhu; T. Cai","Financial Technology Products Department, China Mobile (Shanghai) Information and Communication Technology Co., Ltd., Shanghai, China; Financial Technology Products Department, China Mobile (Shanghai) Information and Communication Technology Co., Ltd., Shanghai, China; Service Department, GE Medical Systems Trade & Development (Shanghai) Co.Ltd., Shanghai, China; Technology Department, China Mobile (Shanghai) Information and Communication Technology Co., Ltd., Shanghai, China; Technology Department, China Mobile (Shanghai) Information and Communication Technology Co., Ltd., Shanghai, China; Technology Department, China Mobile (Shanghai) Information and Communication Technology Co., Ltd., Shanghai, China",2024 12th International Conference on Information Systems and Computing Technology (ISCTech),"22 Jan 2025","2024","","","1","5","The application of Retrieval-Augmented Generation (RAG) technology in the field of text has become increasingly mature. This paper innovatively proposes a new method for applying RAG technology to video retrieval. The method abandons the traditional retrieval method based on video frame descriptions, which often tends to break the context of the video. This paper proposes a context-aware dynamic fragmenting strategy that can intelligently adjust the fragmenting threshold according to the complexity and amount of information in the video content. In addition, to maximize the preservation of video information and by utilizing QKD (Quantum Key Distribution) quantum encryption technology, this method also performs multimodal feature extraction on video fragments, including audio, visual, and text dimensions, ensuring that the loss of information is minimized and data security.","","979-8-3503-7986-0","10.1109/ISCTech63666.2024.10845649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845649","Large Language models;Retrieval-Augmented Generation;Multimodal;Quantum Encryption","Visualization;Accuracy;Databases;Retrieval augmented generation;Feature extraction;Video surveillance;Vectors;Encryption;Quantum key distribution;Optimization","","","","31","IEEE","22 Jan 2025","","","IEEE","IEEE Conferences"
"Privacy-Diffusion: Privacy-Preserving Stable Diffusion Without FHE and Differential Privacy","P. -C. Hsu; Z. Yu; S. Mise; H. Miyaji","Animechain.ai Inc., Tokyo, Japan; Amazon, Irvine, CA, USA; Animechain.ai Inc., Tokyo, Japan; Department of Information Science and Engineering, Ritsumeikan University, Kusatsu, Japan",IEEE Access,"2 May 2025","2025","13","","75194","75203","Text-to-image generation is trending in the generative artificial intelligence (GenAI) field. Among open-sourced image generation projects, Stable Diffusion is the state-of-the-art. Many artists and service providers customize the diffusion model to generate featured high-quality images. However, there is no protection to the privacy of the input text prompt, output image, and customized model. Privacy is very important since it can increase users’ willingness to use the service and protect the service provider’s intellectual property. Existing privacy-preserving diffusion model require fully homomorphic encryption (FHE) to ensure its privacy and security. Nonetheless, FHE is very time-consuming and may reduce accuracy due to approximations and deteriorate image quality. In this research, we propose Privacy-Diffusion, a privacy-preserving diffusion framework without FHE. By utilizing the irreversible property of neural network layers and the property that the predicted noise in the diffusion process is a normalized Gaussian distribution. Our framework can be applied to all kinds of diffusion models to protect clients’ input text prompt and the generated image from being learned by the server, as well as customized models from being learned by the clients. Our protocol is secure and efficient. Compared with existing research, HE-diffusion, which spent 200% extra time and visible quality loss, our protocol can reach the same security level with only 19% extra time and has no quality loss. To the best of our knowledge, our Privacy-Diffusion is the first protocol that achieves this goal without using FHE and maintain the same high-quality image output as the original model.","2169-3536","","10.1109/ACCESS.2025.3562563","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP24K20774); Support Center for Advanced Telecommunications Technology Research (SCAT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10971394","AI security;privacy ML;stable diffusion;generative AI","Privacy;Protocols;Noise;Computational modeling;Diffusion models;Neural networks;Servers;Accuracy;Quantization (signal);Predictive models","","","","41","CCBYNCND","21 Apr 2025","","","IEEE","IEEE Journals"
"Detecting AI Generated Images Through Texture and Frequency Analysis of Patches","Y. Chen; M. Yashtini","Basis International School Naning, Nanjing, China; Department of Mathematics and Statistics, Georgetown University, Washington DC, USA","2024 4th International Conference on Artificial Intelligence, Virtual Reality and Visualization","4 Feb 2025","2024","","","103","110","The significant improvement in AI image generation in recent years poses serious threats to social security, as AI generated misinformation may infringe upon political stability, personal privacy, and digital copy rights of artists. Building an AI generated image detector that accurately identifies generated image is crucial to maintain the social security and property rights of artists. This paper introduces preprocessing pipeline that uses positional encoded azimuthal integrals for image patches to create fingerprints that encapsulate distinguishing features. We then trained a multi-head attention model with 97.5% accuracy on classification of the fingerprints. The model also achieved 80% accuracy on images generated by AI models not presented in the training dataset, demonstrating the robustness of our pipeline and the potential of broader application of our model.","","979-8-3315-2874-4","10.1109/AIVRV63595.2024.10860248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10860248","Generative AI;Detector;Texture;Frequency;Positional Encoding;Multi-head Attention;AI Security","Training;Solid modeling;Accuracy;Image coding;Computational modeling;Pipelines;Fingerprint recognition;Security;Artificial intelligence;Fake news","","","","31","IEEE","4 Feb 2025","","","IEEE","IEEE Conferences"
"Character-Level Adversarial Samples Generation Method Based on Dual-Layer Text Watermark","H. Wu; X. Li; S. Zhang; H. Zhu","School of Computer and Information Engineering, Bengbu University, Bengbu, China; School of Computer and Information Engineering, Bengbu University, Bengbu, China; School of Computer Science and Engineering, Anhui University of Science and Technology, Huainan, China; School of Computer and Information Engineering, Bengbu University, Bengbu, China",IEEE Access,"7 Aug 2025","2025","13","","136409","136419","Textual adversarial samples are widely used to assess the robustness and security of language models. Most existing methods generate these samples by substitution or deletion. However, such approaches are often easy to detect and show limited attack effectiveness. To address these issues, we propose a character-level adversarial attack framework based on dual-layer watermarking. The method embeds explicit and implicit watermarks in the original text to interfere with downstream models. First, we apply character-level gradient optimization to perturb explicit statistical features. Then, we use reinforcement learning to fine-tune semantic and encoding characteristics, guided by feedback from the target model. This approach ensures that the generated samples significantly reduce the performance of target models while preserving semantic meaning. Experiments on four benchmark datasets show that our method outperforms state-of-the-art baselines. It reduces average word distance (WD) by 12.5%, improves BERTScore by 0.9%, lowers the attack success rate (TMASR) by 11.0%, and increases the concealment rate (Hide) by 5.6%.","2169-3536","","10.1109/ACCESS.2025.3594727","National Natural Science Foundation of China(grant numbers:62076006); University Synergy Innovation Program of Anhui Province(grant numbers:GXXT-2021-008); Opening Foundation of the State Key Laboratory of Cognitive Intelligence(grant numbers:COGOS-2023HE02); Key Scientific Research Projects of Colleges and Universities in Anhui Province(grant numbers:2024AH051167); Funding Project for the Cultivation of Outstanding Talents in Colleges and Universities(grant numbers:gxyqZD2021135); Start Up Funds for the Scientific Research of High-Level Talents of Bengbu University(grant numbers:BBXY2020KYQD02); Open Project of Engineering Research Center of Anhui University of Technology(grant numbers:IASII22-08); Science Research Project of Bengbu University(grant numbers:2024YYX47pj,2024YYX48pj); Anhui Province Excellent Research and Innovation Team in Intelligent Manufacturing and Information Technology(grant numbers:2023AH052938); Anhui Province Science and Technology Specialists in the field of Agricultural Material and Technical Equipment to Unveil the List of Marshal Project(grant numbers:2022296906020001); University Collaborative Innovation Project in Anhui Province(grant numbers:GXXT-2023-105); Bengbu University Natural Science General Project(grant numbers:2024ZR02,2024ZR03,2022ZR02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106449","Large language models;adversarial attacks;adversarial sample generation;dual-layer watermark;text watermark","Watermarking;Perturbation methods;Semantics;Detectors;Optimization;Robustness;Predictive models;Encoding;Reinforcement learning;Distortion","","","","36","CCBY","1 Aug 2025","","","IEEE","IEEE Journals"
"AWEB to Bridge Cybersecurity Attack Patterns and Weaknesses","A. Farhan; M. Rahman; M. Akbar; M. S. Hossain","Computer Science University of Texas at El Paso, El Paso, USA; Computer Science University of Texas at El Paso, El Paso, USA; Computer Science University of Texas at El Paso, El Paso, USA; Computer Science University of Texas at El Paso, El Paso, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","5567","5576","Industrial Control Systems (ICS) are pivotal in critical sectors like energy, transportation, and manufacturing. However, their increasing interconnectivity and complex digital environment have amplified cyber threat risks. Ensuring cyber resilience for ICS requires not just the use of current security management tools to address existing threats, but also a forward-thinking approach to anticipating and mitigating future risks. This paper proposes a novel concept: the Attack-Weakness Embedding Bridge (AWEB), which leverages separate graph structures and textual data from MITRE ATT&CK and CWE to create a unified analytical space. AWEB has the potential to discover previously unrecognized relationships between system weaknesses and attack patterns, significantly enhancing cybersecurity defenses. The model has the flexibility of leveraging fine-tuned or pre-trained LLM embeddings to capture the nuances of the two datasets. The experimental results demonstrate that our proposed model effectively brings attack patterns and common weaknesses in a mathematical space, providing valuable insights for cybersecurity practitioners.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825621","Large Language Models;Embeddings;Neural Network;Industrial Control Systems;Cybersecurity","Bridges;Soft sensors;Security management;Retrieval augmented generation;Transportation;Feature extraction;Mathematical models;Data models;Computer security;Resilience","","","","31","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation","C. Cabrera; A. Paleyes; N. D. Lawrence","Department of Computer Science and Technology, University of Cambridge, United Kingdom; Department of Computer Science and Technology, University of Cambridge, United Kingdom; Department of Computer Science and Technology, University of Cambridge, United Kingdom",2024 IEEE/ACM International Workshop New Trends in Software Architecture (SATrends),"10 Sep 2024","2024","","","5","9","Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems’ complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems’ responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems’ performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems’ interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.CCS CONCEPTS• Software and its engineering → Designing software; Automatic programming; Software evolution.","","979-8-4007-0560-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669875","Autonomous Systems;Software Engineering;Knowledge Graphs;Data-Oriented Architectures;Large Language Models","Software architecture;Source coding;Natural languages;Prototypes;Software systems;Market research;Complexity theory","","","","40","CCBY","10 Sep 2024","","","IEEE","IEEE Conferences"
"Reliable and Fault-Tolerant IoT-Edge Architecture","J. Grover; R. M. Garimella","Signal Processing and Communication Research Center, International Institute of Information Technology, Hyderabad; Signal Processing and Communication Research Center, International Institute of Information Technology, Hyderabad",2018 IEEE SENSORS,"27 Dec 2018","2018","","","1","4","Edge computing has emerged as an effective solution for delay sensitive IoT applications. In the edge-cloud hierarchy, reliability and fault tolerance are important issues. This paper proposes a novel agent-based reliable and fault-tolerant hierarchical IoT-cloud architecture which can survive the failures of the edge servers. In the proposed architecture, the cloud is distributed over four levels (cloud-fog-mist-dew) based on the processing power and distance from the end IoT device. It makes the whole system reliable by replicating the data on the edge of the network. The proposed system is fault tolerant as it redirects the application on an alternate server. In case of a server's failure, redirection is done at the best possible level in the hierarchy, based on delay-tolerance of the IoT application. The application keeps on working even if the system fails on any level, on cloud, fog or mist. The solution is proposed using mobile agents (MAs) on servers to share systems' state and other important information with other agents in the hierarchy, to be used for application redirection in case of server's failure. The proposed system is simulated using Matlab and results prove its efficiency.","2168-9229","978-1-5386-4707-3","10.1109/ICSENS.2018.8589624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8589624","Edge Computing;Real-time IoT;Reliability;Fault Tolerance;Fault Localization;Cloud;Mobile Agent","Servers;Cloud computing;Fault tolerance;Fault tolerant systems;Computer architecture;Edge computing","","36","","22","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"Implementation of Decentralized Reinforcement Learning-Based Multi-Quadrotor Flocking","P. Abichandani; C. Speck; D. Bucci; W. Mcintyre; D. Lobo","Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA; Lockheed Martin Advanced Technology Laboratories, Cherry Hill, NJ, USA; Lockheed Martin Advanced Technology Laboratories, Cherry Hill, NJ, USA; Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA",IEEE Access,"1 Oct 2021","2021","9","","132491","132507","Enabling coordinated motion of multiple quadrotors is an active area of research in the field of small unmanned aerial vehicles (sUAVs). While there are many techniques found in the literature that address the problem, these studies are limited to simulation results and seldom account for wind disturbances. This paper presents the experimental validation of a decentralized planner based on multi-objective reinforcement learning (RL) that achieves waypoint-based flocking (separation, velocity alignment, and cohesion) for multiple quadrotors in the presence of wind gusts. The planner is learned using an object-focused, greatest mass, state-action-reward-state-action (OF-GM-SARSA) approach. The Dryden wind gust model is used to simulate wind gusts during hardware-in-the-loop (HWIL) tests. The hardware and software architecture developed for the multi-quadrotor flocking controller is described in detail. HWIL and outdoor flight tests results show that the trained RL planner can generalize the flocking behaviors learned in training to the real-world flight dynamics of the DJI M100 quadrotor in windy conditions.","2169-3536","","10.1109/ACCESS.2021.3115711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548090","Cooperative systems;design for experiments;unmanned aerial vehicles;multi-agent systems;motion planning;supervised learning","Wind;Heuristic algorithms;Atmospheric modeling;Software algorithms;Mathematical models;Birds","","10","","88","CCBY","24 Sep 2021","","","IEEE","IEEE Journals"
"Employing Agent Beliefs during Fault Diagnosis for IEC 61499 Industrial Cyber-Physical Systems","B. Dowdeswell; R. Sinha; D. Jarvis; J. Jarvis; S. G. MacDonell","Computing and Mathematical Sciences, School of Engineering, Auckland University of Technology, Auckland, New Zealand; Computing and Mathematical Sciences, School of Engineering, Auckland University of Technology, Auckland, New Zealand; School of Engineering and Technology, Central Queensland University, Brisbane, Australia; School of Engineering and Technology, Central Queensland University, Brisbane, Australia; Computing and Mathematical Sciences, School of Engineering, Auckland University of Technology, Auckland, New Zealand",IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society,"18 Nov 2020","2020","","","2189","2194","We have come to rely on industrial-scale cyber-physical systems more and more to manage tasks and machinery in safety-critical situations. Efficient, reliable fault identification and management has become a critical factor in the design of these increasingly sophisticated and complex devices.Teams of co-operating software agents are one way to co-ordinate the flow of diagnostic information gathered during fault-finding. By wielding domain knowledge of the software architecture used to construct the system, agents build and refine their beliefs about the location and root cause of faults.This paper examines how agents constructed within the GORITE Multi-Agent Framework create and refine their beliefs. We demonstrate three different belief structures implemented within our Fault Diagnostic Engine, showing how each supports a distinct aspect of the agent's reasoning. Using domain knowledge of the IEC 61499 Function Block architecture, agents are able to examine and rigorously evaluate both individual components and entire sub-systems.","2577-1647","978-1-7281-5414-5","10.1109/IECON43393.2020.9254877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254877","Fault Diagnostics;Multi-Agent Systems;GORITE;Industrial Cyber-Physical Systems;IEC 61499 Function Blocks","IEC Standards;Temperature sensors;HVAC;Task analysis;Multi-agent systems;Actuators;Navigation","","1","","21","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Leveraging Transformer Models for Anti-Jamming in Heavily Attacked UAV Environments","I. Elleuch; A. Pourranjbar; G. Kaddoum","Resilient Machine learning Institute, École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; Resilient Machine learning Institute, École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; Resilient Machine learning Institute, École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada",IEEE Open Journal of the Communications Society,"5 Sep 2024","2024","5","","5337","5347","In recent years, due to their ability to transmit and relay wireless signals in challenging terrains, Unmanned Aerial Vehicles (UAVs) and High Altitude Platform Stations (HAPS) have become indispensable in various operations in security, emergency, and military campaigns. However, these networks’ ad-hoc structure and open nature make them highly vulnerable to numerous threats and, in particular, to severe jamming attacks. Furthermore, the communication link between a HAPS and multiple UAVs is also under the threat of multiple and different jamming attacks. Addressing these challenges requires innovative and novel methods capable of interactive and proactive defence strategies. To this end, in this study, we propose a method that combines a pseudo-random (PR) algorithm for initial channel selection with a Transformer-based module to predict jammer behavior. This proactive approach significantly enhances the robustness of UAV communications. Our results demonstrate substantial improvements in transmission success rates and prediction accuracy, offering a robust solution for secure UAV and HAPS communications under adverse conditions.","2644-125X","","10.1109/OJCOMS.2024.3451288","National Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:CRDPJ 538896-19); ULTRA TCS Research Chair on Intelligent Tactical Wireless Networks for Challenging Environments; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654316","Anti-jamming;smart jamming;multiple-jamming;transformer;LSTM;UAVs;HAPS","Jamming;Transformers;Autonomous aerial vehicles;Predictive models;Prediction algorithms;Ad hoc networks;Communication system security","","1","","34","CCBYNCND","28 Aug 2024","","","IEEE","IEEE Journals"
"FactionFormer: Context-Driven Collaborative Vision Transformer Models for Edge Intelligence","S. T. Nimi; M. Adnan Arefeen; M. Y. Sarwar Uddin; B. Debnath; S. Chakradhar","University of Missouri-Kansas City, Missouri, USA; University of Missouri-Kansas City, Missouri, USA; University of Missouri-Kansas City, Missouri, USA; NEC Laboratories America, New Jersey, USA; NEC Laboratories America, New Jersey, USA",2023 IEEE International Conference on Smart Computing (SMARTCOMP),"7 Aug 2023","2023","","","349","354","Edge Intelligence has received attention in the recent times for its potential towards improving responsiveness, reducing the cost of data transmission, enhancing security and privacy, and enabling autonomous decisions by edge devices. However, edge devices lack the power and compute resources necessary to execute most Al models. In this paper, we present FactionFormer, a novel method to deploy resource-intensive deep-learning models, such as vision transformers (ViT), on resource-constrained edge devices. Our method is based on a key observation: edge devices are often deployed in settings where they encounter only a subset of the classes that the resource-intensive Al model is trained to classify, and this subset changes across deployments. Therefore, we automatically identify this subset as a faction, devise on-the fly a bespoke resource-efficient ViT called a modelette for the faction, and set up an efficient processing pipeline consisting of a modelette on the device, a wireless network such as 5G, and the resource-intensive ViT model on an edge server, all of which work collaboratively to do the inference. For several ViT models pre-trained on benchmark datasets, FactionFormer’s modelettes are up to 4× smaller than the corresponding baseline models in terms of the number of parameters, and they can infer up to 2.5× faster than the baseline setup where every input is processed by the resource-intensive ViT on the edge server. Our work is the first of its kind to propose a device-edge collaborative inference framework where bespoke deep learning models for the device are automatically devised on-the-fly for most frequently encountered subset of classes.","2693-8340","979-8-3503-2281-1","10.1109/SMARTCOMP58114.2023.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10207673","Vision Transformer;Collaborative Inference;Edge AI","Runtime;Computational modeling;Wireless networks;Pipelines;Collaboration;Transformers;Servers","","1","","10","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"Model Editing for LLMs4Code: How Far are we?","X. Li; S. Wang; S. Li; J. Ma; J. Yu; X. Liu; J. Wang; B. Ji; W. Zhang","College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","937","949","Large Language Models for Code (LLMs4Code) have been found to exhibit outstanding performance in the software engineering domain, especially the remarkable performance in coding tasks. However, even the most advanced LLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to the high cost of training LLMs4Code, it is impractical to re-train the models for fixing these problematic code knowledge. Model editing is a new technical field for effectively and efficiently correcting erroneous knowledge in LLMs, where various model editing techniques and benchmarks have been proposed recently. Despite that, a comprehensive study that thoroughly compares and analyzes the performance of the state-of-the-art model editing techniques for adapting the knowledge within LLMs4Code across various code-related tasks is notably absent. To bridge this gap, we perform the first systematic study on applying state-of-the-art model editing approaches to repair the inaccuracy of LLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consists of two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples and CodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the help of CLMEEval, we evaluate six advanced model editing techniques on three LLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findings include that the external memorization-based GRACE approach achieves the best knowledge editing effectiveness and specificity (the editing does not influence untargeted knowledge), while generalization (whether the editing can generalize to other semantically-identical inputs) is a universal challenge for existing techniques. Furthermore, building on in-depth case analysis, we introduce an enhanced version of GRACE called A-GRACE, which incorporates contrastive learning to better capture the semantics of the inputs. Results demonstrate that A-GRACE notably enhances generalization while maintaining similar levels of effectiveness and specificity compared to the vanilla GRACE.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00049","Hunan Provincial Natural Science Foundation Projects(grant numbers:2022JJ30668,2022JJ30046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029902","LLMs4Code;Model Editing;Code Generation;Code Summarization","Training;Adaptation models;Codes;Systematics;Large language models;Semantics;Benchmark testing;Maintenance engineering;Encoding;Software engineering","","1","","70","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"LLMSQLi: A Black-Box Web SQLi Detection Tool Based on Large Language Model","T. Yang; Z. Jiang; Y. Wang","College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China",2024 5th International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE),"26 Nov 2024","2024","","","629","633","Black box detection tools of SQL injection vulnerabilities simulate real-world web attack scenarios, making it essential for evaluating SQLi risks in actual web applications. However, current black-box approaches depend on predefined rules for SQLi vulnerability detection, which limits both their efficiency and accuracy. In this paper, we propose a black-box SQLi detection tool based on large language multi-agent, LLMSQLi, which uses the context understanding and reasoning capabilities of large language models and the cooperative division of labor mode of multi-agent to generate payloads customized for test targets and efficiently detect SQL injection vulnerabilities in Web programs. Drawing inspiration from real-world teams of security experts, LLMSQLi simulates the step-by-step process of human experts in testing tasks through the LLM Muti-Agent collaboration model. We ran experiments on SQLiMicroBenchmark to compare the performance of LLMSQLi and two of the most advanced black-box SQLi testing tools. Experiments show that LLMSQLi successfully detected all 15 targets and outperformed other tools.","","979-8-3315-0661-2","10.1109/ICBASE63199.2024.10762654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10762654","SQLi detection;Web Security;Large Language Model;Multi Agents","Accuracy;Large language models;Closed box;Collaboration;SQL injection;Cognition;Security;Testing;Payloads;Software engineering","","1","","15","IEEE","26 Nov 2024","","","IEEE","IEEE Conferences"
"From Natural Language to Code: AI Automation in Cyber-Physical Manufacturing Systems","A. Boudribila; A. Tajer; Z. Boulghasoul","Systems Engineering and Applications Laboratory, Cadi Ayyad University, ENSA; Systems Engineering and Applications Laboratory, Cadi Ayyad University, ENSA; Systems Engineering and Applications Laboratory, Cadi Ayyad University, ENSA",2024 World Conference on Complex Systems (WCCS),"2 Dec 2024","2024","","","1","6","The complexity of modern manufacturing systems necessitates advanced control programs, yet traditional heuristic and formal methods are hindered by being error-prone, time-consuming, and complex. This paper proposes an AI-driven approach to automate control program development for Cyber-Physical Manufacturing Systems (CPMS). Using Natural Language Processing (NLP), our system converts user-defined natural language requirements into executable control code. We developed the AutoFactory dataset using Large Language Models (LLMs) to capture diverse manufacturing requirements. We fine-tuned the BERT model to accurately extract key components such as actuators, sensors, and pre-actuators from these specifications. Our approach aims to fully automate the transition from informal requirements to formal control programs, significantly reducing the need for manual intervention and minimizing human error. Future work includes developing a library of code for each component, enabling automatic code generation without requiring prior experience with PLC programming languages. This method leverages the speed and efficiency of computers to generate accurate control code swiftly, democratizing control program development and paving the way for more efficient, reliable, and scalable manufacturing systems.","","979-8-3315-1913-1","10.1109/WCCS62745.2024.10765530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765530","Cyber-Physical Manufacturing Systems;Natural Language Processing;BERT;Code generation;Data generation;Manufacturing;Industrial automation;PLC programming;Control program","Codes;Computational modeling;Large language models;Process control;Manuals;Libraries;Natural language processing;Sensors;Reliability;Manufacturing systems","","","","13","IEEE","2 Dec 2024","","","IEEE","IEEE Conferences"
"Research Report: AI Security is a LangSec Problem","M. Von Hippel; E. Miyazono","Benchify, Inc, San Francisco, USA; Atlas Computing, San Francisco, USA",2025 IEEE Security and Privacy Workshops (SPW),"3 Jul 2025","2025","","","73","78","The rapid development of Artificial Intelligence (AI) systems, and particularly Large Language Models (LLMs), has already started changing how software is written in industry. In this work, we categorize two important features of modern AI systems - structured outputs and tool-use - and explain how the security of each is, inherently, a LangSec problem. We provide anecdotal evidence from the San Francisco startup ecosystem to illustrate how companies are currently using, deploying, and securing AI systems with these features. Based on these observations and our analysis of current practices, we identify three concrete research directions where the LangSec community can contribute to securing both the parsing of LLM outputs and the safe deployment of LLM-powered tools. This work should be read as a call-to-action for the LangSec community to tackle outstanding, and growing, security problems catalyzed by AI.","2770-8411","979-8-3315-6643-2","10.1109/SPW67851.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050820","langsec;llm;formal methods;parser","Industries;Privacy;Large language models;Customer services;Ecosystems;Programming;Software systems;Security;Reliability;Software development management","","","","52","IEEE","3 Jul 2025","","","IEEE","IEEE Conferences"
"Cyber Attack Prediction: From Traditional Machine Learning to Generative Artificial Intelligence","S. Ankalaki; A. R. Atmakuri; M. Pallavi; G. S. Hukkeri; T. Jan; G. R. Naik","Department of Computer Science and Engineering, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India; Department of CSE, SoET, Centurion University of Technology and Management, Bhubaneswar, Odisha, India; School of Computer Science and Engineering, Presidency University, Bengaluru, India; Department of Computer Science and Engineering, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India; Centre for Artificial Intelligence Research and Optimization (AIRO), Design and Creative Technology Vertical, Torrens University, Ultimo, NSW, Australia; Centre for Artificial Intelligence Research and Optimization (AIRO), Design and Creative Technology Vertical, Torrens University, Ultimo, NSW, Australia",IEEE Access,"14 Mar 2025","2025","13","","44662","44706","The escalating sophistication of cyber threats poses significant risks to individuals, organizations, and nations. Cybercrime, encompassing activities like hacking and data breaches, has severe economic and societal consequences. In today’s interconnected world, robust cybersecurity measures are paramount to mitigate these risks and protect sensitive information. However, traditional security solutions struggle to keep pace with the evolving threat landscape. Artificial Intelligence (AI) offers a powerful arsenal of techniques to address these challenges. This paper explores the application of AI methods, including Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Explainable AI (XAI), and Generative AI, in solving various cybersecurity problems. This paper presents a comprehensive analysis of AI techniques for enhancing cybersecurity. Key contributions include: 1) comparative study of ML and DL methods: Evaluating their accuracy, applicability, and suitability for various cybersecurity challenges; 2) investigation into XAI approaches: Enhancing the transparency and interpretability of AI-powered security solutions, particularly in anomaly detection; 3) exploration of emerging trends in Generative AI (Gen-AI) and NLP: Examining their potential to simulate and mitigate cyber threats through advanced techniques like threat intelligence generation and attack simulations; 4) application of GenAI in cybersecurity and real-world products of GenAI for cyber security. This research aims to advance the state-of-the-art in AI-driven cybersecurity by providing insights into effective and reliable solutions for mitigating cyber risks and improving the overall security posture.","2169-3536","","10.1109/ACCESS.2025.3547433","Manipal Academy of Higher Education (Open Access Funding); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10909100","Cybersecurity;cyber-attack prediction;machine learning;deep learning;explainable AI;generative AI","Artificial intelligence;Computer security;Security;Cyberattack;Explainable AI;Generative AI;Ransomware;Deep learning;Chatbots;Accuracy","","4","","247","CCBY","3 Mar 2025","","","IEEE","IEEE Journals"
"A Functional Software Reference Architecture for LLM-Integrated Systems","A. Bucaioni; M. Weyssow; J. He; Y. Lyu; D. Lo",Mälardalen University (Sweden); Singapore Management University (Singapore); Singapore Management University (Singapore); Singapore Management University (Singapore); Singapore Management University (Singapore),2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C),"30 May 2025","2025","","","1","5","The integration of large language models into software systems is transforming capabilities such as natural language understanding, decision-making, and autonomous task execution. However, the absence of a commonly accepted software reference architecture hinders systematic reasoning about their design and quality attributes. This gap makes it challenging to address critical concerns like privacy, security, modularity, and interoperability, which are increasingly important as these systems grow in complexity and societal impact. In this paper, we describe our emerging results for a preliminary functional reference architecture as a conceptual framework to address these challenges and guide the design, evaluation, and evolution of large language model-integrated systems. We identify key architectural concerns for these systems, informed by current research and practice. We then evaluate how the architecture addresses these concerns and validate its applicability using three open-source large language model-integrated systems in computer vision, text processing, and coding.","2768-4288","979-8-3315-3336-6","10.1109/ICSA-C65153.2025.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015032","Software reference architecture;functional reference architecture;LLMs","Privacy;Systematics;Software architecture;Computational modeling;Large language models;Computer architecture;Software systems;Natural language processing;Security;Text processing","","","","27","IEEE","30 May 2025","","","IEEE","IEEE Conferences"
"DS-GCG: Enhancing LLM Jailbreaks with Token Suppression and Induction Dual-Strategy","X. Tang; X. Yang; Z. Yao; J. Wen; X. Zhou; J. Han; S. Hu","Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences",2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"23 Jun 2025","2025","","","273","278","In intelligent collaborative systems, the role of Large Language Models (LLMs) is becoming increasingly significant, with their security and privacy being of paramount importance. Greedy Coordinate Gradient (GCG)-based adversarial approaches are a staple in red team testing for circumventing the security alignments of LLMs. Yet, these methods are challenged by issues such as convergence difficulties and pseudo-evasion, which can impede attack efficacy. Our research indicates that the high likelihood of rejection tokens appearing in the initial k positions of generated text is a major contributor to adversarial failures, and their suppression can significantly improve attack success rates. Building on these insights, we present DS-GCG, an innovative adversarial attack methodology that enhances GCG attack potency. It employs adjustable-position prefilling to quell refusal responses and incite harmful outputs, coupled with a bidirectional greedy gradient search to swiftly identify adversarial suffixes. DS-GCG's universal suffix approach not only mitigates refusals but also hastens convergence, offering an efficient and robust search strategy. Our experimental results on widely-used open-source LLMs, showcased on the AdvBench dataset, confirm the cutting-edge performance of DS-GCG.","2768-1904","979-8-3315-1305-4","10.1109/CSCWD64889.2025.11033375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033375","LLM Security;Adversarial Attack;Jailbreak","Privacy;Gradient methods;Federated learning;Large language models;Collaboration;Search problems;Filling;Computer security;Convergence;Testing","","","","24","IEEE","23 Jun 2025","","","IEEE","IEEE Conferences"
"The Causal Reasoning Ability of Open Large Language Model: A Comprehensive and Exemplary Functional Testing","S. -H. Li; G. Zhou; Z. -B. Li; J. -C. Lu; N. -B. Huang","State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","25 Dec 2023","2023","","","240","249","As the intelligent software, the development and application of large language models are extremely hot topics recently, bringing tremendous changes to general AI and software industry. Nonetheless, large language models, especially open source ones, incontrollably suffer from some potential software quality issues such as instability, inaccuracy, and insecurity, making software testing necessary. In this paper, we propose the first solution for functional testing of open large language models to check full-scene availability and conclude empirical principles for better steering large language models, particularly considering their black box and intelligence properties. Specifically, we focus on the model’s causal reasoning ability, which is the core of artificial intelligence but almost ignored by most previous work. First, for comprehensive evaluation, we deconstruct the causal reasoning capability into five dimensions and summary the forms of causal reasoning task as causality identification and causality matching. Then, rich datasets are introduced and further modified to generate test cases along with different ability dimensions and task forms to improve the testing integrity. Moreover, we explore the ability boundary of open large language models in two usage modes: prompting and lightweight fine-tuning. Our work conducts comprehensive functional testing on the causal reasoning ability of open large language models, establishes benchmarks, and derives empirical insights for practical usage. The proposed testing solution can be transferred to other similar evaluation tasks as a general framework for large language models or their derivations.","2693-9177","979-8-3503-1958-3","10.1109/QRS60937.2023.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366620","open large language model;causal reasoning;black-box testing;prompt design;lightweight fine-tuning","Software testing;Sensitivity;Training data;Software quality;Cognition;Data models;Software reliability","","5","","37","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Path Planning and Formation Control for Multiple Quadrotor UAV Leader-Follower Systems","A. Amangeldi; S. Kusdavletov","Department of Intelligent Systems and Cybersecurity, Astana IT University, Astana, Kazakhstan; Department of Intelligent Systems and Cybersecurity, Astana IT University, Astana, Kazakhstan","2023 11th International Conference on Control, Mechatronics and Automation (ICCMA)","1 Jan 2024","2023","","","109","114","This paper investigates the formation control system design for multiple quadcopters with path planning for territory surveillance. The development is manifested with nonlinear dynamic modelling, position and attitude control of the quadrotor UAVs followed by leader-follower formation control for multi-drone systems operated with Rapidly-exploring Random Trees (RRT) based path planner. The simulated experimental validation demonstrates practical potential of the proposed framework.","2837-5149","979-8-3503-1568-4","10.1109/ICCMA59762.2023.10374652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374652","Formation control;UAVs;RRT;Multi-agent systems","Mechatronics;Surveillance;Autonomous aerial vehicles;Formation control;Robustness;Trajectory;Nonlinear dynamical systems","","2","","9","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"CoqPilot, a plugin for LLM-based generation of proofs","A. Kozyrev; G. Solovev; N. Khramov; A. Podkopaev","JetBrains Research Germany, Constructor University, Bremen, Germany; JetBrains Research Germany, Constructor University, Bremen, Germany; JetBrains Research Germany, Constructor University, Bremen, Germany; JetBrains Research the Netherlands, Constructor University, Bremen, Germany",2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"29 Nov 2024","2024","","","2382","2385","We present CoqPilot, a VS Code extension designed to help automate writing of Coq proofs. The plugin collects the parts of proofs marked with the admit tactic in a Coq file, i.e., proof holes, and combines LLMs along with non-machine-learning methods to generate proof candidates for the holes. Then, CoqPilot checks if each proof candidate solves the given subgoal and, if successful, replaces the hole with it. The focus of CoqPilot is twofold. Firstly, we want to allow users to seamlessly combine multiple Coq generation approaches and provide a zero-setup experience for our tool. Secondly, we want to deliver a platform for LLM-based experiments on Coq proof generation. We developed a benchmarking system for Coq generation methods, available in the plugin, and conducted an experiment using it, showcasing the framework’s possibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo. Code at: https://github.com/JetBrains-Research/coqpilot","2643-1572","979-8-4007-1248-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764899","LLM;Coq;code generation","Codes;Switches;Writing;Benchmark testing;Software engineering","","","","20","","29 Nov 2024","","","IEEE","IEEE Conferences"
"FUR-API: Dataset and Baselines Toward Realistic API Anomaly Detection","Y. Liu; H. Yu; F. Dai; X. Gu; C. Cui; B. Li; W. Wang","Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","4525","4529","The Application Program Interface (API) security is crucial for data security as it ensures the safety and authority of data exchange between different applications. However, the absence of high-quality datasets significantly impedes the development of API anomaly detection. This paper presents a benchmark dataset and baselines for realistic API anomaly detection involving few-shot and unknown-risk scenarios. The dataset is synthesized using an Iterative data Generation approach with Dual-channel Filtering (IGDF). By leveraging large language models and dual-channel filtering models, we can iteratively generate and filter data, yielding a high-quality dataset. Moreover, we have developed baselines and conducted extensive experiments on the proposed dataset. The results indicate that few-shot and unknown-risk API anomaly detection remains a challenging task and still requires further research. All details and resources are released at https://github.com/yijunL/FUR-API.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10446512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446512","Data security;API anomaly detection;Large language model","Filtering;Benchmark testing;Signal processing;Data models;Safety;Iterative methods;Task analysis","","1","","21","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"Cognitive Large Language Model in Social Media with Local Memory","V. N; A. Vijayaraj; V. P. Murugan; R. Jebakumar; N. Mageshkumar; R. Megavannan","Department of IT, R.M.K. Engineering College, Chennai; Department of IT, R.M.K. Engineering College, Chennai; Department of Mathematics, Panimalar Engineering College, Chennai; Department of Computing Technologies, SRM Institute of Science and Technology, Chennai; Department of Computer Science and Technology, Madanapalle Institute of Technology & Science, Andhra Pradesh; Faculty of Management, SRM Institute of Science and Technology","2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)","29 May 2025","2025","","","1","5","Enter the era of social media reimagined! This research taps into an interesting combination of advanced Artificial Intelligence, with large language models such as ChatGPT and GEMINI your favorite social platform. Personal information of each user is armed with voice commands and LLM. But this is the first. LLM talk to each other, exchange information. face recognition adds an extra layer in the mass layer the excitement of your Chatbot sharing only the right information Your account security level private, reserved or public. When it comes to security. We got you covered Choose between playing low key or just sharing just the right number of juicy details. Plus, all the classic features It's still fun, like scrolls and scrolls.","","979-8-3315-3755-5","10.1109/ICDSAAI65575.2025.11011588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011588","Artificial Intelligence;Large Language Model;Face Recognition;social media;Personalization;Security;chatbot","Social networking (online);Large language models;Face recognition;Oral communication;Chatbots;Security","","","","20","IEEE","29 May 2025","","","IEEE","IEEE Conferences"
"Work in Progress: AI-Powered Engineering-Bridging Theory and Practice","O. Levy; I. Dikman; N. Levy; M. Winokur","Faculty of Industrial Eng. and Technology Management, HIT, Holon, Israel; Faculty of Industrial Eng. and Technology Management, HIT, Holon, Israel; Dept. Computer Science, HUJI, Jerusalem, Israel; Faculty of Industrial Eng. and Technology Management, HIT, Holon, Israel",2025 IEEE Engineering Education World Conference (EDUNINE),"5 May 2025","2025","","","1","4","This paper explores how generative AI can help automate and improve key steps in systems engineering. It examines AI's ability to analyze system requirements based on INCOSE’s ""good requirement"" criteria, identifying well-formed and poorly written requirements. The AI does not just classify requirements but also explains why some do not meet the standards. By comparing AI assessments with those of experienced engineers, the study evaluates the accuracy and reliability of AI in identifying quality issues. Additionally, it explores AI’s ability to classify functional and non-functional requirements and generate test specifications based on these classifications. Through both quantitative and qualitative analysis, the research aims to assess AI’s potential to streamline engineering processes and improve learning outcomes. It also highlights the challenges and limitations of AI, ensuring its safe and ethical use in professional and academic settings.","","979-8-3315-4278-8","10.1109/EDUNINE62377.2025.10981330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981330","AI technology in Systems Engineering;Requirements Engineering;Quality Criteria for Requirements;Safe AI;AI enhanced test generation","Ethics;Educational programs;Generative AI;Reliability engineering;Safety;Test pattern generators;Requirements engineering;Artificial intelligence;Engineering education;Standards","","","","17","IEEE","5 May 2025","","","IEEE","IEEE Conferences"
"RECOVER: Toward Requirements Generation From Stakeholders’ Conversations","G. Voria; F. Casillo; C. Gravino; G. Catolino; F. Palomba","Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy",IEEE Transactions on Software Engineering,"23 Jun 2025","2025","51","6","1912","1933","Stakeholders’ conversations requirements elicitation meetings hold valuable insights into system and client needs. However, manually extracting requirements is time-consuming, labor-intensive, and prone to errors and biases. While current state-of-the-art methods assist in summarizing stakeholder conversations and classifying requirements based on their nature, there is a noticeable lack of approaches capable of both identifying requirements within these conversations and generating corresponding system requirements. These approaches would assist requirement identification, reducing engineers’ workload, time, and effort. They would also enhance accuracy and consistency in documentation, providing a reliable foundation for further analysis. To address this gap, this paper introduces RECOVER (Requirements EliCitation frOm conVERsations), a novel conversational requirements engineering approach that leverages natural language processing and large language models (LLMs) to support practitioners in automatically extracting system requirements from stakeholder interactions by analyzing individual conversation turns. The approach is evaluated using a mixed-method research design that combines statistical performance analysis with a user study involving requirements engineers, targeting two levels of granularity. First, at the conversation turn level, the evaluation measures RECOVER’s accuracy in identifying requirements-relevant dialogue and the quality of generated requirements in terms of correctness, completeness, and actionability. Second, at the entire conversation level, the evaluation assesses the overall usefulness and effectiveness of RECOVER in synthesizing comprehensive system requirements from full stakeholder discussions. Empirical evaluation of RECOVER shows promising performance, with generated requirements demonstrating satisfactory correctness, completeness, and actionability. The results also highlight the potential of automating requirements elicitation from conversations as an aid that enhances efficiency while maintaining human oversight.","1939-3520","","10.1109/TSE.2025.3572056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008757","Conversational requirements engineering;automated software engineering;natural language processing","Oral communication;Stakeholders;Requirements engineering;Accuracy;Machine learning;Large language models;Data mining;Software engineering;Focusing;Documentation","","","","56","IEEE","21 May 2025","","","IEEE","IEEE Journals"
"Understanding and Enhancing Attribute Prioritization in Fixing Web UI Tests with LLMs","Z. Xu; Q. Li; S. H. Tant","Concordia University, Canada; Concordia University, Canada; Concordia University, Canada","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","326","337","The rapid evolution of Web UI incurs time and effort in UI test maintenance. Prior techniques in Web UI test repair focus on locating the target elements on the new Webpage that match the old ones so that the corresponding broken statements can be repaired. These techniques usually rely on prioritizing certain attributes (e.g., XPath) during matching where the similarity of certain attributes is ranked before other attributes, indicating that there may be bias towards certain attributes during matching. To mitigate the bias, we present the first study that investigates the feasibility of using prior Web UI repair techniques for initial matching and then using ChatGPT to perform subsequent matching. Our key insight is that given a list of elements matched by prior techniques, ChatGPT can leverage language understanding to perform subsequent matching and use its code generation model for fixing the broken statements. To mitigate hallucination in ChatGPT, we design an explanation validator that checks if the provided explanation for the matching results is consistent, and provides hints to ChatGPT via a self-correction prompt to further improve its results. Our evaluation on a widely used dataset shows that the ChatGPT-enhanced techniques improve the effectiveness of existing Web test repair techniques. Our study also shares several important insights in improving future Web UI test repair techniques.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10989008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989008","Web UI Test Repair;Test Maintenance;UI Element Matching","Software testing;Codes;Maintenance engineering;Chatbots;Maintenance","","1","","55","IEEE","20 May 2025","","","IEEE","IEEE Conferences"
"Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge","W. Fu; S. Li; Y. Zhao; H. Ma; R. Dutta; X. Zhang; K. Yang; Y. Jin; X. Guo",Kansas State University; University of Science and Technology of China; University of Science and Technology of China; Tianjin University; Silicon Assurance; Washington University in St. Louis; Michigan Technological University; University of Science and Technology of China; Kansas State University,2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC),"25 Mar 2024","2024","","","349","354","In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware-specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi-1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset—comprising small, medium, and large subsets—and focused our efforts on pretraining using the medium dataset. This approach harnesses the compact yet efficient architecture of the Phi-1.5B model. The creation of this first pre-trained, hardware domain-specific large language model marks a significant advancement, offering improved performance in hardware design and verification tasks and illustrating a promising path forward for AI applications in the semiconductor sector.","2153-697X","979-8-3503-9354-5","10.1109/ASP-DAC58780.2024.10473927","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473927","Large Language Model;Hardware Design;Hardware Verification;Generative AI","Semiconductor device modeling;Design automation;Electronics industry;Natural languages;Computer architecture;Hardware;Software","","9","","37","IEEE","25 Mar 2024","","","IEEE","IEEE Conferences"
"Generative AI-Enabled Blockchain Networks: Fundamentals, Applications, and Case Study","C. T. Nguyen; Y. Liu; H. Du; D. T. Hoang; D. Niyato; D. N. Nguyen; S. Mao","Institute of Fundamental and Applied Sciences, Duy Tan University, Ho Chi Minh City, Vietnam; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA",IEEE Network,"17 Mar 2025","2025","39","2","232","241","Generative Artificial Intelligence (GAI) has recently emerged as a promising solution to address critical challenges of blockchain technology, including scalability, security, privacy, and interoperability. In this paper, we first introduce GAI techniques, outline their applications, and discuss existing solutions for integrating GAI into blockchains. Then, we discuss emerging solutions that demonstrate the effectiveness of GAI in addressing various challenges of blockchain, such as detecting unknown blockchain attacks and smart contract vulnerabilities, designing key secret sharing schemes, and enhancing privacy. Moreover, we present a case study to demonstrate that GAI, specifically the generative diffusion model, can be employed to optimize blockchain network performance metrics. Experimental results clearly show that, compared to a baseline traditional AI approach, the proposed generative diffusion model approach can converge faster, achieve higher rewards, and significantly improve the throughput and latency of the blockchain network. Additionally, we highlight future research directions for GAI in blockchain applications, including personalized GAI-enabled blockchains, GAI-blockchain synergy, and privacy and security considerations within blockchain ecosystems.","1558-156X","","10.1109/MNET.2024.3412161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552807","Generative Artificial Intelligence;Blockchain;Variational Autoencoder;Generative Adversarial Network;Generative Diffusion Model;Large Language Model","Blockchains;Smart contracts;Security;Consensus protocol;Scalability;Privacy;Data privacy;Generative AI;Autoencoders;Large language models","","14","","15","IEEE","11 Jun 2024","","","IEEE","IEEE Magazines"
"Exploring ChatGPT's Potential and Concerns in Higher Education","A. Tick","Keleti Károly Faculty of Business and Management, Óbuda University, Budapest, Hungary",2024 IEEE 22nd Jubilee International Symposium on Intelligent Systems and Informatics (SISY),"5 Nov 2024","2024","","","000447","000454","The present quantitative study investigates the initial application of ChatGPT, an AI-powered chatbot, in higher education. Employing a two-stage survey approach with 133 participants, ChatGPT's awareness, usage patterns, and perceived benefits for educational purposes are assessed. While high awareness was evident, diverse usage patterns and attitude emerged. Most participants engaged with ChatGPT sporadically or not at all, with a minority relying heavily on it, even for homework and exam assistance. Overall responses showed dubious and careful, rather negative attitude towards ChatGPT. However, traditional learning methods remained crucial for the majority, these findings reveal a mixed picture. ChatGPT holds potential to supplement and enhance learning, but it has not replaced traditional methods yet.","1949-0488","979-8-3503-8560-1","10.1109/SISY62279.2024.10737595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10737595","conversational AI;ChatGPT;higher education;ethical and security concerns","Surveys;Learning systems;Industries;Ethics;Privacy;Education;Chatbots;Knowledge management;Security;Artificial intelligence","","3","","29","IEEE","5 Nov 2024","","","IEEE","IEEE Conferences"
"Generative AI Threats to Maritime Navigation Using Deceptive ISAR Images","A. H. Oveis; G. Meucci; F. Mancuso; F. Berizzi; A. Cantelli-Forti","Radar and Surveillance Systems (RaSS) National Laboratory, CNIT, Pisa, Italy; Radar and Surveillance Systems (RaSS) National Laboratory, CNIT, Pisa, Italy; Radar and Surveillance Systems (RaSS) National Laboratory, CNIT, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Radar and Surveillance Systems (RaSS) National Laboratory, CNIT, Pisa, Italy",IEEE Access,"25 Nov 2024","2024","12","","173800","173809","The state of the art in deepfake technology demonstrates rapid technological evolution. Machine learning algorithms are becoming increasingly talented at generating synthetic yet realistic media, raising ethical, social security, and political concerns. Concurrently, the increasing frequency of supply chain attacks and Advanced Persistent Threats (APTs) poses an evolving threat to the security of critical infrastructure, drawing the attention of state-level actors. Our research on AI-generated threats explores the fabrication of images that depict non-existent events, demonstrating the ability to create false radar images. Specifically, counterfeit Inverse Synthetic Aperture Radar (ISAR) images, created using Generative Adversarial Networks (GANs), closely resemble real targets and present a significant threat to maritime operations when exploited in supply chain attacks or by APTs. Radar systems are one of the main elements of ship navigational chains that provide vital information on the surrounding area in terms of distance and speed. Real data analysis in this paper has been conducted on an ISAR database extracted from the NATO SET-196 trials, demonstrating the capability of GANs to create convincing fake ISAR images. Such experiments raise awareness of the vulnerabilities of imaging radar systems to novel, AI-generated cyberattacks.","2169-3536","","10.1109/ACCESS.2024.3500774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10755038","Deepfake;inverse synthetic aperture radar (ISAR);generative adversarial networks (GANs);advanced persistent threats (APT);supply chain attacks;cyber-attacks;maritime navigation","Radar imaging;Radar;Generative adversarial networks;Spaceborne radar;Navigation;Marine vehicles;Imaging;Radar polarimetry;Supply chains;Radar antennas","","1","","53","CCBY","18 Nov 2024","","","IEEE","IEEE Journals"
"A new approach based mobile agent system for ensuring secure big data transmission and storage","D. Kassimi; O. Kazar; H. Saouli; S. Saifi; I. Hassani; O. Boussaid","Department of Computer Science, University of Mohamed KHIDER, Biskra, Algeria; Department of Computer Science, University of Mohamed KHIDER, Biskra, Algeria; Department of Computer Science, University of Mohamed KHIDER, Biskra, Algeria; Department of Computer Science, University of Mohamed KHIDER, Biskra, Algeria; Department of Computer Science, University of Mohamed KHIDER, Biskra, Algeria; Department of Psychology of Health, Education and Development (PSED), University Lumiere Lyon 2, France",2017 International Conference on Mathematics and Information Technology (ICMIT),"18 Jan 2018","2017","","","196","200","Big Data dwarfs all the knowledge that we knew in this decade and also for the rest of our natural lives as well. It is more than just lot of data, it represents the end beginning of industry experience as core competitive advantage. In this paper we treat the problem of Big Data security and privacy using Mobil and stationary agents' technologies. Section 2 presents some related works, in section 3, we explain the proposed architecture. The proposed architecture is mainly based on: Integrity agent for verifying data concordance, path agent to ensure data transmission, and Intrusion detection agent to scan the stored data. In section 4, we implemented a prototype and we use a real Big Data base, to test the effectiveness of using Multi agent systems to improve data security and privacy.","","978-1-5386-3269-7","10.1109/MATHIT.2017.8259716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259716","Big data;Security;Multi-Agent system;Pentaho","Big Data;Mobile agents;Computer architecture;Cloud computing;Intrusion detection;Privacy","","1","","17","IEEE","18 Jan 2018","","","IEEE","IEEE Conferences"
"Enhancing Social Media Security: LSTM-Based Deep Fake Video Detection","A. Barbadekar; S. Sole; A. Shekhavat","Vishwakarma Institute of Technology, Pune, India; Vishwakarma Institute of Technology, Pune, India; Vishwakarma Institute of Technology, Pune, India",2024 IEEE 9th International Conference for Convergence in Technology (I2CT),"10 Jun 2024","2024","","","1","6","The rapid advancement of generative artificial intelligence (AI) techniques has led to the widespread creation and dissemination of deepfake videos, which convincingly manipulated media, containing fabricated content often indistinguishable from reality. Detecting such deepfake videos is a critical challenge in ensuring the originality and credibility of information in the digital age. In this paper, an approach for detecting deepfake videos using generative AI-based methods has been proposed. For this, this paper introduces a deepfake detection method using Long-short term memory (LSTM) based model. Celeb-DF (v2) has been used for this experiment. From the videos in the dataset, faces were extracted, cropped and were saved in a new video having only face images. By using ResNext, a CNN-based approach, feature extraction was performed and classification was done using the LSTM model. Highest accuracy of 95.33% was achieved using this model.","","979-8-3503-9447-4","10.1109/I2CT61223.2024.10543604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543604","Artificial Intelligence (AI);Generative Adversarial Networks (GAN);Long-short term memory (LSTM)","Training;Deepfakes;Visualization;Social networking (online);Media;Feature extraction;Security","","","","13","IEEE","10 Jun 2024","","","IEEE","IEEE Conferences"
"Generative AI-Based Financial Fraud Detection System","S. Behera; V. Kalagudi; S. M. Kumar Reddy B; S. R. Das","Dept. of CSE, CMR Institute of Technology, Bengaluru, India; Dept. of CSE, CMR Institute of Technology, Bengaluru, India; Dept. of CSE, CMR Institute of Technology, Bengaluru, India; Dept. of CSE, CMR Institute of Technology, Bengaluru, India","2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)","14 Mar 2025","2025","","","1","7","Financial fraud presents a serious threat to the stability and integrity of global financial systems. Traditional methods of detecting fraud often struggle to keep pace with fraudsters’ evolving tactics. In this study, a new method is presented to combating financial fraud by integrating various machine learning algorithms with generative artificial intelligence techniques. This work uses advanced deep learning techniques, such as convolutional and recurrent neural networks, to enhance financial system security. It focuses on improving fraud detection accuracy and reducing false positives and negatives by analyzing extensive datasets to detect subtle fraud indicators in real time. This initiative seeks to set a new standard in financial security, aiming to significantly reduce financial losses due to fraud. RNN has high accuracy (99.39%) but low precision, recall, and F1 score (40% each). CNN has slightly lower accuracy (99.29%) and relatively lower precision (33.33%) and F1 score (36.36%). FCNN shows high accuracy (99.49%) and precision (98.96%), with perfect recall (100%) and a very high F1 score (99.47%). It was observed that the GRU performs excellently across all metrics, with perfect scores (100%) in accuracy, precision, recall, and F1 score, indicating its strong ability to detect fraud while minimizing false positives and false negatives. This performance suggests that GRUs are highly effective for this type of task.","","979-8-3315-1591-1","10.1109/IITCEE64140.2025.10915323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915323","Generative Adversarial Networks (GANs);Gated Recurrent Unit (GRU);Recurrent Neural Networks (RNNs);Conditional GANs (CGANs);Convolutional Neural Networks (CNNs);Fully Connected Neural Network (FCNN)","Measurement;Accuracy;Machine learning algorithms;Finance;Stability analysis;Real-time systems;Fraud;Security;Convolutional neural networks;Standards","","","","16","IEEE","14 Mar 2025","","","IEEE","IEEE Conferences"
