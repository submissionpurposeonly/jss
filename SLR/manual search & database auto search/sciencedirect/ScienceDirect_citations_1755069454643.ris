TY  - JOUR
T1  - Large Language Model Architectures in Health Care: Scoping Review of Research Perspectives
AU  - Leiser, Florian
AU  - Guse, Richard
AU  - Sunyaev, Ali
JO  - Journal of Medical Internet Research
VL  - 27
PY  - 2025
DA  - 2025/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/70315
UR  - https://www.sciencedirect.com/science/article/pii/S143888712500843X
KW  - large language models
KW  - scoping review
KW  - ChatGPT
KW  - generative artificial intelligence
KW  - digital health
KW  - medical informatics
AB  - Background
Large language models (LLMs) can support health care professionals in their daily work, for example, when writing and filing reports or communicating diagnoses. With the rise of LLMs, current research investigates how LLMs could be applied in medical practice and their benefits for physicians in clinical workflows. However, most studies neglect the importance of selecting suitable LLM architectures.
Objective
In this literature review, we aim to provide insights on the different LLM model architecture families (ie, Bidirectional Encoder Representations from Transformers [BERT]–based or generative pretrained transformer [GPT]–based models) used in previous research. We report on the suitability and benefits of different LLM model architecture families for various research foci.
Methods
To this end, we conduct a scoping review to identify which LLMs are used in health care. Our search included manuscripts from PubMed, arXiv, and medRxiv. We used open and selective coding to assess the 114 identified manuscripts regarding 11 dimensions related to usage and technical facets and the research focus of the manuscripts.
Results
We identified 4 research foci that emerged previously in manuscripts, with LLM performance being the main focus. We found that GPT-based models are used for communicative purposes such as examination preparation or patient interaction. In contrast, BERT-based models are used for medical tasks such as knowledge discovery and model improvements.
Conclusions
Our study suggests that GPT-based models are better suited for communicative purposes such as report generation or patient interaction. BERT-based models seem to be better suited for innovative applications such as classification or knowledge discovery. This could be due to the architectural differences where GPT processes language unidirectionally and BERT bidirectionally, allowing more in-depth understanding of the text. In addition, BERT-based models seem to allow more straightforward extensions of their models for domain-specific tasks that generally lead to better results. In summary, health care professionals should consider the benefits and differences of the LLM architecture families when selecting a suitable model for their intended purpose.
ER  - 

TY  - JOUR
T1  - Large Language Models in Dental Licensing Examinations: Systematic Review and Meta-Analysis
AU  - Liu, Mingxin
AU  - Okuhara, Tsuyoshi
AU  - Huang, Wenbo
AU  - Ogihara, Atsushi
AU  - Nagao, Hikari Sophia
AU  - Okada, Hiroko
AU  - Kiuchi, Takahiro
JO  - International Dental Journal
VL  - 75
IS  - 1
SP  - 213
EP  - 222
PY  - 2025
DA  - 2025/02/01/
SN  - 0020-6539
DO  - https://doi.org/10.1016/j.identj.2024.10.014
UR  - https://www.sciencedirect.com/science/article/pii/S0020653924015685
KW  - Dentistry
KW  - Systematic review
KW  - Oral medicine
KW  - Dental education
KW  - Healthcare
AB  - Introduction and aims
This study systematically reviews and conducts a meta-analysis to evaluate the performance of various large language models (LLMs) in dental licensing examinations worldwide. The aim is to assess the accuracy of these models in different linguistic and geographical contexts. This will inform their potential application in dental education and diagnostics.
Methods
Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, we conducted a comprehensive search across PubMed, Web of Science, and Scopus for studies published from 1 January 2022 to 1 May 2024. Two authors independently reviewed the literature based on the inclusion and exclusion criteria, extracted data, and evaluated the quality of the studies in accordance with the Quality Assessment of Diagnostic Accuracy Studies-2. We conducted qualitative and quantitative analyses to evaluate the performance of LLMs.
Results
Eleven studies met the inclusion criteria, encompassing dental licensing examinations from eight countries. GPT-3.5, GPT-4, and Bard achieved integrated accuracy rates of 54%, 72%, and 56%, respectively. GPT-4 outperformed GPT-3.5 and Bard, passing more than half of the dental licensing examinations. Subgroup analyses and meta-regression showed that GPT-3.5 performed significantly better in English-speaking countries. GPT-4’s performance, however, remained consistent across different regions.
Conclusion
LLMs, particularly GPT-4, show potential in dental education and diagnostics, yet their accuracy remains below the threshold required for clinical application. The lack of sufficient training data in dentistry has affected LLMs’ accuracy. The reliance on image-based diagnostics also presents challenges. As a result, their accuracy in dental exams is lower compared to medical licensing exams. Additionally, LLMs even provide more detailed explanation for incorrect answer than correct one. Overall, the current LLMs are not yet suitable for use in dental education and clinical diagnosis.
ER  - 

TY  - JOUR
T1  - LLM-based Contrastive Representation Learning for Enhanced Maintenance Work Order Retrieval
AU  - Siouffi, Cyrille
AU  - Glandon, Pierre
AU  - Kubler, Sylvain
AU  - Soumianarayanan, Vijayaraghavan
JO  - Procedia CIRP
VL  - 134
SP  - 981
EP  - 986
PY  - 2025
DA  - 2025/01/01/
T2  - 58th CIRP Conference on Manufacturing Systems 2025
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2025.02.230
UR  - https://www.sciencedirect.com/science/article/pii/S2212827125006158
KW  - Large Language Model
KW  - Retrieval Augmented Generation
KW  - Generative AI
KW  - Maintenance
KW  - Manufacturing
KW  - Document Retrieval
KW  - Decision Support
AB  - The introduction of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP), particularly in domains like manufacturing, where knowledge sharing and retrieval play crucial roles. Traditionally, manufacturers relied on extensive databases and manual querying processes, often limited by domain-specific vocabulary and collaboration challenges. LLMs, with their advanced capabilities in document retrieval and summarization, have spurred interest in Retrieval Augmented Generation (RAG) pipelines, particularly for enhancing decision support systems. Existing approaches to knowledge retrieval, such as hybrid methods combining sparse and dense retrieval, face limitations in interpretability and fine-tuning performance when applied to noisy or scarce manufacturing data. To address these gaps, this study introduces SEASONED (SEquentiAl denoiSing cONtrastive EncoDing), a novel LLM-based contrastive representation learning framework that incorporates triplet loss learning and attention heatmaps to improve retriever module performance and interpretability in RAG pipelines. By leveraging both TSDAE and contrastive fine-tuning, SEASONED enables Efficient sub-cluster segregation and differentiation between closely related sentences. Experimental evaluation on two datasets—one open-source and one proprietary manufacturing dataset—demonstrates that SEASONED enhances document retrieval performance by 28 to 58% (accuracy) and 21 to 62% (Mean Reciprocal Rank - MRR) and compared to six state-of-the-art architectures.
ER  - 

TY  - JOUR
T1  - AgentAI: A comprehensive survey on autonomous agents in distributed AI for industry 4.0
AU  - Piccialli, Francesco
AU  - Chiaro, Diletta
AU  - Sarwar, Sundas
AU  - Cerciello, Donato
AU  - Qi, Pian
AU  - Mele, Valeria
JO  - Expert Systems with Applications
VL  - 291
SP  - 128404
PY  - 2025
DA  - 2025/10/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.128404
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425020238
KW  - AgentAI
KW  - AgenticAI
KW  - Industry 4.0
KW  - Distributed artificial intelligence
KW  - Autonomous decision-making
AB  - AgentAI represents a transformative approach within distributed Artificial Intelligence (AI) in which autonomous agents work either individually or collaboratively in decentralized environments to address challenging problems. AgentAI enhances scalability, robustness, and flexibility by utilizing advanced communication, learning, and decision-making capabilities, making it integral to diverse applications in Industry 4.0. The ability of AI systems to interpret sensory data in open-world environments has seen significant advancements in recent years. This progress emphasizes the need to move beyond reductionist approaches and embrace more embodied and cohesive systems, which integrate foundational models into agent-driven actions. Existing surveys often focus on isolated domains or specific autonomy levels, lacking a cohesive analysis that spans the full spectrum of AgentAI development in Industry 4.0. This survey explicitly fills this gap by introducing a multi-domain taxonomy and by systematically analyzing both non-autonomous and fully autonomous AgentAI systems, offering a comprehensive synthesis not previously available in the literature. Additionally, the paper extends the discussion to Industry 5.0 and 6.0, exploring the evolution of AgentAI from automation to collaboration and, ultimately, to fully autonomous systems. This comprehensive analysis highlights the potential of AgentAI in driving industries toward a more efficient, sustainable, and adaptable future.
ER  - 

TY  - JOUR
T1  - Explainable AI chatbots towards XAI ChatGPT: A review
AU  - Kovari, Attila
JO  - Heliyon
VL  - 11
IS  - 2
SP  - e42077
PY  - 2025
DA  - 2025/01/30/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2025.e42077
UR  - https://www.sciencedirect.com/science/article/pii/S2405844025004578
KW  - Explainable AI (XAI)
KW  - ChatGPT
KW  - AI chatbots
KW  - Natural language processing (NLP)
KW  - Transparency
KW  - Controllable AI
AB  - Advances in artificial intelligence (AI) have had a major impact on natural language processing (NLP), even more so with the emergence of large-scale language models like ChatGPT. This paper aims to provide a critical review of explainable AI (XAI) methodologies for AI chatbots, with a particular focus on ChatGPT. Its main objectives are to investigate the applied methods that improve the explainability of AI chatbots, identify the challenges and limitations within them, and explore future research directions. Such goals emphasize the need for transparency and interpretability of AI systems to build trust with users and allow for accountability. While integrating such interdisciplinary methods, such as hybrid methods combining knowledge graphs with ChatGPT, enhancing explainability, they also highlight industry needs for explainability and user-centred design. This will be followed by a discussion of the balance between explainability and performance, then the role of human judgement, and finally the future of verifiable AI. These are the avenues through which insights can be used to guide the development of transparent, reliable and efficient AI chatbots.
ER  - 

TY  - JOUR
T1  - Integrating domain-specific knowledge and fine-tuned general-purpose large language models for question-answering in construction engineering management
AU  - Zhou, Shenghua
AU  - Liu, Xuefan
AU  - Li, Dezhi
AU  - Gu, Tiantian
AU  - Liu, Keyan
AU  - Yang, Yifan
AU  - Wong, Mun On
JO  - Automation in Construction
VL  - 175
SP  - 106206
PY  - 2025
DA  - 2025/07/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106206
UR  - https://www.sciencedirect.com/science/article/pii/S0926580525002468
KW  - Question-answering
KW  - Construction engineering management
KW  - Knowledge base
KW  - Fine-tuning
KW  - Large language model
AB  - General-purpose Large Language Models (GLLMs) for Question-Answering (QA) of Construction Engineering Management (CEM) usually lack CEM knowledge and fine-tuning datasets, leading to unsatisfactory performance. Hence, this paper integrates the CEM External Knowledge Base (CEM-EKB) with out-of-domain fine-tuned GLLMs for CEM-QA. It encompasses (i) devising a process to develop the CEM-EKB with 235 documents, (ii) conducting out-of-domain fine-tuning to enhance GLLMs' abilities, (iii) integrating CEM-EKB with fine-tuned GLLMs, (iv) building CEM-QA test datasets with 5050 Multiple-Choice Questions (MCQs) and 100 Case-Based Questions (CBQs), and (v) comparing GLLMs' performance. The results indicate that CEM knowledge-incorporated fine-tuned GLLMs surpass original GLLMs by an average of 27.1 % in professional examinations, with an average improvement of 27.5 % across 7 CEM subdomains and 22.05 % for CBQs. This paper contributes to devising an effective, reusable, and updatable CEM-EKB; revealing the feasibility of out-of-domain datasets for fine-tuning; and sharing a large-scale CEM-QA test dataset.
ER  - 

TY  - JOUR
T1  - A Comprehensive Analysis of the per- and poly-fluoroalkyl substances (PFAS) research landscape through AI-assisted text mining
AU  - Kobayashi, Yoshiyuki
AU  - Uchida, Takumi
AU  - Inoue, Takahiro
AU  - Iwasaki, Yusuke
AU  - Ito, Rie
AU  - Akiyama, Hiroshi
JO  - Journal of Hazardous Materials Letters
VL  - 5
SP  - 100121
PY  - 2024
DA  - 2024/11/01/
SN  - 2666-9110
DO  - https://doi.org/10.1016/j.hazl.2024.100121
UR  - https://www.sciencedirect.com/science/article/pii/S2666911024000200
KW  - PFAS
KW  - Research trend analysis
KW  - Natural language processing (LLM)
KW  - Generative AI
KW  - Text mining
AB  - Per- and poly-fluoroalkyl substances (PFAS) have been widely used in various industrial applications due to their unique properties. This study aims to provide a comprehensive analysis of PFAS research trends using a novel approach combining text mining techniques and large-scale language models (LLMs). PFAS-related scientific literature published from 1980 to 2024 was gathered from Scopus, and KH Coder and Claude 3 were used to perform the analysis. The results showed a significant increase in research output and a clear shift in research topics over the past 40 years. Whereas in the past, the focus was on analytical methods, more recently, the emphasis has been on environmental fate, toxicity assessment, alternative compounds, and regulation. With Claude 3, research areas can now be identified without reviewing the results of expert text mining. Comparisons of AI-extracted trends with insights from traditional review articles showed strong agreement, confirming the effectiveness of this approach. These findings suggest the need for continued interdisciplinary research on PFAS such as the development of remediation strategies, elucidation of health effects, and evidence-based policymaking. This study showed the possibility of integrating text mining and LLM for a comprehensive analysis of research trends, which will accelerate future research and development strategies.
ER  - 

TY  - JOUR
T1  - Augmented Intelligence and Dermatology – Part I: Core Concepts and Applications
AU  - Schlessinger, Daniel
AU  - Ko, Justin
AU  - Lee, Ivy
AU  - Rotemberg, Veronica
AU  - Novoa, Roberto
JO  - Journal of the American Academy of Dermatology
PY  - 2025
DA  - 2025/03/14/
SN  - 0190-9622
DO  - https://doi.org/10.1016/j.jaad.2024.09.090
UR  - https://www.sciencedirect.com/science/article/pii/S0190962225004396
KW  - Artificial intelligence
KW  - augmented intelligence
KW  - dermatology
KW  - digital health
KW  - informatics
KW  - imaging
KW  - computer vision
ER  - 

TY  - JOUR
T1  - Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy
AU  - Dwivedi, Yogesh K.
AU  - Kshetri, Nir
AU  - Hughes, Laurie
AU  - Slade, Emma Louise
AU  - Jeyaraj, Anand
AU  - Kar, Arpan Kumar
AU  - Baabdullah, Abdullah M.
AU  - Koohang, Alex
AU  - Raghavan, Vishnupriya
AU  - Ahuja, Manju
AU  - Albanna, Hanaa
AU  - Albashrawi, Mousa Ahmad
AU  - Al-Busaidi, Adil S.
AU  - Balakrishnan, Janarthanan
AU  - Barlette, Yves
AU  - Basu, Sriparna
AU  - Bose, Indranil
AU  - Brooks, Laurence
AU  - Buhalis, Dimitrios
AU  - Carter, Lemuria
AU  - Chowdhury, Soumyadeb
AU  - Crick, Tom
AU  - Cunningham, Scott W.
AU  - Davies, Gareth H.
AU  - Davison, Robert M.
AU  - Dé, Rahul
AU  - Dennehy, Denis
AU  - Duan, Yanqing
AU  - Dubey, Rameshwar
AU  - Dwivedi, Rohita
AU  - Edwards, John S.
AU  - Flavián, Carlos
AU  - Gauld, Robin
AU  - Grover, Varun
AU  - Hu, Mei-Chih
AU  - Janssen, Marijn
AU  - Jones, Paul
AU  - Junglas, Iris
AU  - Khorana, Sangeeta
AU  - Kraus, Sascha
AU  - Larsen, Kai R.
AU  - Latreille, Paul
AU  - Laumer, Sven
AU  - Malik, F. Tegwen
AU  - Mardani, Abbas
AU  - Mariani, Marcello
AU  - Mithas, Sunil
AU  - Mogaji, Emmanuel
AU  - Nord, Jeretta Horn
AU  - O’Connor, Siobhan
AU  - Okumus, Fevzi
AU  - Pagani, Margherita
AU  - Pandey, Neeraj
AU  - Papagiannidis, Savvas
AU  - Pappas, Ilias O.
AU  - Pathak, Nishith
AU  - Pries-Heje, Jan
AU  - Raman, Ramakrishnan
AU  - Rana, Nripendra P.
AU  - Rehm, Sven-Volker
AU  - Ribeiro-Navarrete, Samuel
AU  - Richter, Alexander
AU  - Rowe, Frantz
AU  - Sarker, Suprateek
AU  - Stahl, Bernd Carsten
AU  - Tiwari, Manoj Kumar
AU  - van der Aalst, Wil
AU  - Venkatesh, Viswanath
AU  - Viglia, Giampaolo
AU  - Wade, Michael
AU  - Walton, Paul
AU  - Wirtz, Jochen
AU  - Wright, Ryan
JO  - International Journal of Information Management
VL  - 71
SP  - 102642
PY  - 2023
DA  - 2023/08/01/
SN  - 0268-4012
DO  - https://doi.org/10.1016/j.ijinfomgt.2023.102642
UR  - https://www.sciencedirect.com/science/article/pii/S0268401223000233
KW  - Conversational agent
KW  - Generative artificial intelligence
KW  - Generative AI
KW  - ChatGPT
KW  - Large language models
AB  - Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.
ER  - 

TY  - JOUR
T1  - Research hypothesis generation over scientific knowledge graphs
AU  - Borrego, Agustín
AU  - Dessì, Danilo
AU  - Ayala, Daniel
AU  - Hernández, Inma
AU  - Osborne, Francesco
AU  - Reforgiato Recupero, Diego
AU  - Buscaldi, Davide
AU  - Ruiz, David
AU  - Motta, Enrico
JO  - Knowledge-Based Systems
VL  - 315
SP  - 113280
PY  - 2025
DA  - 2025/04/22/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.113280
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125003272
KW  - Hypothesis generation
KW  - Knowledge graphs
KW  - Link prediction
KW  - Scholarly domain
KW  - Scientific facts
KW  - Artificial Intelligence
AB  - Generating research hypotheses is a crucial step in scientific investigation that involves the creation of precise, verifiable, and logically valid statements that can be empirically examined. Therefore, many efforts have been made to automate or assist this process through the use of various Artificial Intelligence solutions. However, most existing methods are tailored to very specific domains, particularly within the biomedical field. There have been recent attempts to formalize hypothesis generation as a link prediction task over knowledge graphs. This solution is potentially domain-independent and applicable across diverse disciplines. Nevertheless, current approaches for link prediction, which typically rely on embedding models or path-based methods, have shown limited success in accurately predicting new hypotheses. To address these limitations, this paper introduces ResearchLink, an innovative and domain-independent methodology for hypothesis generation over knowledge graphs. ResearchLink combines path-based features and knowledge graph embeddings with text embeddings, capturing the semantic context of entities within a given corpus, and integrates additional information from bibliometric databases to improve research collaboration predictions. To conduct a rigorous evaluation of ResearchLink, we constructed CSKG-600, a new dataset for hypothesis generation, consisting of 600 statements that were manually labeled by domain experts. ResearchLink achieved outstanding performance (78.7% P@20), significantly outperforming alternative approaches such as TransH (71.8%), TransD (71.7%), and RotatE (70.7%).
ER  - 

TY  - JOUR
T1  - Analysis of 50 Years of Health Food Research Trends Using Natural Language Processing and Generative AI
AU  - Kobayashi, Yoshiyuki
AU  - Uchida, Takumi
AU  - Inoue, Takahiro
AU  - Iwasaki, Yusuke
AU  - Ito, Rie
AU  - Saito, Koichi
AU  - Akiyama, Hiroshi
AU  - Tsuda, Kazuhiko
AU  - Yoshida, Kenichi
JO  - Procedia Computer Science
VL  - 246
SP  - 1875
EP  - 1884
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.697
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924027571
KW  - health foods
KW  - health products
KW  - natural language processing
KW  - text mining
KW  - generative AI
KW  - ChatGPT-4
KW  - research trendsIntroduction
AB  - This study investigates trends in health food research from 1975 to 2024 using text mining and generative AI. Analyzing 92,028 journal entries from Scopus revealed a significant increase in publications, with key topics including nutrients, bioactive compounds, disease prevention, and research methods. AI-assisted classification yielded 12 categories reflecting the field’s multidisciplinary nature. Trends include a growing focus on nutrients, health conditions, study design, and food production and consumption context. The findings highlight the increasingly interdisciplinary landscape of health food research, informing future directions and evidence-based decision-making.
ER  - 

TY  - JOUR
T1  - Active in-context learning for cross-domain entity resolution
AU  - Zhang, Ziheng
AU  - Zeng, Weixin
AU  - Tang, Jiuyang
AU  - Huang, Hongbin
AU  - Zhao, Xiang
JO  - Information Fusion
VL  - 117
SP  - 102816
PY  - 2025
DA  - 2025/05/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2024.102816
UR  - https://www.sciencedirect.com/science/article/pii/S1566253524005943
KW  - Entity resolution
KW  - Cross-domain entity resolution
KW  - In-context learning
AB  - Entity resolution (ER) is the task of determining the equivalence between two entity descriptions. In traditional settings, the testing data and training data come from the same domain, e.g., sharing the same attribute structure. Nevertheless, in practical situations, the testing and training data often span different domains, hence calling for the study of the cross-domain ER problem. To tackle the domain shift in cross-domain ER, state-of-the-art solutions devise neural models to utilize the information from the entity pairs in the target domain to guide the feature modeling in the source domain and also the model training. Nevertheless, these approaches require excessive computational resources and fine-tuning efforts to achieve effective matching. To mitigate these issues, in this work, we for the first time investigate the in-context learning (ICL) capabilities of large language models (LLMs) for cross-domain ER and introduce a new framework, CiDER. CiDER consists of three main modules, i.e., active candidate source data generation, in-context demonstration selection, and prompt generation, which can select optimal demonstrations from the source data to enhance LLM inference performance on ER in the target domain. Comprehensive experiments on multiple benchmarks demonstrate that CiDER offers significant improvements over existing methods on cross-domain ER.
ER  - 

TY  - JOUR
T1  - To ChatGPT, or not to ChatGPT: Navigating the paradoxes of generative AI in the advertising industry
AU  - Osadchaya, Elena
AU  - Marder, Ben
AU  - Yule, Jennifer A.
AU  - Yau, Amy
AU  - Lavertu, Laura
AU  - Stylos, Nikolaos
AU  - Oliver, Sebastian
AU  - Angell, Rob
AU  - Regt, Anouk de
AU  - Gao, Liyu
AU  - Qi, Kang
AU  - Zhang, Will Zhiyuan
AU  - Zhang, Yiwei
AU  - Li, Jiayuan
AU  - AlRabiah, Sara
JO  - Business Horizons
VL  - 67
IS  - 5
SP  - 571
EP  - 581
PY  - 2024
DA  - 2024/09/01/
T2  - SPECIAL ISSUE: WRITTEN BY CHATGPT
SN  - 0007-6813
DO  - https://doi.org/10.1016/j.bushor.2024.05.002
UR  - https://www.sciencedirect.com/science/article/pii/S0007681324000624
KW  - ChatGPT
KW  - Generative AI
KW  - Paradoxes
KW  - Advertising
KW  - Chatbots
AB  - Generative AI (GenAI) technology is evoking both excitement and fear about its potential impact across a host of industries—including advertising, where it is expected to have a significant disruptive effect. This article utilizes the paradox lens to explore the implications of text-to-text GenAI in the form of ChatGPT for the advertising industry. Drawing on 48 interviews with advertising professionals, we identify three operational paradoxes that are associated with conducting research, creativity, efficiency, and one psychological paradox related to work identity. To gain a competitive advantage, we urge practitioners to adopt a confrontation-based coping strategy to navigate these paradoxes. This can be mobilized via an ambidexterity or contingency paradox management approach. We outline specific tactics in this article.
ER  - 

TY  - JOUR
T1  - Future of allergy and immunology: Is artificial intelligence the key in the digital era?
AU  - Goktas, Polat
AU  - Damadoglu, Ebru
JO  - Annals of Allergy, Asthma & Immunology
VL  - 134
IS  - 4
SP  - 396
EP  - 407.e2
PY  - 2025
DA  - 2025/04/01/
SN  - 1081-1206
DO  - https://doi.org/10.1016/j.anai.2024.10.019
UR  - https://www.sciencedirect.com/science/article/pii/S1081120624015953
AB  - Artificial intelligence (AI) is reshaping allergy and immunology by integrating cutting-edge technology to enhance patient outcomes and redefine clinical practices and research. This review evaluates AI's evolving role, emphasizing its impact on diagnostic accuracy, personalized treatments, and innovative research methodologies. AI has advanced diagnostic tools, such as models predicting allergen sensitivity, and enhanced immunotherapy strategies. Its ability to process extensive data sets has enabled deeper understanding of allergic diseases and immune system responses, leading to more accurate, effective, and tailored treatments. Furthermore, AI is facilitating personalized care through AI-driven allergen mapping, automated patient monitoring, and targeted immunotherapy. The integration of AI into clinical practice promises a future in which allergy and immunology are characterized by precisely customized health care solutions. This review adheres to Preferred Reporting Items for Systematic reviews and Meta-Analyses flowchart, with a comprehensive analysis of databases, including Scopus, Web of Science, PubMed, and preprint platforms using keywords related to AI and allergy and immunology. From an initial pool of 192 studies, 20 documents were selected based on inclusion criteria. Our findings highlight how AI is transforming allergy and immunology by enhancing patient care, research methodologies, and clinical innovation, offering a glimpse into the near future of technology-driven health care in these fields.
ER  - 

TY  - JOUR
T1  - Originality and the future of copyright in an age of generative AI
AU  - Fenwick, Mark
AU  - Jurcys, Paulius
JO  - Computer Law & Security Review
VL  - 51
SP  - 105892
PY  - 2023
DA  - 2023/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2023.105892
UR  - https://www.sciencedirect.com/science/article/pii/S0267364923001024
KW  - AI
KW  - Generative AI
KW  - Copyright
KW  - Creativity
KW  - Originality
KW  - Artificial intelligence
KW  - Data
KW  - Feist
KW  - David Guetta
KW  - ChatGPT
KW  - Input
KW  - Output
KW  - Machine Learning
KW  - Authorship
KW  - Intellectual Property
AB  - This paper takes the occasion of French DJ David Guetta's use of generative AI tools to create lyrics and a voice in the style of Eminem, which he then used in one of his concerts, as the basis for an exploration of the shifting meaning of creativity and originality in the age of generative AI. Our main contention is that the Guetta form of creativity with generative AI tools differs in certain important respects from what has come before. The paper describes an iterative, dynamic process of conception, prompting, generation, refining, and deployment to characterise creativity in this context. Nevertheless, we contend that copyright – specifically the concept of originality as articulated in US federal law – is a sufficiently durable legal mechanism that can manage these new cultural forms, and that the two basic requirements of modern copyright law (a tangible medium of expression and a modest degree of creativity) remain relevant in identifying the scope of legal protection. The paper argues that the David Guetta story reveals something more general about creativity in a digital age, namely that while hybrid-networked (i.e., human – corporate – machine) creators have always created hybrid-networked cultural forms (i.e., creations that blend human and technology-constituted elements), such hybridity becomes increasingly visible and complex in the context of a new world of generative AI. At the very least, earlier – and influential – models of creativity as human-driven involving creation ex nihilo become harder to sustain in a new age of generative AI. But this does not mean copyright or notions of originality are redundant or that copyright law cannot accommodate Guetta and other cases. Such an account seems important as it challenges the hegemonic and reductive view that AI “generates” artistic works autonomously and avoids reducing the copyright issues raised by such creative works to the related but distinct question of whether learning models rely on copyrighted data. As such, copyright law should remain an important mechanism to facilitate genuine creators who are using AI systems in innovative and unique ways to push the boundaries of their creativity.
ER  - 

TY  - JOUR
T1  - Harnessing language models for computational literature review of emerging AI topics
AU  - Chung, Jaemin
AU  - Jeong, Byeongki
AU  - Park, Young-Jae
AU  - Jeong, Hwihun
AU  - Lee, Jiho
AU  - Yoon, Janghyeok
AU  - Choi, Jaewoong
JO  - Information Processing & Management
VL  - 62
IS  - 6
SP  - 104245
PY  - 2025
DA  - 2025/11/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2025.104245
UR  - https://www.sciencedirect.com/science/article/pii/S0306457325001864
KW  - Computational literature review
KW  - AI landscape
KW  - Pre-trained language model
KW  - Unsupervised clustering
KW  - Emergingness
KW  - Attention mechanism
AB  - As the ability to interpret and anticipate artificial intelligence (AI) research trends is becoming increasingly important, previous studies have highlighted the potential of computational literature review (CLR) within the AI domain. However, existing approaches may be limited in understanding domain-specific terminologies and complex contexts and delivering timely, forward-looking insights within the rapidly evolving AI landscape. As a remedy, this study proposes a systematic approach for effectively exploring AI landscapes using AI-specific pre-trained language model (PLM)-based topic modeling, and emergingness analysis. We newly adopt the PapersWithCode database, considering its credibility based on source codes and venue information, human-crafted tags (e.g., methods), and periodic updatability. The core components of the proposed approach are: (1) constructing a dynamic AI landscape to capture time-varying trends using AI-specific PLMs and unsupervised clustering; (2) assessing the emergingness of individual AI topics to deliver anticipatory insights; and (3) developing an interactive topic evolution map that traces the temporal transitions of key topics from their predecessors to successors. A case study of 18,870 papers on scaled dot-product attention mechanisms demonstrates the effectiveness of the proposed approach in understanding what AI topics can be identified as emerging, along with their defining characteristics, and the evolutionary pathways of a given target topic. Our systematic process and quantitative outcomes are expected to serve as complementary tools for strategic foresight and AI trend monitoring while contributing to academia by proposing the integration of new data sources and perspectives into AI-specific CLR.
ER  - 

TY  - JOUR
T1  - Can popular AI large language models provide reliable answers to frequently asked questions about rotator cuff tears?
AU  - Kolac, Ulas Can
AU  - Karademir, Orhan Mete
AU  - Ayik, Gokhan
AU  - Kaymakoglu, Mehmet
AU  - Familiari, Filippo
AU  - Huri, Gazi
JO  - JSES International
VL  - 9
IS  - 2
SP  - 390
EP  - 397
PY  - 2025
DA  - 2025/03/01/
SN  - 2666-6383
DO  - https://doi.org/10.1016/j.jseint.2024.11.012
UR  - https://www.sciencedirect.com/science/article/pii/S2666638324004717
KW  - Artificial intelligence
KW  - Large language models
KW  - Rotator cuff tears
KW  - Frequently asked questions
KW  - Patient information
KW  - AI Tools in Healthcare
KW  - ChatGPT
AB  - Background
Rotator cuff tears are common upper-extremity injuries that significantly impair shoulder function, leading to pain, reduced range of motion, and a decrease in quality of life. With the increasing reliance on artificial intelligence large language models (AI LLMs) for health information, it is crucial to evaluate the quality and readability of the information provided by these models.
Methods
A pool of 50 questions was generated related to rotator cuff tear by querying popular AI LLMs (ChatGPT 3.5, ChatGPT 4, Gemini, and Microsoft CoPilot) and using Google search. After that, responses from the AI LLMs were saved and evaluated. For information quality the DISCERN tool and a Likert Scale was used, for readability the Patient Education Materials Assessment Tool for Printable Materials (PEMAT) Understandability Score and the Flesch-Kincaid Reading Ease Score was used. Two orthopedic surgeons assessed the responses, and discrepancies were resolved by a senior author.
Results
Out of 198 answers, the median DISCERN score was 40, with 56.6% considered sufficient. The Likert Scale showed 96% sufficiency. The median PEMAT Understandability score was 83.33, with 77.3% sufficiency, while the Flesch-Kincaid Reading Ease score had a median of 42.05 with 88.9% sufficiency. Overall, 39.8% of the answers were sufficient in both information quality and readability. Differences were found among AI models in DISCERN, Likert, PEMAT Understandability, and Flesch-Kincaid scores.
Conclusion
AI LLMs generally cannot offer sufficient information quality and readability. While they are not ready for use in medical field, they show a promising future. There is a necessity for continuous re-evaluation of these models due to their rapid evolution. Developing new, comprehensive tools for evaluating medical information quality and readability is crucial for ensuring these models can effectively support patient education. Future research should focus on enhancing readability and consistent information quality to better serve patients.
ER  - 

TY  - JOUR
T1  - DLA Piper EU update
JO  - Computer Law & Security Review
VL  - 52
SP  - 105859
PY  - 2024
DA  - 2024/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2023.105859
UR  - https://www.sciencedirect.com/science/article/pii/S0267364923000699
ER  - 

TY  - JOUR
T1  - The power of generative marketing: Can generative AI create superhuman visual marketing content?
AU  - Hartmann, Jochen
AU  - Exner, Yannick
AU  - Domdey, Samuel
JO  - International Journal of Research in Marketing
VL  - 42
IS  - 1
SP  - 13
EP  - 31
PY  - 2025
DA  - 2025/03/01/
SN  - 0167-8116
DO  - https://doi.org/10.1016/j.ijresmar.2024.09.002
UR  - https://www.sciencedirect.com/science/article/pii/S0167811624000843
KW  - generative AI
KW  - marketing effectiveness
KW  - productivity
KW  - content creation
KW  - artificial intelligence
KW  - digital marketing
AB  - Generative AI’s capacity to create photorealistic images has the potential to augment human creativity and disrupt the economics of visual marketing content production. This research systematically compares the performance of AI-generated to human-made marketing images across important marketing dimensions. First, we prompt seven state-of-the-art generative text-to-image models (DALL-E 3, Midjourney v6, Firefly 2, Imagen 2, Imagine, Stable Diffusion XL Turbo, and Realistic Vision) to create 10,320 synthetic marketing images, using 2,400 real-world, human-made images as input. 254,400 human evaluations of these images show that AI-generated marketing imagery can surpass human-made images in quality, realism, and aesthetics. Second, we give identical creative briefings to commissioned human freelancers and the AI models, showing that the best synthetic images also excel in ad creativity, ad attitudes, and prompt following. Third, a field study with more than 173,000 impressions demonstrates that AI-generated banner ads can compete with professional human-made stock photography, achieving an up to 50% higher click-through rate than a human-made image. Collectively, our findings suggest that the paradigm shift brought about by generative AI can help advertisers produce marketing content not only faster and orders of magnitude cheaper but also at superhuman effectiveness levels with important implications for firms, consumers, and policymakers. To facilitate future research on AI-generated marketing imagery, we release GenImageNet that contains all of our synthetic images and their human ratings.
ER  - 

TY  - JOUR
T1  - Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions
AU  - Gupta, Tapas
AU  - Devji, Shridev
AU  - Tripathi, Ashish Kumar
JO  - Expert Systems with Applications
VL  - 285
SP  - 127864
PY  - 2025
DA  - 2025/08/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.127864
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425014861
KW  - Stock market prediction
KW  - Social media
KW  - Digital news
KW  - Machine learning
KW  - Deep learning
KW  - Large language models
AB  - Social media and online news have emerged as significant sources of market sentiment, influencing stock market dynamics globally. With the growing availability of digital data, the current research focus is on leveraging advanced computational techniques for sentiment-driven stock market prediction. The era of financial forecasting has been revolutionized by integrating cutting-edge technologies such as Machine Learning, Deep Learning, and Large Language Models. In this paper, a comprehensive survey of 108 research articles has been undertaken to explore the recent advancements in these technologies, with a focus on utilizing sentiment data extracted from social media platforms and news sources. The technology-wise state-of-the-art findings, current trends, challenges, and literature gaps in this domain are analyzed, and potential future directions are proposed to address these gaps. Additionally, publicly available benchmark datasets for social media and news sentiment indices are compiled and analyzed, with insights into their limitations and potential improvements. A comparative evaluation of prediction methods across heterogeneous user-generated datasets is performed, identifying the most effective techniques for various data types and problem formulations. Recommendations are offered for selecting suitable techniques based on the nature of the data and the specific problem formulation. By incorporating the latest advancements in the field of sentiment analysis and stock market prediction, this work provides actionable insights for researchers and practitioners, advancing the understanding and development of sentiment-driven financial forecasting.
ER  - 

TY  - CHAP
T1  - Chapter Six - Emotional AI: Neuroethics and Socially aligned networks
AU  - Krebsz, Markus
AU  - Dwivedi, Divya
A2  - Garg, Muskan
A2  - Koundal, Deepika
BT  - Emotional AI and Human-AI Interactions in Social Networking
PB  - Academic Press
SP  - 101
EP  - 130
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-443-19096-4
DO  - https://doi.org/10.1016/B978-0-443-19096-4.00002-X
UR  - https://www.sciencedirect.com/science/article/pii/B978044319096400002X
KW  - ChatGPT
KW  - Consciousness
KW  - Diverse inputs and multistakeholder feedback
KW  - Freedom of thought
KW  - Generative AI
KW  - IoT (Internet-of-things)
KW  - Neuro-rights
KW  - Neuroethics
KW  - Sentience
KW  - Socially aligned networks
KW  - Spiritual AI
KW  - Thought-related and neural data
AB  - A new term, socially aligned networks, going beyond pure social media is introduced which considers the alignment of participants' common interests and ways how users communicate, create, compete, and/or challenge each other within technological ecosystems such as online services, gaming suites, metaverse or virtual/augmented-/extended-reality spaces. The current scope and predicted growth of the world digital population is considered in light of Big Tech companies' domination of social media as well as continuing digital exclusion. The ethical studies’ landscape is mapped by looking at comparative studies in this relatively new field and with the aim of establishing a suitable ethic principles baseline for such socially aligned networks further illustrated by human–AI interface case studies. Beyond establishing a suitable ethic principles baseline for such socially aligned networks, current advances in neuroethics are considered within the context of emotional AI and human–AI interactions. Neuroethics principles are considered within the context of different philosophical schools, leading to a discussion of relatively new neurorights. An interconnection of morality, ethics, and spirituality is discussed, together with immature legal frameworks and ethical boundaries for Internet of things (IoT) devices. In conclusion, neuroethics are considered a suitable blueprint for socially aligned networks and highlighting that regulation alone is likely not going to be sufficient on its own, particularly when considering the rapid growth of generative AI.
ER  - 

TY  - JOUR
T1  - Autonomous agent-based simulation modelling—A case study on a flexible GPU-card final assembly line
AU  - Wang, Kung-Jeng
AU  - Eunike, Agustina
AU  - Kurniawan, Ivan
AU  - Ardi, Romadhani
AU  - Chiu, Jing-Ming
JO  - Robotics and Autonomous Systems
VL  - 169
SP  - 104511
PY  - 2023
DA  - 2023/11/01/
SN  - 0921-8890
DO  - https://doi.org/10.1016/j.robot.2023.104511
UR  - https://www.sciencedirect.com/science/article/pii/S0921889023001501
KW  - Agent based system
KW  - Flexible assembly line
KW  - Graphic processing unit
KW  - Simulation modelling
AB  - Market demands for high-tech products constantly evolve by product specification. To be competitive, a production system must be flexible and reconfigurable when facing mass customization. Flexible assembly line (FAL) enables mixed production with high efficiency. One example is graphic processing unit (GPU) cards. FAL requires comprehensive system design and scheduling to fully utilize the resources. This study adopts agent-based simulation (ABS) modelling for a FAL because of the abilities of ABS in flexibility and scalability. The proposed framework consists of three parts: real environment, virtual environment, and evaluation and analysis. This study uses agent-based simulation modelling to elaborate on sequencing and scheduling performances in the GPU-card assembly line. The Pareto frontier analysis is conducted to resolve conflicts between part tardiness and throughput.
ER  - 

TY  - JOUR
T1  - Leveraging open-source large language models (LLMs) in scoping reviews: a case study on disability and AI applications
AU  - Bayani, Azadeh
AU  - Epoh Ewane, Leandre Parfait
AU  - Oliveira dos Anjos, Davllyn Santos
AU  - Mac-Seing, Muriel
AU  - Nikiema, Jean Noel
JO  - International Journal of Medical Informatics
VL  - 204
SP  - 106048
PY  - 2025
DA  - 2025/12/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2025.106048
UR  - https://www.sciencedirect.com/science/article/pii/S1386505625002655
KW  - Large language models
KW  - Scoping review
KW  - Automation
KW  - Disability
AB  - Background
Large language models (LLMs) have the potential to offer solutions for automating many of the manual tasks involved in scientific reviews, including data extraction, literature screening, summarization, and quality assessment.
Objectives
This study aims to evaluate the performance of LLMs in the task of title and abstract screening and full-text data extraction of a scoping review study, by identifying their effectiveness, efficiency, and potential integration into human-based and manual tasks.
Materials and Method
The following key three steps of a scientific scoping review were automated: 1) Title and Abstract Screening, 2) Full-Text Screening, and 3) Data Extraction based on nine study dimensions. The four most recent lightweight open-source LLMs −Mistral, Vicuna, and Llama 3.2 with 1B and 3B parameters- were applied and evaluated through the steps.
Results
Llama 3.2-3B demonstrated the best performance in the title and abstract screening, achieving an accuracy of 66 %, excelling in the exclusion of papers. For full-text screening, it maintained the highest overall accuracy of 65 %, effectively identifying excluded papers. In data extraction, the Mistral model outperformed others across most dimensions, though Llama 3.2-3B excelled in extracting objectives and study implications.
Discussion and conclusion
The present study underscores both the potential and limitations of LLMs in automating scoping reviews. Automating the entire scoping review without human intervention is sub-optimal. Using a more controlled approach balances the strengths of LLMs with the need for human judgment, supporting not only the replication of scientific reviews but also their continuous refinement and follow-up over time.
ER  - 

TY  - CHAP
T1  - Natural Language Processing
AU  - Haralambous, Yannis
BT  - Reference Module in Social Sciences
PB  - Elsevier
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-443-15785-1
DO  - https://doi.org/10.1016/B978-0-323-95504-1.00090-9
UR  - https://www.sciencedirect.com/science/article/pii/B9780323955041000909
KW  - Attention mechanism
KW  - Chatbots
KW  - ChatGPT
KW  - Computational linguistics
KW  - Deep learning
KW  - ELIZA
KW  - Ethics in AI
KW  - Interpretability
KW  - Language generation
KW  - Large language models (LLM)
KW  - Machine learning
KW  - Machine translation
KW  - Natural language processing (NLP)
KW  - Neural networks
KW  - Sentiment analysis
KW  - Speech recognition
KW  - Statistical methods
KW  - Summarization
KW  - Text classification
KW  - Word embeddings
AB  - Natural Language Processing (NLP) evolved from rule-based systems in the 1960s–70s to statistical methods in the 1980s–90s, and finally to the deep learning revolution of the 21st century. The key milestones of its evolution include ELIZA, an early chatbot (1966), a focus on formal grammars and knowledge-based systems (1980s), the rise of statistical methods and machine learning (1990s), the popularization of word embeddings (2013), sequence-to-sequence models and attention mechanisms (2014–2016) and large language models like BERT, GPT-3, and ChatGPT (in the recent years). Major NLP applications can be classified in three categories: those that have linguistic input and non-linguistic output (e.g., text classification, sentiment analysis), those that transform linguistic input to linguistic output (e.g., machine translation, summarization), and those that are based on non-linguistic input (or no input at all) and have linguistic output (e.g., weather report generation, poetry generation). As for chatbots, they are comprehensive NLP applications, encompassing multiple tasks. Key challenges in NLP are the difficulty of machine translation and the importance of context in language understanding. Significant progress has been made with deep learning and large language models, but issues remain, like the lack of interpretability and ethical concerns. We provide resources for further learning, including popular textbooks, online courses, scientific journals, and mention platforms like Hugging Face and Kaggle for accessing datasets and models. Looking to the future, we anticipate increased multimodal integration, efforts to support under-resourced languages, and a focus on addressing interpretability and ethical issues in large language models. Overall, NLP is as a rapidly evolving field that has made significant strides in understanding and generating human language, with exciting possibilities and important challenges ahead.
ER  - 

TY  - CHAP
T1  - Chapter 23 - Demystifying machine learning for predictive analytics in construction
AU  - Davila Delgado, Juan Manuel
A2  - Farsangi, Ehsan Noroozinejad
A2  - Noori, Mohammad
A2  - Yang, T.Y
A2  - Sarhosis, Vasilis
A2  - Mirjalili, Seyedali
A2  - Skibniewski, Mirosław J.
BT  - Digital Transformation in the Construction Industry
PB  - Woodhead Publishing
SP  - 463
EP  - 486
PY  - 2025
DA  - 2025/01/01/
T2  - Woodhead Publishing Series in Civil and Structural Engineering
SN  - 978-0-443-29861-5
DO  - https://doi.org/10.1016/B978-0-443-29861-5.00023-8
UR  - https://www.sciencedirect.com/science/article/pii/B9780443298615000238
KW  - Machine learning
KW  - artificial intelligence
KW  - computer vision
KW  - construction
KW  - AEI.
AB  - This is a horizontal analysis on the state of research of machine learning (ML) for construction applications. The objective is to identify relevant topics in the research area and clarify the actual capabilities and limitations of ML approaches for construction. A literature review and thematic analyses were conducted to identify significant topics as well as an analysis of the most cited papers and use cases. A discussion of relevant applications and challenges is presented as well. The key findings are (1) there has been a massive increase on research efforts in the area; however, research is still behind in the use of state-of-the-art models, such as large language models, transformers, and reinforcement learning. Most importantly, it is usually limited to the use of relatively small datasets. (2) There are still significant challenges regarding the creation of sufficiently large datasets, but there are effective manners to address those challenges including the creation of synthetic data. This study provides construction practitioners and researchers with an overview of the key aspects of research on ML in construction that will help improve the understanding in this research area.
ER  - 

TY  - JOUR
T1  - Implementing generative AI (GenAI) in higher education: A systematic review of case studies
AU  - Belkina, Marina
AU  - Daniel, Scott
AU  - Nikolic, Sasha
AU  - Haque, Rezwanul
AU  - Lyden, Sarah
AU  - Neal, Peter
AU  - Grundy, Sarah
AU  - Hassan, Ghulam M.
JO  - Computers and Education: Artificial Intelligence
VL  - 8
SP  - 100407
PY  - 2025
DA  - 2025/06/01/
SN  - 2666-920X
DO  - https://doi.org/10.1016/j.caeai.2025.100407
UR  - https://www.sciencedirect.com/science/article/pii/S2666920X25000475
KW  - Generative AI
KW  - Education
KW  - GenAI
KW  - Case study
KW  - University
KW  - Implementation
AB  - The introduction of Generative Artificial Intelligence (GenAI) tools, like ChatGPT, into higher education heralds a transformative era, reshaping instructional methods, enhancing student support systems, and redefining the educational landscape. Recent literature reviews on GenAI highlight a lack of focus on how these tools are being practically implemented in educational settings. Addressing this gap, the present study systematically examines empirical case studies that demonstrate the integration of GenAI into teaching and learning in higher education, offering actionable insights and guidance for academic practice. We conducted a search of relevant databases and identified 21 empirical studies that met our inclusion criteria. The selected studies cover a diverse range of disciplines, locations, types of participants (from first-year students to postgraduates and academics), and a variety of methodologies. We classified the selected publications based on the pedagogic theory of Laurillard's Conversational Framework (LCF) and the Substitution, Augmentation, Modification, and Redefinition (SAMR) framework. We also synthesized definitions from selected empirical studies and recent research exploring Technological Pedagogical Content Knowledge (TPACK) in the age of GenAI, providing a comprehensive understanding of GenAI-TPACK factors. Limitations and future research opportunities are also discussed. The paper concludes by providing a GenAI-TPACK diagram to guide educators in effectively incorporating GenAI tools into their teaching practices, ensuring responsible and impactful use in higher education.
ER  - 

TY  - JOUR
T1  - A systematic literature review on task recommendation systems for crowdsourced software engineering
AU  - Nirmani, Shashiwadana
AU  - Shahin, Mojtaba
AU  - Khalajzadeh, Hourieh
AU  - Liu, Xiao
JO  - Information and Software Technology
VL  - 184
SP  - 107753
PY  - 2025
DA  - 2025/08/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107753
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925000928
KW  - Crowdsourced software engineering
KW  - Task recommendation
KW  - Systematic literature review
KW  - GitHub
KW  - TopCoder
AB  - Context:
Crowdsourced Software Engineering (CSE) offers outsourcing work to software practitioners by leveraging a global online workforce. However, these software practitioners struggle to identify suitable tasks due to the variety of options available. Hence, there have been a growing number of studies on introducing recommendation systems to recommend CSE tasks to software practitioners.
Objective:
The goal of this study is to analyze the existing CSE task recommendation systems, investigating their extracted data, recommendation methods, key advantages and limitations, recommended task types, the use of human factors in recommendations, popular platforms, and features used to make recommendations.
Methods:
This SLR was conducted according to the Kitchenham and Charters’ guidelines. We used manual and automatic search strategies without putting any time limitation for searching the relevant papers.
Results:
We selected 65 primary studies for data extraction, analysis, and synthesis based on our predefined inclusion and exclusion criteria. Based on our data analysis results, we classified the extracted information into four categories according to the data acquisition sources: Software Practitioner’s Profile, Task or Project, Previous Contributions, and Direct Data Collection. We also organized the proposed recommendation systems into a taxonomy and identified key advantages, such as increased performance, accuracy, and optimized solutions. In addition, we identified the limitations of these systems, such as inadequate or biased recommendations and lack of generalizability. Our results revealed that human factors play a major role in CSE task recommendation. Further, we identified five popular task types recommended, popular platforms, and their features used in task recommendation. We also provided recommendations for future research directions.
Conclusion:
This SLR provides insights into current trends, gaps, and future research directions in CSE task recommendation systems such as the need for comprehensive evaluation, standardized evaluation metrics, and benchmarking in future studies, transferring knowledge from other platforms to address cold start problem.
ER  - 

TY  - JOUR
T1  - Transformer-Based Classification of Road Conditions Using Vehicular Sensor Data
AU  - Aslam, Ibrahim
AU  - Mahfuz, Sazia
JO  - Procedia Computer Science
VL  - 257
SP  - 444
EP  - 451
PY  - 2025
DA  - 2025/01/01/
T2  - The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.03.058
UR  - https://www.sciencedirect.com/science/article/pii/S187705092500794X
KW  - Road Condition Classification
KW  - Vehicular Sensor Data
KW  - Transformer Neural Networks
KW  - Feature Selection
KW  - Intelligent Transportation Systems
KW  - Time-Series Data
KW  - Multi-Head Attention
KW  - Data Dimensionality Reduction
AB  - Precise classification of road surface types is a crucial aspect of current advanced transport systems due to its importance in safety, routing, and prognostic maintenance. This work proposes a transformer model to predict the road surface types (paved or unpaved) based on vehicular sensor data derived from several onboard sensors such as accelerometers, gyroscopes, magnetometers, and temperature sensors. The methodology involves a feature selection step based on the Random Forest classifier ranking without negatively affecting the predictive accuracy. An initial transformer design was furthermore developed with multi-head attention, which was trained and validated on time-series data with regularization. The proposed model achieved a weighted average F1-score of 0.97, which supports the use of transformers in analyzing vehicular sensors and their application in the field of smart transportation.
ER  - 

TY  - JOUR
T1  - Can Large Language Models Serve as Reliable Tools for Information in Dentistry? A Systematic Review
AU  - Alhazmi, Nora
AU  - Alshehri, Aram
AU  - BaHammam, Fahad
AU  - Philip, Manju
AU  - Nadeem, Muhammad
AU  - Khanagar, Sanjeev
JO  - International Dental Journal
VL  - 75
IS  - 4
SP  - 100835
PY  - 2025
DA  - 2025/08/01/
SN  - 0020-6539
DO  - https://doi.org/10.1016/j.identj.2025.04.015
UR  - https://www.sciencedirect.com/science/article/pii/S0020653925001248
KW  - Large language models
KW  - Dentistry
KW  - Performance
KW  - Accuracy
AB  - Large language models (LLMs) have gained popularity among dental students for generating subject-related answers. However, their widespread use raises significant concerns about misinformation. This systematic review aims to critically evaluate studies assessing the performance of LLMs in dentistry. A comprehensive electronic search was conducted in PubMed/Medline, Scopus, Embase, Web of Science, Google Scholar, and the Saudi Digital Library to identify studies published up to September 2024. The study quality was assessed using the Prediction Model Risk of Bias Assessment Tool (PROBAST). A total of 2030 studies have been identified. After removing 907 duplicate records, 1123 studies remained for screening. Ultimately, 31 studies met the inclusion criteria. Approximately half of these studies were classified as “high risk,” while the remainder were classified as “low risk.” The applicability of the findings was rated as “low concern.” The primary limitations of LLMs include their inability to specify information sources and their tendency to generate fabricated citations. Based on this review, LLMs hold promise as supplementary educational tools in dentistry. Evidence indicates that students using LLMs may achieve improved academic performance compared to traditional methods. However, concerns about occasional inaccuracies and unreliable citations underscore the need for further research, integration with validated sources, and adherence to ethical guidelines. Ultimately, LLMs should be viewed as complementary tools within dental education, with careful consideration of their limitations.
ER  - 

TY  - JOUR
T1  - Time, technique and text: scoping review of temporal information extraction and categorisation in documents
AU  - Westin, Fereshta
JO  - Journal of Documentation
VL  - 81
IS  - 7
SP  - 135
EP  - 156
PY  - 2024
DA  - 2024/12/16/
SN  - 0022-0418
DO  - https://doi.org/10.1108/JD-11-2024-0267
UR  - https://www.sciencedirect.com/science/article/pii/S0022041825000086
KW  - Time as aboutness
KW  - Temporal information
KW  - Event
KW  - Ctegorisation
KW  - Classification
KW  - Automated methods
AB  - Purpose
This paper presents an investigation of the concept of “time as aboutness” in various texts, including news articles, social media posts and historical documents. The purpose of this paper is to analyse different forms of temporal information and map the techniques used to extract and categorise this information.
Design/methodology/approach
A scoping review method was adopted to analyse the chosen literature set. This approach allowed for an overview of the different text document types, the techniques used and their temporal information.
Findings
The findings reveal six temporal types of time-related data analysis: social events, socio-political events, news events, temporal expressions, historical events and time periods. Studies analysing social media, news articles, Wikipedia entries and historical documents provide insights into event detection and categorisation. In these documents, time appears as sequences of events, temporal expressions or distinct periods. In news articles, time appears as a series of occurrences, while temporal expressions reveal how time is linguistically articulated and perceived. The analysis also covers event categorisation methods, emphasising machine learning techniques, natural language processing, large language models and rule-based systems.
Originality/value
The analysis of different types of time and methods of extracting temporal information from various texts contributes original insights to the understanding of temporal information. The findings reveal a need for expanding document variety, particularly to include fiction literature and point to the potential use of language models for future temporal information categorisation.
ER  - 

TY  - JOUR
T1  - Generative AI, copyright and the AI Act
AU  - Quintais, João Pedro
JO  - Computer Law & Security Review
VL  - 56
SP  - 106107
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106107
UR  - https://www.sciencedirect.com/science/article/pii/S0267364925000020
KW  - Generative AI
KW  - AI Act
KW  - AI
KW  - Copyright
KW  - Text and data mining
KW  - Transparency
KW  - Remuneration
AB  - This paper provides a critical analysis of the Artificial Intelligence (AI) Act's implications for the European Union (EU) copyright acquis, aiming to clarify the complex relationship between AI regulation and copyright law while identifying areas of legal ambiguity and gaps that may influence future policymaking. The discussion begins with an overview of fundamental copyright concerns related to generative AI, focusing on issues that arise during the input, model, and output stages, and how these concerns intersect with the text and data mining (TDM) exceptions under the Copyright in the Digital Single Market Directive (CDSMD). The paper then explores the AI Act's structure and key definitions relevant to copyright law. The core analysis addresses the AI Act's impact on copyright, including the role of TDM in AI model training, the copyright obligations imposed by the Act, requirements for respecting copyright law—particularly TDM opt-outs—and the extraterritorial implications of these provisions. It also examines transparency obligations, compliance mechanisms, and the enforcement framework. The paper further critiques the current regime's inadequacies, particularly concerning the fair remuneration of creators, and evaluates potential improvements such as collective licensing and bargaining. It also assesses legislative reform proposals, such as statutory licensing and AI output levies, and concludes with reflections on future directions for integrating AI governance with copyright protection.
ER  - 

TY  - JOUR
T1  - The Use of Generative AI for Scientific Literature Searches for Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation
AU  - Gwon, Yong Nam
AU  - Kim, Jae Heon
AU  - Chung, Hyun Soo
AU  - Jung, Eun Jee
AU  - Chun, Joey
AU  - Lee, Serin
AU  - Shim, Sung Ryul
JO  - JMIR Medical Informatics
VL  - 12
PY  - 2024
DA  - 2024/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/51187
UR  - https://www.sciencedirect.com/science/article/pii/S2291969424000528
KW  - artificial intelligence
KW  - search engine
KW  - systematic review
KW  - evidence-based medicine
KW  - ChatGPT
KW  - language model
KW  - education
KW  - tool
KW  - clinical decision support system
KW  - decision support
KW  - support
KW  - treatment
AB  - Background
A large language model is a type of artificial intelligence (AI) model that opens up great possibilities for health care practice, research, and education, although scholars have emphasized the need to proactively address the issue of unvalidated and inaccurate information regarding its use. One of the best-known large language models is ChatGPT (OpenAI). It is believed to be of great help to medical research, as it facilitates more efficient data set analysis, code generation, and literature review, allowing researchers to focus on experimental design as well as drug discovery and development.
Objective
This study aims to explore the potential of ChatGPT as a real-time literature search tool for systematic reviews and clinical decision support systems, to enhance their efficiency and accuracy in health care settings.
Methods
The search results of a published systematic review by human experts on the treatment of Peyronie disease were selected as a benchmark, and the literature search formula of the study was applied to ChatGPT and Microsoft Bing AI as a comparison to human researchers. Peyronie disease typically presents with discomfort, curvature, or deformity of the penis in association with palpable plaques and erectile dysfunction. To evaluate the quality of individual studies derived from AI answers, we created a structured rating system based on bibliographic information related to the publications. We classified its answers into 4 grades if the title existed: A, B, C, and F. No grade was given for a fake title or no answer.
Results
From ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant, whereas Bing AI resulted in 19 (40%) relevant studies out of 48, compared to the human benchmark of 24 studies. In the qualitative evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211 grade F studies, and Bing AI had 19 grade A and 28 grade C studies.
Conclusions
This is the first study to compare AI and conventional human systematic review methods as a real-time literature collection tool for evidence-based medicine. The results suggest that the use of ChatGPT as a tool for real-time evidence generation is not yet accurate and feasible. Therefore, researchers should be cautious about using such AI. The limitations of this study using the generative pre-trained transformer model are that the search for research topics was not diverse and that it did not prevent the hallucination of generative AI. However, this study will serve as a standard for future studies by providing an index to verify the reliability and consistency of generative AI from a user’s point of view. If the reliability and consistency of AI literature search services are verified, then the use of these technologies will help medical research greatly.
ER  - 

TY  - JOUR
T1  - AI-Supported Translation Tools for Legal Texts: A Comparative Analysis
AU  - Greńczuk, Andrzej
AU  - Chomiak-Orsa, Iwona
AU  - Tryczyńska, Katarzyna
JO  - Procedia Computer Science
VL  - 246
SP  - 5545
EP  - 5554
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.707
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924027686
KW  - Artificial intelligence
KW  - legal translation
KW  - legal act
KW  - machine translation
AB  - One of the effects of globalization is the increase in the intensity and importance of international cooperation. The context of internationalization of the functioning of organizations and international contracts has influenced the need to popularize translation services. In the case of everyday language or basic communication processes, the lack of clarity and an appropriate level of quality of translations between any language of the world can cause minor problems and communication problems. However, in the case of contracts, political protocol or legal regulations, the quality of translation processes between languages is very important. Despite the high popularity of IT translation tools, there is still a need for the services of professional, traditional translators, especially when translation processes involve highly specialized vocabulary or highly formalized studies, such as legal regulations. The aim of the article is a comparative analysis of two tools using LLM in the processes of translating legal texts into less popular languages, such as Dutch and Polish. In order to assess the possibility and quality of translation of popular translators such as DeepL and Google Translate, the authors used a scientific experiment in which a sworn translator from Dutch took part, assessing the quality and unambiguity of the translations made by IT tools.
ER  - 

TY  - JOUR
T1  - Addressing the risks of generative AI for the judiciary: The accountability framework(s) under the EU AI Act
AU  - Carnat, Irina
JO  - Computer Law & Security Review
VL  - 55
SP  - 106067
PY  - 2024
DA  - 2024/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.106067
UR  - https://www.sciencedirect.com/science/article/pii/S026736492400133X
KW  - Large Language Models
KW  - Generative Artificial Intelligence
KW  - Accountability
KW  - Automation bias
KW  - Judicial decision-making
AB  - The rapid advancements in natural language processing, particularly the development of generative large language models (LLMs), have renewed interest in using artificial intelligence (AI) for judicial decision-making. While these technological breakthroughs present new possibilities for legal automation, they also raise concerns about over-reliance and automation bias. Drawing insights from the COMPAS case, this paper examines the implications of deploying generative LLMs in the judicial domain. It identifies the persistent factors that contributed to an accountability gap when AI systems were previously used for judicial decision-making. To address these risks, the paper analyses the relevant provisions of the EU Artificial Intelligence Act, outlining a comprehensive accountability framework based on the regulation's risk-based approach. The paper concludes that the successful integration of generative LLMs in judicial decision-making requires a holistic approach addressing cognitive biases. By emphasising shared responsibility and the imperative of AI literacy across the AI value chain, the regulatory framework can help mitigate the risks of automation bias and preserve the rule of law.
ER  - 

TY  - JOUR
T1  - Automatic floor plan analysis: Datasets, methods, and applications (2000–2025)
AU  - Xu, Zhongguo
AU  - Jha, Naresh
AU  - Mehadi, Syed
AU  - Mandal, Mrinal
JO  - Automation in Construction
VL  - 178
SP  - 106378
PY  - 2025
DA  - 2025/10/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106378
UR  - https://www.sciencedirect.com/science/article/pii/S0926580525004182
KW  - Floor plan analysis
KW  - Deep learning
KW  - Image processing
KW  - Object detection
KW  - Segmentation
AB  - Automatic floor plan analysis has been a focus of research for several decades to improve productivity in diverse industries. However, automated floor plan analysis presents significant technical challenges because a floor plan consists of much heterogeneous information. A full analysis of a floor plan can be achieved by combining different floorplan analysis techniques. The prior studies for analyzing floor plans can be broadly classified into four categories: room-boundary-detection, room-type-detection, floorplan-object-detection and floorplan-text-detection. This paper presents a critical review of these techniques published between 2000 and 2025. The datasets, algorithms, and performances of the methodologies are discussed to guide researchers and engineers to improve the algorithms and productivity. This paper concludes that the researches achieve promising results due to the advanced deep learning techniques, but the challenges and research opportunities vary significantly for different categories. The industrial applications might require multiple floorplan analysis techniques to work together to build end-to-end systems.
ER  - 

TY  - JOUR
T1  - Large Language Models in Gastroenterology: Systematic Review
AU  - Gong, Eun Jeong
AU  - Bang, Chang Seok
AU  - Lee, Jae Jun
AU  - Park, Jonghyung
AU  - Kim, Eunsil
AU  - Kim, Subeen
AU  - Kimm, Minjae
AU  - Choi, Seoung-Ho
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/66648
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124009907
KW  - large language model
KW  - LLM
KW  - deep learning
KW  - artificial intelligence
KW  - AI
KW  - endoscopy
KW  - gastroenterology
KW  - clinical practice
KW  - systematic review
KW  - diagnostic
KW  - accuracy
KW  - patient engagement
KW  - emotional support
KW  - data privacy
KW  - diagnosis
KW  - clinical reasoning
AB  - Background
As health care continues to evolve with technological advancements, the integration of artificial intelligence into clinical practices has shown promising potential to enhance patient care and operational efficiency. Among the forefront of these innovations are large language models (LLMs), a subset of artificial intelligence designed to understand, generate, and interact with human language at an unprecedented scale.
Objective
This systematic review describes the role of LLMs in improving diagnostic accuracy, automating documentation, and advancing specialist education and patient engagement within the field of gastroenterology and gastrointestinal endoscopy.
Methods
Core databases including MEDLINE through PubMed, Embase, and Cochrane Central registry were searched using keywords related to LLMs (from inception to April 2024). Studies were included if they satisfied the following criteria: (1) any type of studies that investigated the potential role of LLMs in the field of gastrointestinal endoscopy or gastroenterology, (2) studies published in English, and (3) studies in full-text format. The exclusion criteria were as follows: (1) studies that did not report the potential role of LLMs in the field of gastrointestinal endoscopy or gastroenterology, (2) case reports and review papers, (3) ineligible research objects (eg, animals or basic research), and (4) insufficient data regarding the potential role of LLMs. Risk of Bias in Non-Randomized Studies—of Interventions was used to evaluate the quality of the identified studies.
Results
Overall, 21 studies on the potential role of LLMs in gastrointestinal disorders were included in the systematic review, and narrative synthesis was done because of heterogeneity in the specified aims and methodology in each included study. The overall risk of bias was low in 5 studies and moderate in 16 studies. The ability of LLMs to spread general medical information, offer advice for consultations, generate procedure reports automatically, or draw conclusions about the presumptive diagnosis of complex medical illnesses was demonstrated by the systematic review. Despite promising benefits, such as increased efficiency and improved patient outcomes, challenges related to data privacy, accuracy, and interdisciplinary collaboration remain.
Conclusions
We highlight the importance of navigating these challenges to fully leverage LLMs in transforming gastrointestinal endoscopy practices.
Trial Registration
PROSPERO 581772; https://www.crd.york.ac.uk/prospero/
ER  - 

TY  - JOUR
T1  - SentimentCareBot: Retrieval-Augmented Generation Chatbot for Mental Health Support with Sentiment Analysis
AU  - Nayinzira, Jean Pierre
AU  - Adda, Mehdi
JO  - Procedia Computer Science
VL  - 251
SP  - 334
EP  - 341
PY  - 2024
DA  - 2024/01/01/
T2  - 15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.11.118
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924033520
KW  - Mental Health
KW  - Chatbot
KW  - Retrieval-Augmented Generation (RAG)
KW  - Sentiment Analysis
KW  - Large Language Models (LLMs)
AB  - The global mental healthcare system faces various challenges in terms of accessibility and the availability of specialist support, such as psychologists and counselors, especially following the COVID-19 pandemic. This study explores a potential solution to this problem by developing a chatbot model, SentimentCareBot, which integrates sentiment analysis with retrieved-augmented generation (RAG) techniques and Large Language Models (LLMs). The study uses a public Mental Health Counseling Conversations Dataset and baseline selection methods such as Naive RAG, Multi-query RAG, and Hypothetical Document Embeddings (HyDE) to improve query translations. The findings from Tukey's Honest Significant Difference (HSD) test reveals a significant improvement in sentiment analysis performance when it is applied to the Multi-query RAG using the MistralAI language model, compared to both Multi-query RAG using the OpenAI language model and HyDE using OpenAI with Sentiment Analysis. These results demonstrate the potential of sentiment analysis to enhance the effectiveness of mental health chatbots.
ER  - 

TY  - JOUR
T1  - Exploring the ability of ChatGPT to create quality patient education resources about kidney transplant
AU  - Tian Tran, Jacqueline
AU  - Burghall, Ashley
AU  - Blydt-Hansen, Tom
AU  - Cammer, Allison
AU  - Goldberg, Aviva
AU  - Hamiwka, Lorraine
AU  - Johnson, Corinne
AU  - Kehler, Conner
AU  - Phan, Véronique
AU  - Rosaasen, Nicola
AU  - Ruhl, Michelle
AU  - Strong, Julie
AU  - Teoh, Chia Wei
AU  - Wichart, Jenny
AU  - Mansell, Holly
JO  - Patient Education and Counseling
VL  - 129
SP  - 108400
PY  - 2024
DA  - 2024/12/01/
SN  - 0738-3991
DO  - https://doi.org/10.1016/j.pec.2024.108400
UR  - https://www.sciencedirect.com/science/article/pii/S0738399124002672
KW  - ChatGPT
KW  - Transplant
KW  - Pediatrics
KW  - Health literacy
KW  - Brochures
KW  - Patient education
AB  - Background
Chat Generative Pre-trained Transformer (ChatGPT) is a language model that may have the potential to revolutionize health care. The study purpose was to test whether ChatGPT could be used to create educational brochures about kidney transplant tailored for three target audiences: caregivers, teens and children.
Methods
Using a list of 25 educational topics, standardized prompts were employed to ensure content consistency in ChatGPT generation. An expert panel assessed the accuracy of the content by rating agreement on a Likert scale (1 = <25 % agreement; and 5 = 100 % agreement). The understandability, actionability and readability of the brochures were assessed using the Patient Education Materials Assessment Tool for printable materials (PEMAT-P) and standard readability scales. A caregiver and patient reviewed and provided written feedback.
Results
We found mean understandability scores of 69 %, 66 %, and 73 % for caregiver, teen, and child brochures respectively, with 90.7 % of the ChatGPT generated brochures scoring 40 % on the actionability scale. Generated caregiver and teen materials achieved readability levels of grades 9–14, while child-specific brochures achieved readability levels of grades 6–11. Brochures were formatted appropriately but lacked depth.
Conclusion
ChatGPT demonstrates potential for rapidly generating patient education materials; however, challenges remain in ensuring content specificity. We share the lessons learned to assist other healthcare providers with using this technology.
ER  - 

TY  - JOUR
T1  - A Retrieval-augmented Generation application for Question-Answering in Nutrigenetics Domain
AU  - Benfenati, Domenico
AU  - De Filippis, Giovanni Maria
AU  - Rinaldi, Antonio Maria
AU  - Russo, Cristiano
AU  - Tommasino, Cristian
JO  - Procedia Computer Science
VL  - 246
SP  - 586
EP  - 595
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.467
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924025092
KW  - Retrieval-augmented generation
KW  - AI-generated content
KW  - Large language models
KW  - Information Retrieval
KW  - Nutrigenetics
KW  - Personalized nutrition
AB  - The domain of nutrigenetics investigates the complex relationship between genetic variations and individual dietary responses, encompassing a wide array of disciplines, including genomics, nutrition science, bioinformatics, and personalized medicine. This field is marked by its intricate data landscape, necessitating innovative approaches to effectively manage and interpret the vast volumes of information involved. Given nutrigenetic data sheer volume and complexity, traditional AI models often struggle to maintain comprehensive and up-to-date knowledge. In this paper, we propose an implementation of the Retrieval-Augmented Generation (RAG) strategy to address the question-answering task in nutrigenetic domain. This framework enhances the accuracy and relevancy of outputs produced by an advanced Large Language Model, circumventing the exhaustive model fine-tuning process. As a result, our RAG approach not only alleviates the computational demand but also fortifies against data leakage concerns, particularly critical in the sensitive area of nutrigenetics. The implementation of RAG in the nutrigenetic domain not only addresses the existing challenges but also paves the way for more advanced and efficient exploration of nutrigenetic data. Our proposed workflow could advance the understanding of nutrigenetic interactions and personalized nutrition.
ER  - 

TY  - JOUR
T1  - Access revisited: AI training at the intersection of copyright and cybercrime laws
AU  - Matias, Célia Filipa Ferreira
JO  - Computer Law & Security Review
VL  - 57
SP  - 106149
PY  - 2025
DA  - 2025/07/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106149
UR  - https://www.sciencedirect.com/science/article/pii/S2212473X25000227
KW  - Copyright
KW  - Text and data mining: unlawful access
KW  - Generative AI
AB  - The rise of generative AI (GenAI) poses urgent questions for copyright law, particularly regarding whether AI training infringes on reproduction rights. Some jurisdictions have tried to reduce these uncertainties through new or existing exceptions. Articles 3 and 4 of European Union Directive 2019/790 and sections 243 and 244 of Singapore’s Copyright Act of 2021 are examples. Both exceptions are subject to the condition of ‘lawful access’. The interpretation of this concept, which is vague and undefined by law, is crucial to these exceptions, as it may, ultimately, deprive them of all usefulness. This paper seeks to unpack the meaning of lawful access and its inverse by drawing on other uses of the concept, namely in cybercrime law, and its underlying values. This analysis points towards an understanding of unlawful access as the circumvention of technological restrictions to access, such as paywalls. However, adopting such measures may reduce the content that is freely available in the digital sphere, thereby impoverishing society and depriving creators of a powerful tool for publicising their works. Finally, the paper considers possible solutions to this problem and their drawbacks.
ER  - 

TY  - JOUR
T1  - Airline reviews processing: Abstractive summarization and rating-based sentiment classification using deep transfer learning
AU  - Syed, Ayesha Ayub
AU  - Gaol, Ford Lumban
AU  - Boediman, Alfred
AU  - Budiharto, Widodo
JO  - International Journal of Information Management Data Insights
VL  - 4
IS  - 2
SP  - 100238
PY  - 2024
DA  - 2024/11/01/
SN  - 2667-0968
DO  - https://doi.org/10.1016/j.jjimei.2024.100238
UR  - https://www.sciencedirect.com/science/article/pii/S2667096824000272
KW  - Airline reviews
KW  - Domain adaptation
KW  - Opinion summarization
KW  - Review rating
KW  - Sentiment classification
KW  - Two-stage finetuning
AB  - Opinion summarization and sentiment classification are key processes for understanding, analyzing, and leveraging information from customer opinions. The rapid and ceaseless increase in big data of reviews on e-commerce platforms, social media, or review portals becomes a stimulus for the automation of these processes. In recent years, deep transfer learning has opted to solve many challenging tasks in Natural Language Processing (NLP) relieving the hassles of exhaustive training and the requirement of extensive labelled datasets. In this work, we propose frameworks for Abstractive Summarization (ABS) and Sentiment Analysis (SA) of airline reviews using Pretrained Language Models (PLM). The abstractive summarization model goes through two finetuning stages, the first one, for domain adaptation and the second one, for final task learning. Several studies in the literature empirically demonstrate that review rating has a positive correlation with sentiment valence. For the sentiment classification framework, we used the rating value as a signal to determine the review sentiment, and the model is built on top of BERT (Bidirectional Encoder Representations from Transformers) architecture. We evaluated our models comprehensively with multiple metrics. Our results indicate competitive performance of the models in terms of most of the evaluation metrics.
ER  - 

TY  - JOUR
T1  - Insufficient task description can impair in-context learning: A study from information perspective
AU  - Xuanyuan, Meidai
AU  - Yang, Tao
AU  - Fu, Jingwen
AU  - Zhao, Sicheng
AU  - Wang, Yuwang
JO  - Information Fusion
VL  - 120
SP  - 103116
PY  - 2025
DA  - 2025/08/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103116
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525001897
KW  - In-context learning (ICL)
KW  - Transformer-based models
KW  - Task descriptions
KW  - In-context examples
KW  - Synthetic experiments
AB  - In-context learning, an essential technique in transformer-based models, relies on two main sources of information: in-context examples and task descriptions. While extensive research has focused on the influence of in-context examples, the role of task descriptions remains underexplored, despite its practical significance. This paper investigates how task descriptions impact the in-context learning performance of transformers and how these two sources of information can be effectively fused. We design a synthetic experimental framework to control the information provided in task descriptions and conduct a series of experiments where task description details are systematically varied. Our findings reveal the dual roles of task descriptions: an insufficient task description will cause the model to overlook in-context examples, leading to poor in-context performance; once the amount of information in the task description exceeds a certain threshold, the impact of the task description shifts from negative to positive, and a performance emergence can be observed. We replicate these findings on GPT-4, observing a similar double-sided effect. This study highlights the critical role of task descriptions in in-context learning, offering valuable insights for future applications of transformer models.
ER  - 

TY  - JOUR
T1  - Employees’ perception of generative artificial intelligence and the dark side of work outcomes
AU  - Zhao, Hairong
AU  - Yuan, Bocong
AU  - Song, Yang
JO  - Journal of Hospitality and Tourism Management
VL  - 61
SP  - 191
EP  - 199
PY  - 2024
DA  - 2024/12/01/
SN  - 1447-6770
DO  - https://doi.org/10.1016/j.jhtm.2024.10.007
UR  - https://www.sciencedirect.com/science/article/pii/S1447677024001207
KW  - 
KW  - 
KW  - 
AB  - Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.
ER  - 

TY  - JOUR
T1  - Design science research (DSR) in construction: Theoretical conceptualization of practice and practical realization of theory
AU  - Zeng, Ningshuang
AU  - Han, Luxuan
AU  - Liu, Yan
AU  - Yuan, Jingfeng
AU  - Li, Qiming
JO  - Automation in Construction
VL  - 176
SP  - 106298
PY  - 2025
DA  - 2025/08/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106298
UR  - https://www.sciencedirect.com/science/article/pii/S0926580525003383
KW  - Design science research
KW  - DSR
KW  - Design thinking
KW  - Construction
KW  - Information system
KW  - Methodology
AB  - Design Science Research (DSR) is a methodological framework that goes beyond the traditional divide between empirical studies and theoretical research, with its roots in the early development of artificial intelligence and design practice. The rise of emerging technologies in the construction field has significantly boosted DSR-applied research within this sector. This paper examines the applicability of existing paradigms and investigates whether construction-specific research paradigms exist through a systematic review. It delves into critical issues related to knowledge domains, research orientations, artifact types, and evaluation methods. The findings led to the development of a theory-practice nexus that reflects the evolution of the DSR paradigm in construction, encapsulating both the theoretical conceptualization of practical applications and the practical realization of theoretical insights. This framework is tailored to the dynamic and complex requirements of the construction industry.
ER  - 

TY  - JOUR
T1  - Reflections and attentiveness on eXplainable Artificial Intelligence (XAI). The journey ahead from criticisms to human–AI collaboration
AU  - Herrera, Francisco
JO  - Information Fusion
VL  - 121
SP  - 103133
PY  - 2025
DA  - 2025/09/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103133
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525002064
KW  - eXplainable Artificial Intelligence
KW  - XAI criticisms
KW  - XAI audience
KW  - Explanations
KW  - Human–AI decision-making
KW  - Human–AI collaboration
KW  - AI safety
KW  - Maturity level of explainability
KW  - Auditability
KW  - AI governance
AB  - The emergence of deep learning over the past decade has driven the development of increasingly complex AI models, amplifying the need for Explainable Artificial Intelligence (XAI). As AI systems grow in size and complexity, ensuring interpretability and transparency becomes essential, especially in high-stakes applications. With the rapid expansion of XAI research, addressing emerging debates and criticisms requires a comprehensive examination. This paper explores the complexities of XAI from multiple perspectives, proposing six key axes that shed light on its role in human–AI interaction and collaboration. First, it examines the imperative of XAI under the dominance of black-box AI models. Given the lack of definitional cohesion, the paper argues that XAI must be framed through the lens of audience and understanding, highlighting its different uses in AI–human interaction. The recent BLUE vs. RED XAI distinction is analyzed through this perspective. The study then addresses the criticisms of XAI, evaluating its maturity, current trajectory, and limitations in handling complex problems. The discussion then shifts to explanations as a bridge between AI models and human understanding, emphasizing the importance of usability of explanations in human–AI decision making. Key aspects such as AI reliance, human intuition, and emerging collaboration theories — including the human-algorithm centaur and co-intelligence paradigms — are explored in connection with XAI. The medical field is considered as a case study, given its extensive research on collaboration between doctors and AI through explainability. The paper proposes a framework to evaluate the maturity of XAI using three dimensions: practicality, auditability, and AI governance. Provide the final lessons learned focused on trends and questions to tackle in the near future. This is an in-depth exploration of the impact and urgency of XAI in the era of pervasive expansion of AI. Three Key reflections from this study include: (a) XAI must enhance cognitive engagement with explanations, (b) it must evolve to fully address why, what, and for what purpose explanations are needed, and (c) it plays a crucial role in building societal trust in AI. By advancing XAI in these directions, we can ensure that AI remains transparent, auditable, and accountable, and aligned with human needs.
ER  - 

TY  - JOUR
T1  - Medical radiology report generation: A systematic review of current deep learning methods, trends, and future directions
AU  - Izhar, Amaan
AU  - Idris, Norisma
AU  - Japar, Nurul
JO  - Artificial Intelligence in Medicine
VL  - 168
SP  - 103220
PY  - 2025
DA  - 2025/10/01/
SN  - 0933-3657
DO  - https://doi.org/10.1016/j.artmed.2025.103220
UR  - https://www.sciencedirect.com/science/article/pii/S0933365725001551
KW  - Radiology report generation
KW  - Deep learning
KW  - Systematic review
KW  - Healthcare
KW  - Medical imaging
KW  - Artificial intelligence
AB  - Medical radiology reports play a crucial role in diagnosing various diseases, yet generating them manually is time-consuming and burdens clinical workflows. Medical radiology report generation aims to automate this process using deep learning to assist radiologists and reduce patient wait times. This study presents the most comprehensive systematic review to date on deep learning-based MRRG, encompassing recent advances that span traditional architectures to large language models. We focus on available datasets, modeling approaches, and evaluation practices. Following PRISMA guidelines, we retrieved 323 articles from major academic databases and included 78 studies after eligibility screening. We critically analyze key components such as model architectures, loss functions, datasets, evaluation metrics, and optimizers — identifying 22 widely used datasets, 14 evaluation metrics, around 20 loss functions, over 25 visual backbones, and more than 30 textual backbones. To support reproducibility and accelerate future research, we also compile links to modern models, toolkits, and pretrained resources. Our findings provide technical insights and outline future directions to address current limitations, promoting collaboration at the intersection of medical imaging, natural language processing, and deep learning to advance trustworthy AI systems in radiology.
ER  - 

TY  - JOUR
T1  - Machine learning-driven processes in architectural building design
AU  - Lystbæk, Michael Sahl
JO  - Automation in Construction
VL  - 178
SP  - 106379
PY  - 2025
DA  - 2025/10/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106379
UR  - https://www.sciencedirect.com/science/article/pii/S0926580525004194
KW  - Artificial intelligence
KW  - Machine learning
KW  - Generative design
KW  - Architecture
KW  - Building design
KW  - Systematic review
AB  - Machine learning (ML) has emerged as a transformative technology in the construction industry, enhancing the performance of predictive systems to facilitate earlier decision-making. This paper reviews 230 papers selected from 2706 articles to examine ML applications in architectural building design (ABD) processes, providing both bibliometric and qualitative analyses. Qualitative analysis examines the design domains, purposes, ML methods, and design stages of applied ML applications, revealing a growing focus on building performance and autonomous design generation. To support this, an extended ML-ABD workflow is proposed, integrating insights from state-of-the-art ML applications and addressing advances in generative ML systems. This offers guidance to construction stakeholders on the challenges and opportunities within the design processes, supporting the shift towards more intelligent and innovative workflows. The paper serves as a foundational resource for advancing ML-driven methodologies to enhance construction design processes, in which generative ML shows potential for automating workflows in the ABD process.
ER  - 

TY  - JOUR
T1  - Implementing Large Language Models in Health Care: Clinician-Focused Review With Interactive Guideline
AU  - Li, HongYi
AU  - Fu, Jun-Fen
AU  - Python, Andre
JO  - Journal of Medical Internet Research
VL  - 27
PY  - 2025
DA  - 2025/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/71916
UR  - https://www.sciencedirect.com/science/article/pii/S1438887125009343
KW  - large language model
KW  - LLM
KW  - clinical
KW  - artificial intelligence
KW  - AI
KW  - digital health
KW  - LLM review
AB  - Background
Large language models (LLMs) can generate outputs understandable by humans, such as answers to medical questions and radiology reports. With the rapid development of LLMs, clinicians face a growing challenge in determining the most suitable algorithms to support their work.
Objective
We aimed to provide clinicians and other health care practitioners with systematic guidance in selecting an LLM that is relevant and appropriate to their needs and facilitate the integration process of LLMs in health care.
Methods
We conducted a literature search of full-text publications in English on clinical applications of LLMs published between January 1, 2022, and March 31, 2025, on PubMed, ScienceDirect, Scopus, and IEEE Xplore. We excluded papers from journals below a set citation threshold, as well as papers that did not focus on LLMs, were not research based, or did not involve clinical applications. We also conducted a literature search on arXiv within the same investigated period and included papers on the clinical applications of innovative multimodal LLMs. This led to a total of 270 studies.
Results
We collected 330 LLMs and recorded their application frequency in clinical tasks and frequency of best performance in their context. On the basis of a 5-stage clinical workflow, we found that stages 2, 3, and 4 are key stages in the clinical workflow, involving numerous clinical subtasks and LLMs. However, the diversity of LLMs that may perform optimally in each context remains limited. GPT-3.5 and GPT-4 were the most versatile models in the 5-stage clinical workflow, applied to 52% (29/56) and 71% (40/56) of the clinical subtasks, respectively, and they performed best in 29% (16/56) and 54% (30/56) of the clinical subtasks, respectively. General-purpose LLMs may not perform well in specialized areas as they often require lightweight prompt engineering methods or fine-tuning techniques based on specific datasets to improve model performance. Most LLMs with multimodal abilities are closed-source models and, therefore, lack of transparency, model customization, and fine-tuning for specific clinical tasks and may also pose challenges regarding data protection and privacy, which are common requirements in clinical settings.
Conclusions
In this review, we found that LLMs may help clinicians in a variety of clinical tasks. However, we did not find evidence of generalist clinical LLMs successfully applicable to a wide range of clinical tasks. Therefore, their clinical deployment remains challenging. On the basis of this review, we propose an interactive online guideline for clinicians to select suitable LLMs by clinical task. With a clinical perspective and free of unnecessary technical jargon, this guideline may be used as a reference to successfully apply LLMs in clinical settings.
ER  - 

TY  - JOUR
T1  - Dynamic and Circular Life Cycle Sustainability Assessments (DC-LCSAs) for prefabricated buildings: A systematic review and conceptual model
AU  - Sindhu Pradeep, Megha
AU  - Rismanchi, Behzad
AU  - Ngo, Tuan
JO  - Building and Environment
VL  - 284
SP  - 113396
PY  - 2025
DA  - 2025/10/01/
SN  - 0360-1323
DO  - https://doi.org/10.1016/j.buildenv.2025.113396
UR  - https://www.sciencedirect.com/science/article/pii/S0360132325008728
KW  - Prefabricated buildings
KW  - Dynamism
KW  - Circularity
KW  - Life cycle sustainability assessments
KW  - Sustainability benchmarking
KW  - Literature review
AB  - The growing adoption of Prefabricated Buildings (PBs), driven by their substantial sustainability benefits, underscores the need for accurate Life Cycle Sustainability Assessments (LCSAs). These assessments should integrate time-based changes (dynamic considerations) over their life cycle(s) and the degree of circularity of disassembly-focused designs. A systematic review and gap analysis using the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) framework on existing life cycle sustainability studies for PBs reveals a striking absence of this synergised approach. In response, a broad range of existing literature is reviewed and organised into a stage-wise conceptual model introduced as “DC-LCSA”. “DC-LCSA” synergises dynamism and circularity within LCSAs for PBs, thereby addressing the identified gap. Each stage of the “DC-LCSA” model is discussed by analysing key literature and methodologies. The potential of “DC-LCSA” for future sustainability benchmarking among PBs is explored, followed by its possible stage-wise improvements. This article serves as a conceptual foundation for construction managers, policymakers, and sustainability analysts to perform complex computational LCSAs for PBs in the future, enabling informed decision-making and risk management.
ER  - 

TY  - JOUR
T1  - Transforming education with AI: A systematic review of ChatGPT's role in learning, academic practices, and institutional adoption
AU  - Salih, Sayeed
AU  - Husain, Omayma
AU  - Hamdan, Mosab
AU  - Abdelsalam, Samah
AU  - Elshafie, Hashim
AU  - Motwakel, Abdelwahed
JO  - Results in Engineering
VL  - 25
SP  - 103837
PY  - 2025
DA  - 2025/03/01/
SN  - 2590-1230
DO  - https://doi.org/10.1016/j.rineng.2024.103837
UR  - https://www.sciencedirect.com/science/article/pii/S2590123024020802
KW  - ChatGPT
KW  - Generative AI
KW  - Ai-supported education
KW  - Academic writing
KW  - Teaching preparation
KW  - Institutional policies
KW  - Prompt engineering
KW  - Traditional teaching methods
AB  - The integration of AI tools like ChatGPT into education has generated significant interest due to their potential to transform learning environments by providing personalized learning, automating tasks, and improving student engagement. However, gaps remain in the literature, particularly in comparing AI-supported education methods with traditional approaches and understanding ChatGPT's specific role in academic writing, literature reviews, and teacher development. This study addresses these gaps through a systematic literature review (SLR), evaluating the effectiveness of AI tools versus traditional teaching approaches. It focuses on ChatGPT's application in areas such as academic writing, lesson planning, student assessment, and the professional development of educators. Additionally, the study explores institutional strategies for balancing the benefits of AI with the need to maintain academic integrity and educational quality. The methodology involved a systematic search across academic databases with a structured analysis of key studies in AI-supported education. The main contributions include identifying the comparative advantages and limitations of AI in enhancing student learning, offering best practices for incorporating AI tools into teaching, and examining prompt engineering as a crucial factor in optimizing AI usage. The study reveals that ChatGPT and other AI tools significantly enhance educational efficiency and engagement, but they require careful management to prevent over-reliance. The study advocates for a balanced approach, integrating both AI and traditional methods to achieve optimal educational outcomes while maintaining academic integrity.
ER  - 

TY  - JOUR
T1  - Impacts of generative artificial intelligence on the future of labor market: A systematic review
AU  - Salari, Nader
AU  - Beiromvand, Mahan
AU  - Hosseinian-Far, Amin
AU  - Habibi, Javad
AU  - Babajani, Fateme
AU  - Mohammadi, Masoud
JO  - Computers in Human Behavior Reports
VL  - 18
SP  - 100652
PY  - 2025
DA  - 2025/05/01/
SN  - 2451-9588
DO  - https://doi.org/10.1016/j.chbr.2025.100652
UR  - https://www.sciencedirect.com/science/article/pii/S2451958825000673
KW  - Job market
KW  - AI
KW  - ChatGPT
KW  - Labor market
KW  - GenAI
AB  - Background
Generative AI (GenAI) has the ability to autonomously collect and process data to generate contents, inform decisions, solve problems, and perform tasks that typically require human reasoning. This Systematic Review is conducted to examine the impacts of GenAI on the future of employment, focusing on concerns about rising unemployment, and the positive and negative perspectives outlined within exiting studies. The findings from this review can help identify research gaps, guide organizational planning, and improve AI governance frameworks and policies.
Methods
To identify relevant studies, the PubMed, Scopus, Web of Science, Embase, ScienceDirect and Google Scholar databases and repositories were systematically searched using the keywords: ‘Future of work’, ‘Job market’, ‘Generative AI’, ‘Generative AI’, and ‘ChatGPT’. Additionally, the reference lists of the identified related articles were reviewed for grey literature.
Results
Following the PRISMA guidelines, a total of 14 articles were selected for analysis. Selected studies have examined the positive and negative viewpoints on GenAI, together with pertinent challenges and opportunities. Accordingly, GenAI, when compliant with security and ethical issues, has the potential to increase efficiency whilst reducing costs and time.
Conclusion
Considering the rapid growth and adoption of AI technologies, examining the impacts of GenAI on the future of labor market is crucial. GenAI is likely to create new roles in some sectors yet reduce opportunities in others. A nuanced assessment of the impacts, and ongoing monitoring are vital for effective preparation and adaptation to the evolving work landscape in the presence of advanced AI technologies.
ER  - 

TY  - JOUR
T1  - Better entity matching with transformers through ensembles
AU  - Low, Jwen Fai
AU  - Fung, Benjamin C.M.
AU  - Xiong, Pulei
JO  - Knowledge-Based Systems
VL  - 293
SP  - 111678
PY  - 2024
DA  - 2024/06/07/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.111678
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124003137
KW  - Entity resolution
KW  - Entity matching
KW  - Deduplication
KW  - Neural networks
KW  - Deep learning
KW  - Transformers
AB  - In this paper, we introduce AttendEM, a framework for entity matching (EM), i.e., pairwise identification of duplicates across databases. Eschewing the prevalent focus on text cleaning and training data augmentation of other transformers-based EM solutions, AttendEM leverages intra-transformer ensembling of distinctively rearranged text, additional aggregator tokens, and extra self-attention to enhance the base transformer architecture. Against state-of-the-art (SOTA) solutions on the ER-Magellan benchmark datasets, AttendEM achieved higher F1 scores in most cases. These SOTA solutions are Ditto (mean improvement of 0.21% with Ditto’s own reported results, 3.93% with DAEM’s Ditto replication, 2.99% with HierGAT’s Ditto replication), DAEM (0.53%), and HierGAT (0.54%). AttendEM’s improvements are comparable to solutions that claimed to have outperformed Ditto, HierGAT (Yao et al., 2022) (2.46% compared to AttendEM’s 2.99%) and DAEM (Huang et al., 2022) (3.42% compared to AttendEM’s 3.93%), when calculated using results from their respective Ditto replications.
ER  - 

TY  - JOUR
T1  - Knowledge management for off-site construction
AU  - Zhang, Zhen
AU  - Zou, Yang
AU  - Guo, Brian H.W.
AU  - Dimyadi, Johannes
AU  - Davies, Roy
AU  - Jiang, Lixin
JO  - Automation in Construction
VL  - 166
SP  - 105632
PY  - 2024
DA  - 2024/10/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2024.105632
UR  - https://www.sciencedirect.com/science/article/pii/S0926580524003686
KW  - Off-site construction (OSC)
KW  - Knowledge management (KM)
KW  - Artificial intelligence (AI)
KW  - Systematic literature review
AB  - Off-site construction (OSC) is expected to boost productivity, shorten construction time, and reduce labour and material wastage. Despite these benefits, most OSC projects have not fully achieved these advantages, where a primary obstacle lies in the limited management of OSC knowledge. However, there is still no holistic understanding of the integration of KM in the OSC context. Therefore, this paper explores the latest development in KM for OSC through a systematic literature review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and template analysis. The review is based on 66 screened and assessed journal articles from all years to 2024 with a particular focus on KM and OSC. Through the quantitative and qualitative analysis, this study groups four main research themes including KM for OSC design, KM for OSC project management, knowledge-based OSC decision-making, and the management of OSC knowledge. The results are discussed to gain a systematic understanding of key OSC knowledge domains, investigate the integration of KM for OSC, and explore future research needs including emerging artificial intelligence (AI) technologies.
ER  - 

TY  - JOUR
T1  - Unlocking employer insights: Using large language models to explore human-centric aspects in the context of industry 5.0
AU  - Grybauskas, Andrius
AU  - Cárdenas-Rubio, Jeisson
JO  - Technological Forecasting and Social Change
VL  - 208
SP  - 123719
PY  - 2024
DA  - 2024/11/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2024.123719
UR  - https://www.sciencedirect.com/science/article/pii/S0040162524005171
KW  - Industry 5.0
KW  - Job vacancies
KW  - LLM
KW  - Well-being
KW  - Human-centricity
AB  - This paper aims to enhance the understanding of Industry 5.0 by introducing an innovative AI-based methodology that proficiently maps employer expressions related to well-being using job postings. This process involves creating a comprehensive dictionary of well-being expressions, which is then compared with existing academic literature. This approach facilitates empirical well-being analysis from employers’ perspectives. Bridging theoretical and practical realms, we offer valuable insights to academia and industry about well-being (human-centricity) interpretation by employers. The findings highlight UK employers’ prioritisation of self-realisation and a positive work atmosphere to attract job seekers. Nonetheless, many vacancies do not explicitly emphasise well-being to attract potential workers.
ER  - 

TY  - JOUR
T1  - Refinement and Revision in Academic Writing: Integrating Multi-source Knowledge and LLMs with Delta Feedback
AU  - Ma, Yongqiang
AU  - Qing, Lizhi
AU  - Kang, Yangyang
AU  - Liu, Jiawei
AU  - Zhang, Yue
AU  - Cheng, Qikai
AU  - Lu, Wei
AU  - Liu, Xiaozhong
JO  - Expert Systems with Applications
VL  - 277
SP  - 127226
PY  - 2025
DA  - 2025/06/05/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.127226
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425008486
KW  - Large Language Model
KW  - Academic Writing
KW  - Delta Feedback
KW  - Related Work Section Generation
AB  - As Large Language Models (LLMs) like ChatGPT and GPT-4 continue to evolve, their application in facilitating the academic writing process is increasing. Writing the “Related Work” section in a scientific manuscript requires scholars to integrate knowledge from multiple sources, making it labor-intensive and time-consuming. Current predominant methods typically format the “Related Work” section Generation (RWG) in isolated environments with limited knowledge, which is quite different from how humans write. Therefore, our research pivots RWG toward a more author-centered approach that simulates the human academic writing procedure. We introduce a novel methodology that synergizes the strengths of both small language models (SLMs) and large language models. Our method involves generating author-oriented cues via SLMs, drafting initial versions with LLMs, and designing a delta feedback mechanism for cue refinement, which reveals the information gap between drafts. In the generation process, our approach assembles multiple sources of academic knowledge. This includes the LLMs’ tacit knowledge, the explicit knowledge of domain-specific academic publications, and the context derived from scholarly graphs. Comparative evaluations, both LLM-based and human-based, demonstrate that our method significantly surpasses existing baseline models like original GPT-4 and CoT-based GPT-4. Specifically, the LLM-based evaluation indicates that, when guided by enhanced cues, our model can produce high-quality content with an average of only 3.46 revision edits, compared to approximately 4 revision edits required by the baseline model. Additionally, the human evaluation demonstrates that our model obtained a higher score on the content, structure, and argumentation dimensions. In conclusion, our model has enhanced capability in synthesizing input papers comprehensively and aligning more closely with the authors’ focal points.
ER  - 

TY  - JOUR
T1  - More is more: Addition bias in large language models
AU  - Santagata, Luca
AU  - De Nobili, Cristiano
JO  - Computers in Human Behavior: Artificial Humans
VL  - 3
SP  - 100129
PY  - 2025
DA  - 2025/03/01/
SN  - 2949-8821
DO  - https://doi.org/10.1016/j.chbah.2025.100129
UR  - https://www.sciencedirect.com/science/article/pii/S2949882125000131
KW  - LLMs
KW  - Bias detection
KW  - Cognitive bias
KW  - Addition bias
KW  - Algo-rithmic fairness
AB  - In this paper, we investigate the presence of addition bias in Large Language Models (LLMs), drawing a parallel to the cognitive bias observed in humans where individuals tend to favor additive over sub-tractive changes [3]. Using a series of controlled experiments, we tested various LLMs, including GPT-3.5 Turbo, Claude 3.5 Sonnet, Mistral, MathΣtral, and Llama 3.1, on tasks designed to measure their propensity for additive versus subtractive modifications. Our findings demonstrate a significant preference for additive changes across all tested models. For example, in a palindrome creation task, Llama 3.1 favored adding let-ters 97.85% of the time over removing them. Similarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick 76.38% of the time rather than remove one. In a text summarization task, Mistral 7B pro-duced longer summaries in 59.40%–75.10% of cases when asked to improve its own or others’ writing. These results indicate that, similar to humans, LLMs exhibit a marked addition bias, which might have im-plications when LLMs are used on a large scale. Addittive bias might increase resource use and environmental impact, leading to higher eco-nomic costs due to overconsumption and waste. This bias should be con-sidered in the development and application of LLMs to ensure balanced and efficient problem-solving approaches.
ER  - 

TY  - JOUR
T1  - A survey on detecting mental disorders with natural language processing: Literature review, trends and challenges
AU  - Montejo-Ráez, Arturo
AU  - Molina-González, M. Dolores
AU  - Jiménez-Zafra, Salud María
AU  - García-Cumbreras, Miguel Ángel
AU  - García-López, Luis Joaquín
JO  - Computer Science Review
VL  - 53
SP  - 100654
PY  - 2024
DA  - 2024/08/01/
SN  - 1574-0137
DO  - https://doi.org/10.1016/j.cosrev.2024.100654
UR  - https://www.sciencedirect.com/science/article/pii/S1574013724000388
KW  - Mental disorders detection
KW  - Natural language processing
KW  - Machine learning
KW  - Survey
AB  - For years, the scientific community has researched monitoring approaches for the detection of certain mental disorders and risky behaviors, like depression, eating disorders, gambling, and suicidal ideation among others, in order to activate prevention or mitigation strategies and, in severe cases, clinical treatment. Natural Language Processing is one of the most active disciplines dealing with the automatic detection of mental disorders. This paper offers a comprehensive and extensive review of research works on Natural Language Processing applied to the identification of some mental disorders. To this end, we have identified from a literature review, which are the main types of features used to represent the texts, the machine learning algorithms that are preferred or the most targeted social media platforms, among other aspects. Besides, the paper reports on scientific forums and projects focused on the automatic detection of these problems over the most popular social networks. Thus, this compilation provides a broad view of the matter, summarizing main strategies, and significant findings, but, also, recognizing some of the weaknesses in the research works published so far, serving as clues for future research.
ER  - 

TY  - JOUR
T1  - A literature review of artificial intelligence research in business and management using machine learning and ChatGPT
AU  - Guler, Nazmiye
AU  - Kirshner, Samuel N.
AU  - Vidgen, Richard
JO  - Data and Information Management
VL  - 8
IS  - 3
SP  - 100076
PY  - 2024
DA  - 2024/09/01/
SN  - 2543-9251
DO  - https://doi.org/10.1016/j.dim.2024.100076
UR  - https://www.sciencedirect.com/science/article/pii/S2543925124000123
KW  - Artificial intelligence
KW  - Machine learning
KW  - Topic modelling
KW  - Computational literature reviews
KW  - ChatGPT
AB  - This paper investigates applying AI models and topic modelling techniques to enhance computational literature reviews in business, management, and information systems. The study highlights the significance of impactful journals and emphasises the need for interdisciplinary and transdisciplinary research, especially in addressing AI's ethical and regulatory challenges. We demonstrate the effectiveness of combining machine learning and ChatGPT in the literature review process. Machine learning is used to identify research topics, and ChatGPT assists researchers in labelling the topics, generating content, and improving the efficiency of academic writing. By leveraging topic modelling techniques and ChatGPT, we uncover and label topics within the literature, shedding light on the thematic structure and content of the research field, allowing researchers to uncover meaningful insights, identify research gaps, and highlight rapidly expanding research areas. Additionally, we contribute to the literature review process by introducing a methodology that identifies impactful papers, helping to bridge the gap between computational literature reviews and traditional literature reviews.
ER  - 

TY  - JOUR
T1  - Challenges of implementing ChatGPT on education: Systematic literature review
AU  - García-López, Iván Miguel
AU  - González González, Carina Soledad
AU  - Ramírez-Montoya, María-Soledad
AU  - Molina-Espinosa, José-Martín
JO  - International Journal of Educational Research Open
VL  - 8
SP  - 100401
PY  - 2025
DA  - 2025/06/01/
SN  - 2666-3740
DO  - https://doi.org/10.1016/j.ijedro.2024.100401
UR  - https://www.sciencedirect.com/science/article/pii/S2666374024000839
KW  - Higher education
KW  - Educational innovation
KW  - Chatgpt
KW  - Generative artificial intelligence
KW  - Education 4.0
AB  - Since its launch in 2022, ChatGPT has sparked considerable interest in higher education, raising debates about its benefits, challenges, and ethical implications. This systematic literature review, spanning January 2019 to January 2024, analyzes 42 articles from Web of Science and Scopus to identify key opportunities and challenges in its academic integration. Four core issues emerge: (a) technological integration and obsolescence, emphasizing the need for scalable, modular infrastructures; (b) personalization and equity, focusing on the balance between individualized learning and avoiding algorithmic bias; (c) data quality and security, highlighting the importance of transparent data management and robust encryption to protect sensitive information; and (d) ethics and human-AI collaboration, stressing the importance of institutional policies and continuous teacher intervention to ensure responsible and effective use. This study advances the discourse by recommending sustainable strategies for AI adoption, including professional development and fairness audits, while underscoring the critical role of human oversight in maximizing ChatGPT's educational impact. Ultimately, it offers actionable insights for institutions to align AI use with ethical principles and long-term educational goals.
ER  - 

TY  - JOUR
T1  - Generative AI in manufacturing: a literature review of recent applications and future prospects
AU  - Shafiee, Sara
JO  - Procedia CIRP
VL  - 132
SP  - 1
EP  - 6
PY  - 2025
DA  - 2025/01/01/
T2  - 12th CIRP Global Web Conference (CIRPe 2024)
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2025.01.001
UR  - https://www.sciencedirect.com/science/article/pii/S2212827125000010
KW  - Manufacturing
KW  - Generative AI (GenAI)
KW  - Generative Adversarial Networks (GANs)
KW  - Variational Autoencoders (VAEs)
KW  - Transformer-Based Models
AB  - The manufacturing sector has witnessed significant transformations in recent years, driven by the rapid advancements in artificial intelligence (AI) and its applications. Among the various AI technologies, Generative AI (GenAI) has emerged as a promising tool for revolutionizing the manufacturing process. This review paper provides an overview of the latest developments and applications of GenAI in the manufacturing process, highlighting its potential in the manufacturing process by reviewing the journal articles published in 2024 (Jan-May). This paper explores the landscape of GenAI in manufacturing, focusing on Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-Based Models. The paper underscores the pivotal role of GenAI in enhancing productivity, quality control, predictive maintenance, supply chain optimization, customization, and sustainability in manufacturing.
ER  - 

TY  - JOUR
T1  - Bibliometric analysis of ChatGPT and plastic surgery research: Insights from diverse search strategies and co-word analysis
AU  - Abdelwahab, Siddig Ibrahim
AU  - Farasani, Abdullah
AU  - Alfaifi, Hassan Ahmad
AU  - Hassan, Waseem
JO  - Chinese Journal of Plastic and Reconstructive Surgery
VL  - 6
IS  - 4
SP  - 185
EP  - 195
PY  - 2024
DA  - 2024/12/01/
SN  - 2096-6911
DO  - https://doi.org/10.1016/j.cjprs.2024.10.002
UR  - https://www.sciencedirect.com/science/article/pii/S2096691124000852
KW  - ChatGPT
KW  - Plastic surgery
KW  - Scopus
KW  - Bibliometric analysis
KW  - Co-words analysis
AB  - Background
The rise of artificial intelligence in healthcare, particularly the development of large language models like ChatGPT, has opened new avenues for innovation in medical fields, including plastic surgery. ChatGPT offers potential applications in patient education, surgical planning, and decision-making support, making it an important research subject. However, there has been limited investigation into its impact on plastic surgery. The objective of this study was to investigate the progress of research on ChatGPT and plastic surgery, focusing on key contributors and emerging topics within the field.
Methods
Five distinct search strategies were employed to analyze relevant publications from the Scopus database.
Results
The analysis identified and presented the top authors, universities, countries, sponsors, and journals (within each search strategy). The co-authorship networks of authors, universities, and countries are graphically presented. The authors’ performance was depicted by various indicators, such as total publications, citations, h-index, g-index, and m-index. A co-word analysis revealed the focus of the papers, which were presented in 15 groups. This multifaceted approach provides a detailed understanding of key themes in the field.
Conclusion
This report offers a comprehensive overview of the current state of research at the intersection of ChatGPT and plastic surgery.
ER  - 

TY  - JOUR
T1  - Do large language models understand patents? Enhancing patent classification through AI-generated summaries
AU  - Yoshikawa, Naoya
AU  - Krestel, Ralf
JO  - World Patent Information
VL  - 81
SP  - 102353
PY  - 2025
DA  - 2025/06/01/
SN  - 0172-2190
DO  - https://doi.org/10.1016/j.wpi.2025.102353
UR  - https://www.sciencedirect.com/science/article/pii/S0172219025000201
KW  - Patent classification
KW  - Large language model
KW  - Patent summarization
KW  - Subgroup classification
AB  - Patent classification plays a crucial role in intellectual property management, but remains a challenging task due to the complexity of patent documents. This study explores a novel approach to enhance automatic patent classification by leveraging summaries generated by large language models (LLMs). Our approach involves using the GPT-3.5-turbo model to create concise summaries from different sections of patent texts, which are then used to fine-tune the RoBERTa and XLM-RoBERTa models for classification tasks. We conducted experiments on English and Japanese patent documents using two datasets: the well-established USPTO-70k and the newly developed JPO-70k, that we specifically created for this study. Our findings show that models trained on AI-generated summaries – particularly those derived from patent claims or detailed descriptions – outperform models trained on original abstracts in both subclass-level multi-label classification and subgroup-level single-label classification. In particular, using detailed description summaries improved the micro-average F1 score for subclass-level classification by 2.9 points on the USPTO-70k and 3.0 points on the JPO-70k, compared to using original abstracts. These results indicate that LLM-generated summaries effectively capture information relevant to patent classification from various sections of patent texts, offering a promising approach to enhance the accuracy and efficiency of patent classification across different languages.
ER  - 

TY  - JOUR
T1  - Discovering patterns and trends in customer service technologies patents using large language model
AU  - Kim, Chaeyeon
AU  - Lee, Juyong
JO  - Heliyon
VL  - 10
IS  - 14
SP  - e34701
PY  - 2024
DA  - 2024/07/30/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e34701
UR  - https://www.sciencedirect.com/science/article/pii/S2405844024107323
KW  - Customer service
KW  - Digital transformation
KW  - BERTopic
KW  - Cloud computing
KW  - Large language model
AB  - The definition of service has evolved from a focus on material value in manufacturing before the 2000s to a customer-centric value based on the significant growth of the service industry. Digital transformation has become essential for companies in the service industry due to the incorporation of digital technology through the Fourth Industrial Revolution and COVID-19. This study utilised Bidirectional Encoder Representations from Transformer (BERT) to analyse 3029 international patents related to the customer service industry and digital transformation registered between 2000 and 2022. Through topic modelling, this study identified 10 major topics in the customer service industry and analysed their yearly trends. Our findings show that as of 2022, the trend with the highest frequency is user-centric network service design, while cloud computing has experienced the steepest increase in the last five years. User-centric network services have been steadily developing since the inception of the Internet. Cloud computing is one of the key technologies being developed intensively in 2023 for the digital transformation of customer service. This study identifies time series trends of customer service industry patents and suggests the effectiveness of using BERTopic to predict future trends in technology.
ER  - 

TY  - JOUR
T1  - Automated Paper Screening for Clinical Reviews Using Large Language Models: Data Analysis Study
AU  - Guo, Eddie
AU  - Gupta, Mehul
AU  - Deng, Jiawen
AU  - Park, Ye-Jean
AU  - Paget, Michael
AU  - Naugler, Christopher
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/48996
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124000153
KW  - abstract screening
KW  - Chat GPT
KW  - classification
KW  - extract
KW  - extraction
KW  - free text
KW  - GPT
KW  - GPT-4
KW  - language model
KW  - large language models
KW  - LLM
KW  - natural language processing
KW  - NLP
KW  - nonopiod analgesia
KW  - review methodology
KW  - review methods
KW  - screening
KW  - systematic review
KW  - systematic
KW  - unstructured data
AB  - Background
The systematic review of clinical research papers is a labor-intensive and time-consuming process that often involves the screening of thousands of titles and abstracts. The accuracy and efficiency of this process are critical for the quality of the review and subsequent health care decisions. Traditional methods rely heavily on human reviewers, often requiring a significant investment of time and resources.
Objective
This study aims to assess the performance of the OpenAI generative pretrained transformer (GPT) and GPT-4 application programming interfaces (APIs) in accurately and efficiently identifying relevant titles and abstracts from real-world clinical review data sets and comparing their performance against ground truth labeling by 2 independent human reviewers.
Methods
We introduce a novel workflow using the Chat GPT and GPT-4 APIs for screening titles and abstracts in clinical reviews. A Python script was created to make calls to the API with the screening criteria in natural language and a corpus of title and abstract data sets filtered by a minimum of 2 human reviewers. We compared the performance of our model against human-reviewed papers across 6 review papers, screening over 24,000 titles and abstracts.
Results
Our results show an accuracy of 0.91, a macro F1-score of 0.60, a sensitivity of excluded papers of 0.91, and a sensitivity of included papers of 0.76. The interrater variability between 2 independent human screeners was κ=0.46, and the prevalence and bias-adjusted κ between our proposed methods and the consensus-based human decisions was κ=0.96. On a randomly selected subset of papers, the GPT models demonstrated the ability to provide reasoning for their decisions and corrected their initial decisions upon being asked to explain their reasoning for incorrect classifications.
Conclusions
Large language models have the potential to streamline the clinical review process, save valuable time and effort for researchers, and contribute to the overall quality of clinical reviews. By prioritizing the workflow and acting as an aid rather than a replacement for researchers and reviewers, models such as GPT-4 can enhance efficiency and lead to more accurate and reliable conclusions in medical research.
ER  - 

TY  - JOUR
T1  - Current Landscape and Future Directions Regarding Generative Large Language Models in Stroke Care: Scoping Review
AU  - Zhu, XingCe
AU  - Dai, Wei
AU  - Evans, Richard
AU  - Geng, Xueyu
AU  - Mu, Aruhan
AU  - Liu, Zhiyong
JO  - JMIR Medical Informatics
VL  - 13
PY  - 2025
DA  - 2025/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/76636
UR  - https://www.sciencedirect.com/science/article/pii/S2291969425001577
KW  - large language model
KW  - stroke
KW  - generative artificial intelligence
KW  - health care
KW  - artificial intelligence
KW  - AI
AB  - Background
Stroke has a major impact on global health, causing long-term disability and straining health care resources. Generative large language models (gLLMs) have emerged as promising tools to help address these challenges, but their applications and reported performance in stroke care require comprehensive mapping and synthesis.
Objective
The aim of this scoping review was to consolidate a fragmented evidence base and examine the current landscape, shortcomings, and future directions in the design, reporting, and evaluation of gLLM-based interventions in stroke care.
Methods
In this scoping review, which adhered to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines and the Population, Concept, and Context (PCC) framework, we searched 6 major scientific databases in December 2024 for gLLM-based interventions across the stroke care pathway, mapping their key characteristics and outcomes.
Results
A total of 25 studies met the predefined eligibility criteria and were included for analysis. Retrospective designs predominated (n=16, 64%). Key applications of gLLMs included clinical decision-making support (n=10, 40%), administrative assistance (n=9, 36%), direct patient interaction (n=5, 20%), and automated literature review (n=1, 4%). Implementations mainly used generative pretrained transformer models accessed through task-prompted chat interfaces. In total, 5 key challenges were identified from the included studies during the implementation of gLLM-based interventions: ensuring factual alignment, maintaining system robustness, enhancing interpretability, optimizing efficiency, and facilitating clinical adoption.
Conclusions
The application of gLLMs in stroke care, while promising, remains relatively new, with most interventions reflecting early-stage or relatively simple implementations. Against this backdrop, critical gaps in research and clinical translation persist. To support the development of clinically impactful and trustworthy applications, we propose an actionable framework that prioritizes real-world evidence, mandates transparent technical reporting, broadens evaluation beyond output accuracy, strengthens validation of advanced task adaptation strategies, and investigates mechanisms for safe and effective human-gLLM interaction.
ER  - 

TY  - JOUR
T1  - Beyond ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots for language learning
AU  - Jeon, Jaeho
AU  - Lee, Seongyong
AU  - Choe, Hohsung
JO  - Computers & Education
VL  - 206
SP  - 104898
PY  - 2023
DA  - 2023/12/01/
SN  - 0360-1315
DO  - https://doi.org/10.1016/j.compedu.2023.104898
UR  - https://www.sciencedirect.com/science/article/pii/S0360131523001756
KW  - Chatbot
KW  - Large language model
KW  - Automatic speech recognition
KW  - Affordance
KW  - Computer-assisted language learning
AB  - The diversification of chatbot technology, such as the emergence of large language models and their incorporation into various technologies, necessitates a conceptual framework for a comprehensive understanding of different chatbot types and their possibilities for educational use. However, despite the fact that chatbots with different characteristics can provide learners with different interaction experiences, previous research has drawn on a loose conceptualization of chatbots, ignoring the common or unique design features of different chatbots and the educational affordances that are provided accordingly. In response to this concern, this review aims to further our understanding of different types of speech-recognition chatbots for language learning and the affordances provided by the chatbots. Based on an analysis of 37 empirical studies on uses of chatbots ranging from those with predefined dialogue systems to those utilizing artificial intelligence technology, this review proposes a conceptual framework that comprises three key components of a chatbot system: goal-orientation, embodiment, and multimodality. Using this framework as an analytical tool, eight chatbot types are identified and defined. Additionally, a total of 12 affordances are derived from the presence and absence of each component of the framework. Analysis of the studies through the framework also offers specific insights into how future chatbot research and development should be pursued in terms of goal-orientation, embodiment, and multimodality. Finally, we discuss the potential of the framework as a relevant model for understanding chatbots in adjacent disciplines and types other than speech-recognition chatbots, including ChatGPT and other large language models.
ER  - 

TY  - JOUR
T1  - ChatGPT in radiology: A systematic review of performance, pitfalls, and future perspectives
AU  - Keshavarz, Pedram
AU  - Bagherieh, Sara
AU  - Nabipoorashrafi, Seyed Ali
AU  - Chalian, Hamid
AU  - Rahsepar, Amir Ali
AU  - Kim, Grace Hyun J.
AU  - Hassani, Cameron
AU  - Raman, Steven S.
AU  - Bedayat, Arash
JO  - Diagnostic and Interventional Imaging
VL  - 105
IS  - 7
SP  - 251
EP  - 265
PY  - 2024
DA  - 2024/07/01/
SN  - 2211-5684
DO  - https://doi.org/10.1016/j.diii.2024.04.003
UR  - https://www.sciencedirect.com/science/article/pii/S2211568424001050
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Decision support systems
KW  - Large language model
KW  - OpenAI
AB  - Purpose
The purpose of this study was to systematically review the reported performances of ChatGPT, identify potential limitations, and explore future directions for its integration, optimization, and ethical considerations in radiology applications.
Materials and methods
After a comprehensive review of PubMed, Web of Science, Embase, and Google Scholar databases, a cohort of published studies was identified up to January 1, 2024, utilizing ChatGPT for clinical radiology applications.
Results
Out of 861 studies derived, 44 studies evaluated the performance of ChatGPT; among these, 37 (37/44; 84.1%) demonstrated high performance, and seven (7/44; 15.9%) indicated it had a lower performance in providing information on diagnosis and clinical decision support (6/44; 13.6%) and patient communication and educational content (1/44; 2.3%). Twenty-four (24/44; 54.5%) studies reported the proportion of ChatGPT's performance. Among these, 19 (19/24; 79.2%) studies recorded a median accuracy of 70.5%, and in five (5/24; 20.8%) studies, there was a median agreement of 83.6% between ChatGPT outcomes and reference standards [radiologists’ decision or guidelines], generally confirming ChatGPT's high accuracy in these studies. Eleven studies compared two recent ChatGPT versions, and in ten (10/11; 90.9%), ChatGPTv4 outperformed v3.5, showing notable enhancements in addressing higher-order thinking questions, better comprehension of radiology terms, and improved accuracy in describing images. Risks and concerns about using ChatGPT included biased responses, limited originality, and the potential for inaccurate information leading to misinformation, hallucinations, improper citations and fake references, cybersecurity vulnerabilities, and patient privacy risks.
Conclusion
Although ChatGPT's effectiveness has been shown in 84.1% of radiology studies, there are still multiple pitfalls and limitations to address. It is too soon to confirm its complete proficiency and accuracy, and more extensive multicenter studies utilizing diverse datasets and pre-training techniques are required to verify ChatGPT's role in radiology.
ER  - 

TY  - JOUR
T1  - Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces
AU  - Pfeffer, Maximilian Achim
AU  - Ling, Steve Sai Ho
AU  - Wong, Johnny Kwok Wai
JO  - Computers in Biology and Medicine
VL  - 178
SP  - 108705
PY  - 2024
DA  - 2024/08/01/
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2024.108705
UR  - https://www.sciencedirect.com/science/article/pii/S001048252400790X
KW  - Artificial intelligence
KW  - Brain-computer interface
KW  - Deep learning
KW  - Electroencephalography
KW  - Natural language processing
KW  - Transformer
AB  - This review systematically explores the application of transformer-based models in EEG signal processing and brain-computer interface (BCI) development, with a distinct focus on ensuring methodological rigour and adhering to empirical validations within the existing literature. By examining various transformer architectures, such as the Temporal Spatial Transformer Network (TSTN) and EEG Conformer, this review delineates their capabilities in mitigating challenges intrinsic to EEG data, such as noise and artifacts, and their subsequent implications on decoding and classification accuracies across disparate mental tasks. The analytical scope extends to a meticulous examination of attention mechanisms within transformer models, delineating their role in illuminating critical temporal and spatial EEG features and facilitating interpretability in model decision-making processes. The discourse additionally encapsulates emerging works that substantiate the efficacy of transformer models in noise reduction of EEG signals and diversifying applications beyond the conventional motor imagery paradigm. Furthermore, this review elucidates evident gaps and propounds exploratory avenues in the applications of pre-trained transformers in EEG analysis and the potential expansion into real-time and multi-task BCI applications. Collectively, this review distils extant knowledge, navigates through the empirical findings, and puts forward a structured synthesis, thereby serving as a conduit for informed future research endeavours in transformer-enhanced, EEG-based BCI systems.
ER  - 

TY  - JOUR
T1  - A systematic review of AI-powered collaborative learning in higher education: Trends and outcomes from the last decade
AU  - Kovari, Attila
JO  - Social Sciences & Humanities Open
VL  - 11
SP  - 101335
PY  - 2025
DA  - 2025/01/01/
SN  - 2590-2911
DO  - https://doi.org/10.1016/j.ssaho.2025.101335
UR  - https://www.sciencedirect.com/science/article/pii/S2590291125000622
KW  - AI-Powered collaborative learning
KW  - Higher education
KW  - Personalized learning
KW  - Student engagement
KW  - Social presence
KW  - Educational outcomes
AB  - This review examines the current state of integration and impact of AI-enhanced collaborative learning in the higher education sector. Given the rapid advances in technology, AI has enormous potential for application in educational settings, with benefits in terms of personalizing learning, better engaging learners and improving learning outcomes. Artificial intelligence tools, in particular machine learning, natural language processing and recommender algorithms, facilitate collaborative learning by enabling personalized learning through feedback and group work. Furthermore, this review concludes that predictive analytics and multimodal approaches supported by artificial intelligence have been shown to enhance student engagement and motivation, while personalized learning systems and recommender algorithms ensure the effectiveness of collaborative learning environments. It also identifies two other critical issues: good task design and effective emotional engagement and social presence in AI-based environments. In addition, it highlights some of the problems and ethical considerations arising from the integration of AI like transparency, data protection, and a balance between full automation and human touch. This review aims to integrate the current state and future opportunities of AI-enhanced collaborative learning within a higher education context to inform educators, researchers, and policy makers in pursuit of improving teaching and learning practices.
ER  - 

TY  - JOUR
T1  - Identifying key AI challenges in make-to-order manufacturing organisations: A multiple case study
AU  - Flyckt, Jonatan
AU  - Gorschek, Tony
AU  - Mendez, Daniel
AU  - Lavesson, Niklas
JO  - Journal of Systems and Software
VL  - 230
SP  - 112559
PY  - 2025
DA  - 2025/12/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112559
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002286
KW  - Multiple case study
KW  - Artificial intelligence
KW  - Manufacturing
KW  - Make-to-order
KW  - Data requirements
AB  - Artificial Intelligence can make manufacturing organisations more effective and efficient, but it is not clear which AI tasks hold the greatest potential. Make-to-order manufacturers must constantly adapt to customers’ unique and rapidly changing needs, and therefore have different challenges than make-to-stock manufacturers. Our ambition is to develop an AI-enabled software system to support manufacturing organisations in improving their processes. To this end, we first seek to understand the data and technology requirements for key AI-enabled tasks in a make-to-order setting and determine the level of performance and explainability needed to address them. We perform a multiple case study of five make-to-order packaging manufacturers, interviewing personnel from sales, production, and supply chain to identify and prioritise operational challenges suitable for AI approaches. Demand forecasting emerges as the most important task, followed by predictive maintenance, quality inspection, complex decision risk estimation, and production planning. Participants emphasise the importance of explainable techniques to ensure trust in the systems. The results highlight a need for a greater control of the production process and a better understanding of customer needs. Although most of the tasks could be solved with current techniques, some, such as intermittent demand forecasting and complex decision risk estimation, would require further development. The study clarifies the potential of AI-enabled systems in make-to-order manufacturing and outlines the steps required to realise it.
ER  - 

TY  - JOUR
T1  - Measuring the quality of generative AI systems: Mapping metrics to quality characteristics — Snowballing literature review
AU  - Yu, Liang
AU  - Alégroth, Emil
AU  - Chatzipetrou, Panagiota
AU  - Gorschek, Tony
JO  - Information and Software Technology
VL  - 186
SP  - 107802
PY  - 2025
DA  - 2025/10/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107802
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925001417
KW  - Generative AI
KW  - GenAI
KW  - Large language model
KW  - LLM
KW  - Quality characteristics
KW  - Metric
KW  - Evaluation
AB  - Context
Generative Artificial Intelligence (GenAI) and the use of Large Language Models (LLMs) have revolutionized tasks that previously required significant human effort, which has attracted considerable interest from industry stakeholders. This growing interest has accelerated the integration of AI models into various industrial applications. However, the model integration introduces challenges to product quality, as conventional quality measuring methods may fail to assess GenAI systems. Consequently, evaluation techniques for GenAI systems need to be adapted and refined. Examining the current state and applicability of evaluation techniques for the GenAI system outputs is essential.
Objective
This study aims to explore the current metrics, methods, and processes for assessing the outputs of GenAI systems and the potential of risky outputs.
Method
We performed a snowballing literature review to identify metrics, evaluation methods, and evaluation processes from 43 selected papers.
Results
We identified 28 metrics and mapped these metrics to four quality characteristics defined by the ISO/IEC 25023 standard for software systems. Additionally, we discovered three types of evaluation methods to measure the quality of system outputs and a three-step process to assess faulty system outputs. Based on these insights, we suggested a five-step framework for measuring system quality while utilizing GenAI models.
Conclusion
Our findings present a mapping that visualizes candidate metrics to be selected for measuring quality characteristics of GenAI systems, accompanied by step-by-step processes to assist practitioners in conducting quality assessments.
ER  - 

TY  - JOUR
T1  - An AI-driven approach to extract interrelationships between disasters
AU  - Liu, Bo
AU  - Guo, Haixiang
AU  - Wang, Haizhong
JO  - International Journal of Disaster Risk Reduction
VL  - 121
SP  - 105417
PY  - 2025
DA  - 2025/04/15/
SN  - 2212-4209
DO  - https://doi.org/10.1016/j.ijdrr.2025.105417
UR  - https://www.sciencedirect.com/science/article/pii/S2212420925002419
KW  - Multi-disaster
KW  - Disaster interrelations
KW  - Universal information extraction
KW  - Large language model
AB  - Accurately identifying interrelationships between disasters is essential for comprehensive multi-disaster risk assessment. Traditional manual methods rely heavily on expert judgment, which may lead to overlooked or inconsistently documented disaster interrelationships. To address this challenge, this study develops an AI-driven approach to automatically extract disaster interrelationships from large-scale textual data using a fine-tuned Universal Information Extraction model. First, disaster interrelationships are systematically categorized into six distinct types, considering both disaster causation and impact perspectives. Secondly, a large-scale dataset is constructed by collecting 5212 Chinese-language disaster-related paper abstracts from the China National Knowledge Infrastructure (CNKI). Among them, 267 abstracts were manually annotated to train and evaluate the model. Thirdly, the fine-tuned model is applied to the remaining 4945 abstracts to extract large-scale disaster relationship triplets, with manual validation conducted for less common triplets to ensure result reliability. Finally, disaster interrelationships are visualized using complex network graphs and matrices, providing an intuitive representation of multi-disaster interrelationships. The key contribution of this research is the development of an AI-driven approach to systematically extract disaster interrelationships from large-scale datasets, improving the accuracy and scalability of identifying disaster interrelationships. Furthermore, this study establishes a comprehensive and updatable database of disaster interrelationships, addressing limitations in previous research, such as incomplete data coverage and limited exploration of relationship types, and helps scholars to identify disaster interrelationships that may have been previously overlooked.
ER  - 

TY  - JOUR
T1  - Will artificial intelligence drive the advancements in higher education? A tri-phased exploration
AU  - Kumar, Satish
AU  - Rao, Purnima
AU  - Singhania, Shubham
AU  - Verma, Shubhangi
AU  - Kheterpal, Myra
JO  - Technological Forecasting and Social Change
VL  - 201
SP  - 123258
PY  - 2024
DA  - 2024/04/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2024.123258
UR  - https://www.sciencedirect.com/science/article/pii/S0040162524000544
KW  - AI
KW  - ChatGPT
KW  - SLR
KW  - Higher education
KW  - Interviews
KW  - Survey
AB  - This study explores the impact and potential of generative AI, specifically Open AI's ChatGPT, on the transformation of higher education, particularly in the domain of business education. Adopting a qualitative mixed-methods research strategy, this study employs a three-phased methodology consisting of a systematic literature review, semi-structured interviews with academics, and text analysis of opinion posts on professional platforms. This comprehensive approach lends a holistic perspective, integrating insights from both national and global contexts, thereby enhancing the study's methodological rigor and ensuring a nuanced understanding of AI's implications in the educational landscape. ChatGPT, with its personalized and interactive features, enhances pedagogical innovation, academic integrity, and experiential engagements in the teaching-learning-assessment (TLA) process, as revealed by these methodologies' central themes. However, potential obstacles such as plagiarism and diminished development of interpersonal skills were also identified. The findings have significant ramifications for academia and the evolution of AI in education, casting light on the practical benefits and obstacles associated with AI implementation. The study identifies unexplored research avenues to encourage further investigation in this field. This paper contributes to the emerging discourse on AI-enhanced education in business institutions by providing a comprehensive and multifaceted examination of the impact of generative AI on higher education.
ER  - 

TY  - JOUR
T1  - Unveiling the multifaceted concept of cognitive security: Trends, perspectives, and future challenges
AU  - Casino, Fran
JO  - Technology in Society
VL  - 83
SP  - 102956
PY  - 2025
DA  - 2025/12/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.102956
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25001460
KW  - Cybersecurity
KW  - Cognitive security
KW  - Artificial intelligence
KW  - Human–computer interaction
KW  - Information systems
AB  - As a transversal concept tied to human evolution, security has increased its relevance at the same pace as development and digitisation. With the advancement of artificial intelligence (AI) and the sophistication of advanced persistent threats, the emerging paradigm of cognitive security (i.e., defined by some authors as the use of self-aware and adaptable AI with learning capabilities to detect and mitigate security threats) gains momentum. Nevertheless, cognitive security is a complex concept that requires a more granular description. In this article, we redefine cognitive security by first analysing the state of the art to derive the current state of practice and the definitions of cognitive security. Next, we expand the concept of cognitive security by analysing its multiple pillars, including learning theories, AI technologies, human–computer interactions, and the ethical and legal aspects impacting its development and implementation. The latter is crucial towards understanding cognitive security, providing insight into its potential and prerequisites towards its realisation while emphasising its multidisciplinary nature. In addition to such a description, we analyse the current challenges in three closely interconnected fields, namely cybersecurity, digital forensics, and digital investigations, to provide a taxonomy that can be used to assess the current challenges and limitations of cognitive security and understand its potential better. Finally, we propose future research directions, aiming to develop cognitive systems capable of continuous learning, adaptation, and ethical compliance in dynamic cybersecurity environments. Our findings highlight the role of cognitive computing systems in enhancing cybersecurity, discussing the integration of human cognition and AI for proactive and resilient security solutions.
ER  - 

TY  - JOUR
T1  - Machine learning methods for detecting smart contracts vulnerabilities within Ethereum blockchain − A review
AU  - Crisostomo, Joao
AU  - Bacao, Fernando
AU  - Lobo, Victor
JO  - Expert Systems with Applications
VL  - 268
SP  - 126353
PY  - 2025
DA  - 2025/04/05/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.126353
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424032202
KW  - Review
KW  - Smart Contract
KW  - Vulnerabilities
KW  - Machine Learning
KW  - Deep Learning
AB  - This paper presents a comprehensive exploration of the intersection between machine learning and smart contract vulnerabilities on the Ethereum blockchain. Introduced by Vitalik Buterin in 2015, Ethereum stands as a prominent blockchain network, necessitating innovative approaches to secure smart contracts against vulnerabilities and potential attacks. This research follows PRISMA guidelines, posing three fundamental questions and conducting a meticulous literature review. The study categorises machine learning applications into seven distinct groups, analysing their taxonomy, feature types, and engineering methods. The findings indicate a dynamic landscape characterised by a noticeable trend towards increased complexity. This complexity is evident not only in the integration of machine learning frameworks that combine different architectures of deep learning models, such as Convolutional Neural Networks (CNN), Graph Neural Networks (GNN), or Recurrent Neural Networks (RNN), but also in the incorporation of various types of data related to smart contracts (SCs). The discussion dissects the advantages, limitations, and future directions in securing smart contracts using machine learning. The paper concludes by emphasising the evolving role of machine learning in strengthening the Ethereum blockchain, fostering trust, and enhancing security in decentralised systems.
ER  - 

TY  - JOUR
T1  - Artificial intelligence and Eddy covariance: A review
AU  - Lucarini, Arianna
AU  - Cascio, Mauro Lo
AU  - Marras, Serena
AU  - Sirca, Costantino
AU  - Spano, Donatella
JO  - Science of The Total Environment
VL  - 950
SP  - 175406
PY  - 2024
DA  - 2024/11/10/
SN  - 0048-9697
DO  - https://doi.org/10.1016/j.scitotenv.2024.175406
UR  - https://www.sciencedirect.com/science/article/pii/S0048969724055566
KW  - Flux monitoring
KW  - PRISMA
KW  - Machine learning
KW  - Climate change
KW  - Scoping review
AB  - The Eddy Covariance (EC) method allows for monitoring carbon, water, and energy fluxes between Earth's surface and atmosphere. Due to its varying interdependent data streams and abundance of data as a whole, EC is naturally suited to Artificial Intelligence (AI) approaches. The integration of AI and EC will likely play a crucial role in the climate change mitigation and adaptation goals defined in the Sustainable Development Goals (SDGs) of the Agenda 2030. To aid this, we present a scoping review in which the novelty of various AI techniques in monitoring fluxes through the EC method from the past two decades has been collected. Overall, we find a clear positive trend in the quantity of research in this area, particularly in the last five years. We also find a lack of uniformity in available techniques, due to the diverse technologies and variables employed across environmental conditions and ecosystems. We highlight the most applied Machine Learning (ML) models, over the 71 algorithms identified in the scoping review, such as Random Forest (RF), Support Vector Machine (SVM), Artificial Neural Network (ANN), Support Vector Regression (SVR), and K-Nearest Neigbor (KNN). We suggest that future progress in this field requires an international, collaborative effort involving computer scientists and ecologists. Modern Deep Learning (DL) techniques such as Transformers and generative AI must be investigated to find how they may benefit our field. A forward-looking strategy must be formed for the optimal utilization of AI combined with EC to define future actions in flux monitoring in the face of climate change.
ER  - 

TY  - JOUR
T1  - ScamGen: Unveiling psychological patterns in tele-scam through advanced template-augmented corpus generation
AU  - Han, Xu
AU  - Li, Qiang
AU  - Qi, Yaling
AU  - Cao, Hongbo
AU  - Pedrycz, Witold
AU  - Wang, Wei
JO  - Computers in Human Behavior
VL  - 162
SP  - 108451
PY  - 2025
DA  - 2025/01/01/
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2024.108451
UR  - https://www.sciencedirect.com/science/article/pii/S0747563224003194
KW  - Telephone scam
KW  - Psychological impacts
KW  - Data augmentation
KW  - Open dataset
AB  - Telephone scams, with their profound psychological impact, often compel victims to make hasty and severe decisions. Studying these scams is challenging due to the scarcity of comprehensive datasets, a result of the private nature of telephone interactions. In this paper, we introduce ScamGen, a template-based data augmentation technique designed to enhance Chinese telephone scam data. ScamGen leverages psychological insights to generate diverse and realistic scam scenarios, focusing on the psychological dynamics between scammers and victims. This novel approach integrates psychological theory with data augmentation, diverging from traditional methods by emphasizing scammer–victim interactions. Our method begins with a multi-source data collection framework, compiling an initial seed dataset of tele-scam samples. Using sentence- and word-level perturbations, we expand this seed data to create a comprehensive and diverse dataset covering a wide range of scam scenarios. Rigorous evaluations demonstrate that ScamGen outperforms large language models in generating high-quality, varied datasets. Additionally, we develop five deep learning models for intent detection on this dataset, with BERT achieving the highest precision at 86.68%. The dataset, which will be made publicly available, marks a significant step toward understanding scammer tactics and improving tele-scam detection systems.
ER  - 

TY  - JOUR
T1  - Automation and machine learning augmented by large language models in a catalysis study
AU  - Su, Yuming
AU  - Wang, Xue
AU  - Ye, Yuanxiang
AU  - Xie, Yibo
AU  - Xu, Yujing
AU  - Jiang, Yibin
AU  - Wang, Cheng
JO  - Chemical Science
VL  - 15
IS  - 31
SP  - 12200
EP  - 12233
PY  - 2024
DA  - 2024/08/07/
SN  - 2041-6520
DO  - https://doi.org/10.1039/d3sc07012c
UR  - https://www.sciencedirect.com/science/article/pii/S2041652024010794
AB  - Recent advancements in artificial intelligence and automation are transforming catalyst discovery and design from traditional trial-and-error manual mode into intelligent, high-throughput digital methodologies. This transformation is driven by four key components, including high-throughput information extraction, automated robotic experimentation, real-time feedback for iterative optimization, and interpretable machine learning for generating new knowledge. These innovations have given rise to the development of self-driving labs and significantly accelerated materials research. Over the past two years, the emergence of large language models (LLMs) has added a new dimension to this field, providing unprecedented flexibility in information integration, decision-making, and interacting with human researchers. This review explores how LLMs are reshaping catalyst design, heralding a revolutionary change in the fields.
ER  - 

TY  - JOUR
T1  - Transfer learning for smart construction: Advances and future directions
AU  - Gao, Yu
AU  - Xu, Xiaoxiao
AU  - Yiu, Tak Wing
AU  - Wang, Jiayuan
JO  - Automation in Construction
VL  - 175
SP  - 106238
PY  - 2025
DA  - 2025/07/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106238
UR  - https://www.sciencedirect.com/science/article/pii/S092658052500278X
KW  - Transfer learning
KW  - Deep learning
KW  - Smart construction
KW  - Limited data
KW  - Literature review
AB  - Transfer learning has emerged as a powerful tool and rapidly advanced numerous fields with cutting-edge technologies. This paper provides a comprehensive review of transfer learning applications in smart construction, analyzing its utilization to enrich the construction industry's knowledge. A systematic analysis of 366 publications from 2015 to 2024 highlights the growth and importance of transfer learning in the field. This review establishes a foundational framework by exploring key questions: “Why transfer learning”, “What to transfer”, “How to transfer”, and “When to transfer”. The findings reveal that transfer learning is predominantly applied in seven key construction domains, but it faces four major challenges: “transfer strategy”, “interpretability, security and privacy”, “modality transfer”, and “cross-domain adaptability”. Corresponding future research directions are proposed to address these challenges. This paper serves as a crucial reference point for researchers, practitioners, and stakeholders aiming to harness the transformative potential of transfer learning in the construction industry.
ER  - 

TY  - JOUR
T1  - Using LLMs and ontologies to extract causal relationships from medical abstracts
AU  - Lecu, Alexandru
AU  - Groza, Adrian
AU  - Hawizy, Lezan
JO  - Procedia Computer Science
VL  - 244
SP  - 443
EP  - 452
PY  - 2024
DA  - 2024/01/01/
T2  - 6th International Conference on AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.10.219
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924030205
KW  - Causal Relation Extraction
KW  - Knowledge Graphs
KW  - Large Language Models
KW  - Age-Related Macular Degeneration
AB  - The substantiation of the causal relationships behind its development is very important in identifying possible interventions and early treatment. Knowledge Graphs (KG) play a crucial role in the medical research domain by organizing data into interconnected structures that represent relationships between entities such as disease, treatments, and progressions. This paper shows a complete workflow that demonstrates the extraction of causal relationships from medical abstracts using a fine-tuned GPT-based model and the integration of these relationships into a KG.
ER  - 

TY  - JOUR
T1  - Role of activity-based learning and ChatGPT on students' performance in education
AU  - Al Shloul, Tamara
AU  - Mazhar, Tehseen
AU  - Abbas, Qamar
AU  - Iqbal, Muhammad
AU  - Ghadi, Yazeed Yasin
AU  - Shahzad, Tariq
AU  - Mallek, Fatma
AU  - Hamam, Habib
JO  - Computers and Education: Artificial Intelligence
VL  - 6
SP  - 100219
PY  - 2024
DA  - 2024/06/01/
SN  - 2666-920X
DO  - https://doi.org/10.1016/j.caeai.2024.100219
UR  - https://www.sciencedirect.com/science/article/pii/S2666920X24000201
KW  - ChatGPT
KW  - Education
KW  - AI
KW  - NLP
KW  - Activity-based learning
AB  - Purpose
This study investigates the impact of activity-based learning and the utilization of ChatGPT on students' academic performance within the educational framework.
Objectives
The study aims to assess the effectiveness of activity-based learning in comparison to traditional methods, while also evaluating the potential benefits and drawbacks of integrating ChatGPT as an educational tool.
Methods
The study employs a comparative approach, analyzing the outcomes of students exposed to activity-based learning versus those using conventional methods. Additionally, the study examines the usage of ChatGPT in education through surveys and trials to determine its contribution to personalized feedback, interactive learning, and innovative teaching methods.
Results
The findings reveal that activity-based learning enhances students' engagement, motivation, and critical thinking skills. Students participating in activity-based learning demonstrate improved academic achievement, which is attributed to their active involvement and practical application of knowledge. Similarly, the integration of ChatGPT offers novel avenues for interactive learning and individualized assistance, fostering students' understanding and exploration of complex concepts.
Conclusion
In conclusion, activity-based learning proves to be a student-centered approach that enhances learning outcomes by fostering active participation and practical engagement. The utilization of ChatGPT in education showcases its potential to enhance educational experiences through interactive conversations and innovative teaching methodologies, despite considerations regarding potential limitations and ethical implications.
ER  - 

TY  - JOUR
T1  - Current trends and future implications in the utilization of ChatGPT in nursing: A rapid review
AU  - Kleib, Manal
AU  - Darko, Elizabeth Mirekuwaa
AU  - Akingbade, Oluwadamilare
AU  - Kennedy, Megan
AU  - Majekodunmi, Precious
AU  - Nickel, Emma
AU  - Vogelsang, Laura
JO  - International Journal of Nursing Studies Advances
VL  - 7
SP  - 100252
PY  - 2024
DA  - 2024/12/01/
SN  - 2666-142X
DO  - https://doi.org/10.1016/j.ijnsa.2024.100252
UR  - https://www.sciencedirect.com/science/article/pii/S2666142X24000791
KW  - ChatGPT
KW  - Generative artificial intelligence (Gen AI)
KW  - Nursing education
KW  - Nursing practice
KW  - Nursing research
KW  - Rapid review
AB  - Background
The past decade has witnessed a surge in the development of artificial intelligence (AI)-based technology systems for healthcare. Launched in November 2022, ChatGPT (Generative Pre-trained Transformer), an AI-based Chatbot, is being utilized in nursing education, research and practice. However, little is known about its pattern of usage, which prompted this study.
Objective
To provide a concise overview of the existing literature on the application of ChatGPT in nursing education, practice and research.
Methods
A rapid review based on the Cochrane methodology was applied to synthesize existing literature. We conducted systematic searches in several databases, including CINAHL, Ovid Medline, Embase, Web of Science, Scopus, Education Search Complete, ERIC, and Cochrane CENTRAL, to ensure no publications were missed. All types of primary and secondary research studies, including qualitative, quantitative, mixed methods, and literature reviews published in the English language focused on the use of ChatGPT in nursing education, research, and practice, were included. Dissertations or theses, conference proceedings, government and other organizational reports, white papers, discussion papers, opinion pieces, editorials, commentaries, and published review protocols were excluded. Studies involving other healthcare professionals and/or students without including nursing participants were excluded. Studies exploring other language models without comparison to ChatGPT and those examining the technical specifications of ChatGPT were excluded. Data screening was completed in two stages: titles and abstract and full-text review, followed by data extraction and quality appraisal. Descriptive analysis and narrative synthesis were applied to summarize and categorize the findings.
Results
Seventeen studies were included: 15 (88.2 %) focused on nursing education and one each on nursing practice and research. Of the 17 included studies, 5 (29.4 %) were evaluation studies, 3 (17.6 %) were narrative reviews, 3 (17.6 %) were cross-sectional studies, 2 (11.8 %) were descriptive studies, and 1 (5.9 %) was a randomized controlled trial, quasi-experimental study, case study, and qualitative study, respectively.
Conclusion
This study has provided a snapshot of ChatGPT usage in nursing education, research, and practice. Although evidence is inconclusive, integration of ChatGPT should consider addressing ethical concerns and ongoing education on ChatGPT usage. Further research, specifically interventional studies, is recommended to ascertain and track the impact of ChatGPT in different contexts.
ER  - 

TY  - JOUR
T1  - ChatMatch: Exploring the potential of hybrid vision–language deep learning approach for the intelligent analysis and inference of racket sports
AU  - Zhang, Jiawen
AU  - Han, Dongliang
AU  - Han, Shuai
AU  - Li, Heng
AU  - Lam, Wing-Kai
AU  - Zhang, Mingyu
JO  - Computer Speech & Language
VL  - 89
SP  - 101694
PY  - 2025
DA  - 2025/01/01/
SN  - 0885-2308
DO  - https://doi.org/10.1016/j.csl.2024.101694
UR  - https://www.sciencedirect.com/science/article/pii/S0885230824000779
KW  - Video understanding
KW  - Deep learning
KW  - Expert system
KW  - Large language model
KW  - Badminton
AB  - Video understanding technology has become increasingly important in various disciplines, yet current approaches have primarily focused on lower comprehension level of video content, posing challenges for providing comprehensive and professional insights at a higher comprehension level. Video analysis plays a crucial role in athlete training and strategy development in racket sports. This study aims to demonstrate an innovative and higher-level video comprehension framework (ChatMatch), which integrates computer vision technologies with the cutting-edge large language models (LLM) to enable intelligent analysis and inference of racket sports videos. To examine the feasibility of this framework, we deployed a prototype of ChatMatch in the badminton in this study. A vision-based encoder was first proposed to extract the meta-features included the locations, actions, gestures, and action results of players in each frame of racket match videos, followed by a rule-based decoding method to transform the extracted information in both structured knowledge and unstructured knowledge. A set of LLM-based agents included namely task identifier, coach agent, statistician agent, and video manager, was developed through a prompt engineering and driven by an automated mechanism. The automatic collaborative interaction among the agents enabled the provision of a comprehensive response to professional inquiries from users. The validation findings showed that our vision models had excellent performances in meta-feature extraction, achieving a location identification accuracy of 0.991, an action recognition accuracy of 0.902, and a gesture recognition accuracy of 0.950. Additionally, a total of 100 questions were gathered from four proficient badminton players and one coach to evaluate the performance of the LLM-based agents, and the outcomes obtained from ChatMatch exhibited commendable results across general inquiries, statistical queries, and video retrieval tasks. These findings highlight the potential of using this approach that can offer valuable insights for athletes and coaches while significantly improve the efficiency of sports video analysis.
ER  - 

TY  - JOUR
T1  - Federated and edge learning for large language models
AU  - Piccialli, Francesco
AU  - Chiaro, Diletta
AU  - Qi, Pian
AU  - Bellandi, Valerio
AU  - Damiani, Ernesto
JO  - Information Fusion
VL  - 117
SP  - 102840
PY  - 2025
DA  - 2025/05/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2024.102840
UR  - https://www.sciencedirect.com/science/article/pii/S1566253524006183
KW  - Edge learning
KW  - Edge computing
KW  - Federated learning
KW  - Large language models
KW  - Natural language processing
AB  - As the demand for sophisticated language models (LMs) continues to grow, the necessity to deploy them efficiently across federated and edge environments becomes increasingly evident. This survey explores the nuanced interplay between federated and edge learning for large language models (LLMs), considering the evolving landscape of distributed computing. We investigate how federated learning paradigms can be tailored to accommodate the unique characteristics of LMs, ensuring collaborative model training while respecting privacy constraints inherent in federated environments. Additionally, we scrutinize the challenges posed by resource constraints at the edge, reporting on relevant literature and established techniques within the realm of LLMs for edge deployments, such as model pruning or model quantization. The future holds the potential for LMs to leverage the collective intelligence of distributed networks while respecting the autonomy and privacy of individual edge devices. Through this survey, the objective is to provide an in-depth analysis of the current state of efficient and privacy-aware LLM training and deployment in federated and edge environments, with the aim of offering valuable insights and guidance to researchers shaping the ongoing discussion in this field.
ER  - 

TY  - JOUR
T1  - Generative Artificial Intelligence (GAI) in Breast Cancer Diagnosis and Treatment: A Systematic Review
AU  - Tan, Xiao Jian
AU  - Cheor, Wai Loon
AU  - Cheng, Ee Meng
AU  - Lim, Chee Chin
AU  - Rahman, Khairul Shakir Ab
JO  - Computers, Materials and Continua
VL  - 84
IS  - 2
SP  - 2015
EP  - 2060
PY  - 2025
DA  - 2025/07/03/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.063407
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825006319
KW  - Breast cancer
KW  - generative AI
KW  - artificial intelligence
KW  - deep learning
KW  - diagnosis
KW  - treatment
KW  - oncology
AB  - This study systematically reviews the applications of generative artificial intelligence (GAI) in breast cancer research, focusing on its role in diagnosis and therapeutic development. While GAI has gained significant attention across various domains, its utility in breast cancer research has yet to be comprehensively reviewed. This study aims to fill that gap by synthesizing existing research into a unified document. A comprehensive search was conducted following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, resulting in the retrieval of 3827 articles, of which 31 were deemed eligible for analysis. The included studies were categorized based on key criteria, such as application types, geographical distribution, contributing organizations, leading journals, publishers, and temporal trends. Keyword co-occurrence mapping and subject profiling further highlighted the major research themes in this field. The findings reveal that GAI models have been applied to improve breast cancer diagnosis, treatment planning, and outcome predictions. Geographical and network analyses showed that most contributions come from a few leading institutions, with limited global collaboration. The review also identifies key challenges in implementing GAI in clinical practice, such as data availability, ethical concerns, and model validation. Despite these challenges, the study highlights GAI’s potential to enhance breast cancer research, particularly in generating synthetic data, improving diagnostic accuracy, and personalizing treatment approaches. This review serves as a valuable resource for researchers and stakeholders, providing insights into current research trends, major contributors, and collaborative networks in GAI-based breast cancer studies. By offering a holistic overview, it aims to support future research directions and encourage broader adoption of GAI technologies in healthcare. Additionally, the study emphasizes the importance of overcoming implementation barriers to fully realize GAI’s potential in transforming breast cancer management.
ER  - 

TY  - JOUR
T1  - AI for IMPACTS Framework for Evaluating the Long-Term Real-World Impacts of AI-Powered Clinician Tools: Systematic Review and Narrative Synthesis
AU  - Jacob, Christine
AU  - Brasier, Noé
AU  - Laurenzi, Emanuele
AU  - Heuss, Sabina
AU  - Mougiakakou, Stavroula-Georgia
AU  - Cöltekin, Arzu
AU  - Peter, Marc K
JO  - Journal of Medical Internet Research
VL  - 27
PY  - 2025
DA  - 2025/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/67485
UR  - https://www.sciencedirect.com/science/article/pii/S1438887125001797
KW  - eHealth
KW  - assessment
KW  - adoption
KW  - implementation
KW  - artificial intelligence
KW  - clinician
KW  - efficiency
KW  - health technology assessment
KW  - clinical practice
AB  - Background
Artificial intelligence (AI) has the potential to revolutionize health care by enhancing both clinical outcomes and operational efficiency. However, its clinical adoption has been slower than anticipated, largely due to the absence of comprehensive evaluation frameworks. Existing frameworks remain insufficient and tend to emphasize technical metrics such as accuracy and validation, while overlooking critical real-world factors such as clinical impact, integration, and economic sustainability. This narrow focus prevents AI tools from being effectively implemented, limiting their broader impact and long-term viability in clinical practice.
Objective
This study aimed to create a framework for assessing AI in health care, extending beyond technical metrics to incorporate social and organizational dimensions. The framework was developed by systematically reviewing, analyzing, and synthesizing the evaluation criteria necessary for successful implementation, focusing on the long-term real-world impact of AI in clinical practice.
Methods
A search was performed in July 2024 across the PubMed, Cochrane, Scopus, and IEEE Xplore databases to identify relevant studies published in English between January 2019 and mid-July 2024, yielding 3528 results, among which 44 studies met the inclusion criteria. The systematic review followed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) guidelines and the Cochrane Handbook for Systematic Reviews. Data were analyzed using NVivo through thematic analysis and narrative synthesis to identify key emergent themes in the studies.
Results
By synthesizing the included studies, we developed a framework that goes beyond the traditional focus on technical metrics or study-level methodologies. It integrates clinical context and real-world implementation factors, offering a more comprehensive approach to evaluating AI tools. With our focus on assessing the long-term real-world impact of AI technologies in health care, we named the framework AI for IMPACTS. The criteria are organized into seven key clusters, each corresponding to a letter in the acronym: (1) I—integration, interoperability, and workflow; (2) M—monitoring, governance, and accountability; (3) P—performance and quality metrics; (4) A—acceptability, trust, and training; (5) C—cost and economic evaluation; (6) T—technological safety and transparency; and (7) S—scalability and impact. These are further broken down into 28 specific subcriteria.
Conclusions
The AI for IMPACTS framework offers a holistic approach to evaluate the long-term real-world impact of AI tools in the heterogeneous and challenging health care context and lays the groundwork for further validation through expert consensus and testing of the framework in real-world health care settings. It is important to emphasize that multidisciplinary expertise is essential for assessment, yet many assessors lack the necessary training. In addition, traditional evaluation methods struggle to keep pace with AI’s rapid development. To ensure successful AI integration, flexible, fast-tracked assessment processes and proper assessor training are needed to maintain rigorous standards while adapting to AI’s dynamic evolution.
Trial Registration
reviewregistry1859; https://tinyurl.com/ysn2d7sh
ER  - 

TY  - JOUR
T1  - Towards smart product-service systems 2.0: A retrospect and prospect
AU  - Ren, Mengyang
AU  - Zheng, Pai
JO  - Advanced Engineering Informatics
VL  - 61
SP  - 102466
PY  - 2024
DA  - 2024/08/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2024.102466
UR  - https://www.sciencedirect.com/science/article/pii/S1474034624001149
KW  - Smart product-service systems
KW  - AI generated content
KW  - Digitalization
KW  - Immersive user experience
KW  - Proactive interaction design
KW  - Collaborative intelligence
AB  - Smart product-service systems (Smart PSS), first coined in 2014 as a digital servitization paradigm, have experienced rapid development, especially in the past 5 years. Nevertheless, existing works still concern much on either the solution design principles or the service-dominant logic, while neglecting today’s dramatic shift towards a human-object (machine) symbiotic manner. In this context, by introducing and leveraging advanced networking (e.g., Web 3.0), digitalization (e.g., mixed reality (MR)), and intellectualization (e.g., AI generated content(AIGC)) technologies, Smart PSS has embarked on the second revolution, as the so-called Smart PSS 2.0. To better distinguish such a new paradigm, this paper begins with a systematic review of the existing Smart PSS works, covering its 3 unique solution design characteristics (i.e., value co-creation, closed-loop design, and context awareness). Comparatively, it is found that proactive interaction design, human-SCPs symbiosis, and AIGC-enabled collaborative intelligence become new design features of Smart PSS 2.0. To unlock its power, illustrative examples with underlined technologies and value propositions are given in a grand vision. Both relevant academic researchers and industrial practitioners should re-position and well prepare themselves to embrace the future of digital servitization, i.e., Smart PSS 2.0.
ER  - 

TY  - JOUR
T1  - Empathetic Language in LLMs under Prompt Engineering: A Comparative Study in the Legal Field
AU  - Zhang, Yifan
AU  - Radishian, Christopher
AU  - Brunswicker, Sabine
AU  - Whitenack, Dan
AU  - Linna, Daniel W.
JO  - Procedia Computer Science
VL  - 244
SP  - 308
EP  - 317
PY  - 2024
DA  - 2024/01/01/
T2  - 6th International Conference on AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.10.204
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924030059
KW  - LLM
KW  - Human-AI Interaction
KW  - Empathetic Response
AB  - The demand for empathetic conversations increases with conversational AIs’ rise and exponentially spreading applications. In areas like law and healthcare, where professional and empathetic conversations are essential, conversational AIs must strive to retain the correctness of information and logic while improving on empathetic language use. When addressing such an issue, we focus on linguistic empathy, relating only to syntactic and rhetoric choices in language while disregarding the emotional aspect of influence. By performing this study, we are interested in finding whether current open-sourced Large Language Models (LLMs) can match human experts in the legal field by using empathetic language while not compromising facts and logic in responses. We compare responses from three open-sourced LLMs under four prompting strategies with the expert responses. In the comparison, we use metrics from three aspects: text and semantic similarity, factual consistency, and ten rules of linguistic empathy from previous research literature. After statistical tests, the comparison results show that language models can use empathetic language without compromising the default knowledge base of LLMs when properly prompt-engineered. To accomplish this, additional domain knowledge is still needed to match factually. The data supporting this study is publicly available at huggingface.co/datasets/RCODI/empathy-prompt and code is available at github.com/RCODI-ConversationalAI/Empathy-Prompt.
ER  - 

TY  - JOUR
T1  - Ethics of artificial intelligence and robotics in the architecture, engineering, and construction industry
AU  - Liang, Ci-Jyun
AU  - Le, Thai-Hoa
AU  - Ham, Youngjib
AU  - Mantha, Bharadwaj R.K.
AU  - Cheng, Marvin H.
AU  - Lin, Jacob J.
JO  - Automation in Construction
VL  - 162
SP  - 105369
PY  - 2024
DA  - 2024/06/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2024.105369
UR  - https://www.sciencedirect.com/science/article/pii/S0926580524001055
KW  - Ethics
KW  - Artificial intelligence
KW  - Robotics
KW  - AEC
KW  - Systematic review
AB  - Artificial intelligence (AI) and robotics research and implementation emerged in the architecture, engineering, and construction (AEC) industry to positively impact project efficiency and effectiveness concerns such as safety, productivity, and quality. This shift, however, warrants the need for ethical considerations of AI and robotics adoption due to its potential negative impacts on aspects such as job security, safety, and privacy. Nevertheless, this did not receive sufficient attention, particularly within the academic community. This research systematically reviews AI and robotics research through the lens of ethics in the AEC community for the past five years. It identifies nine key ethical issues namely job loss, data privacy, data security, data transparency, decision-making conflict, acceptance and trust, reliability and safety, fear of surveillance, and liability, by summarizing existing literature and filtering it further based on its AEC relevance. Furthermore, thirteen research topics along the process were identified based on existing AEC studies that had direct relevance to the theme of ethics in general and their parallels are further discussed. Finally, the current challenges and knowledge gaps are discussed and seven specific future research directions are recommended. This study not only signifies more stakeholder awareness of this important topic but also provides imminent steps towards safer and more efficient realization.
ER  - 

TY  - JOUR
T1  - The carbon footprint of predicting CO2 storage capacity in metal-organic frameworks within neural networks
AU  - Korolev, Vadim
AU  - Mitrofanov, Artem
JO  - iScience
VL  - 27
IS  - 5
SP  - 109644
PY  - 2024
DA  - 2024/05/17/
SN  - 2589-0042
DO  - https://doi.org/10.1016/j.isci.2024.109644
UR  - https://www.sciencedirect.com/science/article/pii/S2589004224008666
KW  - Global carbon cycle
KW  - Applied sciences
KW  - Algorithms
AB  - Summary
While artificial intelligence drives remarkable progress in natural sciences, its broader societal implications are mostly disregarded. In this study, we evaluate environmental impacts of deep learning in materials science through extensive benchmarking. In particular, a set of diverse neural networks is trained for a given supervised learning task to assess greenhouse gas (GHG) emissions during training and inference phases. A chronological perspective showed diminishing returns, manifesting themselves as a 28% decrease in mean absolute error and nearly a 15,000% increase in the carbon footprint of model training in 2016–2022. By means of up-to-date graphics processing units, it is possible to partially offset the immense growth of GHG emissions. Nonetheless, the practice of employing energy-efficient hardware is overlooked by the materials informatics community, as follows from a literature analysis in the field. On the basis of our findings, we encourage researchers to report GHG emissions together with standard performance metrics.
ER  - 

TY  - JOUR
T1  - Materials informatics: A review of AI and machine learning tools, platforms, data repositories, and applications to architectured porous materials
AU  - Zivic, Fatima
AU  - Malisic, Ana Kaplarevic
AU  - Grujovic, Nenad
AU  - Stojanovic, Boban
AU  - Ivanovic, Milos
JO  - Materials Today Communications
VL  - 48
SP  - 113525
PY  - 2025
DA  - 2025/09/01/
SN  - 2352-4928
DO  - https://doi.org/10.1016/j.mtcomm.2025.113525
UR  - https://www.sciencedirect.com/science/article/pii/S2352492825020379
KW  - Traditional computational models
KW  - Data-driven AI material models
KW  - Smart materials
KW  - Deep Tech
KW  - Structure-property-processing relationships
KW  - High-throughput screening
KW  - Electrospinning
KW  - 3D printed biomimetic porosity
AB  - This review presents the key aspects and development directions of materials informatics, emphasizing the role of artificial intelligence (AI) and machine learning (ML) in materials science research. The objective is to provide a comprehensive overview of materials informatics tools, workflows, and case studies, particularly aimed at experimental researchers unfamiliar with AI frameworks. Basic concepts are introduced and traditional modelling methods compared to AI/ML-assisted models. Existing material models serve as a foundation for advanced modelling and simulations aimed at reducing the time required for characterisation and discovery, with physics-based models gaining importance in the development of AI-supported surrogate models. This review also covers currently available resources, including: (i) software for solving complex mathematical equations and material modelling; (ii) web-based platforms and tools designed for both expert and non-expert users; and (iii) materials data repositories, prioritising standardisation. Case examples involving materials with architectured macro-, micro-, and nano-porosity are reviewed across three material types: metal-organic frameworks (MOFs), electrospun PVDF piezoelectrics, and 3D printed mechanical metamaterials. Traditional computational models offer interpretability and physical consistency, AI/ML excels in speed and complexity handling but may lack transparency. Hybrid models combining both approaches show excellent results in prediction, simulation, and optimisation, offering both speed and interpretability. Progress depends on modular, interoperable AI systems, standardised FAIR data, and cross-disciplinary collaboration. Addressing data quality and integration challenges will resolve issues related to metadata gaps, semantic ontologies, and data infrastructures, especially for small datasets and unlock transformative advances in fields like nanocomposites, MOFs, and adaptive materials.
ER  - 

TY  - JOUR
T1  - Transformers and large language models for efficient intrusion detection systems: A comprehensive survey
AU  - Kheddar, Hamza
JO  - Information Fusion
VL  - 124
SP  - 103347
PY  - 2025
DA  - 2025/12/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103347
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525004208
KW  - Anomalies detection
KW  - Cyber-security
KW  - Intrusion detection
KW  - Large language model
KW  - Natural language processing
KW  - Transformers
AB  - With significant advancements in Transformers and large language models (LLMs), natural language processing (NLP) has extended its reach into many research fields due to its enhanced capabilities in text generation and user interaction. One field benefiting greatly from these advancements is cybersecurity. In cybersecurity, many parameters that need to be protected and exchanged between senders and receivers are in the form of text and tabular data, making NLP a valuable tool in enhancing the security measures of communication protocols. This survey paper provides a comprehensive analysis of the utilization of Transformers and LLMs in cyber-threat detection systems. The methodology of paper selection and bibliometric analysis is outlined to establish a rigorous framework for evaluating existing research. The fundamentals of Transformers are discussed, including background information on various cyber-attacks and datasets commonly used in this field. The survey explores the application of Transformers in intrusion detection systems (IDSs), focusing on different architectures such as Attention-based models, LLMs like BERT and GPT, CNN/LSTM-Transformer hybrids, and emerging approaches like Vision Transformers (ViTs), and more. Furthermore, it explores the diverse environments and applications where Transformers and LLMs-based IDS have been implemented, including computer networks, Internet of things (IoT) devices, critical infrastructure protection, cloud computing, software-defined networking (SDN), as well as in autonomous vehicles (AVs). The paper also addresses research challenges and future directions in this area, identifying key issues such as interpretability, scalability, and adaptability to evolving threats, and more. Finally, the conclusion summarizes the findings and highlights the significance of Transformers and LLMs in enhancing cyber-threat detection capabilities, while also outlining potential avenues for further research and development.
ER  - 

TY  - JOUR
T1  - Automated research methodology classification using machine learning
AU  - Kosztyán, Zsolt T.
AU  - Király, Tünde
AU  - Csizmadia, Tibor
AU  - Katona, Attila Imre
AU  - Vathy-Fogarassy, Ágnes
JO  - Engineering Applications of Artificial Intelligence
VL  - 156
SP  - 111039
PY  - 2025
DA  - 2025/09/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.111039
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625010395
KW  - Machine learning
KW  - Classification
KW  - Applied research methods
KW  - Extreme Gradient Boosting
KW  - Large language models
AB  - Scientific papers have become the primary means for disseminating scientific research, and thus, the ability to classify research papers based on different aspects has become essential. Therefore, many works have developed classification approaches; however, they focused solely on research topic-based classification. In addition, no solution has been developed to classify papers based on the applied methodology, and finally, the accuracy of the existing paper classification methods is not satisfactory. In this study, a novel automated classification methodology using a refined Extreme Gradient boosting (XGBoost) model is presented to classify the research methods employed in scientific papers. Three article sets, including quantitative and qualitative research methods, were collected from the topics of tourism, medical science and information systems, consisting of 229, 557 and 787 papers, respectively. The classification problem was considered a binary classification task to maintain interpretability. The developed model was trained and tested on article set 1 (tourism) and 2 (medical science), and then, the proposed model was applied to article set 3, (information systems and tourism). The high accuracy achieved in different research fields (90%–95% accuracies on average) indicates that the proposed classification model is generalizable because it can be successfully applied in many disciplines. The automated classifier enables the rapid acquisition of vital information and the identification of significant differences among the applied methodologies in various research domains. A future development direction will be to increase the scalability of the proposed model to achieve efficient operations on large volumes of research papers.
ER  - 

TY  - JOUR
T1  - Offshore wind turbine tower design and optimization: A review and AI-driven future directions
AU  - Alves Ribeiro, João
AU  - Alves Ribeiro, Bruno
AU  - Pimenta, Francisco
AU  - M.O. Tavares, Sérgio
AU  - Zhang, Jie
AU  - Ahmed, Faez
JO  - Applied Energy
VL  - 397
SP  - 126294
PY  - 2025
DA  - 2025/11/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.126294
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925010244
KW  - Offshore wind turbine
KW  - Tower design optimization
KW  - Artificial intelligence
KW  - Digital twin
KW  - Generative AI
KW  - Topology optimization
AB  - Offshore wind energy leverages the high intensity and consistency of oceanic winds, playing a key role in the transition to renewable energy. As energy demands grow, larger turbines are required to optimize power generation and reduce the Levelized Cost of Energy (LCoE), which represents the average cost of electricity over a project’s lifetime. However, upscaling turbines introduces engineering challenges, particularly in the design of supporting structures, especially towers. These towers must support increased loads while maintaining structural integrity, cost-efficiency, and transportability, making them essential to offshore wind projects’ success. This paper presents a comprehensive review of the latest advancements, challenges, and future directions driven by Artificial Intelligence (AI) in the design optimization of Offshore Wind Turbine (OWT) structures, with a focus on towers. It provides an in-depth background on key areas such as design types, load types, analysis methods, design processes, monitoring systems, Digital Twin (DT) technology, software, standards, reference turbines, economic factors, and optimization techniques. Additionally, it includes a state-of-the-art review of optimization studies related to tower design optimization, presenting a detailed examination of turbines, software, loads, optimization methods, design variables and constraints, analysis, and findings, motivating future research to refine design approaches for effective turbine upscaling and improved efficiency. Lastly, the paper explores future directions where AI can revolutionize tower design optimization, enabling the development of efficient, scalable, and sustainable structures. By addressing the upscaling challenges and supporting the growth of renewable energy, this work contributes to shaping the future of offshore wind turbine towers and other supporting structures.
ER  - 

TY  - JOUR
T1  - Disruptive technologies that deliver a circular economy for plastics
AU  - Locock, Katherine E.S.
AU  - Terhorst, Andrew
AU  - King, Sarah
AU  - Scroggie, Kymberley R.
JO  - Next Sustainability
VL  - 6
SP  - 100098
PY  - 2025
DA  - 2025/01/01/
SN  - 2949-8236
DO  - https://doi.org/10.1016/j.nxsust.2025.100098
UR  - https://www.sciencedirect.com/science/article/pii/S2949823625000017
KW  - Plastic
KW  - Circular economy
KW  - Recovery
KW  - Recycling
KW  - ChatGPT
KW  - Patent
AB  - Plastics are ubiquitous and integral to modern life with global production doubling in the next 20 years. Only minimal amounts, however, are reused or recycled with the common methods of dealing with plastic waste i.e., incineration and landfill, and leaking into the environment (pollution) all resulting in a loss of plastic from the economy. A circular economy for plastics reduces plastic pollution and climate effects and provides social and economic benefits. This article reviews the patent landscape and identifies disruptive technologies that contribute to a circular economy for plastics. Using a collaboration between subject matter experts and ChatGPT, we identified five distinct disruptive technology categories and associated keywords that support a circular economy: bioplastics, chemical recycling, synthetic biology, traceable plastics and waste separation. Using the associated keywords, we categorised patents from 2018 to 2022 into these disruptive technologies to assess current trends. The patent landscape was challenging to navigate due to the deliberately broad language used to construct patents, leading to many irrelevant patents being categorised. Low technology readiness levels of some patents examined also limits the current disruptiveness of these technologies. Adequate financial funding and economic incentives were the most evident barriers to disruptive technology maturity and uptake.
ER  - 

TY  - JOUR
T1  - Leveraging language models for automated distribution of review notes in animated productions
AU  - Garcés, Diego
AU  - Santos, Matilde
AU  - Fernández-Llorca, David
JO  - Neurocomputing
VL  - 626
SP  - 129620
PY  - 2025
DA  - 2025/04/14/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.129620
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225002929
KW  - Movie production
KW  - Review notes
KW  - Text Classification
KW  - Large Language Models (LLM)
KW  - Natural Language Processing
AB  - During the production of an animated film, professionals at the animation studio prepare thousands of notes. These notes describe improvements and corrections identified by supervisors and directors during daily meetings where the film’s progress is reviewed. After each meeting, these notes are manually distributed to the appropriate departments that need to address them. Due to the manual nature of this process, many notes are not assigned correctly, and the identified issues are not addressed, reducing the final quality of the film. This article describes and compares several approaches to automatically distribute notes using multi-label text classification with different language models (LM). Implemented methods include logistic regression models, encoder-only models such as the BERT family, and decoder-only models such as Llama 2 including fine-tuning and QLoRA techniques. Training and inference were conducted on a local RTX-3090. The results of the different techniques have been compared, achieving a maximum average accuracy of 0.83 and an f1-score of 0.89 with the fine-tuned Multilingual BERT model. This demonstrates the validity of these models for multi-label text classification, as well as their usefulness in a hitherto unexplored area such as animation studios.
ER  - 

TY  - JOUR
T1  - Comparing the performance of ChatGPT 4o, DeepSeek R1, and Gemini 2 Pro in answering fixed prosthodontics questions over time
AU  - Shirani, Mohammadjavad
JO  - The Journal of Prosthetic Dentistry
PY  - 2025
DA  - 2025/05/22/
SN  - 0022-3913
DO  - https://doi.org/10.1016/j.prosdent.2025.04.038
UR  - https://www.sciencedirect.com/science/article/pii/S0022391325004007
AB  - ABSTRACT
Statement of problem
The accuracy of DeepSeek and the latest versions of ChatGPT and Gemini in responding to prosthodontics questions needs to be evaluated. Additionally, the extent to which the performance of these chatbots changes through user interactions remains unexplored.
Purpose
The purpose of this longitudinal repeated-measures experimental study was to compare the performance of ChatGPT (4o), DeepSeek (R1), and Gemini (2 Pro) in answering multiple-choice (MC) and short-answer (SA) fixed prosthodontics questions over 4 consecutive weeks after exposure to correct responses.
Material and methods
A total of 40 questions (20 MC and 20 SA) were developed based on the sixth edition of Contemporary Fixed Prosthodontics. Following a standardized protocol, these questions were posed to ChatGPT, DeepSeek, and Gemini on 4 consecutive Saturdays using 10 independent accounts per chatbot. After each session, correct answers were provided to the chatbots, and, before the next session, their memory and history were cleared. Responses were scored as correct (1) or incorrect (0) for MC questions and correct (2), partially correct (1), or incorrect (0) for SA questions. Weighted accuracy was calculated accordingly. The Kendall W coefficient was used to assess agreement among the 10 accounts per chatbot. The effects of chatbot type, time (week), and their interaction on performance were analyzed using generalized estimating equations (GEEs), followed by pairwise comparisons using the Mann-Whitney U test and Wilcoxon signed-rank test with Bonferroni adjustments for multiple comparisons (α=.05).
Results
All chatbots showed significant reproducibility, with Gemini exhibiting the highest repeatability for SA questions, followed by ChatGPT for MC questions. Accuracy ranged between 43% and 71%. ChatGPT and DeepSeek demonstrated significantly better performance in MC questions compared with Gemini (P<.017). However, in the third week, Gemini outperformed DeepSeek in SA questions (P=.007). Over time, Gemini showed continuous improvement in SA questions, whereas DeepSeek exhibited a performance surge in the fourth week. ChatGPT’s performance remained stable throughout the study period.
Conclusions
The overall accuracy of the studied chatbots in answering MC and SA prosthodontics questions was not satisfactory. Among them, ChatGPT was the most reliable for MC questions, while ChatGPT and Gemini performed best for SA questions. Gemini (for SA questions) and DeepSeek (for MC and SA questions) demonstrated improvement after exposure to correct responses.
ER  - 

TY  - JOUR
T1  - ELEVATE-GenAI: Reporting Guidelines for the Use of Large Language Models in Health Economics and Outcomes Research: an ISPOR Working Group on Generative AI Report
AU  - Fleurence, Rachael L.
AU  - Dawoud, Dalia
AU  - Bian, Jiang
AU  - Higashi, Mitchell K.
AU  - Wang, Xiaoyan
AU  - Xu, Hua
AU  - Chhatwal, Jagpreet
AU  - Ayer, Turgay
JO  - Value in Health
PY  - 2025
DA  - 2025/07/11/
SN  - 1098-3015
DO  - https://doi.org/10.1016/j.jval.2025.06.018
UR  - https://www.sciencedirect.com/science/article/pii/S1098301525024556
KW  - Generative AI
KW  - Artificial Intelligence
KW  - Large Language Model
KW  - Reporting Guidelines
AB  - Introduction
Generative artificial intelligence (AI), particularly large language models (LLMs), holds significant promise for Health Economics and Outcomes Research (HEOR). However, standardized reporting guidance for LLM-assisted research is lacking. This article introduces the ELEVATE-GenAI framework and checklist—reporting guidelines specifically designed for HEOR studies involving LLMs.
Methods
The framework was developed through a targeted literature review of existing reporting guidelines, AI evaluation frameworks, and expert input from the ISPOR Working Group on Generative AI. It comprises ten domains—including model characteristics, accuracy, reproducibility, and fairness and bias. The accompanying checklist translates the framework into actionable reporting items. To illustrate its use, the framework was applied to two published HEOR studies: one focused on a systematic literature review tasks and the other on economic modeling.
Results
The ELEVATE-GenAI framework offers a comprehensive structure for reporting LLM-assisted HEOR research, while the checklist facilitates practical implementation. Its application to the two case studies demonstrates its relevance and usability across different HEOR contexts.
Limitations
Although the framework provides robust reporting guidance, further empirical testing is needed to assess its validity, completeness, usability as well as its generalizability across diverse HEOR use cases.
Conclusion
The ELEVATE-GenAI framework and checklist address a critical gap by offering structured guidance for transparent, accurate, and reproducible reporting of LLM-assisted HEOR research. Future work will focus on extensive testing and validation to support broader adoption and refinement.
ER  - 

TY  - JOUR
T1  - Transformer-Based Tool for Automated Fact-Checking of Online Health Information: Development Study
AU  - Bayani, Azadeh
AU  - Ayotte, Alexandre
AU  - Nikiema, Jean Noel
JO  - JMIR Infodemiology
VL  - 5
PY  - 2025
DA  - 2025/01/01/
SN  - 2564-1891
DO  - https://doi.org/10.2196/56831
UR  - https://www.sciencedirect.com/science/article/pii/S256418912500009X
KW  - fact-checking automation
KW  - transformers
KW  - infodemic
KW  - credible health information
KW  - machine learning
KW  - automated
KW  - online health information
KW  - misinformation
KW  - natural language processing
KW  - epidemiology
KW  - health domain
AB  - Background
Many people seek health-related information online. The significance of reliable information became particularly evident due to the potential dangers of misinformation. Therefore, discerning true and reliable information from false information has become increasingly challenging.
Objective
This study aimed to present a pilot study in which we introduced a novel approach to automate the fact-checking process, leveraging PubMed resources as a source of truth using natural language processing transformer models to enhance the process.
Methods
A total of 538 health-related web pages, covering 7 different disease subjects, were manually selected by Factually Health Company. The process included the following steps: (1) using transformer models of bidirectional encoder representations from transformers (BERT), BioBERT, and SciBERT, and traditional models of random forests and support vector machines, to classify the contents of web pages into 3 thematic categories (semiology, epidemiology, and management), (2) for each category in the web pages, a PubMed query was automatically produced using a combination of the “WellcomeBertMesh” and “KeyBERT” models, (3) top 20 related literatures were automatically extracted from PubMed, and finally, (4) the similarity checking techniques of cosine similarity and Jaccard distance were applied to compare the content of extracted literature and web pages.
Results
The BERT model for the categorization of web page contents had good performance, with F1-scores and recall of 93% and 94% for semiology and epidemiology, respectively, and 96% for both the recall and F1-score for management. For each of the 3 categories in a web page, 1 PubMed query was generated and with each query, the 20 most related, open access articles within the category of systematic reviews and meta-analyses were extracted. Less than 10% of the extracted literature was irrelevant; those were deleted. For each web page, an average of 23% of the sentences were found to be very similar to the literature. Moreover, during the evaluation, it was found that cosine similarity outperformed the Jaccard distance measure when comparing the similarity between sentences from web pages and academic papers vectorized by BERT. However, there was a significant issue with false positives in the retrieved sentences when compared with accurate similarities, as some sentences had a similarity score exceeding 80%, but they could not be considered similar sentences.
Conclusions
In this pilot study, we have proposed an approach to automate the fact-checking of health-related online information. Incorporating content from PubMed or other scientific article databases as trustworthy resources can automate the discovery of similarly credible information in the health domain.
ER  - 

TY  - JOUR
T1  - ‘Toxic’ memes: A survey of computational perspectives on the detection and explanation of meme toxicities
AU  - Martinez Pandiani, Delfina S.
AU  - Tjong Kim Sang, Erik
AU  - Ceolin, Davide
JO  - Online Social Networks and Media
VL  - 47
SP  - 100317
PY  - 2025
DA  - 2025/07/01/
SN  - 2468-6964
DO  - https://doi.org/10.1016/j.osnem.2025.100317
UR  - https://www.sciencedirect.com/science/article/pii/S2468696425000187
KW  - Internet memes
KW  - Toxicity
KW  - Information quality
KW  - Multimodal discourse
AB  - Internet memes are multimodal, highly shareable cultural units that condense complex messages into compact forms of communication, making them a powerful vehicle for information spread. Increasingly, they are used to propagate hateful, extremist, or otherwise ‘toxic’ narratives, symbols, and messages. Research on computational methods for meme toxicity analysis has expanded significantly over the past five years. However, existing surveys cover only studies published until 2022, resulting in inconsistent terminology and overlooked trends. This survey bridges that gap by systematically reviewing content-based computational approaches to toxic meme analysis, incorporating key developments up to early 2024. Using the PRISMA methodology, we extend the scope of prior analyses, resulting in a threefold increase in the number of reviewed works. This study makes four key contributions. First, we expand the coverage of computational research on toxic memes, reviewing 158 content-based studies, including 119 newly analyzed papers, and identifying over 30 datasets while examining their labeling methodologies. Second, we address the lack of clear definitions of meme toxicity in computational research by introducing a new taxonomy that categorizes different toxicity types, providing a more structured foundation for future studies. Third, we observe that existing content-based studies implicitly focus on three key dimensions of meme toxicity—target, intent, and conveyance tactics. We formalize this perspective by introducing a structured framework that models how these dimensions are computationally analyzed across studies. Finally, we examine emerging trends and challenges, including advancements in cross-modal reasoning, the integration of expert and cultural knowledge, the increasing demand for automatic toxicity explanations, the challenges of handling meme toxicity in low-resource languages, and the rising role of generative AI in both analyzing and generating ‘toxic’ memes.
ER  - 
